r'''
import ctypes
import json
import os
import sys
import tkinter as tk
import tkinter.ttk as ttk
from tkinter import *
import matplotlib
import matplotlib.animation as animation
import matplotlib.dates as mdates
import matplotlib.ticker as mticker
import numpy as np
import pandas as pd
from PyQt5 import QtWidgets
from matplotlib import pyplot as plt
from matplotlib import style
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2TkAgg
from matplotlib.figure import Figure
from matplotlib.ticker import MaxNLocator
from mpl_toolkits.mplot3d.art3d import Poly3DCollection

try:
    from matplotlib.backends.backend_qt5agg import (FigureCanvas)
except:
    from matplotlib.backends.backend_qt5agg import FigureCanvasAgg as FigureCanvas
import lozoya.data
import lozoya.decorators
import lozoya.gui
import lozoya.math
import lozoya.plot

try:
    matplotlib.use("TkAgg")
    from matplotlib import pyplot as plt

    f = plt.figure()
except:
    from matplotlib.figure import Figure
    from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas

    f = Figure()

import datetime
from tkinter import filedialog as tkf

user32 = ctypes.windll.user32
WIDTH = user32.GetSystemMetrics(0)
HEIGHT = user32.GetSystemMetrics(1)
SMALL_FONT = ("Verdana", 8)
MEDIUM_FONT = ("Verdana", 10)
LARGE_FONT = ("Verdana", 12)
# DATABASE
ENCODING = None
ID = None
LATITUDE = None
LONGITUDE = None
NA_VALUES = None  # ['N']
SEPARATOR = ','
HEADERS = ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']
mark = ['o']
fill_style = ['none']  # top, bottom, right, left, full: markerfacecoloralt='gray'
norm = True
normalize = True
current_year = datetime.datetime.now().year - 1
yrs = [y for y in range(1992, 2017)]
colors = [
    ['#3CE1E0', '#56A71E', '#7CD530', '#B6ED15', '#E6F70E', '#F5AB23', '#F06D12', '#B43519', '#891A1A', '#000000'],
    # ['#407140', '#8CBA6C', '#C6E08A', '#DBF794', '#F3FA9E', '#F7D79C', '#F2BE9B', '#B78479', '#8F6161', '#000000'],
    # dark green: 0D690D, light blue: 3CE1EO
    # ['lightpink', 'orange', 'darkcyan', 'springgreen', 'orchid', 'tomato', 'skyblue', 'olive', 'burlywood',
    # 'slategrey'],
    ['maroon', 'darkred', 'brown', 'firebrick', 'crimson', 'indianred', 'lightcoral', 'salmon', 'rosybrown',
     'darksalmon', 'lightsalmon', 'tomato', 'orangered', 'darkorange', 'orange'],
    ['darkcyan', 'teal', 'steelblue', 'cadetblue', 'lightslategrey', 'skyblue', 'turquoise', 'lightseagreen',
     'darkturquoise'], ["salmon"], ["darkcyan"], ["mediumseagreen"],
    ['lightpink', 'orange', 'darkcyan', 'springgreen', 'orchid', 'tomato', 'skyblue', 'olive', 'burlywood',
     'slategrey']]
dash = [[7, 2.5, 3, 2.5, 3, 2.5, 7, 2.5, 3, 2.5, 3, 2.5, 7, 2.5, 7, 2.5],
        [11, 1.7, 5, 1.7, 1.3, 1.7, 5, 1.7, 1.3, 1.7, 5, 1.7, 11, 1.7, 1.3, 1.7], [2, 2, 5, 2, 5, 2, 5, 2],
        [7, 2.1, 4.9, 2.1, 4.9, 2.1, 4.9, 2.1, 2.1, 2.1, 7, 2.1, 2.1, 2.8, 2.1, 2.1, 7, 2.1, 2.8, 2.1],
        [4.8, 1.8, 4.8, 1.8, 1.8, 1.8, 4.8, 1.8, 6.4, 1.8, 4.8, 1.8, 1.8, 1.8],
        [6, 3, 12, 3, 2, 3, 2, 3, 6, 3, 6, 3, 2, 3], [6, 2, 1.5, 2, 1.5, 2, 1.5, 2], [8, 4, 2, 4, 2, 4, 8, 4],
        [5, 1.6, 2, 1.6, 7, 1.6, 2, 1.3], [9, 3, 3, 3, 3, 3]]
titles = [
    "Transition Probabilities",
    "Raw Deterioration",
    "Simulation Deterioration",
    "Raw Frequency (per Year)",
    "Simulation Frequency (per Year)",
    "Raw Frequency (per State)",
    "Simulation Frequency (per State)",
    "3D Frequency"]
labels = (
    ("Time (Years)", "Probability"),
    ("Time (Years)", "State"),
    ("Time (Years)", "Frequency"),
    ("State", "Frequency"),
)
gradationMatrixStartingRow = 1  # 2 ?
gradationMatrixStartingColumn = 0
sieveSize = ['1"', '1/2"', '1/4"', '1/8"', '1/16"', '1/32"', '1/64"', '1/128"', '1/256"', '1/512"']
style.use("ggplot")
matplotlib.use("TkAgg")
a = f.add_subplot(111)
plt.locator_params(nbins=2)
ani = animation.FuncAnimation(f, animate, interval=100)
app = ResultsMenu()
app.geometry("%dx%d" % (WIDTH / 2, 3 * HEIGHT / 4))
app.mainloop()


# print(str(p3)[0:0])  # bug fix
# print(str(bodyQuiverPositive)[0:0])  # bug fix
# print(str(bodyQuiverNegative)[0:0])  # bug fix


def animate(i):
    """dataLink = 'https://btc-e.com/api/3/trades/btc_usd?limit=2000'
    data = urllib.request.urlopen(dataLink)
    data = data.readall().decode("utf-5")
    data = json.loads(data)

    data = data["btc_usd"]
    data = pd.DataFrame(data)

    buys = data[(data['type']=="bid")]
    buys["datestamp"] = np.array(buys["timestamp"]).astype("datetime64[s]")
    buyDates = (buys["datestampe"]).tolist()

    sells = data[(data['type'] == "ask")]
    sells["datestamp"] = np.array(buys["timestamp"]).astype("datetime64[s]")
    sellDates = (buys["datestampe"]).tolist()

    a.clear()

    a.plot_date(buyDates, buys["price"])
    a.plot_date(sellDates, sells["price"])"""
    pullData = ""

    if current_frame == "transition probabilities frame":
        pullData = open("sampleData.txt", "r").read()

    elif current_frame == "deterioration frame":
        pullData = open("data2.txt", "r").read()

    elif current_frame == "frequency frame":
        pullData = open("sampleData.txt", "r").read()

    dataList = pullData.split('\n')
    xList = []
    yList = []

    for eachLine in dataList:
        if len(eachLine) > 1:
            x, y = eachLine.split(',')
            xList.append(int(x))
            yList.append(int(y))

    a.clear()

    a.plot(xList, yList, 'pink', label="Frequency")
    a.plot(yList, xList, 'teal', label="Other thing")
    a.set_title("Frequency \n")

    a.legend(bbox_to_anchor=(0, 1, 1, 0), loc=3, ncol=2, borderaxespad=0)


def animate(i):
    """dataLink = 'https://btc-e.com/api/3/trades/btc_usd?limit=2000'
    data = urllib.request.urlopen(dataLink)
    data = data.readall().decode("utf-8")
    data = json.loads(data)

    data = data["btc_usd"]
    data = pd.DataFrame(data)

    buys = data[(data['type']=="bid")]
    buys["datestamp"] = np.array(buys["timestamp"]).astype("datetime64[s]")
    buyDates = (buys["datestampe"]).tolist()

    sells = data[(data['type'] == "ask")]
    sells["datestamp"] = np.array(buys["timestamp"]).astype("datetime64[s]")
    sellDates = (buys["datestampe"]).tolist()

    a.clear()

    a.plot_date(buyDates, buys["price"])
    a.plot_date(sellDates, sells["price"])"""
    pullData = ""

    if current_frame == "transition probabilities frame":
        pullData = open("sampleData.txt", "r").read()

    elif current_frame == "deterioration frame":
        pullData = open("data2.txt", "r").read()

    elif current_frame == "frequency frame":
        pullData = open("sampleData.txt", "r").read()

    dataList = pullData.split('\n')
    xList = []
    yList = []

    for eachLine in dataList:
        if len(eachLine) > 1:
            x, y = eachLine.split(',')
            xList.append(int(x))
            yList.append(int(y))

    a.clear()

    a.plot(xList, yList, 'pink', label="Frequency")
    a.plot(yList, xList, 'teal', label="Other thing")
    a.set_title("Frequency \n")

    a.legend(bbox_to_anchor=(0, 1, 1, 0), loc=3, ncol=2, borderaxespad=0)


def animate(i):
    """dataLink = 'https://btc-e.com/api/3/trades/btc_usd?limit=2000'
    data = urllib.request.urlopen(dataLink)
    data = data.readall().decode("utf-5")
    data = json.loads(data)
    data = data["btc_usd"]
    data = pd.DataFrame(data)
    buys = data[(data['type']=="bid")]
    buys["datestamp"] = np.array(buys["timestamp"]).astype("datetime64[s]")
    buyDates = (buys["datestampe"]).tolist()
    sells = data[(data['type'] == "ask")]
    sells["datestamp"] = np.array(buys["timestamp"]).astype("datetime64[s]")
    sellDates = (buys["datestampe"]).tolist()
    a.clear()
    a.plot_date(buyDates, buys["price"])
    a.plot_date(sellDates, sells["price"])"""
    pullData = ""
    if current_frame == "transition probabilities frame":
        pullData = open("sampleData.txt", "r").read()
    elif current_frame == "deterioration frame":
        pullData = open("data2.txt", "r").read()
    elif current_frame == "frequency frame":
        pullData = open("sampleData.txt", "r").read()
    dataList = pullData.split('\n')
    xList = []
    yList = []
    for eachLine in dataList:
        if len(eachLine) > 1:
            x, y = eachLine.split(',')
            xList.append(int(x))
            yList.append(int(y))
    a.clear()
    a.plot(xList, yList, 'pink', label="Frequency")
    a.plot(yList, xList, 'teal', label="Other thing")
    a.set_title("Frequency \n")
    a.legend(bbox_to_anchor=(0, 1, 1, 0), loc=3, ncol=2, borderaxespad=0)


def clear(entries):
    for i in range(entries.__len__()):
        entries[FEATURES[i + 0]].setText('')


def graph(data, pt, label, lims, t=0, c=0, legend=None, fill=False):
    plot = plt.subplot2grid((6, 4), (0, 0), rowspan=5, colspan=4)
    # Line Plot
    if pt == 0:
        for index, curve in enumerate(data):
            PlotGenerator.plot_curve(plot, index, curve, c, lims, fill)
    # Histogram
    elif pt == 1:
        for index, curve in enumerate(data):
            PlotGenerator.plot_histogram(
                plot, index, curve, color=c, lims=lims,
                norm=norm
            )
    PlotGenerator.plot_configure(plot, legend, GRAPH_TITLES[t], AXIS_LABELS[label], lims)


def make_grid(parent):
    grid = QtWidgets.QGridLayout(parent)
    return grid


def make_splitter(style, widgets):
    if style == 'h' or style == 'horizontal':
        splitter = QtWidgets.QSplitter(QtCore.Qt.Horizontal)
    else:
        splitter = QtWidgets.QSplitter(QtCore.Qt.Vertical)

    for widget in widgets:
        splitter.addWidget(widget)

    splitter.setStyleSheet(FRAME_STYLE + SPLITTER_STYLE)
    QtWidgets.QSplitter(QtCore.Qt.Horizontal)
    return splitter


def make_frame(parent):
    frame = QtWidgets.QFrame(parent)
    frame.setStyleSheet(FRAME_STYLE)
    frame.setFrameShape(QtWidgets.QFrame.StyledPanel)
    return frame


def make_scroll_area(widget):
    scrollArea = QtWidgets.QScrollArea()
    scrollArea.setFrameShape(QtWidgets.QScrollArea.StyledPanel)
    scrollArea.setStyleSheet(FRAME_STYLE + SCROLL_STYLE)
    scrollArea.setWidget(widget)
    return scrollArea


def make_button(parent, type=None, command=None, text='', icon=None):
    if type == 'radio':
        button = QtWidgets.QRadioButton(parent)

    elif type == 'check':
        button = QtWidgets.QCheckBox(parent)

    else:
        if icon:
            icn = QtGui.QIcon(icon)
            button = QtWidgets.QPushButton(icn, text, parent)
            button.setIconSize(QtCore.QSize(20, 20))
        else:
            button = QtWidgets.QPushButton(text, parent)

        button.setFont(QtGui.QFont('Verdana', 9))
        button.setStyleSheet(BUTTON_STYLE)
        set_widget_size(button, 25, 25)
        button.clicked.connect(command)

    return button


def make_label(parent, text=''):
    label = QtWidgets.QLabel(text, parent)
    label.setFont(QtGui.QFont("Verdana", 9))
    label.setStyleSheet(LABEL_STYLE)
    return label


def make_entry(parent, width=300):
    entry = QtWidgets.QLineEdit(parent)
    entry.setFont(QtGui.QFont("Verdana", 9))
    entry.setStyleSheet(ENTRY_STYLE)
    set_widget_size(entry, width, 20)
    return entry


def make_combo(parent, items, command):
    combo = QtWidgets.QComboBox(parent)
    set_widget_size(combo, 40, 20)
    combo.setStyleSheet(COMBO_STYLE)
    for item in items:
        combo.addItem(item)
    combo.activated[str].connect(command)
    return combo


def open_folder(parent, label=None, default=os.getcwd()):
    dir = QtWidgets.QFileDialog.getExistingDirectory(parent, 'Select folder', default)
    if dir:
        label.setText(str(dir))
        label.adjustSize()
        return dir


def open_folder(parent, label=None):
    dir = QtWidgets.QFileDialog.getExistingDirectory(parent, 'Select folder', os.getcwd())
    if dir:
        label.setText(str(dir))
        label.adjustSize()
        return dir


def popup_message(message):
    popup = tk.Tk()
    popup.wm_title("!")
    label = ttk.Label(popup, text=message, font=MEDIUM_FONT)
    label.pack(side="top", fill="x", pady=10)
    B1 = ttk.Button(popup, text="Okay", command=popup.destroy)
    B1.pack()
    B1.mainloop()


def save_file(parent, fileExt='', label=None):
    paths = QtWidgets.QFileDialog.getSaveFileName(parent, 'Select file', os.getcwd(), fileExt + ALL_FILES)
    if label and paths:
        label.setText(str(paths[0]))
        label.adjustSize()
    if paths:
        return paths[0]


def save_file(parent, fileExt='', label=None):
    paths = QtWidgets.QFileDialog.getSaveFileName(parent, 'Select file', os.getcwd(), fileExt + ";;" + ALL_FILES)
    if label and paths:
        label.setText(str(paths))
        label.adjustSize()
    if paths:
        return paths[0]


def set_widget_size(widget, width, height):
    widget.setMinimumSize(width, height)
    widget.setMaximumSize(width, height)


def writer(file, info, i):
    try:
        file.write(str(info[i].get()) + "\n")
    except:
        file.write(str(info[i]) + "\n")


class AnalysisMenu(SubMenu):
    def __init__(self, parent, title, icon, algorithms):
        SubMenu.__init__(self, parent, title, icon)
        self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)

        self.modelSelection = self.set_models(algorithms, self.hbox, multiSelect=True)

        self.scalerSelection = self.set_scalers(SCALER_NAMES, self.hbox)

        self.set_mode()

    @staticmethod
    def set_models(models, tab, multiSelect=False, command=None, row=0, column=0):
        modelsGrid = make_group_box(
            tab, layout=make_grid(), text='Models', row=row, column=column, width=205,
            height=225, strictWidth=True
        )

        modelSelection = make_list(
            items=models, command=command, multiSelect=multiSelect, layout=modelsGrid, row=0,
            column=0, width=200, height=175
        )
        return modelSelection

    @staticmethod
    def set_scalers(scalers, tab, row=0, column=1):
        scalersGrid = make_group_box(
            tab, layout=make_grid(), text='Scalers', row=row, column=column, width=205,
            height=225, strictWidth=True
        )

        scalerSelection = make_list(
            items=scalers, multiSelect=False, layout=scalersGrid, row=0, column=0, width=200,
            height=175
        )
        scalerSelection.setCurrentRow(0)

        return scalerSelection

    def set_mode(self):
        self.modeGrid = make_group_box(
            self.hbox, layout=make_grid(), text='Mode', row=0, column=2, width=75, height=75,
            strictWidth=True
        )

        self.mode = make_list(
            items=('Series', 'Parallel'), default=0, layout=self.modeGrid, row=0, column=0, width=50,
            height=36
        )
        return self.mode


class ClassificationMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)

        self.classGrid = make_group_box(
            self.container, layout=make_grid(), text='Class', row=3, column=2, width=205,
            height=225
        )

        self.columnGrid = make_group_box(
            self.container, layout=make_grid(), text='y', row=1, column=2, width=205,
            height=225
        )

        self.indexGrid = make_group_box(
            self.container, layout=make_grid(), text='x', row=0, column=2, width=205,
            height=225
        )

        self.siteContainer = make_browser(layout=self.bottomLayout, file=CLASSIFICATION_GRAPH)

        try:
            self.combos()
        except:
            pass

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=10, column=0,
            description=RUN_CLASSIFICATION_DESCRIPTION
        )

        self.analysisTab, self.parametersTab, self.exportTab = set_tabs(
            self, ('Analysis', 'Parameters', 'Export'),
            layout=self.topRightLayout
        )

        self.modelSelection = set_models(CLASSIFIERS_NAMES, self.analysisTab, multiSelect=True)

        self.modelParameterSelection = set_models(
            CLASSIFIERS_NAMES, self.parametersTab,
            command=self.set_parameters_layout, multiSelect=False
        )

        self.parametersGrid = make_group_box(
            self.parametersTab, layout=make_grid(), text='Settings', row=0, column=1,
            width=205, height=225
        )

        self.classificationLayouts = {name: make_grid() for name in CLASSIFIERS_NAMES}
        self.set_classifiers()
        self.set_parameters_tab()

        self.autoTuneGrid = make_group_box(
            self.parametersTab, layout=make_grid(), text='Tune', row=0, column=3,
            width=45, height=45
        )

        self.autoCheck = make_button(type='check', layout=self.autoTuneGrid, description=AUTOMATIC_TUNING_DESCRIPTION)

        """EXPORT"""
        set_export_options(self)

    def get_options(self):
        options = {
            'abcEstimators':                    self.ABestimatorsDial.value(),
            'abcLearningRate':                  self.ABlearningRateDial.value() / 10.0,
            # 'abcLoss': self.ABlossCombo.currentText(),

            'dtcCriterion':                     self.DTcriterionCombo.currentText(),
            'dtcMaximumDepth':                  self.DTmaxDepthDial.value(),
            'dtcMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
            'dtcMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
            'dtcMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
            'dtcMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
            'dtcMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
            'dtcPresort':                       self.DTpresortCheck.isChecked(),
            'dtcRandomState':                   self.DTrandomStateEntry.text(),
            'dtcSplitter':                      self.DTsplitterCombo.currentText(),

            'gpcAlpha':                         None,  # self.GPalphaDial.value() / 100.0,
            'gpcKernel':                        None,  # self.GPkernelCombo.currentText(),
            'gpcNormalize':                     None,  # self.GPnormalizeCheck.isChecked(),
            'gpcOptimizer':                     None,  # self.GPoptimizerCombo.currentText(),

            'knncAlgorithm':                    self.KNNalgorithmCombo.currentText(),
            'knncLeafSize':                     self.KNNleafSizeDial.value(),
            'knncMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
            'knncNumberOfNeighbors':            self.KNNneighborsDial.value(),
            'knncWeightsFunction':              self.KNNweightsCombo.currentText(),

            'mlpcActivationFunction':           self.MLPactivationCombo.currentText(),
            # 'mlpcBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
            'mlpcEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
            'mlpcFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
            'mlpcHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
            'mlpcInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
            'mlpcLearningRate':                 self.MLPlearningRateCombo.currentText(),
            'mlpcMaximumIterations':            self.MLPmaxIterDial.value(),
            'mlpcMomentum':                     self.MLPmomentumDial.value() / 10.0,
            'mlpcNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
            'mlpcNumericalStability':           self.MLPepsilonDial.value() / 100.0,
            'mlpcPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
            'mlpcPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
            'mlpcRandomState':                  self.MLPrandomStateEntry.text(),
            'mlpcShuffle':                      self.MLPshuffleCheck.isChecked(),
            'mlpcSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
            'mlpcTolerance':                    self.MLPtolDial.value() / 100.0,
            'mlpcValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
            'mlpcWarmStart':                    self.MLPwarmStartCheck.isChecked(),
            'mlpcWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

            'nb':                               None,

            'qda':                              None,

            'rfcBootstrap':                     self.RFbootstrapCheck.isChecked(),
            'rfcCriterion':                     self.RFcriterionCombo.currentText(),
            'rfcMaximumDepth':                  self.RFmaxDepthDial.value(),
            'rfcMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
            'rfcMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
            'rfcMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
            'rfcMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
            'rfcMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
            'rfcMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
            'rfcNumberOfTrees':                 self.RFestimatorsDial.value(),
            'rfcOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
            'rfcRandomState':                   self.RFrandomStateEntry.text(),
            'rfcWarmStart':                     self.RFwarmStartCheck.isChecked(),

            'sgdcAlpha':                        self.SGDalphaDial.value() / 100000,
            'sgdcAverage':                      self.SGDaverageCheck.isChecked(),
            'sgdcEta0':                         self.SGDeta0Dial.value() / 10.0,
            'sgdcFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
            'sgdcLearningRate':                 self.SGDlearningRateCombo.currentText(),
            'sgdcLoss':                         self.SGDlossCombo.currentText(),
            'sgdcL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
            'sgdcMaxIterations':                self.SGDmaxIterationsDial.value(),
            'sgdcPenalty':                      self.SGDpenaltyCombo.currentText(),
            'sgdcPowerT':                       self.SGDpowerTDial.value() / 10.0,
            'sgdcShuffle':                      self.SGDshuffleCheck.isChecked(),
            'sgdcTolerance':                    self.SGDtolDial.value() / 100.0,
            'sgdcWarmStart':                    self.SGDwarmStartCheck.isChecked(),

            'svmcC':                            dh.nonize(self.SVMCDial.value()),
            # 'svmcCacheSize': self.SVMcacheSizeDial.value(),
            'svmcCoefficient0':                 self.SVMcoef0Dial.value() / 10.0,
            # 'svmcEpsilon': self.SVMepsilonDial.value() / 10.0,
            'svmcGamma':                        self.SVMgammaDial.value(),
            'svmcKernel':                       self.SVMkernelCombo.currentText(),
            'svmcMaximumIterations':            self.SVMmaxIterDial.value(),
            'svmcPolynomialDegree':             self.SVMdegreeCombo.currentText(),
            'svmcShrinking':                    self.SVMshrinkingCheck.isChecked(),
            'svmcTolerance':                    self.SVMtolDial.value() / 100.0,
        }
        return options

    def set_parameters_tab(self):
        self.parametersSelection = make_scroll_area(self.classificationLayouts['Adaptive Boost'], width=275)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 1)

    def set_parameters_layout(self):
        self.parametersGrid.removeWidget(self.parametersSelection)
        self.parametersSelection = make_scroll_area(
            self.classificationLayouts[self.modelParameterSelection.currentItem().text()], width=275
        )
        self.parametersGrid.addWidget(self.parametersSelection, 0, 1)

    def set_classifiers(self):
        self.set_ab_classifier()
        self.set_dt_classifier()
        self.set_gp_classifier()
        self.set_knn_classifier()
        self.set_mlp_classifier()
        self.set_nb_classifier()
        self.set_qda_classifier()
        self.set_rf_classifier()
        self.set_sgd_classifier()
        self.set_svm_classifier()

    def set_ab_classifier(self):
        layout = self.classificationLayouts['Adaptive Boost']
        _, self.ABalgorithmCombo = make_pair(
            pair='combo', comboItems=('SAMME', 'SAMME.R'), text='Algorithm:',
            layout=layout, row=1, column=0, pairWidth=100, description=''
        )

        _, self.ABestimatorsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
            layout=layout, row=2, column=0, description=''
        )

        _, self.ABlearningRateDial = make_pair(
            pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
            layout=layout, row=3, column=0, description=''
        )

        _, self.ABrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=4, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

    def set_dt_classifier(self):
        layout = self.classificationLayouts['Decision Tree']
        _, self.DTcriterionCombo = make_pair(
            pair='combo', comboItems=('mse', 'friedman_mse', 'mae'), text='Criterion:',
            layout=layout, row=1, column=0, labelWidth=200, pairWidth=100,
            description=CRITERION_DESCRIPTION
        )

        _, self.DTmaxDepthDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=2, column=0, labelWidth=125,
            description=MAX_DEPTH_DESCRIPTION
        )

        _, self.DTmaxFeaturesCombo = make_pair(
            pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=3, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.DTminImpurityDecreaseDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1),
            text='Min Impurity Decrease:', layout=layout, row=5, column=0,
            labelWidth=200, description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        _, self.DTminSamplesLeafDial = make_pair(
            pair='dial', dialSettings=(1, 4, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=6, column=0,
            labelWidth=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        _, self.DTminSamplesSplitDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=7, column=0,
            labelWidth=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        _, self.DTminWeightFractionLeafDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=8,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        _, self.DTpresortCheck = make_pair(
            pair='check', text='Presort Data:', layout=layout, row=9, column=0,
            labelWidth=200, description=PRESORT_DESCRIPTION
        )

        _, self.DTrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=10, column=0,
            labelWidth=125, pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )

        _, self.DTsplitterCombo = make_pair(
            pair='combo', comboItems=('best', 'random'), text='Splitter:',
            layout=layout, row=11, column=0, pairWidth=75,
            description=SPLITTER_DESCRIPTION
        )

    def set_gp_classifier(self):
        layout = self.classificationLayouts['Gaussian Process']
        _, self.GPrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=1, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

        _, self.GPwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=2, column=0,
            description=''
        )

    def set_knn_classifier(self):
        layout = self.classificationLayouts['Nearest Neighbors']
        _, self.KNNalgorithmCombo = make_pair(
            pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
            text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
            description=ALGORITHM_DESCRIPTION
        )

        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

        _, self.KNNleafSizeDial = make_pair(
            pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:', layout=layout,
            row=2, column=0, description=LEAF_SIZE_DESCRIPTION
        )

        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

        _, self.KNNminkowskiPowerDial = make_pair(
            pair='dial', dialSettings=(1, 100, 2, 1), text='Minkowski Power:',
            layout=layout, row=3, column=0, description=P_DESCRIPTION
        )

        _, self.KNNneighborsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 5, 1), text='Number of Neighbors:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=N_NEIGHBORS_DESCRIPTION
        )

        _, self.KNNweightsCombo = make_pair(
            pair='combo', comboItems=('uniform', 'distance'), text='Weights Function:',
            layout=layout, row=5, column=0, labelWidth=200, pairWidth=100,
            description=WEIGHTS_DESCRIPTION
        )

    def set_mlp_classifier(self):
        layout = self.classificationLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )

        _, self.MLPalphaDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha (Penalty Parameter):',
            layout=layout, row=2, column=0, labelWidth=200,
            description=MLP_ALPHA_DESCRIPTION
        )

        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)

        _, self.MLPbeta1Dial = make_pair(
            pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )

        _, self.MLPbeta2Dial = make_pair(
            pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )

        _, self.MLPearlyStoppingCheck = make_pair(
            pair='check', text='Early Stopping:', layout=layout, row=5, column=0,
            labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )

        _, self.MLPepsilonDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )

        _, self.MLPhiddenLayerSizesEntry = make_pair(
            pair='entry', text='Hidden Layer Sizes:', layout=layout, row=7,
            column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

        _, self.MLPinitLearningRateDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )

        _, self.MLPlearningRateCombo = make_pair(
            pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )

        _, self.MLPmaxIterDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
            layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )

        _, self.MLPmomentumDial = make_pair(
            pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:', layout=layout,
            row=11, column=0, description=MOMENTUM_DESCRIPTION
        )

        _, self.MLPnesterovsMomentumCheck = make_pair(
            pair='check', text='Nesterov\'s Momentum:', layout=layout, row=12,
            column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )

        _, self.MLPpowerTDial = make_pair(
            pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )

        _, self.MLPrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=14, column=0,
            pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )

        _, self.MLPshuffleCheck = make_pair(
            pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )

        _, self.MLPsolverCombo = make_pair(
            pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )

        _, self.MLPtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=17, column=0, description=MLP_TOL_DESCRIPTION
        )

        _, self.MLPvalidationFractionDial = make_pair(
            pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )

        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

        _, self.MLPwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def set_nb_classifier(self):
        pass

    def set_qda_classifier(self):
        layout = self.classificationLayouts['Quadratic Discriminant']
        _, self.QDAregParamDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Regularization Parameter:',
            layout=layout, row=1, column=0, description=''
        )

        _, self.QDAstoreCovarianceCheck = make_pair(
            pair='check', text='Store Covariance:', layout=layout, row=2,
            column=0, description=''
        )

        _, self.QDAtolDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Tolerance:', layout=layout,
            row=3, column=0, description=''
        )

    def set_rf_classifier(self):
        layout = self.classificationLayouts['Random Forest']
        _, self.RFbootstrapCheck = make_pair(
            pair='check', text='Bootstrap:', layout=layout, row=1, column=0,
            description=BOOTSTRAP_DESCRIPTION
        )

        _, self.RFcriterionCombo = make_pair(
            pair='combo', comboItems=('mse', 'mae'), text='Criterion:', layout=layout,
            row=2, column=0, pairWidth=50, description=CRITERION_DESCRIPTION
        )

        _, self.RFmaxDepthDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=3, column=0, description=MAX_DEPTH_DESCRIPTION
        )

        _, self.RFmaxFeaturesCombo = make_pair(
            pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=4, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.RFmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=5, column=0, labelWidth=220,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.RFminImpurityDecreaseDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Impurity Decrease:', layout=layout, row=6, column=0,
            labelWidth=220, description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        _, self.RFminSamplesLeafDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=7, column=0,
            labelWidth=220, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        _, self.RFminSamplesSplitDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=8, column=0,
            labelWidth=175, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        _, self.RFminWeightFractionLeafDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=9,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        _, self.RFestimatorsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
            layout=layout, row=10, column=0, labelWidth=200,
            description=N_ESTIMATORS_DESCRIPTION
        )

        _, self.RFoobScoreCheck = make_pair(
            pair='check', text='Out-of-Bag Samples:', layout=layout, row=11, column=0,
            labelWidth=200, description=OOB_SCORE_DESCRIPTION
        )

        # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
        # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)

        # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
        # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
        _, self.RFrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=12, column=0,
            pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )

        _, self.RFwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=13, column=0,
            labelWidth=200, description=WARM_START_DESCRIPTION
        )

    def set_sgd_classifier(self):
        pass
        layout = self.classificationLayouts['Stochastic Gradient Descent']
        _, self.SGDalphaDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=''
        )

        _, self.SGDaverageCheck = make_pair(
            pair='check', text='Average:', layout=layout, row=2, column=0,
            description=''
        )

        _, self.SGDeta0Dial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout, row=3,
            column=0, description=''
        )

        _, self.SGDepsilonDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:', layout=layout,
            row=4, column=0, description=''
        )

        _, self.SGDfitInterceptCheck = make_pair(
            pair='check', text='Fit Intercept:', layout=layout, row=5, column=0,
            description=''
        )

        _, self.SGDlearningRateCombo = make_pair(
            pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
            text='Learning Rate:', layout=layout, row=6, column=0, pairWidth=100,
            description=''
        )

        _, self.SGDlossCombo = make_pair(
            pair='combo', comboItems=(
                'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
            layout=layout,
            row=7, column=0, pairWidth=100, description=''
        )

        _, self.SGDl1RatioDial = make_pair(
            pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
            row=8, column=0, description=''
        )

        _, self.SGDmaxIterationsDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=9, column=0,
            description=''
        )

        _, self.SGDpenaltyCombo = make_pair(
            pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
            text='Penalty:', layout=layout, row=10, column=0, pairWidth=100,
            description=''
        )

        _, self.SGDpowerTDial = make_pair(
            pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
            row=11, column=0, description=''
        )

        _, self.SGDrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=12, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

        _, self.SGDshuffleCheck = make_pair(
            pair='check', text='Shuffle:', layout=layout, row=13, column=0,
            description=''
        )

        _, self.SGDtolDial = make_pair(
            pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:', layout=layout,
            row=14, column=0, description=''
        )

        _, self.SGDwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=15, column=0,
            description=''
        )

    def set_svm_classifier(self):
        pass
        layout = self.classificationLayouts['Support Vector Machine']
        _, self.SVMCDial = make_pair(
            pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
            column=0, description=C_DESCRIPTION
        )

        # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=0,
        #                                    description=CACHE_SIZE_DESCRIPTION)
        # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=1, width=50,
        #                                    description=CACHE_SIZE_DESCRIPTION)

        _, self.SVMcoef0Dial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:', layout=layout,
            row=2, column=0, description=COEF0_DESCRIPTION
        )
        # DecisionFunctionShape
        _, self.SVMdegreeCombo = make_pair(
            pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:', layout=layout,
            row=3, column=0, pairWidth=100, description=DEGREE_DESCRIPTION
        )

        _, self.SVMprobabilityCheck = make_pair(
            pair='check', text='Probability:', layout=layout, row=4, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMgammaDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout, row=5,
            column=0, description=GAMMA_DESCRIPTION
        )

        _, self.SVMkernelCombo = make_pair(
            pair='combo', comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
            text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
            description=KERNEL_DESCRIPTION
        )

        _, self.SVMmaxIterDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
            layout=layout, row=7, column=0, labelWidth=200,
            description=MAX_ITER_DESCRIPTION
        )

        _, self.SVMrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=8, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

        _, self.SVMshrinkingCheck = make_pair(
            pair='check', text='Shrinking:', layout=layout, row=9, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=10, column=0, description=TOL_DESCRIPTION
        )

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.classCombo = make_combo(
            self, [''] + self.headers, command=None, layout=self.classGrid, row=9, column=1,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.columnCombo.setCurrentText(self.headers[1])
        self.classCombo.setCurrentText(self.headers[2])

        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, row=0, column=0,
            width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            classification = self.classCombo.currentText()
            dir = self.readLabel.text()
            data, classLabels, xKeys, yKeys, labelKeys = dh.process_classification_data(
                dir, index, column,
                classification
            )
            # data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.iloc[:, 0],),)
            y = ((pd.DataFrame(data.iloc[:, 1]),),)
            make_plot(
                CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Raw Data',), xLabels=(index,), yLabels=(column,),
                lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print(e)

    def run(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        classification = self.classCombo.currentText()
        dir = self.readLabel.text()
        try:
            models = self.get_models()
            if self.validate(models):
                data, classLabels, xKeys, yKeys, labelKeys = dh.process_classification_data(
                    dir, index, column,
                    classification, )

                results = Classifiers.classification(models, x=data, y=classLabels)
                # data = pd.DataFrame(data, columns=(column,), index=data.index)
                x = ((data.iloc[:, 0],),)
                y = ((pd.DataFrame(data.iloc[:, 1]),),)
                make_contour_plot(
                    CLASSIFICATION_GRAPH, X=x, Y=y, boundaries=results, titles=('Classification',),
                    xLabels=(index,), yLabels=(column,), lineWidths=((1,),), legends=((True,),),
                    types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
                )
                self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print('lerk')
            print(e)

    def get_models(self):
        checks = [x.text() for x in self.modelSelection.selectedItems()]
        if self.autoCheck.isChecked():
            models = Classifiers.cross_validation_classification_models(checks)
        else:
            options = self.get_options()
            models = Classifiers.classification_models(checks, options)
        return models

    def validate(self, models):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if error == False:
            return True
        else:
            return False

    def export_results(self):
        print("loser")

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)

        self.classGrid = make_group_box(
            self.container, layout=make_grid(), text='Class', row=3, column=2, width=205,
            height=225
        )

        self.columnGrid = make_group_box(
            self.container, layout=make_grid(), text='y', row=1, column=2, width=205,
            height=225
        )

        self.indexGrid = make_group_box(
            self.container, layout=make_grid(), text='x', row=0, column=2, width=205,
            height=225
        )

        self.siteContainer = make_browser(layout=self.bottomLayout, file=CLASSIFICATION_GRAPH)

        try:
            self.combos()
        except:
            pass

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=10, column=0,
            description=RUN_CLASSIFICATION_DESCRIPTION
        )

        self.analysisTab, self.parametersTab, self.exportTab = set_tabs(
            self, ('Analysis', 'Parameters', 'Export'),
            layout=self.topRightLayout
        )

        self.modelSelection = set_models(CLASSIFIERS_NAMES, self.analysisTab, multiSelect=True)

        self.modelParameterSelection = set_models(
            CLASSIFIERS_NAMES, self.parametersTab,
            command=self.set_parameters_layout, multiSelect=False
        )

        self.parametersGrid = make_group_box(
            self.parametersTab, layout=make_grid(), text='Settings', row=0, column=1,
            width=205, height=225
        )

        self.classificationLayouts = {name: make_grid() for name in CLASSIFIERS_NAMES}
        self.set_classifiers()
        self.set_parameters_tab()

        self.autoTuneGrid = make_group_box(
            self.parametersTab, layout=make_grid(), text='Tune', row=0, column=3,
            width=45, height=45
        )

        self.autoCheck = make_button(type='check', layout=self.autoTuneGrid, description=AUTOMATIC_TUNING_DESCRIPTION)

        """EXPORT"""
        set_export_options(self)

    def get_options(self):
        options = {
            'abcEstimators':                    self.ABestimatorsDial.value(),
            'abcLearningRate':                  self.ABlearningRateDial.value() / 10.0,
            # 'abcLoss': self.ABlossCombo.currentText(),

            'dtcCriterion':                     self.DTcriterionCombo.currentText(),
            'dtcMaximumDepth':                  self.DTmaxDepthDial.value(),
            'dtcMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
            'dtcMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
            'dtcMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
            'dtcMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
            'dtcMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
            'dtcPresort':                       self.DTpresortCheck.isChecked(),
            'dtcRandomState':                   self.DTrandomStateEntry.text(),
            'dtcSplitter':                      self.DTsplitterCombo.currentText(),

            'gpcAlpha':                         None,  # self.GPalphaDial.value() / 100.0,
            'gpcKernel':                        None,  # self.GPkernelCombo.currentText(),
            'gpcNormalize':                     None,  # self.GPnormalizeCheck.isChecked(),
            'gpcOptimizer':                     None,  # self.GPoptimizerCombo.currentText(),

            'knncAlgorithm':                    self.KNNalgorithmCombo.currentText(),
            'knncLeafSize':                     self.KNNleafSizeDial.value(),
            'knncMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
            'knncNumberOfNeighbors':            self.KNNneighborsDial.value(),
            'knncWeightsFunction':              self.KNNweightsCombo.currentText(),

            'mlpcActivationFunction':           self.MLPactivationCombo.currentText(),
            # 'mlpcBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
            'mlpcEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
            'mlpcFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
            'mlpcHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
            'mlpcInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
            'mlpcLearningRate':                 self.MLPlearningRateCombo.currentText(),
            'mlpcMaximumIterations':            self.MLPmaxIterDial.value(),
            'mlpcMomentum':                     self.MLPmomentumDial.value() / 10.0,
            'mlpcNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
            'mlpcNumericalStability':           self.MLPepsilonDial.value() / 100.0,
            'mlpcPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
            'mlpcPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
            'mlpcRandomState':                  self.MLPrandomStateEntry.text(),
            'mlpcShuffle':                      self.MLPshuffleCheck.isChecked(),
            'mlpcSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
            'mlpcTolerance':                    self.MLPtolDial.value() / 100.0,
            'mlpcValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
            'mlpcWarmStart':                    self.MLPwarmStartCheck.isChecked(),
            'mlpcWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

            'nb':                               None,

            'qda':                              None,

            'rfcBootstrap':                     self.RFbootstrapCheck.isChecked(),
            'rfcCriterion':                     self.RFcriterionCombo.currentText(),
            'rfcMaximumDepth':                  self.RFmaxDepthDial.value(),
            'rfcMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
            'rfcMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
            'rfcMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
            'rfcMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
            'rfcMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
            'rfcMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
            'rfcNumberOfTrees':                 self.RFestimatorsDial.value(),
            'rfcOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
            'rfcRandomState':                   self.RFrandomStateEntry.text(),
            'rfcWarmStart':                     self.RFwarmStartCheck.isChecked(),

            'sgdcAlpha':                        self.SGDalphaDial.value() / 100000,
            'sgdcAverage':                      self.SGDaverageCheck.isChecked(),
            'sgdcEta0':                         self.SGDeta0Dial.value() / 10.0,
            'sgdcFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
            'sgdcLearningRate':                 self.SGDlearningRateCombo.currentText(),
            'sgdcLoss':                         self.SGDlossCombo.currentText(),
            'sgdcL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
            'sgdcMaxIterations':                self.SGDmaxIterationsDial.value(),
            'sgdcPenalty':                      self.SGDpenaltyCombo.currentText(),
            'sgdcPowerT':                       self.SGDpowerTDial.value() / 10.0,
            'sgdcShuffle':                      self.SGDshuffleCheck.isChecked(),
            'sgdcTolerance':                    self.SGDtolDial.value() / 100.0,
            'sgdcWarmStart':                    self.SGDwarmStartCheck.isChecked(),

            'svmcC':                            dh.nonize(self.SVMCDial.value()),
            # 'svmcCacheSize': self.SVMcacheSizeDial.value(),
            'svmcCoefficient0':                 self.SVMcoef0Dial.value() / 10.0,
            # 'svmcEpsilon': self.SVMepsilonDial.value() / 10.0,
            'svmcGamma':                        self.SVMgammaDial.value(),
            'svmcKernel':                       self.SVMkernelCombo.currentText(),
            'svmcMaximumIterations':            self.SVMmaxIterDial.value(),
            'svmcPolynomialDegree':             self.SVMdegreeCombo.currentText(),
            'svmcShrinking':                    self.SVMshrinkingCheck.isChecked(),
            'svmcTolerance':                    self.SVMtolDial.value() / 100.0,
        }
        return options

    def set_parameters_tab(self):
        self.parametersSelection = make_scroll_area(self.classificationLayouts['Adaptive Boost'], width=275)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 1)

    def set_parameters_layout(self):
        self.parametersGrid.removeWidget(self.parametersSelection)
        self.parametersSelection = make_scroll_area(
            self.classificationLayouts[self.modelParameterSelection.currentItem().text()], width=275
        )
        self.parametersGrid.addWidget(self.parametersSelection, 0, 1)

    def set_classifiers(self):
        self.set_ab_classifier()
        self.set_dt_classifier()
        self.set_gp_classifier()
        self.set_knn_classifier()
        self.set_mlp_classifier()
        self.set_nb_classifier()
        self.set_qda_classifier()
        self.set_rf_classifier()
        self.set_sgd_classifier()
        self.set_svm_classifier()

    def set_ab_classifier(self):
        layout = self.classificationLayouts['Adaptive Boost']
        _, self.ABalgorithmCombo = make_pair(
            pair='combo', comboItems=('SAMME', 'SAMME.R'), text='Algorithm:',
            layout=layout, row=1, column=0, pairWidth=100, description=''
        )

        _, self.ABestimatorsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
            layout=layout, row=2, column=0, description=''
        )

        _, self.ABlearningRateDial = make_pair(
            pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
            layout=layout, row=3, column=0, description=''
        )

        _, self.ABrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=4, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

    def set_dt_classifier(self):
        layout = self.classificationLayouts['Decision Tree']
        _, self.DTcriterionCombo = make_pair(
            pair='combo', comboItems=('mse', 'friedman_mse', 'mae'), text='Criterion:',
            layout=layout, row=1, column=0, labelWidth=200, pairWidth=100,
            description=CRITERION_DESCRIPTION
        )

        _, self.DTmaxDepthDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=2, column=0, labelWidth=125,
            description=MAX_DEPTH_DESCRIPTION
        )

        _, self.DTmaxFeaturesCombo = make_pair(
            pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=3, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.DTminImpurityDecreaseDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1),
            text='Min Impurity Decrease:', layout=layout, row=5, column=0,
            labelWidth=200, description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        _, self.DTminSamplesLeafDial = make_pair(
            pair='dial', dialSettings=(1, 4, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=6, column=0,
            labelWidth=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        _, self.DTminSamplesSplitDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=7, column=0,
            labelWidth=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        _, self.DTminWeightFractionLeafDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=8,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        _, self.DTpresortCheck = make_pair(
            pair='check', text='Presort Data:', layout=layout, row=9, column=0,
            labelWidth=200, description=PRESORT_DESCRIPTION
        )

        _, self.DTrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=10, column=0,
            labelWidth=125, pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )

        _, self.DTsplitterCombo = make_pair(
            pair='combo', comboItems=('best', 'random'), text='Splitter:',
            layout=layout, row=11, column=0, pairWidth=75,
            description=SPLITTER_DESCRIPTION
        )

    def set_gp_classifier(self):
        layout = self.classificationLayouts['Gaussian Process']
        _, self.GPrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=1, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

        _, self.GPwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=2, column=0,
            description=''
        )

    def set_knn_classifier(self):
        layout = self.classificationLayouts['Nearest Neighbors']
        _, self.KNNalgorithmCombo = make_pair(
            pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
            text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
            description=ALGORITHM_DESCRIPTION
        )

        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

        _, self.KNNleafSizeDial = make_pair(
            pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:', layout=layout,
            row=2, column=0, description=LEAF_SIZE_DESCRIPTION
        )

        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

        _, self.KNNminkowskiPowerDial = make_pair(
            pair='dial', dialSettings=(1, 100, 2, 1), text='Minkowski Power:',
            layout=layout, row=3, column=0, description=P_DESCRIPTION
        )

        _, self.KNNneighborsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 5, 1), text='Number of Neighbors:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=N_NEIGHBORS_DESCRIPTION
        )

        _, self.KNNweightsCombo = make_pair(
            pair='combo', comboItems=('uniform', 'distance'), text='Weights Function:',
            layout=layout, row=5, column=0, labelWidth=200, pairWidth=100,
            description=WEIGHTS_DESCRIPTION
        )

    def set_mlp_classifier(self):
        layout = self.classificationLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )

        _, self.MLPalphaDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha (Penalty Parameter):',
            layout=layout, row=2, column=0, labelWidth=200,
            description=MLP_ALPHA_DESCRIPTION
        )

        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)

        _, self.MLPbeta1Dial = make_pair(
            pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )

        _, self.MLPbeta2Dial = make_pair(
            pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )

        _, self.MLPearlyStoppingCheck = make_pair(
            pair='check', text='Early Stopping:', layout=layout, row=5, column=0,
            labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )

        _, self.MLPepsilonDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )

        _, self.MLPhiddenLayerSizesEntry = make_pair(
            pair='entry', text='Hidden Layer Sizes:', layout=layout, row=7,
            column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

        _, self.MLPinitLearningRateDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )

        _, self.MLPlearningRateCombo = make_pair(
            pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )

        _, self.MLPmaxIterDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
            layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )

        _, self.MLPmomentumDial = make_pair(
            pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:', layout=layout,
            row=11, column=0, description=MOMENTUM_DESCRIPTION
        )

        _, self.MLPnesterovsMomentumCheck = make_pair(
            pair='check', text='Nesterov\'s Momentum:', layout=layout, row=12,
            column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )

        _, self.MLPpowerTDial = make_pair(
            pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )

        _, self.MLPrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=14, column=0,
            pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )

        _, self.MLPshuffleCheck = make_pair(
            pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )

        _, self.MLPsolverCombo = make_pair(
            pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )

        _, self.MLPtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=17, column=0, description=MLP_TOL_DESCRIPTION
        )

        _, self.MLPvalidationFractionDial = make_pair(
            pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )

        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

        _, self.MLPwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def set_nb_classifier(self):
        pass

    def set_qda_classifier(self):
        layout = self.classificationLayouts['Quadratic Discriminant']
        _, self.QDAregParamDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Regularization Parameter:',
            layout=layout, row=1, column=0, description=''
        )

        _, self.QDAstoreCovarianceCheck = make_pair(
            pair='check', text='Store Covariance:', layout=layout, row=2,
            column=0, description=''
        )

        _, self.QDAtolDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Tolerance:', layout=layout,
            row=3, column=0, description=''
        )

    def set_rf_classifier(self):
        layout = self.classificationLayouts['Random Forest']
        _, self.RFbootstrapCheck = make_pair(
            pair='check', text='Bootstrap:', layout=layout, row=1, column=0,
            description=BOOTSTRAP_DESCRIPTION
        )

        _, self.RFcriterionCombo = make_pair(
            pair='combo', comboItems=('mse', 'mae'), text='Criterion:', layout=layout,
            row=2, column=0, pairWidth=50, description=CRITERION_DESCRIPTION
        )

        _, self.RFmaxDepthDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=3, column=0, description=MAX_DEPTH_DESCRIPTION
        )

        _, self.RFmaxFeaturesCombo = make_pair(
            pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=4, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.RFmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=5, column=0, labelWidth=220,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.RFminImpurityDecreaseDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Impurity Decrease:', layout=layout, row=6, column=0,
            labelWidth=220, description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        _, self.RFminSamplesLeafDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=7, column=0,
            labelWidth=220, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        _, self.RFminSamplesSplitDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=8, column=0,
            labelWidth=175, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        _, self.RFminWeightFractionLeafDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=9,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        _, self.RFestimatorsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
            layout=layout, row=10, column=0, labelWidth=200,
            description=N_ESTIMATORS_DESCRIPTION
        )

        _, self.RFoobScoreCheck = make_pair(
            pair='check', text='Out-of-Bag Samples:', layout=layout, row=11, column=0,
            labelWidth=200, description=OOB_SCORE_DESCRIPTION
        )

        # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
        # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)

        # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
        # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
        _, self.RFrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=12, column=0,
            pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )

        _, self.RFwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=13, column=0,
            labelWidth=200, description=WARM_START_DESCRIPTION
        )

    def set_sgd_classifier(self):
        pass
        layout = self.classificationLayouts['Stochastic Gradient Descent']
        _, self.SGDalphaDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=''
        )

        _, self.SGDaverageCheck = make_pair(
            pair='check', text='Average:', layout=layout, row=2, column=0,
            description=''
        )

        _, self.SGDeta0Dial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout, row=3,
            column=0, description=''
        )

        _, self.SGDepsilonDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:', layout=layout,
            row=4, column=0, description=''
        )

        _, self.SGDfitInterceptCheck = make_pair(
            pair='check', text='Fit Intercept:', layout=layout, row=5, column=0,
            description=''
        )

        _, self.SGDlearningRateCombo = make_pair(
            pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
            text='Learning Rate:', layout=layout, row=6, column=0, pairWidth=100,
            description=''
        )

        _, self.SGDlossCombo = make_pair(
            pair='combo', comboItems=(
                'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
            layout=layout,
            row=7, column=0, pairWidth=100, description=''
        )

        _, self.SGDl1RatioDial = make_pair(
            pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
            row=8, column=0, description=''
        )

        _, self.SGDmaxIterationsDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=9, column=0,
            description=''
        )

        _, self.SGDpenaltyCombo = make_pair(
            pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
            text='Penalty:', layout=layout, row=10, column=0, pairWidth=100,
            description=''
        )

        _, self.SGDpowerTDial = make_pair(
            pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
            row=11, column=0, description=''
        )

        _, self.SGDrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=12, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

        _, self.SGDshuffleCheck = make_pair(
            pair='check', text='Shuffle:', layout=layout, row=13, column=0,
            description=''
        )

        _, self.SGDtolDial = make_pair(
            pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:', layout=layout,
            row=14, column=0, description=''
        )

        _, self.SGDwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=15, column=0,
            description=''
        )

    def set_svm_classifier(self):
        pass
        layout = self.classificationLayouts['Support Vector Machine']
        _, self.SVMCDial = make_pair(
            pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
            column=0, description=C_DESCRIPTION
        )

        # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=0,
        #                                    description=CACHE_SIZE_DESCRIPTION)
        # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=1, width=50,
        #                                    description=CACHE_SIZE_DESCRIPTION)

        _, self.SVMcoef0Dial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:', layout=layout,
            row=2, column=0, description=COEF0_DESCRIPTION
        )
        # DecisionFunctionShape
        _, self.SVMdegreeCombo = make_pair(
            pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:', layout=layout,
            row=3, column=0, pairWidth=100, description=DEGREE_DESCRIPTION
        )

        _, self.SVMprobabilityCheck = make_pair(
            pair='check', text='Probability:', layout=layout, row=4, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMgammaDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout, row=5,
            column=0, description=GAMMA_DESCRIPTION
        )

        _, self.SVMkernelCombo = make_pair(
            pair='combo', comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
            text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
            description=KERNEL_DESCRIPTION
        )

        _, self.SVMmaxIterDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
            layout=layout, row=7, column=0, labelWidth=200,
            description=MAX_ITER_DESCRIPTION
        )

        _, self.SVMrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=8, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

        _, self.SVMshrinkingCheck = make_pair(
            pair='check', text='Shrinking:', layout=layout, row=9, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=10, column=0, description=TOL_DESCRIPTION
        )

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.classCombo = make_combo(
            self, [''] + self.headers, command=None, layout=self.classGrid, row=9, column=1,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.columnCombo.setCurrentText(self.headers[1])
        self.classCombo.setCurrentText(self.headers[2])

        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, row=0, column=0,
            width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            classification = self.classCombo.currentText()
            dir = self.readLabel.text()
            data, classLabels, xKeys, yKeys, labelKeys = dh.process_classification_data(
                dir, index, column,
                classification
            )
            # data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.iloc[:, 0],),)
            y = ((pd.DataFrame(data.iloc[:, 1]),),)
            make_plot(
                CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Raw Data',), xLabels=(index,), yLabels=(column,),
                lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print(e)

    def run(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        classification = self.classCombo.currentText()
        dir = self.readLabel.text()
        try:
            models = self.get_models()
            if self.validate(models):
                data, classLabels, xKeys, yKeys, labelKeys = dh.process_classification_data(
                    dir, index, column,
                    classification, )

                results = Classifiers.classification(models, x=data, y=classLabels)
                # data = pd.DataFrame(data, columns=(column,), index=data.index)
                x = ((data.iloc[:, 0],),)
                y = ((pd.DataFrame(data.iloc[:, 1]),),)
                make_contour_plot(
                    CLASSIFICATION_GRAPH, X=x, Y=y, boundaries=results, titles=('Classification',),
                    xLabels=(index,), yLabels=(column,), lineWidths=((1,),), legends=((True,),),
                    types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
                )
                self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print('lerk')
            print(e)

    def get_models(self):
        checks = [x.text() for x in self.modelSelection.selectedItems()]
        if self.autoCheck.isChecked():
            models = Classifiers.cross_validation_classification_models(checks)
        else:
            options = self.get_options()
            models = Classifiers.classification_models(checks, options)
        return models

    def validate(self, models):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if error == False:
            return True
        else:
            return False

    def export_results(self):
        print("loser")


class ClassificationMenu(MachineLearningMenu):
    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, CLASSIFIERS_NAMES, CLASSIFICATION_GRAPH, Classifiers)

    def get_options(self):
        options = {
            'abcEstimators':                    self.ABestimatorsDial.value(),
            'abcLearningRate':                  self.ABlearningRateDial.value() / 10.0,
            # 'abcLoss': self.ABlossCombo.currentText(),

            'dtcCriterion':                     self.DTcriterionCombo.currentText(),
            'dtcMaximumDepth':                  self.DTmaxDepthDial.value(),
            'dtcMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
            'dtcMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
            'dtcMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
            'dtcMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
            'dtcMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
            'dtcPresort':                       self.DTpresortCheck.isChecked(),
            'dtcRandomState':                   self.DTrandomStateEntry.text(),
            'dtcSplitter':                      self.DTsplitterCombo.currentText(),

            'gpcAlpha':                         None,  # self.GPalphaDial.value() / 100.0,
            'gpcKernel':                        None,  # self.GPkernelCombo.currentText(),
            'gpcNormalize':                     None,  # self.GPnormalizeCheck.isChecked(),
            'gpcOptimizer':                     None,  # self.GPoptimizerCombo.currentText(),

            'knncAlgorithm':                    self.KNNalgorithmCombo.currentText(),
            'knncLeafSize':                     self.KNNleafSizeDial.value(),
            'knncMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
            'knncNumberOfNeighbors':            self.KNNneighborsDial.value(),
            'knncWeightsFunction':              self.KNNweightsCombo.currentText(),

            'mlpcActivationFunction':           self.MLPactivationCombo.currentText(),
            # 'mlpcBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
            'mlpcEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
            'mlpcFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
            'mlpcHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
            'mlpcInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
            'mlpcLearningRate':                 self.MLPlearningRateCombo.currentText(),
            'mlpcMaximumIterations':            self.MLPmaxIterDial.value(),
            'mlpcMomentum':                     self.MLPmomentumDial.value() / 10.0,
            'mlpcNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
            'mlpcNumericalStability':           self.MLPepsilonDial.value() / 100.0,
            'mlpcPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
            'mlpcPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
            'mlpcRandomState':                  self.MLPrandomStateEntry.text(),
            'mlpcShuffle':                      self.MLPshuffleCheck.isChecked(),
            'mlpcSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
            'mlpcTolerance':                    self.MLPtolDial.value() / 100.0,
            'mlpcValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
            'mlpcWarmStart':                    self.MLPwarmStartCheck.isChecked(),
            'mlpcWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

            'nb':                               None,

            'qda':                              None,

            'rfcBootstrap':                     self.RFbootstrapCheck.isChecked(),
            'rfcCriterion':                     self.RFcriterionCombo.currentText(),
            'rfcMaximumDepth':                  self.RFmaxDepthDial.value(),
            'rfcMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
            'rfcMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
            'rfcMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
            'rfcMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
            'rfcMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
            'rfcMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
            'rfcNumberOfTrees':                 self.RFestimatorsDial.value(),
            'rfcOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
            'rfcRandomState':                   self.RFrandomStateEntry.text(),
            'rfcWarmStart':                     self.RFwarmStartCheck.isChecked(),

            'sgdcAlpha':                        self.SGDalphaDial.value() / 100000,
            'sgdcAverage':                      self.SGDaverageCheck.isChecked(),
            'sgdcEta0':                         self.SGDeta0Dial.value() / 10.0,
            'sgdcFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
            'sgdcLearningRate':                 self.SGDlearningRateCombo.currentText(),
            'sgdcLoss':                         self.SGDlossCombo.currentText(),
            'sgdcL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
            'sgdcMaxIterations':                self.SGDmaxIterationsDial.value(),
            'sgdcPenalty':                      self.SGDpenaltyCombo.currentText(),
            'sgdcPowerT':                       self.SGDpowerTDial.value() / 10.0,
            'sgdcShuffle':                      self.SGDshuffleCheck.isChecked(),
            'sgdcTolerance':                    self.SGDtolDial.value() / 100.0,
            'sgdcWarmStart':                    self.SGDwarmStartCheck.isChecked(),

            'svmcC':                            dh.nonize(self.SVMCDial.value()),
            # 'svmcCacheSize': self.SVMcacheSizeDial.value(),
            'svmcCoefficient0':                 self.SVMcoef0Dial.value() / 10.0,
            # 'svmcEpsilon': self.SVMepsilonDial.value() / 10.0,
            'svmcGamma':                        self.SVMgammaDial.value(),
            'svmcKernel':                       self.SVMkernelCombo.currentText(),
            'svmcMaximumIterations':            self.SVMmaxIterDial.value(),
            'svmcPolynomialDegree':             self.SVMdegreeCombo.currentText(),
            'svmcShrinking':                    self.SVMshrinkingCheck.isChecked(),
            'svmcTolerance':                    self.SVMtolDial.value() / 100.0,
        }
        return options

    def set_algorithms(self):
        def set_ab_classifier(self):
            layout = self.optionLayouts['Adaptive Boost']
            _, self.ABalgorithmCombo = make_pair(
                pair='combo', comboItems=('SAMME', 'SAMME.R'), text='Algorithm:',
                layout=layout, row=1, column=0, pairWidth=100, description=''
            )

            _, self.ABestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
                layout=layout, row=2, column=0, description=''
            )

            _, self.ABlearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
                layout=layout, row=3, column=0, description=''
            )

            _, self.ABrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=4, column=0,
                labelWidth=125, pairWidth=50, description=''
            )

        def set_dt_classifier(self):
            layout = self.optionLayouts['Decision Tree']
            _, self.DTcriterionCombo = make_pair(
                pair='combo', comboItems=('mse', 'friedman_mse', 'mae'),
                text='Criterion:', layout=layout, row=1, column=0, labelWidth=200,
                pairWidth=100, description=CRITERION_DESCRIPTION
            )

            _, self.DTmaxDepthDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
                layout=layout, row=2, column=0, labelWidth=125,
                description=MAX_DEPTH_DESCRIPTION
            )

            _, self.DTmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=3, column=0,
                labelWidth=200, pairWidth=50, description=MAX_FEATURES_DESCRIPTION
            )

            _, self.DTmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=4, column=0, labelWidth=200,
                description=MAX_LEAF_NODES_DESCRIPTION
            )

            _, self.DTmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=4, column=0, labelWidth=200,
                description=MAX_LEAF_NODES_DESCRIPTION
            )

            _, self.DTminImpurityDecreaseDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1),
                text='Min Impurity Decrease:', layout=layout, row=5, column=0,
                labelWidth=200, description=MIN_IMPURITY_DECREASE_DESCRIPTION
            )

            _, self.DTminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 4, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=6, column=0,
                labelWidth=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
            )

            _, self.DTminSamplesSplitDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Minimum Samples Split:', layout=layout, row=7, column=0,
                labelWidth=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
            )

            _, self.DTminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=8,
                column=0, labelWidth=220,
                description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
            )

            _, self.DTpresortCheck = make_pair(
                pair='check', text='Presort Data:', layout=layout, row=9, column=0,
                labelWidth=200, description=PRESORT_DESCRIPTION
            )

            _, self.DTrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=10, column=0,
                labelWidth=125, pairWidth=50, description=RANDOM_STATE_DESCRIPTION
            )

            _, self.DTsplitterCombo = make_pair(
                pair='combo', comboItems=('best', 'random'), text='Splitter:',
                layout=layout, row=11, column=0, pairWidth=75,
                description=SPLITTER_DESCRIPTION
            )

        def set_gp_classifier(self):
            layout = self.optionLayouts['Gaussian Process']
            _, self.GPrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=1, column=0,
                labelWidth=125, pairWidth=50, description=''
            )

            _, self.GPwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=2, column=0,
                description=''
            )

        def set_knn_classifier(self):
            layout = self.optionLayouts['Nearest Neighbors']
            _, self.KNNalgorithmCombo = make_pair(
                pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
                text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
                description=ALGORITHM_DESCRIPTION
            )

            # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
            # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

            _, self.KNNleafSizeDial = make_pair(
                pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:',
                layout=layout, row=2, column=0, description=LEAF_SIZE_DESCRIPTION
            )

            # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
            # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

            # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
            # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

            _, self.KNNminkowskiPowerDial = make_pair(
                pair='dial', dialSettings=(1, 100, 2, 1), text='Minkowski Power:',
                layout=layout, row=3, column=0, description=P_DESCRIPTION
            )

            _, self.KNNneighborsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 5, 1), text='Number of Neighbors:',
                layout=layout, row=4, column=0, labelWidth=200,
                description=N_NEIGHBORS_DESCRIPTION
            )

            _, self.KNNweightsCombo = make_pair(
                pair='combo', comboItems=('uniform', 'distance'),
                text='Weights Function:', layout=layout, row=5, column=0,
                labelWidth=200, pairWidth=100, description=WEIGHTS_DESCRIPTION
            )

        def set_mlp_classifier(self):
            layout = self.optionLayouts['Multilayer Perceptron']
            _, self.MLPactivationCombo = make_pair(
                pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
                text='Activation Function:', layout=layout, row=1, column=0,
                labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
            )

            _, self.MLPalphaDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1),
                text='Alpha (Penalty Parameter):', layout=layout, row=2, column=0,
                labelWidth=200, description=MLP_ALPHA_DESCRIPTION
            )

            # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=0, width=200,
            #                                    description=BATCH_SIZE_DESCRIPTION)
            # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=1, width=50,
            #                                    description=BATCH_SIZE_DESCRIPTION)

            _, self.MLPbeta1Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
                column=0, labelWidth=250, description=BETA_1_DESCRIPTION
            )

            _, self.MLPbeta2Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
                column=0, labelWidth=250, description=BETA_2_DESCRIPTION
            )

            _, self.MLPearlyStoppingCheck = make_pair(
                pair='check', text='Early Stopping:', layout=layout, row=5,
                column=0, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
            )

            _, self.MLPepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
                labelWidth=200, description=MLP_EPSILON_DESCRIPTION
            )

            _, self.MLPhiddenLayerSizesEntry = make_pair(
                pair='entry', text='Hidden Layer Sizes:', layout=layout, row=7,
                column=0, labelWidth=200, pairWidth=50,
                description=HIDDEN_LAYER_SIZES_DESCRIPTION
            )

            _, self.MLPinitLearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Initial Learning Rate:', layout=layout, row=8, column=0,
                labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
            )

            _, self.MLPlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
                text='Learning Rate:', layout=layout, row=9, column=0,
                labelWidth=200, pairWidth=100,
                description=LEARNING_RATE_DESCRIPTION
            )

            _, self.MLPmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=10, column=0, labelWidth=250,
                description=MLP_MAX_ITER_DESCRIPTION
            )

            _, self.MLPmomentumDial = make_pair(
                pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
                layout=layout, row=11, column=0, description=MOMENTUM_DESCRIPTION
            )

            _, self.MLPnesterovsMomentumCheck = make_pair(
                pair='check', text='Nesterov\'s Momentum:', layout=layout,
                row=12, column=0, labelWidth=200,
                description=NESTEROVS_MOMENTUM_DESCRIPTION
            )

            _, self.MLPpowerTDial = make_pair(
                pair='dial', dialSettings=(1, 10, 5, 1),
                text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
                labelWidth=250, description=POWER_T_DESCRIPTION
            )

            _, self.MLPrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=14, column=0,
                pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
            )

            _, self.MLPshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=15, column=0,
                description=SHUFFLE_DESCRIPTION
            )

            _, self.MLPsolverCombo = make_pair(
                pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
                text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
                labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
            )

            _, self.MLPtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=17, column=0, description=MLP_TOL_DESCRIPTION
            )

            _, self.MLPvalidationFractionDial = make_pair(
                pair='dial', dialSettings=(1, 9, 9, 1),
                text='Validation Fraction:', layout=layout, row=18, column=0,
                labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
            )

            # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
            # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

            _, self.MLPwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=19, column=0,
                labelWidth=200, description=MLP_WARM_START_DESCRIPTION
            )

        def set_nb_classifier(self):
            pass

        def set_qda_classifier(self):
            layout = self.optionLayouts['Quadratic Discriminant']
            _, self.QDAregParamDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1),
                text='Regularization Parameter:', layout=layout, row=1, column=0,
                description=''
            )

            _, self.QDAstoreCovarianceCheck = make_pair(
                pair='check', text='Store Covariance:', layout=layout, row=2,
                column=0, description=''
            )

            _, self.QDAtolDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Tolerance:', layout=layout,
                row=3, column=0, description=''
            )

        def set_rf_classifier(self):
            layout = self.optionLayouts['Random Forest']
            _, self.RFbootstrapCheck = make_pair(
                pair='check', text='Bootstrap:', layout=layout, row=1, column=0,
                description=BOOTSTRAP_DESCRIPTION
            )

            _, self.RFcriterionCombo = make_pair(
                pair='combo', comboItems=('mse', 'mae'), text='Criterion:',
                layout=layout, row=2, column=0, pairWidth=50,
                description=CRITERION_DESCRIPTION
            )

            _, self.RFmaxDepthDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
                layout=layout, row=3, column=0, description=MAX_DEPTH_DESCRIPTION
            )

            _, self.RFmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=4, column=0,
                labelWidth=200, pairWidth=50, description=MAX_FEATURES_DESCRIPTION
            )

            _, self.RFmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=5, column=0, labelWidth=220,
                description=MAX_LEAF_NODES_DESCRIPTION
            )

            _, self.RFminImpurityDecreaseDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Minimum Impurity Decrease:', layout=layout, row=6,
                column=0, labelWidth=220,
                description=MIN_IMPURITY_DECREASE_DESCRIPTION
            )

            _, self.RFminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=7, column=0,
                labelWidth=220, description=MIN_SAMPLES_LEAF_DESCRIPTION
            )

            _, self.RFminSamplesSplitDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Minimum Samples Split:', layout=layout, row=8, column=0,
                labelWidth=175, description=MIN_SAMPLES_SPLIT_DESCRIPTION
            )

            _, self.RFminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=9,
                column=0, labelWidth=220,
                description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
            )

            _, self.RFestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
                layout=layout, row=10, column=0, labelWidth=200,
                description=N_ESTIMATORS_DESCRIPTION
            )

            _, self.RFoobScoreCheck = make_pair(
                pair='check', text='Out-of-Bag Samples:', layout=layout, row=11,
                column=0, labelWidth=200, description=OOB_SCORE_DESCRIPTION
            )

            # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
            # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)

            # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
            # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
            _, self.RFrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=12, column=0,
                pairWidth=50, description=RANDOM_STATE_DESCRIPTION
            )

            _, self.RFwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=13, column=0,
                labelWidth=200, description=WARM_START_DESCRIPTION
            )

        def set_sgd_classifier(self):
            pass
            layout = self.optionLayouts['Stochastic Gradient Descent']
            _, self.SGDalphaDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout,
                row=1, column=0, description=''
            )

            _, self.SGDaverageCheck = make_pair(
                pair='check', text='Average:', layout=layout, row=2, column=0,
                description=''
            )

            _, self.SGDeta0Dial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout,
                row=3, column=0, description=''
            )

            _, self.SGDepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:', layout=layout,
                row=4, column=0, description=''
            )

            _, self.SGDfitInterceptCheck = make_pair(
                pair='check', text='Fit Intercept:', layout=layout, row=5,
                column=0, description=''
            )

            _, self.SGDlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
                text='Learning Rate:', layout=layout, row=6, column=0,
                pairWidth=100, description=''
            )

            _, self.SGDlossCombo = make_pair(
                pair='combo', comboItems=(
                    'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
                layout=layout, row=7, column=0, pairWidth=100, description=''
            )

            _, self.SGDl1RatioDial = make_pair(
                pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
                row=8, column=0, description=''
            )

            _, self.SGDmaxIterationsDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1),
                text='Maximum Iterations:', layout=layout, row=9, column=0,
                description=''
            )

            _, self.SGDpenaltyCombo = make_pair(
                pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
                text='Penalty:', layout=layout, row=10, column=0, pairWidth=100,
                description=''
            )

            _, self.SGDpowerTDial = make_pair(
                pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
                row=11, column=0, description=''
            )

            _, self.SGDrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=12, column=0,
                labelWidth=125, pairWidth=50, description=''
            )

            _, self.SGDshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=13, column=0,
                description=''
            )

            _, self.SGDtolDial = make_pair(
                pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:', layout=layout,
                row=14, column=0, description=''
            )

            _, self.SGDwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=15, column=0,
                description=''
            )

        def set_svm_classifier(self):
            pass
            layout = self.optionLayouts['Support Vector Machine']
            _, self.SVMCDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
                column=0, description=C_DESCRIPTION
            )

            # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=0,
            #                                    description=CACHE_SIZE_DESCRIPTION)
            # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=1, width=50,
            #                                    description=CACHE_SIZE_DESCRIPTION)

            _, self.SVMcoef0Dial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
                layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
            )
            # DecisionFunctionShape
            _, self.SVMdegreeCombo = make_pair(
                pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
                layout=layout, row=3, column=0, pairWidth=100,
                description=DEGREE_DESCRIPTION
            )

            _, self.SVMprobabilityCheck = make_pair(
                pair='check', text='Probability:', layout=layout, row=4, column=0,
                description=SHRINKING_DESCRIPTION
            )

            _, self.SVMgammaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
                row=5, column=0, description=GAMMA_DESCRIPTION
            )

            _, self.SVMkernelCombo = make_pair(
                pair='combo',
                comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
                text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
                description=KERNEL_DESCRIPTION
            )

            _, self.SVMmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=7, column=0, labelWidth=200,
                description=MAX_ITER_DESCRIPTION
            )

            _, self.SVMrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=8, column=0,
                labelWidth=125, pairWidth=50, description=''
            )

            _, self.SVMshrinkingCheck = make_pair(
                pair='check', text='Shrinking:', layout=layout, row=9, column=0,
                description=SHRINKING_DESCRIPTION
            )

            _, self.SVMtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=10, column=0, description=TOL_DESCRIPTION
            )

        set_ab_classifier(self)
        set_dt_classifier(self)
        set_gp_classifier(self)
        set_knn_classifier(self)
        set_mlp_classifier(self)
        set_nb_classifier(self)
        set_qda_classifier(self)
        set_rf_classifier(self)
        set_sgd_classifier(self)
        set_svm_classifier(self)

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.classCombo = make_combo(
            self, [''] + self.headers, command=None, layout=self.classGrid, row=9, column=1,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            row=9, column=1, width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, row=9,
            column=1, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        self.columnCombo.setCurrentText(self.headers[1])
        self.classCombo.setCurrentText(self.headers[2])

        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, row=9, column=1,
            width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            classification = self.classCombo.currentText()
            dir = self.readLabel.text()
            data, classLabels, xKeys, yKeys, labelKeys = dh.process_classification_data(
                dir, index, column,
                classification
            )
            # data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.iloc[:, 0],),)
            y = ((pd.DataFrame(data.iloc[:, 1]),),)
            make_plot(
                CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Raw Data',), xLabels=(index,), yLabels=(column,),
                lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print(e)

    def run(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        classification = self.classCombo.currentText()
        dir = self.readLabel.text()
        try:
            models = self.get_models()
            if self.validate(models):
                data, classLabels, xKeys, yKeys, labelKeys = dh.process_classification_data(
                    dir, index, column,
                    classification, )

                results = Classifiers.classification(models, x=data, y=classLabels)
                # data = pd.DataFrame(data, columns=(column,), index=data.index)
                x = ((data.iloc[:, 0],),)
                y = ((pd.DataFrame(data.iloc[:, 1]),),)
                make_contour_plot(
                    CLASSIFICATION_GRAPH, X=x, Y=y, boundaries=results, titles=('Classification',),
                    xLabels=(index,), yLabels=(column,), lineWidths=((1,),), legends=((True,),),
                    types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
                )
                self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print('lerk')
            print(e)

    def validate(self, models):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, CLASSIFIERS_NAMES, CLASSIFICATION_GRAPH, Classifiers)
        self.resultsSuffix = ' classification0 results'

    def get_options(self):
        options = {name: None for name in CLASSIFIERS_NAMES}

        options['Adaptive Boost'] = {
            'algorithm':     self.ABalgorithmCombo.currentText(),
            'learning_rate': self.ABlearningRateDial.value() / 10.0,
            'n_estimators':  self.ABestimatorsDial.value()
        }

        options['Decision Tree'] = {
            'criterion':                self.DTcriterionCombo.currentText(),
            'max_depth':                self.DTmaxDepthDial.value(),
            'max_features':             self.DTmaxFeaturesCombo.currentText(),
            'max_leaf_nodes':           self.DTmaxLeafNodesDial.value(),
            'min_samples_leaf':         self.DTminSamplesLeafDial.value() / 10.0,
            'min_weight_fraction_leaf': self.DTminWeightFractionLeafDial.value() / 10.0,
            'presort':                  self.DTpresortCheck.isChecked(),
            'splitter':                 self.DTsplitterCombo.currentText()
        }

        options['Gaussian Process'] = {
            'copy_X_train':         False, 'max_iter_predict': self.GPmaxIterPredict.value(),
            'n_restarts_optimizer': self.GPnRestartsOptimizer.value(),
            'warm_start':           self.GPwarmStartCheck.isChecked()
        }

        options['Multilayer Perceptron'] = {
            'activation':          self.MLPactivationCombo.currentText(),
            'alpha':               self.MLPalphaDial.value() / 100000.0,
            'beta_1':              self.MLPbeta1Dial.value() / 100.0,
            'beta_2':              self.MLPbeta2Dial.value() / 100.0,
            'early_stopping':      self.MLPearlyStoppingCheck.isChecked(),
            'epsilon':             self.MLPepsilonDial.value() / 100.0,
            'hidden_layer_sizes':  self.MLPhiddenLayerSizesEntry.text(),
            'learning_rate':       self.MLPlearningRateCombo.currentText(),
            'learning_rate_init':  self.MLPinitLearningRateDial.value() / 10.0,
            'max_iter':            self.MLPmaxIterDial.value(),
            'momentum':            self.MLPmomentumDial.value() / 10.0,
            'nesterovs_momentum':  self.MLPnesterovsMomentumCheck.isChecked(),
            'power_t':             self.MLPpowerTDial.value() / 10.0,
            'shuffle':             self.MLPshuffleCheck.isChecked(),
            'solver':              self.MLPsolverCombo.currentText(),
            'tol':                 self.MLPtolDial.value() / 100.0,
            'validation_fraction': self.MLPvalidationFractionDial.value() / 10.0,
            'warm_start':          self.MLPwarmStartCheck.isChecked()
        }

        options['Naive Bayes'] = {}

        options['Nearest Neighbors'] = {
            'algorithm':   self.KNNalgorithmCombo.currentText(),
            'leaf_size':   self.KNNleafSizeDial.value(),
            'n_neighbors': self.KNNneighborsDial.value(),
            'p':           self.KNNminkowskiPowerDial.value(),
            'weights':     self.KNNweightsCombo.currentText(),
        }

        options['Quadratic Discriminant'] = {
            'reg_param':        self.QDAregParamDial.value() / 100.0,
            'store_covariance': self.QDAstoreCovarianceCheck.isChecked(),
            'tol':              self.QDAtolDial.value() / 1000.0
        }

        options['Random Forest'] = {
            'bootstrap2':                self.RFbootstrapCheck.isChecked(),
            'criterion':                self.RFcriterionCombo.currentText(),
            'max_depth':                self.RFmaxDepthDial.value(),
            'max_features':             self.RFmaxFeaturesCombo.currentText(),
            'max_leaf_nodes':           self.RFmaxLeafNodesDial.value(),
            'min_impurity_decrease':    self.RFminImpurityDecreaseDial.value() / 10.0,
            'min_samples_leaf':         self.RFminSamplesLeafDial.value() / 10.0,
            'min_samples_split':        self.RFminSamplesSplitDial.value() / 10.0,
            'min_weight_fraction_leaf': self.RFminWeightFractionLeafDial.value() / 10.0,
            'n_estimators':             self.RFestimatorsDial.value(),
            'oob_score':                self.RFoobScoreCheck.isChecked(),
            'warm_start':               self.RFwarmStartCheck.isChecked()
        }

        options['Stochastic Gradient Descent'] = {
            'alpha':         self.SGDalphaDial.value() / 100000,
            'average':       self.SGDaverageCheck.isChecked(),
            'eta0':          self.SGDeta0Dial.value() / 10.0,
            'fit_intercept': self.SGDfitInterceptCheck.isChecked(),
            'learning_rate': self.SGDlearningRateCombo.currentText(),
            'loss':          self.SGDlossCombo.currentText(),
            'l1_ratio':      self.SGDl1RatioDial.value() / 10.0,
            'max_iter':      self.SGDmaxIterationsDial.value(),
            'penalty':       self.SGDpenaltyCombo.currentText(),
            'power_t':       self.SGDpowerTDial.value() / 10.0,
            'shuffle':       self.SGDshuffleCheck.isChecked(),
            'tol':           self.SGDtolDial.value() / 100.0,
            'warm_start':    self.SGDwarmStartCheck.isChecked(),
        }

        options['Support Vector Machine'] = {
            'C':                       dh.nonize(self.SVMCDial.value()),
            'coef0':                   self.SVMcoef0Dial.value() / 10.0,
            'decision_function_shape': self.SVMdecisionFunctionShapeCombo.currentText(),
            'degree':                  self.SVMdegreeCombo.currentText(),
            'gamma':                   self.SVMgammaDial.value(),
            'kernel':                  self.SVMkernelCombo.currentText(),
            'max_iter':                self.SVMmaxIterDial.value(),
            'shrinking':               self.SVMshrinkingCheck.isChecked(),
            'tol':                     self.SVMtolDial.value() / 100.0,
        }

        return options

    def set_algorithms(self):
        def set_ab_classifier(self):
            layout = self.optionLayouts['Adaptive Boost']
            _, self.ABalgorithmCombo = make_pair(
                pair='combo', comboItems=('SAMME', 'SAMME.R'), text='Algorithm:',
                layout=layout, row=1, column=0, pairWidth=100, description=''
            )

            _, self.ABestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
                layout=layout, row=2, column=0, description=''
            )

            _, self.ABlearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
                layout=layout, row=3, column=0, description=''
            )

            """_, self.ABrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=3, column=0, labelWidth=125, pairWidth=50,
                                                   description='')"""

        def set_dt_classifier(self):
            layout = self.optionLayouts['Decision Tree']
            _, self.DTcriterionCombo = make_pair(
                pair='combo', comboItems=('gini', 'entropy'), text='Criterion:',
                layout=layout, row=1, column=0, labelWidth=200, pairWidth=100,
                description=CRITERION_DESCRIPTION
            )

            _, self.DTmaxDepthDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
                layout=layout, row=2, column=0, labelWidth=125, description=''
            )

            _, self.DTmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=3, column=0,
                labelWidth=200, pairWidth=50, description=''
            )

            _, self.DTmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=4, column=0, labelWidth=200, description=''
            )

            _, self.DTmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=4, column=0, labelWidth=200, description=''
            )

            """_, self.DTminImpurityDecreaseDial = make_pair(pair='dial',
                                                          dialSettings=(0, 100, 0, 1),
                                                          text='Min Impurity Decrease:',
                                                          layout=layout,
                                                          row=5, column=0, labelWidth=200,
                                                          description=MIN_IMPURITY_DECREASE_DESCRIPTION)"""

            _, self.DTminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 4, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=6, column=0,
                labelWidth=200, description=''
            )

            """_, self.DTminSamplesSplitDial = make_pair(pair='dial',
                                                      dialSettings=(1, 10, 1, 1),
                                                      text='Minimum Samples Split:',
                                                      layout=layout,
                                                      row=3, column=0, labelWidth=150,
                                                      description=MIN_SAMPLES_SPLIT_DESCRIPTION)"""

            _, self.DTminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 5, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=8,
                column=0, labelWidth=220, description=''
            )

            _, self.DTpresortCheck = make_pair(
                pair='check', text='Presort Data:', layout=layout, row=9, column=0,
                labelWidth=200, description=PRESORT_DESCRIPTION
            )

            """_, self.DTrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=10, column=0, labelWidth=125, pairWidth=50,
                                                   description=RANDOM_STATE_DESCRIPTION)"""

            _, self.DTsplitterCombo = make_pair(
                pair='combo', comboItems=('best', 'random'), text='Splitter:',
                layout=layout, row=11, column=0, pairWidth=75,
                description=SPLITTER_DESCRIPTION
            )

        def set_gp_classifier(self):
            layout = self.optionLayouts['Gaussian Process']
            """_, self.GPrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=1, column=0, labelWidth=125, pairWidth=50,
                                                   description='')"""
            _, self.GPmaxIterPredict = make_pair(
                pair='dial', dialSettings=(1, 1000, 1, 1), text='Maximum Iterations:',
                layout=layout, row=0, column=0, description=''
            )

            _, self.GPnRestartsOptimizer = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Number of Restarts:', layout=layout, row=0, column=1,
                description=''
            )

            _, self.GPwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=0, column=2,
                description=''
            )

        def set_knn_classifier(self):
            layout = self.optionLayouts['Nearest Neighbors']
            _, self.KNNalgorithmCombo = make_pair(
                pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
                text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
                description=ALGORITHM_DESCRIPTION
            )

            # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
            # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

            _, self.KNNleafSizeDial = make_pair(
                pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:',
                layout=layout, row=2, column=0, description=LEAF_SIZE_DESCRIPTION
            )

            # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
            # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

            # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
            # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

            _, self.KNNminkowskiPowerDial = make_pair(
                pair='dial', dialSettings=(1, 100, 2, 1), text='Minkowski Power:',
                layout=layout, row=3, column=0, description=''
            )

            _, self.KNNneighborsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 5, 1), text='Number of Neighbors:',
                layout=layout, row=4, column=0, labelWidth=200, description=''
            )

            _, self.KNNweightsCombo = make_pair(
                pair='combo', comboItems=('uniform', 'distance'),
                text='Weights Function:', layout=layout, row=5, column=0,
                labelWidth=200, pairWidth=100, description=''
            )

        def set_mlp_classifier(self):
            layout = self.optionLayouts['Multilayer Perceptron']
            _, self.MLPactivationCombo = make_pair(
                pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
                text='Activation Function:', layout=layout, row=1, column=0,
                labelWidth=200, pairWidth=100, description=''
            )

            _, self.MLPalphaDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1),
                text='Alpha (Penalty Parameter):', layout=layout, row=2, column=0,
                labelWidth=200, description=''
            )

            # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=0, width=200,
            #                                    description=BATCH_SIZE_DESCRIPTION)
            # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=1, width=50,
            #                                    description=BATCH_SIZE_DESCRIPTION)

            _, self.MLPbeta1Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
                column=0, labelWidth=250, description=''
            )

            _, self.MLPbeta2Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
                column=0, labelWidth=250, description=''
            )

            _, self.MLPearlyStoppingCheck = make_pair(
                pair='check', text='Early Stopping:', layout=layout, row=5,
                column=0, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
            )

            _, self.MLPepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
                labelWidth=200, description=''
            )

            _, self.MLPhiddenLayerSizesEntry = make_pair(
                pair='entry', text='Hidden Layer Sizes:', layout=layout, row=7,
                column=0, labelWidth=200, pairWidth=50,
                description=HIDDEN_LAYER_SIZES_DESCRIPTION
            )

            _, self.MLPinitLearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Initial Learning Rate:', layout=layout, row=8, column=0,
                labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
            )

            _, self.MLPlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
                text='Learning Rate:', layout=layout, row=9, column=0,
                labelWidth=200, pairWidth=100,
                description=LEARNING_RATE_DESCRIPTION
            )

            _, self.MLPmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=10, column=0, labelWidth=250, description=''
            )

            _, self.MLPmomentumDial = make_pair(
                pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
                layout=layout, row=11, column=0, description=MOMENTUM_DESCRIPTION
            )

            _, self.MLPnesterovsMomentumCheck = make_pair(
                pair='check', text='Nesterov\'s Momentum:', layout=layout,
                row=12, column=0, labelWidth=200,
                description=NESTEROVS_MOMENTUM_DESCRIPTION
            )

            _, self.MLPpowerTDial = make_pair(
                pair='dial', dialSettings=(1, 10, 5, 1),
                text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
                labelWidth=250, description=POWER_T_DESCRIPTION
            )

            """_, self.MLPrandomStateEntry = make_pair(pair='entry',
                                                    text='Random State:',
                                                    layout=layout,
                                                    row=14, column=0, pairWidth=50,
                                                    description=MLP_RANDOM_STATE_DESCRIPTION)"""

            _, self.MLPshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=15, column=0,
                description=SHUFFLE_DESCRIPTION
            )

            _, self.MLPsolverCombo = make_pair(
                pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
                text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
                labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
            )

            _, self.MLPtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=17, column=0, description=''
            )

            _, self.MLPvalidationFractionDial = make_pair(
                pair='dial', dialSettings=(1, 9, 9, 1),
                text='Validation Fraction:', layout=layout, row=18, column=0,
                labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
            )

            # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
            # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

            _, self.MLPwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=19, column=0,
                labelWidth=200, description=''
            )

        def set_nb_classifier(self):
            layout = self.optionLayouts['Naive Bayes']
            _ = make_label(None, text='No settings.', layout=layout)

        def set_qda_classifier(self):
            layout = self.optionLayouts['Quadratic Discriminant']
            _, self.QDAregParamDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1),
                text='Regularization Parameter:', layout=layout, row=1, column=0,
                description=''
            )

            _, self.QDAstoreCovarianceCheck = make_pair(
                pair='check', text='Store Covariance:', layout=layout, row=2,
                column=0, description=''
            )

            _, self.QDAtolDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Tolerance:', layout=layout,
                row=3, column=0, description=''
            )

        def set_rf_classifier(self):
            layout = self.optionLayouts['Random Forest']
            _, self.RFbootstrapCheck = make_pair(
                pair='check', text='Bootstrap:', layout=layout, row=1, column=0,
                description=BOOTSTRAP_DESCRIPTION
            )

            _, self.RFcriterionCombo = make_pair(
                pair='combo', comboItems=('gini', 'entropy'), text='Criterion:',
                layout=layout, row=2, column=0, pairWidth=50,
                description=CRITERION_DESCRIPTION
            )

            _, self.RFmaxDepthDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='Maximum Depth:',
                layout=layout, row=3, column=0, description=''
            )

            _, self.RFmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=4, column=0,
                labelWidth=200, pairWidth=50, description=''
            )

            _, self.RFmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(2, 100, 2, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=5, column=0, labelWidth=220, description=''
            )

            _, self.RFminImpurityDecreaseDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Minimum Impurity Decrease:', layout=layout, row=6,
                column=0, labelWidth=220, description=''
            )

            _, self.RFminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 5, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=7, column=0,
                labelWidth=220, description=''
            )

            _, self.RFminSamplesSplitDial = make_pair(
                pair='dial', dialSettings=(1, 10, 2, 1),
                text='Minimum Samples Split:', layout=layout, row=8, column=0,
                labelWidth=175, description=''
            )

            _, self.RFminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 5, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=9,
                column=0, labelWidth=220, description=''
            )

            _, self.RFestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
                layout=layout, row=10, column=0, labelWidth=200, description=''
            )

            _, self.RFoobScoreCheck = make_pair(
                pair='check', text='Out-of-Bag Samples:', layout=layout, row=11,
                column=0, labelWidth=200, description=''
            )

            # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
            # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)

            # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
            # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
            """_, self.RFrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=12, column=0, pairWidth=50,
                                                   description=RANDOM_STATE_DESCRIPTION)"""

            _, self.RFwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=13, column=0,
                labelWidth=200, description=WARM_START_DESCRIPTION
            )

        def set_sgd_classifier(self):
            pass
            layout = self.optionLayouts['Stochastic Gradient Descent']
            _, self.SGDalphaDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout,
                row=1, column=0, description=''
            )

            _, self.SGDaverageCheck = make_pair(
                pair='check', text='Average:', layout=layout, row=2, column=0,
                description=''
            )

            _, self.SGDeta0Dial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout,
                row=3, column=0, description=''
            )

            _, self.SGDepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:', layout=layout,
                row=4, column=0, description=''
            )

            _, self.SGDfitInterceptCheck = make_pair(
                pair='check', text='Fit Intercept:', layout=layout, row=5,
                column=0, description=''
            )

            _, self.SGDlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
                text='Learning Rate:', layout=layout, row=6, column=0,
                pairWidth=100, description=''
            )

            _, self.SGDlossCombo = make_pair(
                pair='combo', comboItems=(
                    'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
                layout=layout, row=7, column=0, pairWidth=100, description=''
            )

            _, self.SGDl1RatioDial = make_pair(
                pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
                row=8, column=0, description=''
            )

            _, self.SGDmaxIterationsDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1),
                text='Maximum Iterations:', layout=layout, row=9, column=0,
                description=''
            )

            _, self.SGDpenaltyCombo = make_pair(
                pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
                text='Penalty:', layout=layout, row=10, column=0, pairWidth=100,
                description=''
            )

            _, self.SGDpowerTDial = make_pair(
                pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
                row=11, column=0, description=''
            )

            """_, self.SGDrandomStateEntry = make_pair(pair='entry',
                                                    text='Random State:',
                                                    layout=layout,
                                                    row=12, column=0, labelWidth=125, pairWidth=50,
                                                    description='')"""

            _, self.SGDshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=13, column=0,
                description=''
            )

            _, self.SGDtolDial = make_pair(
                pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:', layout=layout,
                row=14, column=0, description=''
            )

            _, self.SGDwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=15, column=0,
                description=''
            )

        def set_svm_classifier(self):
            layout = self.optionLayouts['Support Vector Machine']
            _, self.SVMCDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
                column=0, description=C_DESCRIPTION
            )

            # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=0,
            #                                    description=CACHE_SIZE_DESCRIPTION)
            # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=1, width=50,
            #                                    description=CACHE_SIZE_DESCRIPTION)

            _, self.SVMcoef0Dial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
                layout=layout, row=2, column=0, description=''
            )

            _, self.SVMdecisionFunctionShapeCombo = make_pair(
                pair='combo', comboItems=('ovr', 'ovo'),
                text='Decision Function Shape:', layout=layout, row=3,
                column=0, pairWidth=100, description=''
            )

            _, self.SVMdegreeCombo = make_pair(
                pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
                layout=layout, row=3, column=0, pairWidth=100, description=''
            )

            _, self.SVMgammaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
                row=5, column=0, description=GAMMA_DESCRIPTION
            )

            _, self.SVMkernelCombo = make_pair(
                pair='combo',
                comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
                text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
                description=KERNEL_DESCRIPTION
            )

            _, self.SVMmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=7, column=0, labelWidth=200, description=''
            )

            _, self.SVMrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=8, column=0,
                labelWidth=125, pairWidth=50, description=''
            )

            _, self.SVMshrinkingCheck = make_pair(
                pair='check', text='Shrinking:', layout=layout, row=9, column=0,
                description=SHRINKING_DESCRIPTION
            )

            _, self.SVMtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=10, column=0, description=''
            )

        set_ab_classifier(self)
        set_dt_classifier(self)
        set_gp_classifier(self)
        set_knn_classifier(self)
        set_mlp_classifier(self)
        set_nb_classifier(self)
        set_qda_classifier(self)
        set_rf_classifier(self)
        set_sgd_classifier(self)
        set_svm_classifier(self)

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.inputsSelection.clear()
        self.inputsSelection.addItems(self.headers)

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.classCombo = make_combo(
            items=[''] + self.headers, command=self.graph_raw, layout=self.classGrid,
            width=200, description=''
        )

        self.columnCombo.setCurrentText(self.headers[1])
        self.classCombo.setCurrentText(self.headers[2])

        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            classification = self.classCombo.currentText()
            dir = self.readLabel.text()
            data, classLabels, xKeys, yKeys, labelKeys, classifiedMatrix = dh.process_classification_data(
                dir, index,
                column,
                classification
            )
            x = [[i.loc[:, 'index'] for i in classifiedMatrix]]
            y = [[pd.DataFrame(i.iloc[:, 1], columns=[i.columns[1]]) for i in classifiedMatrix]]

            make_plot(
                CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Raw Data',), xLabels=(index,), yLabels=(column,),
                lineWidths=([1 for i in classifiedMatrix],), legends=([True for i in classifiedMatrix],),
                types=(['scatter' for i in classifiedMatrix],), xKeys=(xKeys,), yKeys=(yKeys,),
                colors=[[[c] for c in COLOR_SET[:len(classifiedMatrix)]]]
            )
            self.mainPlotContainer = load_browser(self.mainPlotContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print(e)

    def run(self):
        try:
            mode, index, column, dir, models, scaler = self.get_parameters()
            classification = self.classCombo.currentText()
            if self.validate(models):
                data, classLabels, xKeys, yKeys, labelKeys, classifiedMatrix = dh.process_classification_data(
                    dir,
                    index,
                    column,
                    classification
                )

                results = Classifiers.classification(models, x=data, y=classLabels)
                # data = pd.DataFrame(data, columns=(column,), index=data.index)
                # x = ((data.iloc[:, 0],),)
                # y = ((pd.DataFrame(data.iloc[:, 1]),),)
                x = [[i.loc[:, 'index'] for i in classifiedMatrix]]
                y = [[pd.DataFrame(i.iloc[:, 1], columns=[i.columns[1]]) for i in classifiedMatrix]]
                make_contour_plot(
                    CLASSIFICATION_GRAPH, X=x, Y=y, boundaries=results, titles=('Classification',),
                    xLabels=(index,), yLabels=(column,), lineWidths=([1 for i in classifiedMatrix],),
                    legends=([True for i in classifiedMatrix],),
                    types=(['scatter' for i in classifiedMatrix],), xKeys=(xKeys,), yKeys=(yKeys,),
                    colors=[[[c] for c in COLOR_SET[:len(classifiedMatrix)]]]
                )
                self.mainPlotContainer = load_browser(self.mainPlotContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print('lerk')
            print(e)

    def validate(self, models):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, CLASSIFIERS_NAMES, CLASSIFICATION_GRAPH, Classifiers)

    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, CLASSIFIERS_NAMES, CLASSIFICATION_GRAPH, Classifiers)
        self.resultsSuffix = ' classification0 results'

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            classification = self.classCombo.currentText()
            dir = self.readLabel.text()
            data, classLabels, xKeys, yKeys, labelKeys, classifiedMatrix = dh.process_classification_data(
                dir, index,
                column,
                classification
            )
            # data = pd.DataFrame(data, columns=(column,), index=data.index)
            # x = [[data.iloc[:, 0]]]
            # y = [[pd.DataFrame(data.iloc[:, 1])]]
            x = [[i.loc[:, 'index'] for i in classifiedMatrix]]
            y = [[pd.DataFrame(i.iloc[:, 1], columns=[i.columns[1]]) for i in classifiedMatrix]]

            make_plot(
                CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Raw Data',), xLabels=(index,), yLabels=(column,),
                lineWidths=([1 for i in classifiedMatrix],), legends=([True for i in classifiedMatrix],),
                types=(['scatter' for i in classifiedMatrix],), xKeys=(xKeys,), yKeys=(yKeys,),
                colors=[[[c] for c in COLOR_SET[:len(classifiedMatrix)]]]
            )
            self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print(e)

    def run(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        classification = self.classCombo.currentText()
        dir = self.readLabel.text()
        try:
            models = self.get_models()
            if self.validate(models):
                data, classLabels, xKeys, yKeys, labelKeys, classifiedMatrix = dh.process_classification_data(
                    dir,
                    index,
                    column,
                    classification
                )

                results = Classifiers.classification(models, x=data, y=classLabels)
                # data = pd.DataFrame(data, columns=(column,), index=data.index)
                # x = ((data.iloc[:, 0],),)
                # y = ((pd.DataFrame(data.iloc[:, 1]),),)
                x = [[i.loc[:, 'index'] for i in classifiedMatrix]]
                y = [[pd.DataFrame(i.iloc[:, 1], columns=[i.columns[1]]) for i in classifiedMatrix]]
                make_contour_plot(
                    CLASSIFICATION_GRAPH, X=x, Y=y, boundaries=results, titles=('Classification',),
                    xLabels=(index,), yLabels=(column,), lineWidths=([1 for i in classifiedMatrix],),
                    legends=([True for i in classifiedMatrix],),
                    types=(['scatter' for i in classifiedMatrix],), xKeys=(xKeys,), yKeys=(yKeys,),
                    colors=[[[c] for c in COLOR_SET[:len(classifiedMatrix)]]]
                )
                self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print('lerk')
            print(e)

    def validate(self, models):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if error == False:
            return True
        else:
            return False

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            classification = self.classCombo.currentText()
            dir = self.readLabel.text()
            data, classLabels, xKeys, yKeys, labelKeys, classifiedMatrix = DataProcessor.process_classification_data(
                dir, index, column, classification
            )
            x = [[i.loc[:, 'index'] for i in classifiedMatrix]]
            y = [[pd.DataFrame(i.iloc[:, 1], columns=[i.columns[1]]) for i in classifiedMatrix]]

            DynamicPlotGenerator.make_plot(
                CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Raw Data',), xLabels=(index,),
                yLabels=(column,), lineWidths=([1 for i in classifiedMatrix],),
                legends=([True for i in classifiedMatrix],),
                types=(['scatter' for i in classifiedMatrix],), xKeys=(xKeys,),
                yKeys=(yKeys,), colors=[[[c] for c in COLOR_SET[:len(classifiedMatrix)]]]
            )
            self.mainPlotContainer = load_browser(self.mainPlotContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print(e)

    def run(self):
        try:
            mode, index, column, dir, models, scaler = self.get_parameters()
            classification = self.classCombo.currentText()
            if self.validate(models):
                data, classLabels, xKeys, yKeys, labelKeys, classifiedMatrix = DataProcessor.process_classification_data(
                    dir, index, column, classification
                )

                results = Classifiers.classification(models, x=data, y=classLabels)
                # data = pd.DataFrame(data, columns=(column,), index=data.index)
                # x = ((data.iloc[:, 0],),)
                # y = ((pd.DataFrame(data.iloc[:, 1]),),)
                x = [[i.loc[:, 'index'] for i in classifiedMatrix]]
                y = [[pd.DataFrame(i.iloc[:, 1], columns=[i.columns[1]]) for i in classifiedMatrix]]
                DynamicPlotGenerator.make_contour_plot(
                    CLASSIFICATION_GRAPH, X=x, Y=y, boundaries=results,
                    titles=('Classification',), xLabels=(index,), yLabels=(column,),
                    lineWidths=([1 for i in classifiedMatrix],),
                    legends=([True for i in classifiedMatrix],),
                    types=(['scatter' for i in classifiedMatrix],), xKeys=(xKeys,),
                    yKeys=(yKeys,),
                    colors=[[[c] for c in COLOR_SET[:len(classifiedMatrix)]]]
                )
                self.mainPlotContainer = load_browser(self.mainPlotContainer, CLASSIFICATION_GRAPH)
        except Exception as e:
            print('lerk')
            print(e)

    def validate(self, models):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, CLASSIFIERS_NAMES, CLASSIFICATION_GRAPH, Classifiers)


# TODO add option for mlp number of layers
class ClusteringMenu(MachineLearningMenu):
    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, CLUSTERERS_NAMES, CLUSTERING_GRAPH, Clusterers)
        self.resultsSuffix = ' clustering results'
        self.parent = parent
        self.title = title
        self.icon = icon

    def get_options(self):
        options = {name: None for name in CLUSTERERS_NAMES}

        options['Affinity Propagation'] = {'damping': self.APdampeningDial.value() / 100.0}

        options['Agglomerative Clustering'] = {
            'n_clusters': self.ACaffinityCombo.currentText(),
            'affinity':   self.ACnClustersDial.value()
        }

        options['Birch Clustering'] = {
            'threshold':        self.BCthresholdDial.value() / 10.0,
            'branching_factor': self.BCbranchingDial.value(),
            'n_clusters':       self.BCnClustersDial.value()
        }

        options['DBSCAN'] = {
            'algorithm': self.DBalgorithmCombo.currentText(), 'eps': self.DBepsDial.value() / 10.0,
            'leaf_size': self.DBleafSizeDial.value(), 'p': self.DBminkowskiPowerDial.value()
        }

        options['Gaussian Mixtures'] = {
            'n_components':    self.GMcomponentsDial.value(),
            'covariance_type': self.GMcovarianceCombo.currentText(),
            'tol':             self.GMtolDial.value() / 1000.0,
            'reg_covar':       self.GMregDial.value() / 1000000.0
        }

        options['K-Means'] = {
            'algorithm':  self.KMalgorithmCombo.currentText(),
            'n_clusters': self.KMnClustersDial.value(), 'tol': self.KMtolDial.value() / 10000.0,
            'n_init':     self.KMinitCombo.currentText()
        }

        options['Mean Shift'] = {'bandwidth': self.MSbandwidthDial.value() / 100.0}

        options['Spectral Clustering'] = {
            'algorithm':   self.SCalgorithmCombo.currentText(),
            'affinity':    self.SCaffinityCombo.currentText(),
            'n_clusters':  self.SCnClustersDial.value(),
            'n_neighbors': self.SCnNeighborsDial.value(),
            'gamma':       self.SCgammaDial.value() / 10.0, 'degree': self.SCdegreeDial.value()
        }

        options['Ward Hierarchical Clustering'] = {
            'n_clusters':   self.WHclustersDial.value(),
            'n_components': self.WHcomponentsDial.value()
        }

        return options

    def set_algorithms(self):
        def set_ap_clusterer(self):
            layout = self.optionLayouts['Affinity Propagation']
            _, self.APdampeningDial = make_pair(
                pair='dial', dialSettings=(50, 100, 50, 1), text='Damping',
                layout=layout, row=0, column=0, description=''
            )

        def set_ac_clusterer(self):
            layout = self.optionLayouts['Agglomerative Clustering']
            _, self.ACaffinityCombo = make_pair(
                pair='combo',
                comboItems=('euclidean', 'l1', 'l2', 'manhattan', 'cosine'),
                text='Affinity', layout=layout, row=0, column=0, pairWidth=100,
                description=''
            )

            _, self.ACnClustersDial = make_pair(
                pair='dial', dialSettings=(2, 10, 2, 1), text='Clusters', layout=layout,
                row=0, column=1, description=''
            )

        def set_bc_clusterer(self):
            layout = self.optionLayouts['Birch Clustering']
            # divide threshold by 10
            _, self.BCthresholdDial = make_pair(
                pair='dial', dialSettings=(5, 100, 5, 1), text='Threshold',
                layout=layout, row=0, column=0, description=''
            )

            _, self.BCbranchingDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Branching Factor',
                layout=layout, row=0, column=1, description=''
            )

            _, self.BCnClustersDial = make_pair(
                pair='dial', dialSettings=(2, 10, 2, 1), text='Clusters', layout=layout,
                row=0, column=2, description=''
            )

        def set_db_clusterer(self):
            layout = self.optionLayouts['DBSCAN']

            _, self.DBalgorithmCombo = make_pair(
                pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
                text='Algorithm', layout=layout, row=0, column=0, pairWidth=100,
                description=''
            )

            _, self.DBepsDial = make_pair(
                pair='dial', dialSettings=(5, 100, 5, 1), text='Eps', layout=layout, row=0,
                column=1, description=''
            )

            _, self.DBleafSizeDial = make_pair(
                pair='dial', dialSettings=(2, 100, 30, 1), text='Leaf Size',
                layout=layout, row=1, column=0, description=''
            )

            _, self.DBminkowskiPowerDial = make_pair(
                pair='dial', dialSettings=(2, 10, 2, 1), text='Minkowski Power',
                layout=layout, row=1, column=1, description=''
            )

        def set_gm_clusterer(self):
            layout = self.optionLayouts['Gaussian Mixtures']

            _, self.GMcomponentsDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Components',
                layout=layout, row=0, column=0, description=''
            )

            _, self.GMcovarianceCombo = make_pair(
                pair='combo', comboItems=('full', 'tied', 'diag', 'spherical'),
                text='Covariance', layout=layout, row=0, column=1, pairWidth=100,
                description=''
            )

            # divide tol by 1000
            _, self.GMtolDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Tolerance', layout=layout,
                row=1, column=0, description=''
            )

            # divide reg by 1000000
            _, self.GMregDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 1, 1), text='Covariance Regularization',
                layout=layout, row=1, column=0, description=''
            )

        def set_km_clusterer(self):
            layout = self.optionLayouts['K-Means']
            _, self.KMalgorithmCombo = make_pair(
                pair='combo', comboItems=('auto', 'full', 'elkan'), text='Algorithm',
                layout=layout, row=0, column=0, pairWidth=100, description=''
            )

            _, self.KMnClustersDial = make_pair(
                pair='dial', dialSettings=(2, 10, 2, 1), text='Clusters', layout=layout,
                row=0, column=1, description=''
            )

            # divide tol by 10000
            _, self.KMtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='Tolerance', layout=layout,
                row=0, column=2, description=''
            )

            _, self.KMinitCombo = make_pair(
                pair='combo', comboItems=('k-means++', 'random'), text='Initialization',
                layout=layout, row=1, column=0, pairWidth=100, description=''
            )

        def set_ms_clusterer(self):
            layout = self.optionLayouts['Mean Shift']

            _, self.MSbandwidthDial = make_pair(
                pair='dial', dialSettings=(1, 10000, 5, 1), text='Bandwidth',
                layout=layout, row=0, column=0, description=''
            )

        def set_sc_clusterer(self):
            layout = self.optionLayouts['Spectral Clustering']

            _, self.SCalgorithmCombo = make_pair(
                pair='combo', comboItems=('arpack', 'lobpcg'), text='Algorithm',
                layout=layout, row=0, column=0, pairWidth=100, description=''
            )

            _, self.SCaffinityCombo = make_pair(
                pair='combo', comboItems=(
                    'nearest_neighbors', 'rbf', 'sigmoid', 'polynomial', 'linear', 'cosine'), text='Affinity',
                layout=layout, row=0, column=1, pairWidth=100, description=''
            )

            _, self.SCnClustersDial = make_pair(
                pair='dial', dialSettings=(2, 10, 2, 1), text='Clusters', layout=layout,
                row=0, column=2, description=''
            )

            _, self.SCnNeighborsDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Neighbors',
                layout=layout, row=1, column=0, description=''
            )

            _, self.SCgammaDial = make_pair(
                pair='dial', dialSettings=(1, 100, 10, 1), text='Gamma', layout=layout,
                row=1, column=1, description=''
            )

            _, self.SCdegreeDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Degree', layout=layout,
                row=1, column=2, description=''
            )

        def set_wh_clusterer(self):
            layout = self.optionLayouts['Ward Hierarchical Clustering']

            _, self.WHclustersDial = make_pair(
                pair='dial', dialSettings=(2, 10, 1, 1), text='Clusters', layout=layout,
                row=0, column=0, description=''
            )

            _, self.WHcomponentsDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Components',
                layout=layout, row=0, column=1, description=''
            )

        set_ap_clusterer(self)
        set_ac_clusterer(self)
        set_bc_clusterer(self)
        set_db_clusterer(self)
        set_gm_clusterer(self)
        set_km_clusterer(self)
        set_ms_clusterer(self)
        set_sc_clusterer(self)
        set_wh_clusterer(self)

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, row=0, column=0,
            width=200, description=''
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        remove_tabs(self.tabs)
        self.inputsSelection.clear()
        self.inputsSelection.addItems([h for h in self.headers if h != self.columnCombo.currentText()])
        self.results = None

        mode, index, column, dir, _, _ = self.get_parameters()

        data, xKeys, yKeys = dh.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            CLUSTERING_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,),
            colors=(((CONTRASTED_COLOR,),),)
        )
        self.mainPlotContainer = load_browser(self.mainPlotContainer, CLUSTERING_GRAPH)

    def run(self):
        try:
            remove_tabs(self.tabs)
            mode, index, column, dir, models, scaler = self.get_parameters()
            inputs = self.get_inputs()
            if len(inputs) == 0:
                inputs = [index]
            if self.validate(models, mode):
                x, y, results, xKeys, yKeys = Regressors.train_nn(
                    self, dir, index, [column] + inputs, column, models,
                    scaler, mode
                )

                if True:
                    m = [index] if index else []
                    for c in x.columns:
                        if c != index:
                            m.append(c)
                    for c in results.columns:
                        m.append(c)  # TODO categorical results are not denumerified yet
                # self.results = pd.DataFrame(results.reset_index().values if index else results.values,
                #                            index=y.index, columns=m)

                for i, input in enumerate(inputs):
                    data, xKeys, yKeys = dh.process_regression_data(dir, input, column, mode)
                    data = pd.DataFrame(data, columns=(column,), index=data.index)
                    tempPlot = os.path.join(CLUSTERING_GRAPHS, 'temp' + str(i) + '.html')
                    tempTab = make_tab(self, input, self.tabs)
                    Regressors.plot_regression(
                        data, results, xLabel=input, yLabel=column, xKeys=xKeys, yKeys=yKeys,
                        file=tempPlot, title=column + ' vs ' + input
                    )
                    tempContainer = make_browser(layout=tempTab, file=tempPlot)
                self.progressBar.setValue(100)
                self.progressBar.setValue(0)

        except Exception as e:
            print(e)

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    def graph_raw(self):
        remove_tabs(self.tabs)
        self.inputsSelection.clear()
        self.inputsSelection.addItems([h for h in self.headers if h != self.columnCombo.currentText()])
        self.results = None

        mode, index, column, dir, _, _ = self.get_parameters()

        data, xKeys, yKeys = DataProcessor.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        print("about to plot0")
        DynamicPlotGenerator.make_plot(
            CLUSTERING_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,),
            lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,),
            yKeys=(yKeys,), colors=(((CONTRASTED_COLOR,),),)
        )
        print("done plotting")
        self.mainPlotContainer = load_browser(self.mainPlotContainer, CLUSTERING_GRAPH)

    def run(self):
        try:
            remove_tabs(self.tabs)
            mode, index, column, dir, models, scaler = self.get_parameters()
            inputs = self.get_inputs()
            if len(inputs) == 0:
                inputs = [index]
            if self.validate(models, mode):
                x, y, results, xKeys, yKeys = Regressors.train_nn(
                    self, dir, index, [column] + inputs, column, models,
                    scaler, mode
                )

                if True:
                    m = [index] if index else []
                    for c in x.columns:
                        if c != index:
                            m.append(c)
                    for c in results.columns:
                        m.append(c)  # TODO categorical results are not denumerified yet
                # self.results = pd.DataFrame(results.reset_index().values if index else results.values,
                #                            index=y.index, columns=m)

                for i, input in enumerate(inputs):
                    data, xKeys, yKeys = DataProcessor.process_regression_data(dir, input, column, mode)
                    data = pd.DataFrame(data, columns=(column,), index=data.index)
                    tempPlot = os.path.join(CLUSTERING_GRAPHS, 'temp' + str(i) + '.html')
                    tempTab = make_tab(self, input, self.tabs)
                    Regressors.plot_regression(
                        data, results, xLabel=input, yLabel=column, xKeys=xKeys, yKeys=yKeys,
                        file=tempPlot, title=column + ' vs ' + input
                    )
                    tempContainer = make_browser(layout=tempTab, file=tempPlot)
                self.progressBar.setValue(100)
                self.progressBar.setValue(0)

        except Exception as e:
            print(e)

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if DataProcessor.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False


# TODO get_options(), set_nb_classifier()
# TODO add option for mlp number of layers
class DimensionalityMenu(MachineLearningMenu):
    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(
            self, parent, title, icon, DIMENSIONALITY_REDUCERS_NAMES, DIMENSIONALITY_GRAPH,
            DimensionalityReducers
        )
        self.resultsSuffix = ' dimensionality reduction results'
        self.parent = parent
        self.title = title
        self.icon = icon

    def get_options(self):
        options = {name: None for name in DIMENSIONALITY_REDUCERS_NAMES}

        options['Feature Agglomeration'] = {}

        options['Principal Component Analysis'] = {}

        options['Random Projection'] = {}

        return options

    def set_algorithms(self):
        def set_fa_dimred(self):
            layout = self.optionLayouts['Feature Agglomeration']

        def set_pca_dimred(self):
            layout = self.optionLayouts['Principal Component Analysis']

        def set_rp_dimred(self):
            layout = self.optionLayouts['Random Projection']

        set_fa_dimred(self)
        set_pca_dimred(self)
        set_rp_dimred(self)

    def graph_raw(self):
        remove_tabs(self.tabs)
        self.inputsSelection.clear()
        self.inputsSelection.addItems([h for h in self.headers if h != self.columnCombo.currentText()])
        self.results = None

        mode, index, column, dir, _, _ = self.get_parameters()

        data, xKeys, yKeys = dh.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            DIMENSIONALITY_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,),
            colors=(((CONTRASTED_COLOR,),),)
        )
        self.mainPlotContainer = load_browser(self.mainPlotContainer, DIMENSIONALITY_GRAPH)

    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(
            self, parent, title, icon, DIMENSIONALITY_REDUCERS_NAMES, DIMENSIONALITY_GRAPH,
            DimensionalityReducers
        )
        self.resultsSuffix = ' dimensionality reduction results'
        self.parent = parent
        self.title = title
        self.icon = icon

    def get_options(self):
        options = {name: None for name in DIMENSIONALITY_REDUCERS_NAMES}

        options['Feature Agglomeration'] = {}

        options['Principal Component Analysis'] = {}

        options['Random Projection'] = {}

        return options

    def set_algorithms(self):
        def set_fa_dimred(self):
            layout = self.optionLayouts['Feature Agglomeration']

        def set_pca_dimred(self):
            layout = self.optionLayouts['Principal Component Analysis']

        def set_rp_dimred(self):
            layout = self.optionLayouts['Random Projection']

        set_fa_dimred(self)
        set_pca_dimred(self)
        set_rp_dimred(self)

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = DataProcessor.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def graph_raw(self):
        remove_tabs(self.tabs)
        self.inputsSelection.clear()
        self.inputsSelection.addItems([h for h in self.headers if h != self.columnCombo.currentText()])
        self.results = None

        mode, index, column, dir, _, _ = self.get_parameters()

        data, xKeys, yKeys = DataProcessor.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        DynamicPlotGenerator.make_plot(
            DIMENSIONALITY_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,),
            lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,),
            yKeys=(yKeys,), colors=(((CONTRASTED_COLOR,),),)
        )
        self.mainPlotContainer = load_browser(self.mainPlotContainer, DIMENSIONALITY_GRAPH)

    def run(self):
        try:
            remove_tabs(self.tabs)
            mode, index, column, dir, models, scaler = self.get_parameters()
            inputs = self.get_inputs()
            if len(inputs) == 0:
                inputs = [index]
            if self.validate(models, mode):
                x, y, results, xKeys, yKeys = Regressors.train_nn(
                    self, dir, index, [column] + inputs, column, models,
                    scaler, mode
                )

                if True:
                    m = [index] if index else []
                    for c in x.columns:
                        if c != index:
                            m.append(c)
                    for c in results.columns:
                        m.append(c)  # TODO categorical results are not denumerified yet
                # self.results = pd.DataFrame(results.reset_index().values if index else results.values,
                #                            index=y.index, columns=m)

                for i, input in enumerate(inputs):
                    data, xKeys, yKeys = DataProcessor.process_regression_data(dir, input, column, mode)
                    data = pd.DataFrame(data, columns=(column,), index=data.index)
                    tempPlot = os.path.join(REGRESSION_GRAPHS, 'temp' + str(i) + '.html')
                    tempTab = make_tab(self, input, self.tabs)
                    Regressors.plot_regression(
                        data, results, xLabel=input, yLabel=column, xKeys=xKeys, yKeys=yKeys,
                        file=tempPlot, title=column + ' vs ' + input
                    )
                    tempContainer = make_browser(layout=tempTab, file=tempPlot)
                self.progressBar.setValue(100)
                self.progressBar.setValue(0)

        except Exception as e:
            print(e)


class DeteriorationPage(tk.Frame):
    def __init__(self, parent, controller):
        tk.Frame.__init__(self, parent)
        label = tk.Label(self, text="Deterioration", font=LARGE_FONT)
        label.pack(pady=10, padx=10)
        # button1 = ttk.Button(self, text="Back to Home", command=lambda: controller.show_frame(StartPage))
        # button1.pack()
        # button2 = ttk.Button(self, text="Frequency", command=lambda: controller.show_frame(FrequencyPage))
        # button2.pack()
        canvas = FigureCanvasTkAgg(f, self)
        canvas.show()
        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        toolbar = NavigationToolbar2TkAgg(canvas, self)
        toolbar.update()
        canvas._tkcanvas.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        canvas._tkcanvas.pack()
        global current_frame
        current_frame = "deterioration frame"


class DocumentationMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.documentationTab = make_tab(self, text='1', master=self.tabs)
        self.documentationContainer = make_browser(layout=self.documentationTab, file=DOCUMENTATION)
        self.tutorialsTab = make_tab(self, text='Tutorials', master=self.tabs)
        self.tutorialsContainer = make_browser(layout=self.tutorialsTab, file=None)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.documentationTab = make_tab(self, text='1', master=self.tabs)
        self.documentationContainer = make_browser(layout=self.documentationTab, file=DOCUMENTATION)
        self.tutorialsTab = make_tab(self, text='Tutorials', master=self.tabs)
        self.tutorialsContainer = make_browser(layout=self.tutorialsTab, file=None)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.documentationTab = make_tab(self, text='1', master=self.tabs)
        self.documentationContainer = make_browser(layout=self.documentationTab, file=DOCUMENTATION)
        self.tutorialsTab = make_tab(self, text='Tutorials', master=self.tabs)
        self.tutorialsContainer = make_browser(layout=self.tutorialsTab, file=None)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.documentationTab = make_tab(self, text='1', master=self.tabs)
        self.documentationContainer = make_browser(layout=self.documentationTab, file=DOCUMENTATION)
        self.tutorialsTab = make_tab(self, text='Tutorials', master=self.tabs)
        self.tutorialsContainer = make_browser(layout=self.tutorialsTab, file=None)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.documentationTab = make_tab(self, text='1', master=self.tabs)
        self.documentationContainer = make_browser(layout=self.documentationTab, file=DOCUMENTATION)
        self.tutorialsTab = make_tab(self, text='Tutorials', master=self.tabs)
        self.tutorialsContainer = make_browser(layout=self.tutorialsTab, file=None)


class ExportMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)


class FrequencyPage(tk.Frame):
    def __init__(self, parent, controller):
        tk.Frame.__init__(self, parent)
        label = tk.Label(self, text="Frequency", font=LARGE_FONT)
        label.pack(pady=10, padx=10)
        # button1 = ttk.Button(self, text="Back to Home", command=lambda: controller.show_frame(StartPage))
        # button1.pack()
        # button2 = ttk.Button(self, text="Deterioration", command=lambda: controller.show_frame(DeteriorationPage))
        # button2.pack()
        canvas = FigureCanvasTkAgg(f, self)
        canvas.show()
        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        toolbar = NavigationToolbar2TkAgg(canvas, self)
        toolbar.update()
        canvas._tkcanvas.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        canvas._tkcanvas.pack()
        global current_frame
        current_frame = "frequency frame"


class GeneratorSettings:
    def __init__(self, parent, MASTERPATH, case):
        top = self.top = Toplevel(parent)
        self.top.grab_set()
        self.MASTERPATH = MASTERPATH
        self.case = case

        if self.case == 0:
            self.top.title("Generate Random Initial State")
        elif self.case == 1:
            self.top.title("Generate Random Transition Matrix")

        Label(top, text="size:").grid(row=1, column=1, sticky=W)
        self.length = Entry(top, width=5)
        self.length.grid(row=1, column=2, columnspan=2, sticky=E)

        # SEPARATOR
        separator = ttk.Separator(top, orient=HORIZONTAL)
        separator.grid(row=3, column=0, columnspan=7, sticky=W + E)

        generate_button = Button(top, text="Generate", command=self.apply, cursor='hand2')
        generate_button.grid(row=4, column=1, sticky=E)

        cancel_button = Button(top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=4, column=2, sticky=E)

    def apply(self):
        if self.case == 0:
            lozoya.data_api.statistics.markov_chain.Generate_New_Random_Initial_State(int(self.length.get()))
        else:
            TransitionMatrixGenerator.Generate_New_Random_Transition_Matrix(int(self.length.get()))

        self.top.destroy()

    def cancel(self):
        self.top.destroy()


class GeographicSearchMenu(SubMenu):
    def browse(self):
        path = tkf.askdirectory(parent=self.top, initialdir="/", title='Select Folder')
        self.parent.util.entries[0].delete(0, END)
        self.parent.util.entries[0].insert(0, path)

    def save(self):
        path = tkf.asksaveasfilename(filetypes=(("KML files", "*.kml"), ("All files", "*.*")))
        self.parent.util.entries[4].delete(0, END)
        self.parent.util.entries[4].insert(0, path)

    def populate(self):
        # label
        self.util.name(
            container=self.top,
            text=["Directory:", "Units:", "Radius:", "Latitude:", "Longitude:", "Save:"],
            row=[1, 3, 1, 2, 3, 4], column=[1] * 2 + [4] * 3 + [1], columnspan=[1] * 6, sticky=['w'] * 6
        )
        # Entries (File Paths, Iterations)
        self.util.entry(
            container=self.top, width=[15] * 5, row=[2, 1, 2, 3, 4], column=[1] + [5] * 3 + [2],
            columnspan=[1] * 5, sticky=['we'] * 5
        )
        try:
            for entry in self.util.entries:
                entry.insert(0, '')
            self.util.entries[0].insert(self.parent.filepath)
        except:
            pass

        # Separators
        self.util.separator(container=self.top, orient='h', row=6, column=1, columnspan=5, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=["Browse", "Cancel", "Run", "Save"],
            commands=[self.browse, self.cancel, self.run, self.save], cursor='hand2', row=[2, 7, 7, 4],
            column=[2, 1, 5, 5], sticky=['e'] * 4
        )

        # Create a Tkinter variable to store the item
        self.units = StringVar(self.top)
        # Dictionary with options
        self.units.set(UNITS[0])  # set the default option
        # List
        listMenu1 = ttk.OptionMenu(self.top, self.units, *UNITS, command=self.units_selection)
        listMenu1.grid(row=3, column=2, columnspan=2, sticky='we')

    def units_selection(self, value):
        self.units.set(value)


class GraphsMenu(Window):
    def __init__(self, model, windowName):
        super().__init__(windowName)
        self.model = model
        self.sampler = model.sampler
        self.vS = self.model.vS
        self.populate_menubar()
        self.frame = FrameCanvas(self.container, self, windowName, f)

        self.cx = (1, len(self.model.yrs))
        self.cy = (0, len(self.vS))

        self.rLimsY = ((0, len(self.vS)), (0, 1) if norm == True else (0, len(self.model.yrs)))
        self.rLimsYH = ((0, len(self.vS)), (0, 1) if norm == True else (0, len(self.model.yrs)))

        self.rLimsS = ((1, 25), (0, 1) if norm == True else (0, len(self.model.data.T.columns)))
        self.rLimsSH = ((1, 26), (0, 1) if norm == True else (0, len(self.model.data.T.columns)))

        self.sLimsY = ((0, len(self.vS)), (0, 1) if norm == True else (0, int(self.model.iterations)))
        self.sLimsYH = ((0, len(self.vS)), (0, 1) if norm == True else (0, int(self.model.iterations)))

        self.sLimsS = ((1, 25), (0, 1) if norm == True else (0, int(self.model.iterations)))
        self.sLimsSH = ((1, 26), (0, 1) if norm == True else (0, int(self.model.iterations)))

        ani = animation.FuncAnimation(f, animate, interval=1000)
        self.mainloop()

    def populate_menubar(self):
        menubar = tk.Menu(self.container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)

        trnData = (self.model.pdf.as_matrix().astype(np.float64))
        detData = (self.model.data.as_matrix().astype(np.float64), self.sampler.simulation)
        frqData = (0,)
        hstData = (0,)

        self.transition_probabilities_menu(menubar, data=trnData)
        self.deterioration_menu(menubar, data=detData)
        self.frequency_menu(menubar, data=frqData)
        self.histogram_menu(menubar, data=hstData)

        tk.Tk.config(self, menu=menubar)

    def transition_probabilities_menu(self, menubar, data):
        menubar.add_command(
            label=titles[0],
            command=lambda: GraphsMenu.graph(
                data=data, lims=((1, len(data[0])), (0, 1)), pt=0, label=0,
                t=0, c=0, legend=self.vS, fill=True
            )
        )

    def deterioration_menu(self, menubar, data):
        deterioration_menu = tk.Menu(menubar, tearoff=1)
        # Raw Deterioration
        deterioration_menu.add_command(
            label=titles[1],
            command=lambda: GraphsMenu.graph(
                data=data[0], pt=0, label=1, t=1, c=1,
                lims=(self.cx, self.cy)
            )
        )

        # Simulation2 Deterioration
        deterioration_menu.add_command(
            label=titles[2],
            command=lambda: GraphsMenu.graph(
                data=data[1], pt=0, label=1, t=2, c=2,
                lims=(self.cx, self.cy)
            )
        )

        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

    def frequency_menu(self, menubar, data):
        frequency_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        frequency_menu.add_command(
            label=titles[3],
            command=lambda: GraphsMenu.graph(
                data=self.model.raw_frq("year"), pt=0, label=3,
                lims=self.rLimsY, t=3, c=1, legend=yrs, fill=True
            )
        )

        # Simulation2 Per Year
        frequency_menu.add_command(
            label=titles[4],
            command=lambda: GraphsMenu.graph(
                data=self.sampler.sim_frq("year"), pt=0, label=3,
                lims=self.sLimsY, t=4, c=2, legend=yrs, fill=True
            )
        )

        # Raw Per State
        frequency_menu.add_command(
            label=titles[5],
            command=lambda: GraphsMenu.graph(
                data=self.model.raw_frq("state"), pt=0, label=2,
                lims=self.rLimsS, t=5, c=0, legend=self.vS,
                fill=True
            )
        )

        # Simulation2 Per State
        frequency_menu.add_command(
            label=titles[6],
            command=lambda: GraphsMenu.graph(
                data=self.sampler.sim_frq("state"), pt=0, label=2,
                lims=self.sLimsS, t=6, c=0, legend=self.vS,
                fill=True
            )
        )

        menubar.add_cascade(label="Frequency", menu=frequency_menu)

    def histogram_menu(self, menubar, data):
        histogram_menu = tk.Menu(menubar, tearoff=1)
        # bins = int(len(self.vS))

        # Raw Per Year
        histogram_menu.add_command(
            label=titles[3],
            command=lambda: GraphsMenu.graph(
                data=self.model.raw_hst("year"), pt=1, label=3,
                lims=self.rLimsYH, t=3, c=1, legend=yrs
            )
        )

        # Simulation2 Per Year
        histogram_menu.add_command(
            label=titles[4],
            command=lambda: GraphsMenu.graph(
                data=self.sampler.sim_hst("year"), pt=1, label=3,
                lims=self.sLimsYH, t=4, c=2, legend=yrs
            )
        )

        # Raw Per State
        histogram_menu.add_command(
            label=titles[5],
            command=lambda: GraphsMenu.graph(
                data=self.model.raw_hst("state"), pt=1, label=2,
                lims=self.rLimsSH, t=5, c=0, legend=self.vS
            )
        )

        # Simulation2 Per State
        histogram_menu.add_command(
            label=titles[6],
            command=lambda: GraphsMenu.graph(
                data=self.sampler.sim_hst("state"), pt=1, label=2,
                lims=self.sLimsSH, t=6, c=0, legend=self.vS
            )
        )

        menubar.add_cascade(label="Histogram", menu=histogram_menu)

    @staticmethod
    def graph(data, pt, label, lims, t=0, c=0, legend=None, fill=False):
        plot = plt.subplot2grid((6, 4), (0, 0), rowspan=5, colspan=4)
        # Line Plot
        if pt == 0:
            for index, curve in enumerate(data):
                PlotGenerator.plot_curve(plot, index, curve, c, lims, fill)
        # Histogram
        elif pt == 1:
            for index, curve in enumerate(data):
                PlotGenerator.plot_histogram(
                    plot, index, curve, color=c, lims=lims,
                    norm=norm
                )
        PlotGenerator.plot_configure(plot, legend, titles[t], labels[label], lims)

    def populate(self, model):
        self.model = model
        self.sampler = model.sampler
        self.vS = self.model.vS
        self.populate_menubar()
        self.frame = FrameCanvas(self.top, self.title, f)

        self.cx = (1, len(self.model.yrs))
        self.cy = (0, len(self.vS))

        self.rLimsY = ((0, len(self.vS)), (0, 1) if norm == True else (0, len(self.model.yrs)))
        self.rLimsYH = ((0, len(self.vS)), (0, 1) if norm == True else (0, len(self.model.yrs)))

        self.rLimsS = ((1, 25), (0, 1) if norm == True else (0, len(self.model.data.T.columns)))
        self.rLimsSH = ((1, 26), (0, 1) if norm == True else (0, len(self.model.data.T.columns)))

        self.sLimsY = ((0, len(self.vS)), (0, 1) if norm == True else (0, int(self.model.iterations)))
        self.sLimsYH = ((0, len(self.vS)), (0, 1) if norm == True else (0, int(self.model.iterations)))

        self.sLimsS = ((1, 25), (0, 1) if norm == True else (0, int(self.model.iterations)))
        self.sLimsSH = ((1, 26), (0, 1) if norm == True else (0, int(self.model.iterations)))

        ani = animation.FuncAnimation(f, animate, interval=1000)
        self.top.mainloop()

    def populate_menubar(self):
        menubar = tk.Menu(self.top)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=self.cancel)
        menubar.add_cascade(label="File", menu=filemenu)

        trnData = (self.model.pdf.as_matrix().astype(np.float64))
        detData = (self.model.data.as_matrix().astype(np.float64), self.sampler.simulation)
        frqData = (0,)
        hstData = (0,)

        self.transition_probabilities_menu(menubar, data=trnData)
        self.deterioration_menu(menubar, data=detData)
        self.frequency_menu(menubar, data=frqData)
        self.histogram_menu(menubar, data=hstData)

        tk.Tk.config(self.top, menu=menubar)

    def transition_probabilities_menu(self, menubar, data):
        menubar.add_command(
            label=GRAPH_TITLES[0],
            command=lambda: graph(
                data=data, pt=0, label=0, lims=((1, len(data[0])), (0, 1)), t=0, c=0,
                legend=self.vS, fill=True
            )
        )

    def deterioration_menu(self, menubar, data):
        deterioration_menu = tk.Menu(menubar, tearoff=1)
        # Raw Deterioration
        deterioration_menu.add_command(
            label=GRAPH_TITLES[1],
            command=lambda: graph(
                data=data[0], pt=0, label=1, lims=(self.cx, self.cy), t=1,
                c=1
            )
        )

        # Simulation2 Deterioration
        deterioration_menu.add_command(
            label=GRAPH_TITLES[2],
            command=lambda: graph(
                data=data[1], pt=0, label=1, lims=(self.cx, self.cy), t=2,
                c=2
            )
        )

        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

    def frequency_menu(self, menubar, data):
        frequency_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        frequency_menu.add_command(
            label=GRAPH_TITLES[3],
            command=lambda: graph(
                data=self.model.raw_frq("year"), pt=0, label=3,
                lims=self.rLimsY, t=3, c=1, legend=yrs, fill=True
            )
        )

        # Simulation2 Per Year
        frequency_menu.add_command(
            label=GRAPH_TITLES[4],
            command=lambda: graph(
                data=self.sampler.sim_frq("year"), pt=0, label=3,
                lims=self.sLimsY, t=4, c=2, legend=yrs, fill=True
            )
        )

        # Raw Per State
        frequency_menu.add_command(
            label=GRAPH_TITLES[5],
            command=lambda: graph(
                data=self.model.raw_frq("state"), pt=0, label=2,
                lims=self.rLimsS, t=5, c=0, legend=self.vS, fill=True
            )
        )

        # Simulation2 Per State
        frequency_menu.add_command(
            label=GRAPH_TITLES[6],
            command=lambda: graph(
                data=self.sampler.sim_frq("state"), pt=0, label=2,
                lims=self.sLimsS, t=6, c=0, legend=self.vS, fill=True
            )
        )

        menubar.add_cascade(label="Frequency", menu=frequency_menu)

    def histogram_menu(self, menubar, data):
        histogram_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        histogram_menu.add_command(
            label=GRAPH_TITLES[3],
            command=lambda: graph(
                data=self.model.raw_hst("year"), pt=1, label=3,
                lims=self.rLimsYH, t=3, c=1, legend=yrs
            )
        )

        # Simulation2 Per Year
        histogram_menu.add_command(
            label=GRAPH_TITLES[4],
            command=lambda: graph(
                data=self.sampler.sim_hst("year"), pt=1, label=3,
                lims=self.sLimsYH, t=4, c=2, legend=yrs
            )
        )

        # Raw Per State
        histogram_menu.add_command(
            label=GRAPH_TITLES[5],
            command=lambda: graph(
                data=self.model.raw_hst("state"), pt=1, label=2,
                lims=self.rLimsSH, t=5, c=0, legend=self.vS
            )
        )

        # Simulation2 Per State
        histogram_menu.add_command(
            label=GRAPH_TITLES[6],
            command=lambda: graph(
                data=self.sampler.sim_hst("state"), pt=1, label=2,
                lims=self.sLimsSH, t=6, c=0, legend=self.vS
            )
        )

        menubar.add_cascade(label="Histogram", menu=histogram_menu)

    def populate(self, model):
        self.model = model
        self.sampler = model.sampler
        self.vS = self.model.vS
        self.populate_menubar()
        if True:
            pass
        else:
            from Interface.CreateWindow import FrameCanvas
            self.frame = FrameCanvas(self.top, self.title, f)

        self.cx = (1, len(self.model.yrs))
        self.cy = (0, len(self.vS))

        self.rLimsY = ((0, len(self.vS)), (0, 1) if norm == True else (0, len(self.model.yrs)))
        self.rLimsYH = ((0, len(self.vS)), (0, 1) if norm == True else (0, len(self.model.yrs)))

        self.rLimsS = ((1, 25), (0, 1) if norm == True else (0, len(self.model.data.T.columns)))
        self.rLimsSH = ((1, 26), (0, 1) if norm == True else (0, len(self.model.data.T.columns)))

        self.sLimsY = ((0, len(self.vS)), (0, 1) if norm == True else (0, int(self.model.iterations)))
        self.sLimsYH = ((0, len(self.vS)), (0, 1) if norm == True else (0, int(self.model.iterations)))

        self.sLimsS = ((1, 25), (0, 1) if norm == True else (0, int(self.model.iterations)))
        self.sLimsSH = ((1, 26), (0, 1) if norm == True else (0, int(self.model.iterations)))

        ani = animation.FuncAnimation(f, animate, interval=1000)
        self.top.mainloop()

    def populate_menubar(self):
        menubar = self.util.partial_drop(self.top, tearoff=0)
        filemenu = self.util.partial_drop(menubar, tearoff=0)
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=self.cancel)
        menubar.add_cascade(label="File", menu=filemenu)

        trnData = (self.model.pdf.as_matrix().astype(np.float64))
        detData = (self.model.data.as_matrix().astype(np.float64), self.sampler.simulation)
        frqData = (0,)
        hstData = (0,)

        self.transition_probabilities_menu(menubar, data=trnData)
        self.deterioration_menu(menubar, data=detData)
        self.frequency_menu(menubar, data=frqData)
        self.histogram_menu(menubar, data=hstData)

        self.util.set_drop(self.top, menu=menubar)

    def transition_probabilities_menu(self, menubar, data):
        menubar.add_command(
            label=GRAPH_TITLES[0],
            command=lambda: graph(
                data=data, pt=0, label=0, lims=((1, len(data[0])), (0, 1)), t=0, c=0,
                legend=self.vS, fill=True
            )
        )

    def deterioration_menu(self, menubar, data):
        deterioration_menu = self.util.partial_drop(menubar, tearoff=1)
        # Raw Deterioration
        deterioration_menu.add_command(
            label=GRAPH_TITLES[1],
            command=lambda: graph(
                data=data[0], pt=0, label=1, lims=(self.cx, self.cy), t=1,
                c=1
            )
        )

        # Simulation2 Deterioration
        deterioration_menu.add_command(
            label=GRAPH_TITLES[2],
            command=lambda: graph(
                data=data[1], pt=0, label=1, lims=(self.cx, self.cy), t=2,
                c=2
            )
        )

        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

    def frequency_menu(self, menubar, data):
        frequency_menu = self.util.partial_drop(menubar, tearoff=1)

        # Raw Per Year
        frequency_menu.add_command(
            label=GRAPH_TITLES[3],
            command=lambda: graph(
                data=self.model.raw_frq("year"), pt=0, label=3,
                lims=self.rLimsY, t=3, c=1, legend=yrs, fill=True
            )
        )

        # Simulation2 Per Year
        frequency_menu.add_command(
            label=GRAPH_TITLES[4],
            command=lambda: graph(
                data=self.sampler.sim_frq("year"), pt=0, label=3,
                lims=self.sLimsY, t=4, c=2, legend=yrs, fill=True
            )
        )

        # Raw Per State
        frequency_menu.add_command(
            label=GRAPH_TITLES[5],
            command=lambda: graph(
                data=self.model.raw_frq("state"), pt=0, label=2,
                lims=self.rLimsS, t=5, c=0, legend=self.vS, fill=True
            )
        )

        # Simulation2 Per State
        frequency_menu.add_command(
            label=GRAPH_TITLES[6],
            command=lambda: graph(
                data=self.sampler.sim_frq("state"), pt=0, label=2,
                lims=self.sLimsS, t=6, c=0, legend=self.vS, fill=True
            )
        )

        menubar.add_cascade(label="Frequency", menu=frequency_menu)

    def histogram_menu(self, menubar, data):
        histogram_menu = self.util.partial_drop(menubar, tearoff=1)

        # Raw Per Year
        histogram_menu.add_command(
            label=GRAPH_TITLES[3],
            command=lambda: graph(
                data=self.model.raw_hst("year"), pt=1, label=3,
                lims=self.rLimsYH, t=3, c=1, legend=yrs
            )
        )

        # Simulation2 Per Year
        histogram_menu.add_command(
            label=GRAPH_TITLES[4],
            command=lambda: graph(
                data=self.sampler.sim_hst("year"), pt=1, label=3,
                lims=self.sLimsYH, t=4, c=2, legend=yrs
            )
        )

        # Raw Per State
        histogram_menu.add_command(
            label=GRAPH_TITLES[5],
            command=lambda: graph(
                data=self.model.raw_hst("state"), pt=1, label=2,
                lims=self.rLimsSH, t=5, c=0, legend=self.vS
            )
        )

        # Simulation2 Per State
        histogram_menu.add_command(
            label=GRAPH_TITLES[6],
            command=lambda: graph(
                data=self.sampler.sim_hst("state"), pt=1, label=2,
                lims=self.sLimsSH, t=6, c=0, legend=self.vS
            )
        )

        menubar.add_cascade(label="Histogram", menu=histogram_menu)


class MachineLearningAdvancedOptionsMenu(SubMenu):
    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        """BOTTOM"""
        self.rewindow()

    def refresh(self):
        self.set_svm()
        self.set_knn()
        self.set_kr()
        self.set_nn()
        self.set_dt()
        self.set_rf()

    def set_svm(self):
        # SUPPORT VECTOR MACHINE
        label1 = make_label(
            self, text='S U P P O R T   V E C T O R   M A C H I N E', layout=self.bottom,
            row=0, column=0, width=200
        )

        self.SVMCLabel = make_label(
            self, text='C:', layout=self.bottom,
            row=1, column=0,
            description=C_DESCRIPTION
        )
        self.SVMCEntry = make_entry(
            self, layout=self.bottom,
            row=1, column=1, width=50,
            description=C_DESCRIPTION
        )

        self.SVMepsilonLabel = make_label(
            self, text='Epsilon:', layout=self.bottom,
            row=2, column=0,
            description=EPSILON_DESCRIPTION
        )
        self.SVMepsilonEntry = make_entry(
            self, layout=self.bottom,
            row=2, column=1, width=50,
            description=EPSILON_DESCRIPTION
        )

        self.SVMkernelLabel = make_label(
            self, text='Kernel:', layout=self.bottom,
            row=3, column=0,
            description=KERNEL_DESCRIPTION
        )
        self.SVMkernelCombo = make_combo(
            self, ('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'), layout=self.bottom,
            row=3, column=1, width=100,
            description=KERNEL_DESCRIPTION
        )

        self.SVMdegreeLabel = make_label(
            self, text='Polynomial Degree:', layout=self.bottom,
            row=4, column=0,
            description=DEGREE_DESCRIPTION
        )
        self.SVMdegreeCombo = make_combo(
            self, ('0', '1', '1', '2', '3', '5'), layout=self.bottom,
            row=4, column=1, width=100,
            description=DEGREE_DESCRIPTION
        )

        self.SVMgammaLabel = make_label(
            self, text='Gamma:', layout=self.bottom,
            row=5, column=0,
            description=GAMMA_DESCRIPTION
        )
        self.SVMgammaEntry = make_entry(
            self, layout=self.bottom,
            row=5, column=1, width=50,
            description=GAMMA_DESCRIPTION
        )

        self.SVMcoef0Label = make_label(
            self, text='Coefficient 0:', layout=self.bottom,
            row=6, column=0,
            description=COEF0_DESCRIPTION
        )
        self.SVMcoef0Entry = make_entry(
            self, layout=self.bottom,
            row=6, column=1, width=50,
            description=COEF0_DESCRIPTION
        )

        self.SVMshrinkingLabel = make_label(
            self, text='Shrinking:', layout=self.bottom,
            row=7, column=0,
            description=SHRINKING_DESCRIPTION
        )
        self.SVMshrinkingCheck = make_button(
            self, type='check', layout=self.bottom,
            row=7, column=1,
            description=SHRINKING_DESCRIPTION
        )

        self.SVMtolLabel = make_label(
            self, text='Tolerance:', layout=self.bottom,
            row=8, column=0,
            description=TOL_DESCRIPTION
        )
        self.SVMtolEntry = make_entry(
            self, layout=self.bottom,
            row=8, column=1, width=50,
            description=TOL_DESCRIPTION
        )

        self.SVMcacheSizeLabel = make_label(
            self, text='Cache Size:', layout=self.bottom,
            row=9, column=0,
            description=CACHE_SIZE_DESCRIPTION
        )
        self.SVMcacheSizeEntry = make_entry(
            self, layout=self.bottom,
            row=9, column=1, width=50,
            description=CACHE_SIZE_DESCRIPTION
        )

        self.SVMmaxIterLabel = make_label(
            self, text='Maximum Iterations:', layout=self.bottom,
            row=10, column=0,
            width=200, description=MAX_ITER_DESCRIPTION
        )
        self.SVMmaxIterEntry = make_entry(
            self, layout=self.bottom,
            row=10, column=1, width=50,
            description=MAX_ITER_DESCRIPTION
        )

    def set_knn(self):
        # K NEIGHBORS
        label2 = make_label(
            self, text='K   N E A R E S T   N E I G H B O R S', layout=self.bottom,
            row=11, column=0,
            width=200
        )

        self.KNnNeighborsLabel = make_label(
            self, text='Number of Neighbors:', layout=self.bottom,
            row=12, column=0,
            width=200, description=N_NEIGHBORS_DESCRIPTION
        )
        self.KNnNeighborsEntry = make_entry(
            self, layout=self.bottom,
            row=12, column=1, width=50,
            description=N_NEIGHBORS_DESCRIPTION
        )

        self.KNweightsLabel = make_label(
            self, text='Weights Function:', layout=self.bottom,
            row=13, column=0,
            width=200, description=WEIGHTS_DESCRIPTION
        )
        self.KNweightsCombo = make_combo(
            self, ('uniform', 'distance'), layout=self.bottom,
            row=13, column=1, width=100,
            description=WEIGHTS_DESCRIPTION
        )

        self.KNalgorithmLabel = make_label(
            self, text='Algorithm:', layout=self.bottom,
            row=14, column=0,
            description=ALGORITHM_DESCRIPTION
        )
        self.KNalgorithmCombo = make_combo(
            self, ('auto', 'ball_tree', 'kd_tree', 'brute'), layout=self.bottom,
            row=14,
            column=1, width=100, description=ALGORITHM_DESCRIPTION
        )

        self.KNleafSizeLabel = make_label(
            self, text='Leaf Size:', layout=self.bottom,
            row=15, column=0,
            description=LEAF_SIZE_DESCRIPTION
        )
        self.KNleafSizeEntry = make_entry(
            self, layout=self.bottom,
            row=15, column=1, width=50,
            description=LEAF_SIZE_DESCRIPTION
        )

        self.KNpLabel = make_label(
            self, text='Minkowski Power:', layout=self.bottom,
            row=16, column=0, width=200,
            description=P_DESCRIPTION
        )
        self.KNpEntry = make_entry(
            self, layout=self.bottom,
            row=16, column=1, width=50, description=P_DESCRIPTION
        )

        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

    def set_dt(self):
        # DECISION TREE
        label3 = make_label(
            self, text='D E C I S I O N   T R E E', layout=self.bottom,
            row=20, column=0, width=250
        )
        self.DTcriterionLabel = make_label(
            self, text='Criterion:', layout=self.bottom,
            row=21, column=0, width=200,
            description=CRITERION_DESCRIPTION
        )
        self.DTcriterionCombo = make_combo(
            self, ('mse', 'friedman_mse', 'mae'),
            layout=self.bottom,
            row=21, column=1, width=100,
            description=CRITERION_DESCRIPTION
        )

        self.DTsplitterLabel = make_label(
            self, text='Splitter:', layout=self.bottom,
            row=22, column=0,
            description=SPLITTER_DESCRIPTION
        )
        self.DTsplitterCombo = make_combo(
            self, ('best', 'random'), layout=self.bottom,
            row=22, column=1, width=75,
            description=SPLITTER_DESCRIPTION
        )

        self.DTmaxDepthLabel = make_label(
            self, text='Maximum Depth:', layout=self.bottom,
            row=23, column=0, width=125,
            description=MAX_DEPTH_DESCRIPTION
        )
        self.DTmaxDepthEntry = make_entry(
            self, layout=self.bottom,
            row=23, column=1, width=50,
            description=MAX_DEPTH_DESCRIPTION
        )

        self.DTminSamplesSplitLabel = make_label(
            self, text='Minimum Samples Split:', layout=self.bottom,
            row=24, column=0, width=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )
        self.DTminSamplesSplitEntry = make_entry(
            self, layout=self.bottom,
            row=24, column=1, width=50,
            description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        self.DTminSamplesLeafLabel = make_label(
            self, text='Minimum Samples at Leaf:', layout=self.bottom,
            row=25, column=0, width=200,
            description=MIN_SAMPLES_LEAF_DESCRIPTION
        )
        self.DTminSamplesLeafEntry = make_entry(
            self, layout=self.bottom,
            row=25, column=1, width=50,
            description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        self.DTminWeightFractionLeafLabel = make_label(
            self, text='Minimum Sum Weighted Fraction:', layout=self.bottom,
            row=26, column=0, width=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )
        self.DTminWeightFractionLeafEntry = make_entry(
            self, layout=self.bottom,
            row=26, column=1, width=50,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        self.DTmaxFeaturesLabel = make_label(
            self, text='Maximum Features:', layout=self.bottom,
            row=27, column=0, width=200,
            description=MAX_FEATURES_DESCRIPTION
        )
        self.DTmaxFeaturesCombo = make_combo(
            self, ('auto', 'sqrt', 'log2'), layout=self.bottom,
            row=27, column=1, width=50,
            description=MAX_FEATURES_DESCRIPTION
        )

        self.DTrandomStateLabel = make_label(
            self, text='Random State:', layout=self.bottom,
            row=28, column=0,
            width=125, description=RANDOM_STATE_DESCRIPTION
        )
        self.DTrandomStateEntry = make_entry(
            self, layout=self.bottom,
            row=28, column=1, width=50,
            description=RANDOM_STATE_DESCRIPTION
        )

        self.DTmaxLeafNodesLabel = make_label(
            self, text='Maximum Leaf Nodes:', layout=self.bottom,
            row=29, column=0,
            width=200, description=MAX_LEAF_NODES_DESCRIPTION
        )
        self.DTmaxLeafNodesEntry = make_entry(
            self, layout=self.bottom,
            row=29, column=1, width=50,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        self.DTminImpurityDecreaseLabel = make_label(
            self, text='Minimum Impurity Decrease:', layout=self.bottom,
            row=30, column=0, width=200,
            description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )
        self.DTminImpurityDecreaseEntry = make_entry(
            self, layout=self.bottom,
            row=30, column=1, width=50,
            description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        self.DTpresortLabel = make_label(
            self, text='Presort Data:', layout=self.bottom,
            row=31, column=0, width=200,
            description=PRESORT_DESCRIPTION
        )
        self.DTpresortCheck = make_button(
            self, type='check', layout=self.bottom,
            row=31, column=1,
            description=PRESORT_DESCRIPTION
        )

    def set_rf(self):
        # RANDOM FOREST
        label4 = make_label(
            self, text='R A N D O M   F O R E S T', layout=self.bottom,
            row=32, column=0, width=200
        )

        self.RFnEstimatorsLabel = make_label(
            self, text='Number of Trees:', layout=self.bottom,
            row=33, column=0,
            width=200, description=N_ESTIMATORS_DESCRIPTION
        )
        self.RFnEstimatorsEntry = make_entry(
            self, layout=self.bottom,
            row=33, column=1, width=50,
            description=N_ESTIMATORS_DESCRIPTION
        )

        self.RFcriterionLabel = make_label(
            self, text='Criterion:', layout=self.bottom,
            row=34, column=0,
            description=CRITERION_DESCRIPTION
        )
        self.RFcriterionCombo = make_combo(
            self, ('mse', 'mae'), layout=self.bottom,
            row=34, column=1, width=50,
            description=CRITERION_DESCRIPTION
        )

        self.RFmaxFeaturesLabel = make_label(
            self, text='Maximum Features:', layout=self.bottom,
            row=35, column=0,
            width=200, description=MAX_FEATURES_DESCRIPTION
        )
        self.RFmaxFeaturesCombo = make_combo(
            self, ('auto', 'sqrt', 'log2'), layout=self.bottom,
            row=35, column=1,
            width=50, description=MAX_FEATURES_DESCRIPTION
        )

        self.RFmaxDepthLabel = make_label(
            self, text='Maximum Depth:', layout=self.bottom,
            row=36, column=0,
            width=200, description=MAX_DEPTH_DESCRIPTION
        )
        self.RFmaxDepthEntry = make_entry(
            self, layout=self.bottom,
            row=36, column=1, width=50,
            description=MAX_DEPTH_DESCRIPTION
        )

        self.RFminSamplesSplitLabel = make_label(
            self, text='Minimum Samples Split:', layout=self.bottom,
            row=37, column=0, width=175,
            description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )
        self.RFminSamplesSplitEntry = make_entry(
            self, layout=self.bottom,
            row=37, column=1, width=50,
            description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        self.RFminSamplesLeafLabel = make_label(
            self, text='Minimum Samples at Leaf:', layout=self.bottom,
            row=38, column=0, width=220,
            description=MIN_SAMPLES_LEAF_DESCRIPTION
        )
        self.RFminSamplesLeafEntry = make_entry(
            self, layout=self.bottom,
            row=38, column=1, width=50,
            description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        self.RFminWeightFractionLeafLabel = make_label(
            self, text='Minimum Sum Weighted Fraction:',
            layout=self.bottom,
            row=39, column=0, width=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )
        self.RFminWeightFractionLeafEntry = make_entry(
            self, layout=self.bottom,
            row=39, column=1, width=50,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        self.RFmaxLeafNodesLabel = make_label(
            self, text='Maximum Leaf Nodes:', layout=self.bottom,
            row=40, column=0, width=220,
            description=MAX_LEAF_NODES_DESCRIPTION
        )
        self.RFmaxLeafNodesEntry = make_entry(
            self, layout=self.bottom,
            row=40, column=1, width=50,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        self.RFminImpurityDecreaseLabel = make_label(
            self, text='Minimum Impurity Decrease:', layout=self.bottom,
            row=41, column=0, width=220,
            description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )
        self.RFminImpurityDecreaseEntry = make_entry(
            self, layout=self.bottom,
            row=41, column=1, width=50,
            description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        self.RFbootstrapLabel = make_label(
            self, text='Bootstrap:', layout=self.bottom,
            row=42, column=0,
            description=BOOTSTRAP_DESCRIPTION
        )
        self.RFbootstrapCheck = make_button(
            self, type='check', layout=self.bottom,
            row=42, column=1,
            description=BOOTSTRAP_DESCRIPTION
        )

        self.RFoobScoreLabel = make_label(
            self, text='Out-of-Bag Samples:', layout=self.bottom,
            row=43, column=0, width=200,
            description=OOB_SCORE_DESCRIPTION
        )
        self.RFoobScoreCheck = make_button(
            self, type='check', layout=self.bottom,
            row=43, column=1,
            description=OOB_SCORE_DESCRIPTION
        )

        # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottom, row=44, column=0, width=200)
        # self.RFnJobsEntry = make_entry(self, layout=self.bottom, row=44, column=1, width=50)

        self.RFrandomStateLabel = make_label(
            self, text='Random State:', layout=self.bottom,
            row=45, column=0, width=200,
            description=RANDOM_STATE_DESCRIPTION
        )
        self.RFrandomStateEntry = make_entry(
            self, layout=self.bottom,
            row=45, column=1, width=50,
            description=RANDOM_STATE_DESCRIPTION
        )

        # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.bottom, row=46, column=0, width=200)
        # self.RFverboseEntry = make_entry(self, layout=self.bottom, row=46, column=1, width=50)

        self.RFwarmStartLabel = make_label(
            self, text='Warm Start:', layout=self.bottom,
            row=47, column=0, width=200,
            description=WARM_START_DESCRIPTION
        )
        self.RFwarmStartCheck = make_button(
            self, type='check', layout=self.bottom,
            row=47, column=1,
            description=WARM_START_DESCRIPTION
        )

    def set_nn(self):
        # MULTI-LAYER PERCEPTRON
        label5 = make_label(
            self, text='M U L T I - L A Y E R   P E R C E P T R O N', layout=self.bottom,
            row=48, column=0, width=200
        )

        self.MLPhiddenLayerSizesLabel = make_label(
            self, text='Hidden Layer Sizes:', layout=self.bottom,
            row=49, column=0, width=200,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )
        self.MLPLayerSizesEntry = make_entry(
            self, layout=self.bottom,
            row=49, column=1, width=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

        self.MLPActivationLabel = make_label(
            self, text='Activation Function', layout=self.bottom,
            row=50, column=0, width=200,
            description=ACTIVATION_DESCRIPTION
        )
        self.MLPActivationCombo = make_combo(
            self, ('identity', 'logistic', 'tanh', 'relu'),
            layout=self.bottom,
            row=50, column=1, width=100,
            description=ACTIVATION_DESCRIPTION
        )

        self.MLPSolverLabel = make_label(
            self, text='Weight Optimization Solver:', layout=self.bottom,
            row=51, column=0, width=200,
            description=SOLVER_DESCRIPTION
        )
        self.MLPSolverCombo = make_combo(
            self, ('lbfgs', 'sgd', 'adam'), layout=self.bottom,
            row=51, column=1, width=100,
            description=SOLVER_DESCRIPTION
        )

        self.MLPAlphaLabel = make_label(
            self, text='Penalty Parameter:', layout=self.bottom,
            row=52, column=0, width=200,
            description=MLP_ALPHA_DESCRIPTION
        )
        self.MLPAlphaEntry = make_entry(
            self, layout=self.bottom,
            row=52, column=1, width=100,
            description=MLP_ALPHA_DESCRIPTION
        )

        self.MLPBatchSizeLabel = make_label(
            self, text='Batch Size:', layout=self.bottom,
            row=53, column=0, width=200,
            description=BATCH_SIZE_DESCRIPTION
        )
        self.MLPBatchSizeEntry = make_entry(
            self, layout=self.bottom,
            row=53, column=1, width=50,
            description=BATCH_SIZE_DESCRIPTION
        )

        self.MLPlearningRateLabel = make_label(
            self, text='Learning Rate:', layout=self.bottom,
            row=54, column=0, width=200,
            description=LEARNING_RATE_DESCRIPTION
        )
        self.MLPlearningRateCombo = make_combo(
            self, ('constant', 'invscaling', 'adaptive'),
            layout=self.bottom,
            row=54, column=1, width=100,
            description=LEARNING_RATE_DESCRIPTION
        )

        self.MLPlearningRateInitLabel = make_label(
            self, text='Initial Learning Rate:',
            layout=self.bottom,
            row=55, column=0, width=200,
            description=LEARNING_RATE_INIT_DESCRIPTION
        )
        self.MLPlearningRateInitEntry = make_entry(
            self, layout=self.bottom,
            row=55, column=1, width=50,
            description=LEARNING_RATE_INIT_DESCRIPTION
        )

        self.MLPpowerTLabel = make_label(
            self, text='Power for Inverse Learning Rate:',
            layout=self.bottom,
            row=56, column=0, width=250,
            description=POWER_T_DESCRIPTION
        )
        self.MLPpowerTEntry = make_entry(
            self, layout=self.bottom,
            row=56, column=1, width=50,
            description=POWER_T_DESCRIPTION
        )

        self.MLPmaxIterLabel = make_label(
            self, text='Maximum Iterations:', layout=self.bottom,
            row=57, column=0, width=250, description=MLP_MAX_ITER_DESCRIPTION
        )
        self.MLPmaxIterEntry = make_entry(
            self, layout=self.bottom,
            row=57, column=1, width=50,
            description=MLP_MAX_ITER_DESCRIPTION
        )

        self.MLPshuffleLabel = make_label(
            self, text='Shuffle:', layout=self.bottom,
            row=58, column=0,
            description=SHUFFLE_DESCRIPTION
        )
        self.MLPshuffleCheck = make_button(
            self, type='check', layout=self.bottom,
            row=58, column=1,
            description=SHUFFLE_DESCRIPTION
        )

        self.MLPrandomStateLabel = make_label(
            self, text='Random State:', layout=self.bottom,
            row=59, column=0,
            width=200, description=MLP_RANDOM_STATE_DESCRIPTION
        )
        self.MLPrandomStateEntry = make_entry(
            self, layout=self.bottom,
            row=59, column=1, width=50,
            description=MLP_RANDOM_STATE_DESCRIPTION
        )

        self.MLPtolLabel = make_label(
            self, text='Tolerance:', layout=self.bottom,
            row=60, column=0,
            description=MLP_TOL_DESCRIPTION
        )
        self.MLPtolEntry = make_entry(
            self, layout=self.bottom,
            row=60, column=1, width=50,
            description=MLP_TOL_DESCRIPTION
        )

        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.bottom, row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.bottom, row=61, column=1)

        self.MLPwarmStartLabel = make_label(
            self, text='Warm Start:', layout=self.bottom,
            row=62, column=0, width=200,
            description=MLP_WARM_START_DESCRIPTION
        )
        self.MLPwarmStartCheck = make_button(
            self, type='check', layout=self.bottom,
            row=62, column=1,
            description=MLP_WARM_START_DESCRIPTION
        )

        self.MLPmomentumLabel = make_label(
            self, text='Momentum:', layout=self.bottom,
            row=63, column=0,
            description=MOMENTUM_DESCRIPTION
        )
        self.MLPmomentumEntry = make_entry(
            self, layout=self.bottom,
            row=63, column=1, width=50,
            description=MOMENTUM_DESCRIPTION
        )

        self.MLPnesterovsMomentumLabel = make_label(
            self, text='Nesterov\'s Momentum:', layout=self.bottom,
            row=64, column=0, width=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )
        self.MLPnesterovsMomentumCheck = make_button(
            self, type='check', layout=self.bottom,
            row=64, column=1,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )

        self.MLPearlyStoppingLabel = make_label(
            self, text='Early Stopping:', layout=self.bottom,
            row=65, column=0, width=200,
            description=EARLY_STOPPING_DESCRIPTION
        )
        self.MLPearlyStoppingCheck = make_button(
            self, type='check', layout=self.bottom,
            row=65, column=1,
            description=EARLY_STOPPING_DESCRIPTION
        )

        self.MLPvalidationFractionLabel = make_label(
            self, text='Validation Fraction:', layout=self.bottom,
            row=66, column=0, width=200,
            description=VALIDATION_FRACTION_DESCRIPTION
        )
        self.MLPvalidationFractionEntry = make_entry(
            self, layout=self.bottom,
            row=66, column=1, width=50,
            description=VALIDATION_FRACTION_DESCRIPTION
        )

        self.MLPbeta1Label = make_label(
            self, text='First Moment Exponential Decay:', layout=self.bottom,
            row=67, column=0, width=250,
            description=BETA_1_DESCRIPTION
        )
        self.MLPbeta1Entry = make_entry(
            self, layout=self.bottom,
            row=67, column=1, width=50,
            description=BETA_1_DESCRIPTION
        )

        self.MLPbeta2Label = make_label(
            self, text='Second Moment Exponential Decay:', layout=self.bottom,
            row=68, column=0, width=250,
            description=BETA_2_DESCRIPTION
        )
        self.MLPbeta2Entry = make_entry(
            self, layout=self.bottom,
            row=68, column=1, width=50,
            description=BETA_2_DESCRIPTION
        )

        self.MLPepsilonLabel = make_label(
            self, text='Numerical Stability:', layout=self.bottom,
            row=69, column=0, width=200, description=MLP_EPSILON_DESCRIPTION
        )
        self.MLPepsilonEntry = make_entry(
            self, layout=self.bottom,
            row=69, column=1, width=50,
            description=MLP_EPSILON_DESCRIPTION
        )

    def set_kr(self):
        # KERNEL RIDGE
        label6 = make_label(
            self, text='K E R N E L   R I D G E', layout=self.bottom,
            row=70, column=0
        )
        self.KRalphaLabel = make_label(
            self, text='Alpha:', layout=self.bottom,
            row=71, column=0,
            description=ALPHA_DESCRIPTION
        )
        self.KRalphaEntry = make_entry(
            self, layout=self.bottom,
            row=71, column=1, description=ALPHA_DESCRIPTION
        )

        self.KRkernelLabel = make_label(
            self, text='Kernel:', layout=self.bottom,
            row=72, column=0,
            description=KERNEL_DESCRIPTION
        )
        self.KRkernelCombo = make_combo(
            self, ('linear', 'poly', 'rbf'), layout=self.bottom,
            row=72, column=1,
            description=KERNEL_DESCRIPTION
        )

        self.KRgammaLabel = make_label(
            self, text='Gamma:', layout=self.bottom,
            row=73, column=0,
            description=GAMMA_DESCRIPTION
        )
        self.KRgammaEntry = make_entry(
            self, layout=self.bottom,
            row=73, column=1, description=GAMMA_DESCRIPTION
        )

        self.KRdegreeLabel = make_label(
            self, text='Polynomial Degree:', layout=self.bottom,
            row=74, column=0,
            description=DEGREE_DESCRIPTION
        )
        self.KRdegreeCombo = make_combo(
            self, ('0', '1', '1', '2', '3', '5'), layout=self.bottom,
            row=74, column=1,
            description=DEGREE_DESCRIPTION
        )

        self.KRcoef0Label = make_label(
            self, text='Coefficient 0:', layout=self.bottom,
            row=75, column=0,
            description=COEF0_DESCRIPTION
        )
        self.KRcoef0Entry = make_entry(
            self, layout=self.bottom,
            row=75, column=1,
            description=COEF0_DESCRIPTION
        )

    def rewindow(self):
        # self.svmTab = make_tab(self, text='Support Vector Machine', master=self.tabs)
        # self.mlpTab = make_tab(self, text='Multilayer Perceptron', master=self.tabs)
        # self.knnTab = make_tab(self, text='K Nearest Neighbors', master=self.tabs)
        # self.dtTab = make_tab(self, text='Decision Tree', master=self.tabs)
        # self.rfTab = make_tab(self, text='Random Forest', master=self.tabs)
        # self.krTab = make_tab(self, text='K Ridge', master=self.tabs)
        # label = make_label(self, text='ass', layout=self.svmTab)

        self.widget = QtWidgets.QWidget()
        self.widget.setStyleSheet(WIDGET_STYLE)
        self.bottom = make_grid(self)
        self.refresh()
        self.widget.setLayout(self.bottom)
        self.scrollArea = make_scroll_area(self.widget)
        self.bottomLayout = make_grid(self.scrollArea)
        self.splitter2 = make_splitter(style='v', widgets=(self.tabs, self.scrollArea))
        self.scrollArea.setMinimumSize(WIDTH / 4, HEIGHT / 4)
        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def get_options(self):
        options = {
            'krAlpha':                       dh.nonize(self.KRalphaEntry.text()),
            'krkernel':                      self.KRkernelCombo.currentText(),
            'krGamma':                       dh.nonize(self.KRgammaEntry.text()),
            'krPolynomialDegree':            self.KRdegreeCombo.currentText(),
            'krcoef0':                       dh.nonize(self.KRcoef0Entry.text()),

            'dtrCriterion':                  self.DTcriterionCombo.currentText(),
            'dtrSplitter':                   self.DTsplitterCombo.currentText(),
            'dtrMaxDepth':                   dh.nonize(self.DTmaxDepthEntry.text()),
            'dtrMinSamplesSplit':            dh.nonize(self.DTminSamplesSplitEntry.text()),
            'dtrMinSamplesLeaf':             dh.nonize(self.DTminSamplesLeafEntry.text()),
            'dtrMinWeightFractionLeaf':      dh.nonize(self.DTminWeightFractionLeafEntry.text()),
            'dtrMaxFeatures':                self.DTmaxFeaturesCombo.currentText(),
            'dtrRandomState':                dh.nonize(self.DTrandomStateEntry.text()),
            'dtrMaxLeafNodes':               dh.nonize(self.DTmaxLeafNodesEntry.text()),
            'dtrMinImpurityDecrease':        dh.nonize(self.DTminImpurityDecreaseEntry.text()),
            'dtrPresort':                    dh.nonize(self.DTpresortCheck.isCheck()),

            'svrC':                          dh.nonize(self.SVMCEntry.text()),
            'svrEpsilon':                    dh.nonize(self.SVMepsilonEntry.text()),
            'svrKernel':                     self.SVMkernelCombo.currentText(),
            'svrPolynomialDegree':           self.SVMdegreeCombo.currentText(),
            'svrGamma':                      dh.nonize(self.SVMgammaEntry.text()),
            'svrCoefficient0':               dh.nonize(self.SVMcoef0Entry.text()),
            'svrShrinking':                  self.SVMshrinkingCheck.isChecked(),
            'svrTolerance':                  dh.nonize(self.SVMtolEntry.text()),
            'svrCacheSize':                  dh.nonize(self.SVMcacheSizeEntry.text()),
            'svrMaximumIterations':          dh.nonize(self.SVMmaxIterEntry.text()),
            'rfrNumberOfTrees':              dh.nonize(self.RFnEstimatorsEntry.text()),
            'rfrCriterion':                  self.RFcriterionCombo.currentText(),
            'rfrMaximumFeatures':            self.RFmaxFeaturesCombo.currentText(),
            'rfrMaximumDepth':               dh.nonize(self.RFmaxDepthEntry.text()),
            'rfrMinimumSamplesSplit':        dh.nonize(self.RFminSamplesSplitEntry.text()),
            'rfrMinimumSamplesAtLeaf':       dh.nonize(self.RFminSamplesLeafEntry.text()),
            'rfrMinimumSumWeightedFraction': dh.nonize(self.RFminWeightFractionLeafEntry.text()),
            'rfrMaximumLeafNodes':           dh.nonize(self.RFmaxLeafNodesEntry.text()),
            'rfrBootstrap':                  self.RFbootstrapCheck.isChecked(),
            'rfrOutOfBagSamples':            self.RFoobScoreCheck.isChecked(),
            'RandomState':                   dh.nonize(self.RFrandomStateEntry.text()),
            'rfrWarmStart':                  self.RFwarmStartCheck.isChecked(),
        }
        return options

    def defaults(self):
        pass

    def apply(self):
        pass

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        """BOTTOM"""
        self.rewindow()

    def refresh(self):
        self.set_svm()
        self.set_knn()
        self.set_kr()
        self.set_nn()
        self.set_dt()
        self.set_rf()

    def set_svm(self):
        # SUPPORT VECTOR MACHINE
        label1 = make_label(
            self, text='S U P P O R T   V E C T O R   M A C H I N E', layout=self.bottom, row=0,
            column=0, width=200
        )

        self.SVMCLabel = make_label(self, text='C:', layout=self.bottom, row=1, column=0, description=C_DESCRIPTION)
        self.SVMCEntry = make_entry(self, layout=self.bottom, row=1, column=1, width=50, description=C_DESCRIPTION)

        self.SVMepsilonLabel = make_label(
            self, text='Epsilon:', layout=self.bottom, row=2, column=0,
            description=EPSILON_DESCRIPTION
        )
        self.SVMepsilonEntry = make_entry(
            self, layout=self.bottom, row=2, column=1, width=50,
            description=EPSILON_DESCRIPTION
        )

        self.SVMkernelLabel = make_label(
            self, text='Kernel:', layout=self.bottom, row=3, column=0,
            description=KERNEL_DESCRIPTION
        )
        self.SVMkernelCombo = make_combo(
            self, ('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'), layout=self.bottom,
            row=3, column=1, width=100, description=KERNEL_DESCRIPTION
        )

        self.SVMdegreeLabel = make_label(
            self, text='Polynomial Degree:', layout=self.bottom, row=4, column=0,
            description=DEGREE_DESCRIPTION
        )
        self.SVMdegreeCombo = make_combo(
            self, ('0', '1', '1', '2', '3', '5'), layout=self.bottom, row=4, column=1,
            width=100, description=DEGREE_DESCRIPTION
        )

        self.SVMgammaLabel = make_label(
            self, text='Gamma:', layout=self.bottom, row=5, column=0,
            description=GAMMA_DESCRIPTION
        )
        self.SVMgammaEntry = make_entry(
            self, layout=self.bottom, row=5, column=1, width=50,
            description=GAMMA_DESCRIPTION
        )

        self.SVMcoef0Label = make_label(
            self, text='Coefficient 0:', layout=self.bottom, row=6, column=0,
            description=COEF0_DESCRIPTION
        )
        self.SVMcoef0Entry = make_entry(
            self, layout=self.bottom, row=6, column=1, width=50,
            description=COEF0_DESCRIPTION
        )

        self.SVMshrinkingLabel = make_label(
            self, text='Shrinking:', layout=self.bottom, row=7, column=0,
            description=SHRINKING_DESCRIPTION
        )
        self.SVMshrinkingCheck = make_button(
            self, type='check', layout=self.bottom, row=7, column=1,
            description=SHRINKING_DESCRIPTION
        )

        self.SVMtolLabel = make_label(
            self, text='Tolerance:', layout=self.bottom, row=8, column=0,
            description=TOL_DESCRIPTION
        )
        self.SVMtolEntry = make_entry(self, layout=self.bottom, row=8, column=1, width=50, description=TOL_DESCRIPTION)

        self.SVMcacheSizeLabel = make_label(
            self, text='Cache Size:', layout=self.bottom, row=9, column=0,
            description=CACHE_SIZE_DESCRIPTION
        )
        self.SVMcacheSizeEntry = make_entry(
            self, layout=self.bottom, row=9, column=1, width=50,
            description=CACHE_SIZE_DESCRIPTION
        )

        self.SVMmaxIterLabel = make_label(
            self, text='Maximum Iterations:', layout=self.bottom, row=10, column=0,
            width=200, description=MAX_ITER_DESCRIPTION
        )
        self.SVMmaxIterEntry = make_entry(
            self, layout=self.bottom, row=10, column=1, width=50,
            description=MAX_ITER_DESCRIPTION
        )

    def set_knn(self):
        # K NEIGHBORS
        label2 = make_label(
            self, text='K   N E A R E S T   N E I G H B O R S', layout=self.bottom, row=11, column=0,
            width=200
        )

        self.KNnNeighborsLabel = make_label(
            self, text='Number of Neighbors:', layout=self.bottom, row=12, column=0,
            width=200, description=N_NEIGHBORS_DESCRIPTION
        )
        self.KNnNeighborsEntry = make_entry(
            self, layout=self.bottom, row=12, column=1, width=50,
            description=N_NEIGHBORS_DESCRIPTION
        )

        self.KNweightsLabel = make_label(
            self, text='Weights Function:', layout=self.bottom, row=13, column=0,
            width=200, description=WEIGHTS_DESCRIPTION
        )
        self.KNweightsCombo = make_combo(
            self, ('uniform', 'distance'), layout=self.bottom, row=13, column=1, width=100,
            description=WEIGHTS_DESCRIPTION
        )

        self.KNalgorithmLabel = make_label(
            self, text='Algorithm:', layout=self.bottom, row=14, column=0,
            description=ALGORITHM_DESCRIPTION
        )
        self.KNalgorithmCombo = make_combo(
            self, ('auto', 'ball_tree', 'kd_tree', 'brute'), layout=self.bottom, row=14,
            column=1, width=100, description=ALGORITHM_DESCRIPTION
        )

        self.KNleafSizeLabel = make_label(
            self, text='Leaf Size:', layout=self.bottom, row=15, column=0,
            description=LEAF_SIZE_DESCRIPTION
        )
        self.KNleafSizeEntry = make_entry(
            self, layout=self.bottom, row=15, column=1, width=50,
            description=LEAF_SIZE_DESCRIPTION
        )

        self.KNpLabel = make_label(
            self, text='Minkowski Power:', layout=self.bottom, row=16, column=0, width=200,
            description=P_DESCRIPTION
        )
        self.KNpEntry = make_entry(self, layout=self.bottom, row=16, column=1, width=50, description=P_DESCRIPTION)

        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)  # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)  # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)  # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

    def set_dt(self):
        # DECISION TREE
        label3 = make_label(self, text='D E C I S I O N   T R E E', layout=self.bottom, row=20, column=0, width=250)
        self.DTcriterionLabel = make_label(
            self, text='Criterion:', layout=self.bottom, row=21, column=0, width=200,
            description=CRITERION_DESCRIPTION
        )
        self.DTcriterionCombo = make_combo(
            self, ('mse', 'friedman_mse', 'mae'), layout=self.bottom, row=21, column=1,
            width=100, description=CRITERION_DESCRIPTION
        )

        self.DTsplitterLabel = make_label(
            self, text='Splitter:', layout=self.bottom, row=22, column=0,
            description=SPLITTER_DESCRIPTION
        )
        self.DTsplitterCombo = make_combo(
            self, ('best', 'random'), layout=self.bottom, row=22, column=1, width=75,
            description=SPLITTER_DESCRIPTION
        )

        self.DTmaxDepthLabel = make_label(
            self, text='Maximum Depth:', layout=self.bottom, row=23, column=0, width=125,
            description=MAX_DEPTH_DESCRIPTION
        )
        self.DTmaxDepthEntry = make_entry(
            self, layout=self.bottom, row=23, column=1, width=50,
            description=MAX_DEPTH_DESCRIPTION
        )

        self.DTminSamplesSplitLabel = make_label(
            self, text='Minimum Samples Split:', layout=self.bottom, row=24,
            column=0, width=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )
        self.DTminSamplesSplitEntry = make_entry(
            self, layout=self.bottom, row=24, column=1, width=50,
            description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        self.DTminSamplesLeafLabel = make_label(
            self, text='Minimum Samples at Leaf:', layout=self.bottom, row=25,
            column=0, width=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )
        self.DTminSamplesLeafEntry = make_entry(
            self, layout=self.bottom, row=25, column=1, width=50,
            description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        self.DTminWeightFractionLeafLabel = make_label(
            self, text='Minimum Sum Weighted Fraction:', layout=self.bottom,
            row=26, column=0, width=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )
        self.DTminWeightFractionLeafEntry = make_entry(
            self, layout=self.bottom, row=26, column=1, width=50,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        self.DTmaxFeaturesLabel = make_label(
            self, text='Maximum Features:', layout=self.bottom, row=27, column=0,
            width=200, description=MAX_FEATURES_DESCRIPTION
        )
        self.DTmaxFeaturesCombo = make_combo(
            self, ('auto', 'sqrt', 'log2'), layout=self.bottom, row=27, column=1,
            width=50, description=MAX_FEATURES_DESCRIPTION
        )

        self.DTrandomStateLabel = make_label(
            self, text='Random State:', layout=self.bottom, row=28, column=0,
            width=125, description=RANDOM_STATE_DESCRIPTION
        )
        self.DTrandomStateEntry = make_entry(
            self, layout=self.bottom, row=28, column=1, width=50,
            description=RANDOM_STATE_DESCRIPTION
        )

        self.DTmaxLeafNodesLabel = make_label(
            self, text='Maximum Leaf Nodes:', layout=self.bottom, row=29, column=0,
            width=200, description=MAX_LEAF_NODES_DESCRIPTION
        )
        self.DTmaxLeafNodesEntry = make_entry(
            self, layout=self.bottom, row=29, column=1, width=50,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        self.DTminImpurityDecreaseLabel = make_label(
            self, text='Minimum Impurity Decrease:', layout=self.bottom,
            row=30, column=0, width=200,
            description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )
        self.DTminImpurityDecreaseEntry = make_entry(
            self, layout=self.bottom, row=30, column=1, width=50,
            description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        self.DTpresortLabel = make_label(
            self, text='Presort Data:', layout=self.bottom, row=31, column=0, width=200,
            description=PRESORT_DESCRIPTION
        )
        self.DTpresortCheck = make_button(
            self, type='check', layout=self.bottom, row=31, column=1,
            description=PRESORT_DESCRIPTION
        )

    def set_rf(self):
        # RANDOM FOREST
        label4 = make_label(self, text='R A N D O M   F O R E S T', layout=self.bottom, row=32, column=0, width=200)

        self.RFnEstimatorsLabel = make_label(
            self, text='Number of Trees:', layout=self.bottom, row=33, column=0,
            width=200, description=N_ESTIMATORS_DESCRIPTION
        )
        self.RFnEstimatorsEntry = make_entry(
            self, layout=self.bottom, row=33, column=1, width=50,
            description=N_ESTIMATORS_DESCRIPTION
        )

        self.RFcriterionLabel = make_label(
            self, text='Criterion:', layout=self.bottom, row=34, column=0,
            description=CRITERION_DESCRIPTION
        )
        self.RFcriterionCombo = make_combo(
            self, ('mse', 'mae'), layout=self.bottom, row=34, column=1, width=50,
            description=CRITERION_DESCRIPTION
        )

        self.RFmaxFeaturesLabel = make_label(
            self, text='Maximum Features:', layout=self.bottom, row=35, column=0,
            width=200, description=MAX_FEATURES_DESCRIPTION
        )
        self.RFmaxFeaturesCombo = make_combo(
            self, ('auto', 'sqrt', 'log2'), layout=self.bottom, row=35, column=1,
            width=50, description=MAX_FEATURES_DESCRIPTION
        )

        self.RFmaxDepthLabel = make_label(
            self, text='Maximum Depth:', layout=self.bottom, row=36, column=0, width=200,
            description=MAX_DEPTH_DESCRIPTION
        )
        self.RFmaxDepthEntry = make_entry(
            self, layout=self.bottom, row=36, column=1, width=50,
            description=MAX_DEPTH_DESCRIPTION
        )

        self.RFminSamplesSplitLabel = make_label(
            self, text='Minimum Samples Split:', layout=self.bottom, row=37,
            column=0, width=175, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )
        self.RFminSamplesSplitEntry = make_entry(
            self, layout=self.bottom, row=37, column=1, width=50,
            description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        self.RFminSamplesLeafLabel = make_label(
            self, text='Minimum Samples at Leaf:', layout=self.bottom, row=38,
            column=0, width=220, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )
        self.RFminSamplesLeafEntry = make_entry(
            self, layout=self.bottom, row=38, column=1, width=50,
            description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        self.RFminWeightFractionLeafLabel = make_label(
            self, text='Minimum Sum Weighted Fraction:', layout=self.bottom,
            row=39, column=0, width=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )
        self.RFminWeightFractionLeafEntry = make_entry(
            self, layout=self.bottom, row=39, column=1, width=50,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        self.RFmaxLeafNodesLabel = make_label(
            self, text='Maximum Leaf Nodes:', layout=self.bottom, row=40, column=0,
            width=220, description=MAX_LEAF_NODES_DESCRIPTION
        )
        self.RFmaxLeafNodesEntry = make_entry(
            self, layout=self.bottom, row=40, column=1, width=50,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        self.RFminImpurityDecreaseLabel = make_label(
            self, text='Minimum Impurity Decrease:', layout=self.bottom,
            row=41, column=0, width=220,
            description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )
        self.RFminImpurityDecreaseEntry = make_entry(
            self, layout=self.bottom, row=41, column=1, width=50,
            description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        self.RFbootstrapLabel = make_label(
            self, text='Bootstrap:', layout=self.bottom, row=42, column=0,
            description=BOOTSTRAP_DESCRIPTION
        )
        self.RFbootstrapCheck = make_button(
            self, type='check', layout=self.bottom, row=42, column=1,
            description=BOOTSTRAP_DESCRIPTION
        )

        self.RFoobScoreLabel = make_label(
            self, text='Out-of-Bag Samples:', layout=self.bottom, row=43, column=0,
            width=200, description=OOB_SCORE_DESCRIPTION
        )
        self.RFoobScoreCheck = make_button(
            self, type='check', layout=self.bottom, row=43, column=1,
            description=OOB_SCORE_DESCRIPTION
        )

        # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottom, row=44, column=0, width=200)
        # self.RFnJobsEntry = make_entry(self, layout=self.bottom, row=44, column=1, width=50)

        self.RFrandomStateLabel = make_label(
            self, text='Random State:', layout=self.bottom, row=45, column=0,
            width=200, description=RANDOM_STATE_DESCRIPTION
        )
        self.RFrandomStateEntry = make_entry(
            self, layout=self.bottom, row=45, column=1, width=50,
            description=RANDOM_STATE_DESCRIPTION
        )

        # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.bottom, row=46, column=0, width=200)
        # self.RFverboseEntry = make_entry(self, layout=self.bottom, row=46, column=1, width=50)

        self.RFwarmStartLabel = make_label(
            self, text='Warm Start:', layout=self.bottom, row=47, column=0, width=200,
            description=WARM_START_DESCRIPTION
        )
        self.RFwarmStartCheck = make_button(
            self, type='check', layout=self.bottom, row=47, column=1,
            description=WARM_START_DESCRIPTION
        )

    def set_nn(self):
        # MULTI-LAYER PERCEPTRON
        label5 = make_label(
            self, text='M U L T I - L A Y E R   P E R C E P T R O N', layout=self.bottom, row=48,
            column=0, width=200
        )

        self.MLPhiddenLayerSizesLabel = make_label(
            self, text='Hidden Layer Sizes:', layout=self.bottom, row=49,
            column=0, width=200, description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )
        self.MLPLayerSizesEntry = make_entry(
            self, layout=self.bottom, row=49, column=1, width=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

        self.MLPActivationLabel = make_label(
            self, text='Activation Function', layout=self.bottom, row=50, column=0,
            width=200, description=ACTIVATION_DESCRIPTION
        )
        self.MLPActivationCombo = make_combo(
            self, ('identity', 'logistic', 'tanh', 'relu'), layout=self.bottom, row=50,
            column=1, width=100, description=ACTIVATION_DESCRIPTION
        )

        self.MLPSolverLabel = make_label(
            self, text='Weight Optimization Solver:', layout=self.bottom, row=51, column=0,
            width=200, description=SOLVER_DESCRIPTION
        )
        self.MLPSolverCombo = make_combo(
            self, ('lbfgs', 'sgd', 'adam'), layout=self.bottom, row=51, column=1,
            width=100, description=SOLVER_DESCRIPTION
        )

        self.MLPAlphaLabel = make_label(
            self, text='Penalty Parameter:', layout=self.bottom, row=52, column=0,
            width=200, description=MLP_ALPHA_DESCRIPTION
        )
        self.MLPAlphaEntry = make_entry(
            self, layout=self.bottom, row=52, column=1, width=100,
            description=MLP_ALPHA_DESCRIPTION
        )

        self.MLPBatchSizeLabel = make_label(
            self, text='Batch Size:', layout=self.bottom, row=53, column=0, width=200,
            description=BATCH_SIZE_DESCRIPTION
        )
        self.MLPBatchSizeEntry = make_entry(
            self, layout=self.bottom, row=53, column=1, width=50,
            description=BATCH_SIZE_DESCRIPTION
        )

        self.MLPlearningRateLabel = make_label(
            self, text='Learning Rate:', layout=self.bottom, row=54, column=0,
            width=200, description=LEARNING_RATE_DESCRIPTION
        )
        self.MLPlearningRateCombo = make_combo(
            self, ('constant', 'invscaling', 'adaptive'), layout=self.bottom, row=54,
            column=1, width=100, description=LEARNING_RATE_DESCRIPTION
        )

        self.MLPlearningRateInitLabel = make_label(
            self, text='Initial Learning Rate:', layout=self.bottom, row=55,
            column=0, width=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )
        self.MLPlearningRateInitEntry = make_entry(
            self, layout=self.bottom, row=55, column=1, width=50,
            description=LEARNING_RATE_INIT_DESCRIPTION
        )

        self.MLPpowerTLabel = make_label(
            self, text='Power for Inverse Learning Rate:', layout=self.bottom, row=56,
            column=0, width=250, description=POWER_T_DESCRIPTION
        )
        self.MLPpowerTEntry = make_entry(
            self, layout=self.bottom, row=56, column=1, width=50,
            description=POWER_T_DESCRIPTION
        )

        self.MLPmaxIterLabel = make_label(
            self, text='Maximum Iterations:', layout=self.bottom, row=57, column=0,
            width=250, description=MLP_MAX_ITER_DESCRIPTION
        )
        self.MLPmaxIterEntry = make_entry(
            self, layout=self.bottom, row=57, column=1, width=50,
            description=MLP_MAX_ITER_DESCRIPTION
        )

        self.MLPshuffleLabel = make_label(
            self, text='Shuffle:', layout=self.bottom, row=58, column=0,
            description=SHUFFLE_DESCRIPTION
        )
        self.MLPshuffleCheck = make_button(
            self, type='check', layout=self.bottom, row=58, column=1,
            description=SHUFFLE_DESCRIPTION
        )

        self.MLPrandomStateLabel = make_label(
            self, text='Random State:', layout=self.bottom, row=59, column=0,
            width=200, description=MLP_RANDOM_STATE_DESCRIPTION
        )
        self.MLPrandomStateEntry = make_entry(
            self, layout=self.bottom, row=59, column=1, width=50,
            description=MLP_RANDOM_STATE_DESCRIPTION
        )

        self.MLPtolLabel = make_label(
            self, text='Tolerance:', layout=self.bottom, row=60, column=0,
            description=MLP_TOL_DESCRIPTION
        )
        self.MLPtolEntry = make_entry(
            self, layout=self.bottom, row=60, column=1, width=50,
            description=MLP_TOL_DESCRIPTION
        )

        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.bottom, row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.bottom, row=61, column=1)

        self.MLPwarmStartLabel = make_label(
            self, text='Warm Start:', layout=self.bottom, row=62, column=0, width=200,
            description=MLP_WARM_START_DESCRIPTION
        )
        self.MLPwarmStartCheck = make_button(
            self, type='check', layout=self.bottom, row=62, column=1,
            description=MLP_WARM_START_DESCRIPTION
        )

        self.MLPmomentumLabel = make_label(
            self, text='Momentum:', layout=self.bottom, row=63, column=0,
            description=MOMENTUM_DESCRIPTION
        )
        self.MLPmomentumEntry = make_entry(
            self, layout=self.bottom, row=63, column=1, width=50,
            description=MOMENTUM_DESCRIPTION
        )

        self.MLPnesterovsMomentumLabel = make_label(
            self, text='Nesterov\'s Momentum:', layout=self.bottom, row=64,
            column=0, width=200, description=NESTEROVS_MOMENTUM_DESCRIPTION
        )
        self.MLPnesterovsMomentumCheck = make_button(
            self, type='check', layout=self.bottom, row=64, column=1,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )

        self.MLPearlyStoppingLabel = make_label(
            self, text='Early Stopping:', layout=self.bottom, row=65, column=0,
            width=200, description=EARLY_STOPPING_DESCRIPTION
        )
        self.MLPearlyStoppingCheck = make_button(
            self, type='check', layout=self.bottom, row=65, column=1,
            description=EARLY_STOPPING_DESCRIPTION
        )

        self.MLPvalidationFractionLabel = make_label(
            self, text='Validation Fraction:', layout=self.bottom, row=66,
            column=0, width=200, description=VALIDATION_FRACTION_DESCRIPTION
        )
        self.MLPvalidationFractionEntry = make_entry(
            self, layout=self.bottom, row=66, column=1, width=50,
            description=VALIDATION_FRACTION_DESCRIPTION
        )

        self.MLPbeta1Label = make_label(
            self, text='First Moment Exponential Decay:', layout=self.bottom, row=67,
            column=0, width=250, description=BETA_1_DESCRIPTION
        )
        self.MLPbeta1Entry = make_entry(
            self, layout=self.bottom, row=67, column=1, width=50,
            description=BETA_1_DESCRIPTION
        )

        self.MLPbeta2Label = make_label(
            self, text='Second Moment Exponential Decay:', layout=self.bottom, row=68,
            column=0, width=250, description=BETA_2_DESCRIPTION
        )
        self.MLPbeta2Entry = make_entry(
            self, layout=self.bottom, row=68, column=1, width=50,
            description=BETA_2_DESCRIPTION
        )

        self.MLPepsilonLabel = make_label(
            self, text='Numerical Stability:', layout=self.bottom, row=69, column=0,
            width=200, description=MLP_EPSILON_DESCRIPTION
        )
        self.MLPepsilonEntry = make_entry(
            self, layout=self.bottom, row=69, column=1, width=50,
            description=MLP_EPSILON_DESCRIPTION
        )

    def set_kr(self):
        # KERNEL RIDGE
        label6 = make_label(self, text='K E R N E L   R I D G E', layout=self.bottom, row=70, column=0)
        self.KRalphaLabel = make_label(
            self, text='Alpha:', layout=self.bottom, row=71, column=0,
            description=ALPHA_DESCRIPTION
        )
        self.KRalphaEntry = make_entry(self, layout=self.bottom, row=71, column=1, description=ALPHA_DESCRIPTION)

        self.KRkernelLabel = make_label(
            self, text='Kernel:', layout=self.bottom, row=72, column=0,
            description=KERNEL_DESCRIPTION
        )
        self.KRkernelCombo = make_combo(
            self, ('linear', 'poly', 'rbf'), layout=self.bottom, row=72, column=1,
            description=KERNEL_DESCRIPTION
        )

        self.KRgammaLabel = make_label(
            self, text='Gamma:', layout=self.bottom, row=73, column=0,
            description=GAMMA_DESCRIPTION
        )
        self.KRgammaEntry = make_entry(self, layout=self.bottom, row=73, column=1, description=GAMMA_DESCRIPTION)

        self.KRdegreeLabel = make_label(
            self, text='Polynomial Degree:', layout=self.bottom, row=74, column=0,
            description=DEGREE_DESCRIPTION
        )
        self.KRdegreeCombo = make_combo(
            self, ('0', '1', '1', '2', '3', '5'), layout=self.bottom, row=74, column=1,
            description=DEGREE_DESCRIPTION
        )

        self.KRcoef0Label = make_label(
            self, text='Coefficient 0:', layout=self.bottom, row=75, column=0,
            description=COEF0_DESCRIPTION
        )
        self.KRcoef0Entry = make_entry(self, layout=self.bottom, row=75, column=1, description=COEF0_DESCRIPTION)

    def rewindow(self):
        # self.svmTab = make_tab(self, text='Support Vector Machine', master=self.tabs)
        # self.mlpTab = make_tab(self, text='Multilayer Perceptron', master=self.tabs)
        # self.knnTab = make_tab(self, text='K Nearest Neighbors', master=self.tabs)
        # self.dtTab = make_tab(self, text='Decision Tree', master=self.tabs)
        # self.rfTab = make_tab(self, text='Random Forest', master=self.tabs)
        # self.krTab = make_tab(self, text='K Ridge', master=self.tabs)
        # label = make_label(self, text='ass', layout=self.svmTab)

        self.widget = QtWidgets.QWidget()
        self.widget.setStyleSheet(WIDGET_STYLE)
        self.bottom = make_grid(self)
        self.refresh()
        self.widget.setLayout(self.bottom)
        self.scrollArea = make_scroll_area(self.widget)
        self.bottomLayout = make_grid(self.scrollArea)
        self.splitter2 = make_splitter(style='v', widgets=(self.tabs, self.scrollArea))
        self.scrollArea.setMinimumSize(WIDTH / 4, HEIGHT / 4)
        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def get_options(self):
        options = {
            'krAlpha':                       dh.nonize(self.KRalphaEntry.text()),
            'krkernel':                      self.KRkernelCombo.currentText(),
            'krGamma':                       dh.nonize(self.KRgammaEntry.text()),
            'krPolynomialDegree':            self.KRdegreeCombo.currentText(),
            'krcoef0':                       dh.nonize(self.KRcoef0Entry.text()),

            'dtrCriterion':                  self.DTcriterionCombo.currentText(),
            'dtrSplitter':                   self.DTsplitterCombo.currentText(),
            'dtrMaxDepth':                   dh.nonize(self.DTmaxDepthEntry.text()),
            'dtrMinSamplesSplit':            dh.nonize(self.DTminSamplesSplitEntry.text()),
            'dtrMinSamplesLeaf':             dh.nonize(self.DTminSamplesLeafEntry.text()),
            'dtrMinWeightFractionLeaf':      dh.nonize(self.DTminWeightFractionLeafEntry.text()),
            'dtrMaxFeatures':                self.DTmaxFeaturesCombo.currentText(),
            'dtrRandomState':                dh.nonize(self.DTrandomStateEntry.text()),
            'dtrMaxLeafNodes':               dh.nonize(self.DTmaxLeafNodesEntry.text()),
            'dtrMinImpurityDecrease':        dh.nonize(self.DTminImpurityDecreaseEntry.text()),
            'dtrPresort':                    dh.nonize(self.DTpresortCheck.isCheck()),

            'svrC':                          dh.nonize(self.SVMCEntry.text()),
            'svrEpsilon':                    dh.nonize(self.SVMepsilonEntry.text()),
            'svrKernel':                     self.SVMkernelCombo.currentText(),
            'svrPolynomialDegree':           self.SVMdegreeCombo.currentText(),
            'svrGamma':                      dh.nonize(self.SVMgammaEntry.text()),
            'svrCoefficient0':               dh.nonize(self.SVMcoef0Entry.text()),
            'svrShrinking':                  self.SVMshrinkingCheck.isChecked(),
            'svrTolerance':                  dh.nonize(self.SVMtolEntry.text()),
            'svrCacheSize':                  dh.nonize(self.SVMcacheSizeEntry.text()),
            'svrMaximumIterations':          dh.nonize(self.SVMmaxIterEntry.text()),
            'rfrNumberOfTrees':              dh.nonize(self.RFnEstimatorsEntry.text()),
            'rfrCriterion':                  self.RFcriterionCombo.currentText(),
            'rfrMaximumFeatures':            self.RFmaxFeaturesCombo.currentText(),
            'rfrMaximumDepth':               dh.nonize(self.RFmaxDepthEntry.text()),
            'rfrMinimumSamplesSplit':        dh.nonize(self.RFminSamplesSplitEntry.text()),
            'rfrMinimumSamplesAtLeaf':       dh.nonize(self.RFminSamplesLeafEntry.text()),
            'rfrMinimumSumWeightedFraction': dh.nonize(self.RFminWeightFractionLeafEntry.text()),
            'rfrMaximumLeafNodes':           dh.nonize(self.RFmaxLeafNodesEntry.text()),
            'rfrBootstrap':                  self.RFbootstrapCheck.isChecked(),
            'rfrOutOfBagSamples':            self.RFoobScoreCheck.isChecked(),
            'RandomState':                   dh.nonize(self.RFrandomStateEntry.text()),
            'rfrWarmStart':                  self.RFwarmStartCheck.isChecked(),
        }
        return options

    def defaults(self):
        pass

    def apply(self):
        pass


class MachineLearningMenu(SubMenu):
    def __init__(self, parent, title, icon, algorithms, graph=None, module=None):
        SubMenu.__init__(self, parent, title, icon)
        self.module = module
        self.toolbar = QtWidgets.QToolBar(self)
        self.hbox.addWidget(self.toolbar)
        # self.bottomLayout = make_grid(make_frame(self))

        # self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 3)
        # self.topright.setMinimumSize(WIDTH / 2, HEIGHT / 3)
        # top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        # self.readLabel.setText(self.parent.databaseMenu.dataSource)

        """self.analysisTab, self.settingsTab, self.exportTab = set_tabs(self,
                                                                        ('Analysis', 'Settings', 'Export'),
                                                                        layout=self.topRightLayout)

        self.modelSelection = self.set_models(algorithms, self.analysisTab, multiSelect=True)

        self.scalerSelection = self.set_scalers(SCALER_NAMES, self.analysisTab)

        self.modelParameterSelection = self.set_models(algorithms, self.settingsTab,
                                                  command=self.set_parameters_layout,
                                                  multiSelect=False)

        self.columnGrid = make_group_box(self.container,
                                         layout=make_grid(),
                                         text='y',
                                         row=1, column=1, width=205, height=225)

        self.indexGrid = make_group_box(self.container,
                                        layout=make_grid(),
                                        text='x',
                                        row=0, column=1, width=205, height=225)

        self.runButton = make_button(self,
                                     command=self.run,
                                     text='Run',
                                     layout=self.topRightLayout,
                                     row=2, column=0,
                                     description=REGRESSION_RUN_DESCRIPTION)

        self.optionLayouts = {name: make_grid() for name in algorithms}

        self.autoTuneGrid = make_group_box(self.settingsTab,
                                           layout=make_grid(),
                                           text='Tune',
                                           row=0, column=2, width=45, height=45)

        self.autoCheck = make_button(buttonType='check',
                                     layout=self.autoTuneGrid,
                                     description=AUTOMATIC_TUNING_DESCRIPTION)

        if graph2: self.siteContainer = make_browser(layout=self.bottomLayout, file=graph2)

        self.set_algorithms()
        self.set_parameters_tab()
        set_export_options(self)

        if graph2 == CLASSIFICATION_GRAPH:
            self.classGrid = make_group_box(self.container,
                                            layout=make_grid(),
                                            text='Class',
                                            row=2, column=1, width=205, height=225)

        self.mode = self.set_mode()



        try:
            self.combos()
            self.modelParameterSelection.setCurrentRow(0)
        except Exception as e:
            print(e)

    def set_mode(self):
        self.modeGrid = make_group_box(self.analysisTab,
                                       layout=make_grid(),
                                       text='Mode',
                                       row=0, column=1, width=75, height=75, strictWidth=True)

        self.mode = make_list(items=('Series', 'Parallel'),
                              default=0,
                              layout=self.modeGrid,
                              row=0, column=0, width=50, height=36)
        return self.mode

    def set_parameters_tab(self):
        self.parametersGrid = make_group_box(self.settingsTab,
                                             layout=make_grid(),
                                             text='Settings',
                                             row=0, column=1, width=1000, height=225)

        default = None#self.optionLayouts[sorted(list(self.optionLayouts.keys()))[0]]
        self.parametersSelection = make_scroll_area(default, width=1000)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_parameters_layout(self):
        self.parametersGrid.removeWidget(self.parametersSelection)
        self.parametersSelection = make_scroll_area(
            self.optionLayouts[self.modelParameterSelection.currentItem().text()], width=1000)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def get_models(self):
        checks = [x.text() for x in self.modelSelection.selectedItems()]
        if self.autoCheck.isChecked():
            models = self.module.cross_validation_models(checks)
        else:
            options = self.get_options()
            models = self.module.models(checks, options)
        return models

    def get_scaler(self):
        scaler = [x.text() for x in self.scalerSelection.selectedItems()][0]
        scaler = Scalers.scaler(scaler)
        return scaler

    @staticmethod
    def set_models(models, tab, multiSelect=False, command=None, row=0, column=0):
        modelsGrid = make_group_box(tab,
                                    layout=make_grid(),
                                    text='Models',
                                    row=row, column=column, width=205, height=225, strictWidth=True)

        modelSelection = make_list(items=models,
                                   command=command,
                                   multiSelect=multiSelect,
                                   layout=modelsGrid,
                                   row=0, column=0, width=200, height=175)
        return modelSelection

    @staticmethod
    def set_scalers(scalers, tab, row=0, column=1):
        scalersGrid = make_group_box(tab,
                                     layout=make_grid(),
                                     text='Scalers',
                                     row=row, column=column, width=205, height=225, strictWidth=True)

        scalerSelection = make_list(items=scalers,
                                    multiSelect=False,
                                    layout=scalersGrid,
                                    row=0, column=0, width=200, height=175)
        scalerSelection.setCurrentRow(0)

        return scalerSelection"""

    def __init__(self, parent, title, icon, algorithms, graph=None, module=None):
        SubMenu.__init__(self, parent, title, icon)
        self.module = module
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)

        self.analysisTab, self.settingsTab, self.exportTab = set_tabs(
            self, ('Analysis', 'Settings', 'Export'),
            layout=self.topRightLayout
        )

        self.modelSelection = self.set_models(algorithms, self.analysisTab, multiSelect=True)

        self.scalerSelection = self.set_scalers(SCALER_NAMES, self.analysisTab)

        self.modelParameterSelection = self.set_models(
            algorithms, self.settingsTab, command=self.set_parameters_layout,
            multiSelect=False
        )

        self.parametersGrid = make_group_box(
            self.settingsTab, layout=make_grid(), text='Settings', row=0, column=1,
            width=1000, height=225
        )

        self.columnGrid = make_group_box(
            self.container, layout=make_grid(), text='y', row=1, column=2, width=205,
            height=225
        )

        self.indexGrid = make_group_box(
            self.container, layout=make_grid(), text='x', row=0, column=2, width=205,
            height=225
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=3, column=0,
            description=RUN_REGRESSION_DESCRIPTION
        )

        self.optionLayouts = {name: make_grid() for name in algorithms}

        self.autoTuneGrid = make_group_box(
            self.settingsTab, layout=make_grid(), text='Tune', row=0, column=3, width=45,
            height=45
        )

        self.autoCheck = make_button(
            buttonType='check', layout=self.autoTuneGrid,
            description=AUTOMATIC_TUNING_DESCRIPTION
        )

        if graph:
            self.siteContainer = make_browser(layout=self.bottomLayout, file=graph)

        self.set_algorithms()
        self.set_parameters_tab()
        set_export_options(self)

        if graph == CLASSIFICATION_GRAPH:
            self.classGrid = make_group_box(
                self.container, layout=make_grid(), text='Class', row=3, column=2,
                width=205, height=225
            )
        else:
            self.modeGrid = make_group_box(
                self.analysisTab, layout=make_grid(), text='Mode', row=0, column=2, width=75,
                height=75
            )

            self.mode = make_list(
                items=('Series', 'Parallel'), default=0, layout=self.modeGrid, row=0, column=0,
                width=50, height=36
            )

        try:
            self.combos()
        except Exception as e:
            print(e)

    def set_parameters_tab(self):
        self.parametersSelection = make_scroll_area(self.optionLayouts[list(self.optionLayouts.keys())[0]], width=1000)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_parameters_layout(self):
        self.parametersGrid.removeWidget(self.parametersSelection)
        self.parametersSelection = make_scroll_area(
            self.optionLayouts[self.modelParameterSelection.currentItem().text()], width=1000
        )
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def get_models(self):
        checks = [x.text() for x in self.modelSelection.selectedItems()]
        if self.autoCheck.isChecked():
            models = self.module.cross_validation_models(checks)
        else:
            options = self.get_options()
            models = self.module.SklearnModels(checks, options)
        return models

    @staticmethod
    def set_models(models, tab, multiSelect, command=None, row=0, column=0):
        modelsGrid = make_group_box(
            tab, layout=make_grid(), text='Models', row=row, column=column, width=205,
            height=225
        )

        modelSelection = make_list(
            items=models, command=command, multiSelect=multiSelect, layout=modelsGrid, row=0,
            column=0, width=200, height=175
        )
        return modelSelection

    @staticmethod
    def set_scalers(scalers, tab, row=0, column=1):
        scalersGrid = make_group_box(
            tab, layout=make_grid(), text='Scalers', row=row, column=column, width=205,
            height=225
        )

        scalerSelection = make_list(
            items=scalers, multiSelect=False, layout=scalersGrid, row=0, column=0, width=200,
            height=175
        )
        return scalerSelection

    def populate(self):
        self.settings = [self.util.get_var(self.top, 'bool', False)]
        # Create a Tkinter variable to store the item
        self.item = self.util.get_var(self.top, 'str', LEARNABLE[0])
        self.iS = self.util.get_var(self.top, 'str', None)
        self.util.name(
            container=self.top, text=ML_ML, coords=((1, 1), (2, 1), (3, 1), (4, 1)), columnspan=[1] * 4,
            sticky=['w'] * 4
        )
        # Entries (File Paths, Iterations)
        self.util.entry(
            container=self.top, width=[15] * 2, coords=((1, 3), (4, 3)), columnspan=[1] * 2,
            sticky=['we'] * 2
        )
        try:
            self.util.entries[0].insert(0, self.parent.filepath)
        except:
            pass
        # ITEM OF INTEREST
        self.util.list_menu(
            container=self.top, variable=self.item, contents=LEARNABLE, command=self.item_selection,
            coords=(2, 2), span=(1, 2), sticky='we'
        )
        # INITIAL STATE
        self.item_selection(self.item)
        self.util.radio_button(
            container=self.top, text=ML_RT, variables=[self.settings[0]] * 2, values=[False, True],
            commands=[(lambda: self.toggle_radio(0, False)), (lambda: self.toggle_radio(0, True))],
            cursor=PTR, coords=((5, 1), (5, 3)), sticky=['w', 'e']
        )
        self.util.separator(container=self.top, orient='h', coords=(6, 1), columnspan=5, sticky='we')
        self.util.button(
            container=self.top, text=ML_BT,
            commands=[self.run, self.cancel, lambda: self.util.select_folder(self)], cursor=HAND,
            coords=((7, 5), (7, 1), (1, 5)), sticky=['e'] * 3
        )

        self.select_radio(self.settings[0].get())

    def item_selection(self, value):
        self.vS = self.get_valid_lists(str(self.item.get()))
        self.iS.update(self.vS[0])
        self.util.list_menu(
            container=self.top, variable=self.iS, contents=self.vS, command=None, coords=(3, 2),
            span=(1, 2), sticky='we'
        )

    def get_valid_lists(self, index):
        """
        List of items corresponding to a specific item in the nonNoneValueList
        """
        self.validValues = ''
        with open(VALUES, 'r') as parameterValuesFile:
            with open(ITEM_NAMES, 'r') as parameterNamesFile:
                for omega, row in zip(csv.reader(parameterNamesFile), csv.reader(parameterValuesFile)):
                    if omega[0] == index:
                        self.validValues = row
                        break
        return self.validValues

    def __init__(self, parent, title, icon, algorithms, graph=None, module=None):
        SubMenu.__init__(self, parent, title, icon)
        self.module = module
        top_left_splitter(
            self, open=open_folder, save=save_file, updateFunction=self.combos,
            layout=self.topRightLayout
        )

        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.analysisTab, self.settingsTab, self.exportTab = set_tabs(
            self, ('Analysis', 'Settings', 'Export'),
            layout=self.topRightLayout, row=0, column=2
        )

        self.inputsSelection = self.set_inputs(self.analysisTab, row=0, column=0)

        self.modelSelection = self.set_models(
            algorithms, self.analysisTab,
            multiSelect=True if title == 'Regression6' else False, row=0, column=1
        )

        self.scalerSelection = self.set_scalers(SCALER_NAMES, self.analysisTab, row=0, column=2)

        self.modelParameterSelection = self.set_models(
            algorithms, self.settingsTab, command=self.set_parameters_layout,
            multiSelect=False
        )

        self.columnGrid = make_group_box(
            self.container, layout=make_grid(), text='y', row=1, column=2, width=205,
            height=225
        )

        self.indexGrid = make_group_box(
            self.container, layout=make_grid(), text='x', row=0, column=2, width=205,
            height=225
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=0, column=3,
            description=REGRESSION_RUN_DESCRIPTION
        )

        self.optionLayouts = {name: make_grid() for name in algorithms}

        self.autoTuneGrid = make_group_box(
            self.settingsTab, layout=make_grid(), text='Tune', row=0, column=3, width=45,
            height=45
        )

        self.autoCheck = make_button(
            buttonType='check', layout=self.autoTuneGrid,
            description=AUTOMATIC_TUNING_DESCRIPTION
        )

        if graph:  # self.siteContainer = make_browser(layout=self.bottomLayout, file=graph2)
            self.tabs = QtWidgets.QTabWidget()
            self.tabs.setStyleSheet(TAB_STYLE)
            self.bottomLayout.addWidget(self.tabs)
            self.mainPlotTab = make_tab(self, 'Data', self.tabs)
            self.mainPlotContainer = make_browser(layout=self.mainPlotTab, file=SIMULATION_GRAPH)

        self.set_algorithms()
        self.set_parameters_tab()
        set_export_options(self)

        if graph == CLASSIFICATION_GRAPH:
            self.classGrid = make_group_box(
                self.container, layout=make_grid(), text='Class', row=3, column=2,
                width=205, height=225
            )

        self.mode = self.set_mode(row=0, column=3)
        self.statusBar, self.progressBar = make_status_bar(self.bottomLayout, progressBar=True)

        try:
            self.combos()
            self.modelParameterSelection.setCurrentRow(0)
        except Exception as e:
            print(e)

    @staticmethod
    def set_inputs(tab, row, column):
        inputsGrid = make_group_box(
            tab, layout=make_grid(), text='Inputs', row=row, column=column, width=205,
            height=225, strictWidth=True
        )

        inputSelection = make_list(
            items=[], command=None, multiSelect=True, layout=inputsGrid, row=0, column=0,
            width=200, height=175
        )
        return inputSelection

    def set_mode(self, row, column):
        self.modeGrid = make_group_box(
            self.analysisTab, layout=make_grid(), text='Mode', row=row, column=column,
            width=75, height=75, strictWidth=True
        )

        self.mode = make_list(
            items=('Series', 'Parallel'), default=0, layout=self.modeGrid, row=0, column=0, width=50,
            height=36
        )
        return self.mode

    def set_parameters_tab(self):
        self.parametersGrid = make_group_box(
            self.settingsTab, layout=make_grid(), text='Settings', row=0, column=1,
            width=1000, height=225
        )

        default = None  # self.optionLayouts[sorted(list(self.optionLayouts.keys()))[0]]
        self.parametersSelection = make_scroll_area(default, width=1000)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_parameters_layout(self):
        self.parametersSelection.destroy()
        self.parametersSelection = make_scroll_area(
            self.optionLayouts[self.modelParameterSelection.currentItem().text()], width=1000
        )
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def get_models(self):
        checks = [x.text() for x in self.modelSelection.selectedItems()]
        if self.autoCheck.isChecked():
            models = self.module.cross_validation_models(checks)
        else:
            options = self.get_options()
            models = self.module.SklearnModels(checks, options)
        return models

    def get_inputs(self):
        inputs = [x.text() for x in self.inputsSelection.selectedItems()]
        return inputs

    def get_scaler(self):
        scaler = [x.text() for x in self.scalerSelection.selectedItems()][0]
        scaler = Scalers.scaler(scaler)
        return scaler

    @staticmethod
    def set_models(models, tab, multiSelect=False, command=None, row=0, column=0):
        modelsGrid = make_group_box(
            tab, layout=make_grid(), text='Models', row=row, column=column, width=205,
            height=225, strictWidth=True
        )

        modelSelection = make_list(
            items=models, command=command, multiSelect=multiSelect, layout=modelsGrid, row=0,
            column=0, width=200, height=175
        )
        return modelSelection

    @staticmethod
    def set_scalers(scalers, tab, row=0, column=1):
        scalersGrid = make_group_box(
            tab, layout=make_grid(), text='Scalers', row=row, column=column, width=205,
            height=225, strictWidth=True
        )

        scalerSelection = make_list(
            items=scalers, multiSelect=False, layout=scalersGrid, row=0, column=0, width=200,
            height=175
        )
        scalerSelection.setCurrentRow(0)

        return scalerSelection

    def get_parameters(self):
        mode = self.mode.selectedItems()[0].text().lower()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        models = self.get_models()
        scaler = self.get_scaler()
        return mode, index, column, dir, models, scaler

    def run(self):
        try:
            int(self.util.entries[1].get())
        except:
            print("Enter integer iterations")
            return

        self.fp_list = self.parent.util.entries[0].get()
        self.iSV = np.array([1 if state == self.iS.get() else 0 for i, state in enumerate(self.vS)])
        self.model = Model(
            item=self.item.get(), iterations=int(self.parent.util.entries[1].get()),
            initialState=self.iSV, validStates=self.vS, files=self.fp_list, clean=self.settings[0].get()
        )
        GraphsMenu.GraphsMenu(self, self.top, "Results").populate(self.model)

    def populate(self):
        self.settings = [BooleanVar(False)]
        # Create a Tkinter variable to store the item
        self.item = StringVar(self.top)
        self.iS = StringVar(self.top)
        self.item.set(LEARNABLE[0])  # set the default option
        self.util.name(
            container=self.top, text=ML_ML, row=[1, 2, 3, 4], column=[1] * 4, columnspan=[1] * 4,
            sticky=['w'] * 4
        )
        # Entries (File Paths, Iterations)
        self.util.entry(
            container=self.top, width=[15] * 2, row=[1, 4], column=[3] * 2, columnspan=[1] * 2,
            sticky=['we'] * 2
        )
        try:
            self.util.entries[0].insert(0, self.parent.filepath)
        except:
            pass
        # ITEM OF INTEREST
        listMenu1 = ttk.OptionMenu(self.top, self.item, *LEARNABLE, command=self.item_selection)
        listMenu1.grid(row=2, column=2, columnspan=2, sticky='we')
        # INITIAL STATE
        self.item_selection(self.item)
        self.util.radio_button(
            container=self.top, text=ML_RT, variables=[self.settings[0]] * 2, values=[False, True],
            commands=[(lambda: self.toggle_radio(0, False)), (lambda: self.toggle_radio(0, True))],
            cursor=PTR, row=[5] * 2, column=[1, 3], sticky=['w', 'e']
        )
        self.util.separator(container=self.top, orient='h', row=6, column=1, columnspan=5, sticky='we')
        self.util.button(
            container=self.top, text=ML_BT, commands=[self.run, self.cancel, lambda: select_folder(self)],
            cursor=HAND, row=[7, 7, 1], column=[5, 1, 5], sticky=['e'] * 3
        )

        self.select_radio(self.settings[0].get())

    def item_selection(self, value):
        self.vS = self.get_valid_lists(str(self.item.get()))
        self.iS.set(self.vS[0])
        listMenu2 = ttk.OptionMenu(self.top, self.iS, *self.vS)
        listMenu2.grid(row=3, column=2, columnspan=2, sticky='we')

    def get_valid_lists(self, index):
        """
        List of items corresponding to a specific item in the nonNoneValueList
        """
        self.validValues = ''
        with open(VALUES, 'r') as parameterValuesFile:
            with open(ITEM_NAMES, 'r') as parameterNamesFile:
                for omega, row in zip(csv.reader(parameterNamesFile), csv.reader(parameterValuesFile)):
                    if omega[0] == index:
                        self.validValues = row
                        break
        return self.validValues

    def __init__(self, parent, title, icon, algorithms, graph=None, module=None):
        SubMenu.__init__(self, parent, title, icon)
        self.module = module
        self.toolbar = QtWidgets.QToolBar(self)
        self.hbox.addWidget(self.toolbar)
        # self.bottomLayout = make_grid(make_frame(self))

        # self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 3)
        # self.topright.setMinimumSize(WIDTH / 2, HEIGHT / 3)
        # top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        # self.readLabel.setText(self.parent.databaseMenu.dataSource)

        """self.analysisTab, self.settingsTab, self.exportTab = set_tabs(self,
                                                                        ('Analysis', 'Settings', 'Export'),
                                                                        layout=self.topRightLayout)

        self.modelSelection = self.set_models(algorithms, self.analysisTab, multiSelect=True)

        self.scalerSelection = self.set_scalers(SCALER_NAMES, self.analysisTab)

        self.modelParameterSelection = self.set_models(algorithms, self.settingsTab,
                                                  command=self.set_parameters_layout,
                                                  multiSelect=False)

        self.columnGrid = make_group_box(self.container,
                                         layout=make_grid(),
                                         text='y',
                                         row=1, column=1, width=205, height=225)

        self.indexGrid = make_group_box(self.container,
                                        layout=make_grid(),
                                        text='x',
                                        row=0, column=1, width=205, height=225)

        self.runButton = make_button(self,
                                     command=self.run,
                                     text='Run',
                                     layout=self.topRightLayout,
                                     row=2, column=0,
                                     description=REGRESSION_RUN_DESCRIPTION)

        self.optionLayouts = {name: make_grid() for name in algorithms}

        self.autoTuneGrid = make_group_box(self.settingsTab,
                                           layout=make_grid(),
                                           text='Tune',
                                           row=0, column=2, width=45, height=45)

        self.autoCheck = make_button(buttonType='check',
                                     layout=self.autoTuneGrid,
                                     description=AUTOMATIC_TUNING_DESCRIPTION)

        if graph2: self.siteContainer = make_browser(layout=self.bottomLayout, file=graph2)

        self.set_algorithms()
        self.set_parameters_tab()
        set_export_options(self)

        if graph2 == CLASSIFICATION_GRAPH:
            self.classGrid = make_group_box(self.container,
                                            layout=make_grid(),
                                            text='Class',
                                            row=2, column=1, width=205, height=225)

        self.mode = self.set_mode()



        try:
            self.combos()
            self.modelParameterSelection.setCurrentRow(0)
        except Exception as e:
            print(e)

    def set_mode(self):
        self.modeGrid = make_group_box(self.analysisTab,
                                       layout=make_grid(),
                                       text='Mode',
                                       row=0, column=1, width=75, height=75, strictWidth=True)

        self.mode = make_list(items=('Series', 'Parallel'),
                              default=0,
                              layout=self.modeGrid,
                              row=0, column=0, width=50, height=36)
        return self.mode

    def set_parameters_tab(self):
        self.parametersGrid = make_group_box(self.settingsTab,
                                             layout=make_grid(),
                                             text='Settings',
                                             row=0, column=1, width=1000, height=225)

        default = None#self.optionLayouts[sorted(list(self.optionLayouts.keys()))[0]]
        self.parametersSelection = make_scroll_area(default, width=1000)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_parameters_layout(self):
        self.parametersGrid.removeWidget(self.parametersSelection)
        self.parametersSelection = make_scroll_area(
            self.optionLayouts[self.modelParameterSelection.currentItem().text()], width=1000)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def get_models(self):
        checks = [x.text() for x in self.modelSelection.selectedItems()]
        if self.autoCheck.isChecked():
            models = self.module.cross_validation_models(checks)
        else:
            options = self.get_options()
            models = self.module.models(checks, options)
        return models

    def get_scaler(self):
        scaler = [x.text() for x in self.scalerSelection.selectedItems()][0]
        scaler = Scalers.scaler(scaler)
        return scaler

    @staticmethod
    def set_models(models, tab, multiSelect=False, command=None, row=0, column=0):
        modelsGrid = make_group_box(tab,
                                    layout=make_grid(),
                                    text='Models',
                                    row=row, column=column, width=205, height=225, strictWidth=True)

        modelSelection = make_list(items=models,
                                   command=command,
                                   multiSelect=multiSelect,
                                   layout=modelsGrid,
                                   row=0, column=0, width=200, height=175)
        return modelSelection

    @staticmethod
    def set_scalers(scalers, tab, row=0, column=1):
        scalersGrid = make_group_box(tab,
                                     layout=make_grid(),
                                     text='Scalers',
                                     row=row, column=column, width=205, height=225, strictWidth=True)

        scalerSelection = make_list(items=scalers,
                                    multiSelect=False,
                                    layout=scalersGrid,
                                    row=0, column=0, width=200, height=175)
        scalerSelection.setCurrentRow(0)

        return scalerSelection"""

    def __init__(self, parent, title, icon, algorithms, graph=None, module=None):
        SubMenu.__init__(self, parent, title, icon)
        self.module = module
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)

        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.analysisTab, self.settingsTab, self.exportTab = set_tabs(
            self, ('Analysis', 'Settings', 'Export'),
            layout=self.topRightLayout
        )

        self.modelSelection = self.set_models(algorithms, self.analysisTab, multiSelect=True)

        self.scalerSelection = self.set_scalers(SCALER_NAMES, self.analysisTab)

        self.modelParameterSelection = self.set_models(
            algorithms, self.settingsTab, command=self.set_parameters_layout,
            multiSelect=False
        )

        self.columnGrid = make_group_box(
            self.container, layout=make_grid(), text='y', row=1, column=2, width=205,
            height=225
        )

        self.indexGrid = make_group_box(
            self.container, layout=make_grid(), text='x', row=0, column=2, width=205,
            height=225
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=3, column=0,
            description=REGRESSION_RUN_DESCRIPTION
        )

        self.optionLayouts = {name: make_grid() for name in algorithms}

        self.autoTuneGrid = make_group_box(
            self.settingsTab, layout=make_grid(), text='Tune', row=0, column=3, width=45,
            height=45
        )

        self.autoCheck = make_button(
            buttonType='check', layout=self.autoTuneGrid,
            description=AUTOMATIC_TUNING_DESCRIPTION
        )

        if graph:
            self.siteContainer = make_browser(layout=self.bottomLayout, file=graph)

        self.set_algorithms()
        self.set_parameters_tab()
        set_export_options(self)

        if graph == CLASSIFICATION_GRAPH:
            self.classGrid = make_group_box(
                self.container, layout=make_grid(), text='Class', row=3, column=2,
                width=205, height=225
            )

        self.mode = self.set_mode()

        try:
            self.combos()
            self.modelParameterSelection.setCurrentRow(0)
        except Exception as e:
            print(e)

    def set_mode(self):
        self.modeGrid = make_group_box(
            self.analysisTab, layout=make_grid(), text='Mode', row=0, column=2, width=75,
            height=75, strictWidth=True
        )

        self.mode = make_list(
            items=('Series', 'Parallel'), default=0, layout=self.modeGrid, row=0, column=0, width=50,
            height=36
        )
        return self.mode

    def set_parameters_tab(self):
        self.parametersGrid = make_group_box(
            self.settingsTab, layout=make_grid(), text='Settings', row=0, column=1,
            width=1000, height=225
        )

        default = None  # self.optionLayouts[sorted(list(self.optionLayouts.keys()))[0]]
        self.parametersSelection = make_scroll_area(default, width=1000)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_parameters_layout(self):
        self.parametersGrid.removeWidget(self.parametersSelection)
        self.parametersSelection = make_scroll_area(
            self.optionLayouts[self.modelParameterSelection.currentItem().text()], width=1000
        )
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def get_models(self):
        checks = [x.text() for x in self.modelSelection.selectedItems()]
        if self.autoCheck.isChecked():
            models = self.module.cross_validation_models(checks)
        else:
            options = self.get_options()
            models = self.module.SklearnModels(checks, options)
        return models


class MainMenu(Window):
    def c_lo_run(self):
        if True:
            args = (self.app, self.title)
        else:
            args = None
            self.populate()
        self.mainloop(args)

    def help(self):
        HelpMenu(self, self.container, "Help2").populate()

    def search(self):
        SearchMenu(self, self.container, "search").populate()

    def report_settings(self):
        ReportMenu(self, self.container, "report_generator0 Settings").populate()

    def machine_learning(self):
        MachineLearningMenu(self, self.container, "Markov Chain Monte Carlo").populate()

    def geo_search(self):
        GeographicSearchMenu(self, self.container, "Geographic search").populate()

    def populate(self):
        self.util.separator(container=self.container, orient='h', row=2, column=0, columnspan=3, sticky='we')
        self.util.drop_down_menu(
            parent=self, menus=MM_DM, tearoff=[0] * 5, labels=MM_DL,
            commands=[[self.report_settings, quit], [self.search], [self.machine_learning],
                      [self.geo_search], [self.help]]
        )


class MainMenu(QtWidgets.QMainWindow):
    def __init__(self, app, title):
        super(MainMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE)
        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        self.setWindowIcon(QtGui.QIcon(WINDOW_ICON))
        self.databaseMenu = DatabaseMenu(self, 'Database', DATABASE_ICON)
        self.searchMenu = SearchMenu(self, 'search', SEARCH_ICON)
        self.geoSearchMenu = GeoSearchMenu(self, 'Geographic search', GEO_SEARCH_ICON)
        self.machineLearningMenu = MachineLearningMenu(self, 'Machine Learning', MACHINE_LEARNING_ICON)
        self.data_toolbar()
        self.show()
        sys.exit(app.exec_())

    def data_toolbar(self):
        self.dataToolbar = QtWidgets.QToolBar(self)
        self.dataToolbar.setStyleSheet(TOOLBAR_STYLE)
        self.dataToolbar.setIconSize(QtCore.QSize(100, 100))
        self.dataToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)
        icon = QtGui.QIcon(DATABASE_ICON)
        databaseAction = QtWidgets.QAction(icon, DATABASE_DESCRIPTION, self)
        databaseAction.setShortcut('Ctrl+D')
        databaseAction.triggered.connect(self.databaseMenu.show)
        databaseAction.setIconText("Database")
        self.dataToolbar.addAction(databaseAction)
        icon = QtGui.QIcon(SEARCH_ICON)
        searchAction = QtWidgets.QAction(icon, SEARCH_DESCRIPTION, self)
        searchAction.setShortcut('Ctrl+R')
        searchAction.triggered.connect(self.searchMenu.show)
        searchAction.setIconText("search Engine")
        self.dataToolbar.addAction(searchAction)
        icon = QtGui.QIcon(GEO_SEARCH_ICON)
        geoSearchAction = QtWidgets.QAction(icon, GEO_SEARCH_DESCRIPTION, self)
        geoSearchAction.setShortcut('Ctrl+G')
        geoSearchAction.triggered.connect(self.geoSearchMenu.show)
        geoSearchAction.setIconText("Geographic search")
        self.dataToolbar.addAction(geoSearchAction)
        icon = QtGui.QIcon(MACHINE_LEARNING_ICON)
        machineLearningAction = QtWidgets.QAction(icon, MACHINE_LEARNING_DESCRIPTION, self)
        machineLearningAction.setShortcut('Ctrl+M')
        machineLearningAction.triggered.connect(self.machineLearningMenu.show)
        machineLearningAction.setIconText("Machine Learning")
        self.dataToolbar.addAction(machineLearningAction)
        self.addToolBar(self.dataToolbar)

    def __init__(self, app, title):
        super(MainMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE)
        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        self.setWindowIcon(QtGui.QIcon(WINDOW_ICON))
        """self.databaseMenu = DatabaseMenu(self,
                                         title='Database',
                                         icon2=DATABASE_ICON)"""

        # self.geoSearchMenu = GeoSearchMenu(self, 'Geographic search', GEO_SEARCH_ICON)
        self.regressionMenu = RegressionMenu(self, title='Regression6', icon=REGRESSION_ICON)

        """self.classificationMenu = ClassificationMenu(self,
                                                     title='Classification',
                                                     icon2=CLASSIFICATION_ICON)

        self.simulationMenu = SimulationMenu(self,
                                             title='Simulation2',
                                             icon2=SIMULATION_ICON)
        self.searchMenu = SearchMenu(self, 'search', SEARCH_ICON)

        # self.webScrapingMenu = WebScrapingMenu(self, 'Web Scraping', WEB_SCRAPING_ICON)

        self.documentationMenu = DocumentationMenu(self,
                                                   title='1',
                                                   icon2=DOCUMENTATION_ICON)"""
        self.tool_bars()
        self.menu_bar()
        self.status_bar()
        self.showMaximized()
        sys.exit(app.exec_())

    def status_bar(self):
        statusBar = QtWidgets.QStatusBar()
        statusBar.setStyleSheet(STATUSBAR_STYLE)
        statusBar.showMessage('hi')

    def menu_bar(self):
        mainMenu = self.menuBar()
        mainMenu.setStyleSheet(MENUBAR_STYLE)
        fileMenu = mainMenu.addMenu('File')
        editMenu = mainMenu.addMenu('Edit')
        viewMenu = mainMenu.addMenu('View')
        searchMenu = mainMenu.addMenu('search')
        toolsMenu = mainMenu.addMenu('Tools')
        helpMenu = mainMenu.addMenu('Help2')

    def tool_bars(self):
        """database = add_action(self, command=self.databaseMenu.show,
                                    icon2=DATABASE_ICON,
                                    description=DATABASE_MENU_DESCRIPTION,
                                    shortcut='Ctrl+D')"""

        """interface7 = add_action(self, command=self.searchMenu.show,
                                  icon2=SEARCH_ICON,
                                  description=SEARCH_MENU_DESCRIPTION, shortcut='Ctrl+S')"""

        # geoSearchAction = add_action(self, command=self.geoSearchMenu.show, text='Geographic search',
        #                             icon2=GEO_SEARCH_ICON, description=GEO_SEARCH_DESCRIPTION, shortcut='Ctrl+G')
        # self.dataToolbar.addAction(geoSearchAction)

        regression = add_toolbar(
            self, command=self.regressionMenu.show, icon=REGRESSION_ICON,
            description=REGRESSION_MENU_DESCRIPTION, shortcut='Ctrl+R'
        )

        """classification0 = add_action(self, command=self.classificationMenu.show,
                                          icon2=CLASSIFICATION_ICON,
                                          description=CLASSIFICATION_MENU_DESCRIPTION,
                                          shortcut='Ctrl+C')"""

        """simulation = add_action(self, command=self.simulationMenu.show,
                                      text='Simulation2',
                                      icon2=None,
                                      description=SIMULATION_MENU_DESCRIPTION,
                                      shortcut='Ctrl+M')"""

        """webScrapingAction = add_action(self, command=self.webScrapingMenu.show, text='Web Scraping', icon2=WEB_SCRAPING_ICON,
                                       description=WEB_SCRAPING_DESCRIPTION, shortcut='Ctrl+W')
        self.dataToolbar.addAction(webScrapingAction)"""

        """statistics = add_action(self, command=None,
                                icon2=STATISTICS_ICON,
                                description='',
                                shortcut=None)"""

        """1 = add_action(self, command=self.documentationMenu.show,
                                         icon2=DOCUMENTATION_ICON,
                                         description=DOCUMENTATION_MENU_DESCRIPTION,
                                         shortcut='Ctrl+D+C')"""

    def __init__(self, app, title):
        super(MainMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE)
        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        self.setWindowIcon(QtGui.QIcon(WINDOW_ICON))
        self.databaseMenu = DatabaseMenu(self, title='Database', icon=DATABASE_ICON)

        # self.geoSearchMenu = GeoSearchMenu(self, 'Geographic search', GEO_SEARCH_ICON)
        self.regressionMenu = RegressionMenu(self, title='Regression6', icon=REGRESSION_ICON)

        self.classificationMenu = ClassificationMenu(self, title='Classification', icon=CLASSIFICATION_ICON)

        self.simulationMenu = SimulationMenu(self, title='Simulation2', icon=SIMULATION_ICON)
        self.searchMenu = SearchMenu(self, 'search', SEARCH_ICON)

        # self.webScrapingMenu = WebScrapingMenu(self, 'Web Scraping', WEB_SCRAPING_ICON)

        self.documentationMenu = DocumentationMenu(self, title='1', icon=DOCUMENTATION_ICON)
        self.tool_bars()
        self.menu_bar()
        self.status_bar()
        self.showMaximized()
        sys.exit(app.exec_())

    def status_bar(self):
        statusBar = QtWidgets.QStatusBar()
        statusBar.setStyleSheet(STATUSBAR_STYLE)
        statusBar.showMessage('hi')

    def menu_bar(self):
        mainMenu = self.menuBar()
        mainMenu.setStyleSheet(MENUBAR_STYLE)
        fileMenu = mainMenu.addMenu('File')
        editMenu = mainMenu.addMenu('Edit')
        viewMenu = mainMenu.addMenu('View')
        searchMenu = mainMenu.addMenu('search')
        toolsMenu = mainMenu.addMenu('Tools')
        helpMenu = mainMenu.addMenu('Help2')

    def tool_bars(self):
        database = add_toolbar(
            self, command=self.databaseMenu.show, icon=DATABASE_ICON,
            description=DATABASE_MENU_DESCRIPTION, shortcut='Ctrl+D'
        )

        search = add_toolbar(
            self, command=self.searchMenu.show, icon=SEARCH_ICON, description=SEARCH_MENU_DESCRIPTION,
            shortcut='Ctrl+S'
        )

        # geoSearchAction = add_action(self, command=self.geoSearchMenu.show, text='Geographic search',
        #                             icon2=GEO_SEARCH_ICON, description=GEO_SEARCH_DESCRIPTION, shortcut='Ctrl+G')
        # self.dataToolbar.addAction(geoSearchAction)

        regression = add_toolbar(
            self, command=self.regressionMenu.show, icon=REGRESSION_ICON,
            description=REGRESSION_MENU_DESCRIPTION, shortcut='Ctrl+R'
        )

        classification = add_toolbar(
            self, command=self.classificationMenu.show, icon=CLASSIFICATION_ICON,
            description=CLASSIFICATION_MENU_DESCRIPTION, shortcut='Ctrl+C'
        )

        simulation = add_toolbar(
            self, command=self.simulationMenu.show, text='Simulation2', icon=None,
            description=SIMULATION_MENU_DESCRIPTION, shortcut='Ctrl+M'
        )

        """webScrapingAction = add_action(self, command=self.webScrapingMenu.show, text='Web Scraping', icon2=WEB_SCRAPING_ICON,
                                       description=WEB_SCRAPING_DESCRIPTION, shortcut='Ctrl+W')
        self.dataToolbar.addAction(webScrapingAction)"""

        statistics = add_toolbar(self, command=None, icon=STATISTICS_ICON, description='', shortcut=None)

        documentation = add_toolbar(
            self, command=self.documentationMenu.show, icon=DOCUMENTATION_ICON,
            description=DOCUMENTATION_MENU_DESCRIPTION, shortcut='Ctrl+D+C'
        )

    def __init__(self, app, title):
        super(MainMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE)
        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        self.setWindowIcon(QtGui.QIcon(WINDOW_ICON))
        self.databaseMenu = DatabaseMenu(self, title='Database', icon=DATABASE_ICON, )
        self.regressionMenu = RegressionMenu(self, title='Regression6', icon=REGRESSION_ICON, )
        self.documentationMenu = DocumentationMenu(self, title='1', icon=DOCUMENTATION_ICON, )
        self.tool_bars()
        self.menu_bar()
        self.status_bar()
        self.showMaximized()
        sys.exit(app.exec_())

    def status_bar(self):
        statusBar = QtWidgets.QStatusBar()
        statusBar.setStyleSheet(STATUSBAR_STYLE)
        statusBar.showMessage('hi')

    def menu_bar(self):
        mainMenu = self.menuBar()
        mainMenu.setStyleSheet(MENUBAR_STYLE)
        fileMenu = mainMenu.addMenu('File')
        editMenu = mainMenu.addMenu('Edit')
        viewMenu = mainMenu.addMenu('View')
        searchMenu = mainMenu.addMenu('search')
        toolsMenu = mainMenu.addMenu('Tools')
        helpMenu = mainMenu.addMenu('Help2')

    def tool_bars(self):
        database = add_toolbar(
            self, command=self.databaseMenu.show, icon=DATABASE_ICON,
            description=DATABASE_MENU_DESCRIPTION, shortcut='Ctrl+D', )
        regression = add_toolbar(
            self, command=self.regressionMenu.show, icon=REGRESSION_ICON,
            description=REGRESSION_MENU_DESCRIPTION, shortcut='Ctrl+R', )
        documentation = add_toolbar(
            self, command=self.documentationMenu.show, icon=DOCUMENTATION_ICON,
            description=DOCUMENTATION_MENU_DESCRIPTION, shortcut='Ctrl+D+C', )

    def __init__(self, app, title):
        super(MainMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE)
        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        self.setWindowIcon(QtGui.QIcon(WINDOW_ICON))
        self.databaseMenu = DatabaseMenu(self, title='Database', icon=DATABASE_ICON)

        # self.geoSearchMenu = GeoSearchMenu(self, 'Geographic search', GEO_SEARCH_ICON)
        self.regressionMenu = RegressionMenu(self, title='Regression6', icon=REGRESSION_ICON)

        self.classificationMenu = ClassificationMenu(self, title='Classification', icon=CLASSIFICATION_ICON)

        self.simulationMenu = SimulationMenu(self, title='Simulation2', icon=MCMC_ICON)
        self.searchMenu = SearchMenu(self, 'search', SEARCH_ICON)

        # self.webScrapingMenu = WebScrapingMenu(self, 'Web Scraping', WEB_SCRAPING_ICON)

        self.documentationMenu = DocumentationMenu(self, title='1', icon=DOCUMENTATION_ICON)
        self.data_toolbar()
        self.show()
        sys.exit(app.exec_())

    def data_toolbar(self):
        self.dataToolbar = QtWidgets.QToolBar(self)
        self.dataToolbar.setStyleSheet(TOOLBAR_STYLE)
        self.dataToolbar.setIconSize(QtCore.QSize(150, 150))
        self.dataToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        databaseAction = add_action(
            self, command=self.databaseMenu.show, text='Database', icon=DATABASE_ICON,
            description=DATABASE_DESCRIPTION, shortcut='Ctrl+D'
        )

        searchAction = add_action(
            self, command=self.searchMenu.show, text='search Engine', icon=SEARCH_ICON,
            description=SEARCH_DESCRIPTION, shortcut='Ctrl+S'
        )

        # geoSearchAction = add_action(self, command=self.geoSearchMenu.show, text='Geographic search',
        #                             icon2=GEO_SEARCH_ICON, description=GEO_SEARCH_DESCRIPTION, shortcut='Ctrl+G')
        # self.dataToolbar.addAction(geoSearchAction)

        regressionAction = add_action(
            self, command=self.regressionMenu.show, text='Regression6', icon=REGRESSION_ICON,
            description=REGRESSION_DESCRIPTION, shortcut='Ctrl+R'
        )

        classificationAction = add_action(
            self, command=self.classificationMenu.show, text='Classification',
            icon=CLASSIFICATION_ICON, description=CLASSIFICATION_DESCRIPTION,
            shortcut='Ctrl+C'
        )

        simulationAction = add_action(
            self, command=self.simulationMenu.show, text='Simulation2', icon=MCMC_ICON,
            description=MCMC_DESCRIPTION, shortcut='Ctrl+M'
        )

        """webScrapingAction = add_action(self, command=self.webScrapingMenu.show, text='Web Scraping', icon2=WEB_SCRAPING_ICON,
                                       description=WEB_SCRAPING_DESCRIPTION, shortcut='Ctrl+W')
        self.dataToolbar.addAction(webScrapingAction)"""

        documentationAction = add_action(
            self, command=self.documentationMenu.show, text='1', icon=DOCUMENTATION_ICON,
            description=DOCUMENTATION_DESCRIPTION, shortcut='Ctrl+D+C'
        )

        self.dataToolbar.addAction(databaseAction)
        self.dataToolbar.addAction(searchAction)
        self.dataToolbar.addAction(regressionAction)
        self.dataToolbar.addAction(classificationAction)
        self.dataToolbar.addAction(simulationAction)
        self.dataToolbar.addAction(documentationAction)

        self.addToolBar(self.dataToolbar)

    def __init__(self, app, title):
        super(MainMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE)
        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        self.setWindowIcon(QtGui.QIcon(WINDOW_ICON))
        self.databaseMenu = DatabaseMenu(self, title='Database', icon=DATABASE_ICON)

        # self.geoSearchMenu = GeoSearchMenu(self, 'Geographic search', GEO_SEARCH_ICON)
        self.regressionMenu = RegressionMenu(self, title='Regression6', icon=REGRESSION_ICON)

        self.classificationMenu = ClassificationMenu(self, title='Classification', icon=CLASSIFICATION_ICON)

        self.clusteringMenu = ClusteringMenu(self, title='Clustering', icon=CLUSTERING_ICON)

        self.dimensionalityMenu = DimensionalityMenu(self, title='Dimensionality', icon=DIMENSIONALITY_ICON)

        self.simulationMenu = SimulationMenu(self, title='Simulation2', icon=SIMULATION_ICON)
        self.searchMenu = SearchMenu(self, 'search', SEARCH_ICON)

        # self.webScrapingMenu = WebScrapingMenu(self, 'Web Scraping', WEB_SCRAPING_ICON)

        self.documentationMenu = DocumentationMenu(self, title='1', icon=DOCUMENTATION_ICON)
        self.tool_bars()
        self.menu_bar()
        self.status_bar()
        self.showMaximized()
        sys.exit(app.exec_())

    def status_bar(self):
        statusBar = QtWidgets.QStatusBar()
        statusBar.setStyleSheet(STATUSBAR_STYLE)
        statusBar.showMessage('hi')

    def menu_bar(self):
        mainMenu = self.menuBar()
        mainMenu.setStyleSheet(MENUBAR_STYLE)
        fileMenu = mainMenu.addMenu('File')
        editMenu = mainMenu.addMenu('Edit')
        viewMenu = mainMenu.addMenu('View')
        searchMenu = mainMenu.addMenu('search')
        toolsMenu = mainMenu.addMenu('Tools')
        helpMenu = mainMenu.addMenu('Help2')

    def tool_bars(self):
        database = add_toolbar(
            self, command=self.databaseMenu.show, icon=DATABASE_ICON,
            description=DATABASE_MENU_DESCRIPTION, shortcut='Ctrl+D'
        )

        search = add_toolbar(
            self, command=self.searchMenu.show, icon=SEARCH_ICON, description=SEARCH_MENU_DESCRIPTION,
            shortcut='Ctrl+S'
        )

        # geoSearchAction = add_action(self, command=self.geoSearchMenu.show, text='Geographic search',
        #                             icon2=GEO_SEARCH_ICON, description=GEO_SEARCH_DESCRIPTION, shortcut='Ctrl+G')
        # self.dataToolbar.addAction(geoSearchAction)

        regression = add_toolbar(
            self, command=self.regressionMenu.show, icon=REGRESSION_ICON,
            description=REGRESSION_MENU_DESCRIPTION, shortcut='Ctrl+R'
        )

        classification = add_toolbar(
            self, command=self.classificationMenu.show, icon=CLASSIFICATION_ICON,
            description=CLASSIFICATION_MENU_DESCRIPTION, shortcut='Ctrl+C'
        )

        clustering = add_toolbar(
            self, command=self.clusteringMenu.show, icon=CLUSTERING_ICON,
            description=CLUSTERING_MENU_DESCRIPTION, shortcut='Ctrl+G'
        )

        dimensionality = add_toolbar(
            self, command=self.dimensionalityMenu.show, icon=DIMENSIONALITY_ICON,
            description=DIMENSIONALITY_MENU_DESCRIPTION, shortcut='Ctrl+Y'
        )

        simulation = add_toolbar(
            self, command=self.simulationMenu.show, icon=SIMULATION_ICON,
            description=SIMULATION_MENU_DESCRIPTION, shortcut='Ctrl+M'
        )

        """webScrapingAction = add_action(self, command=self.webScrapingMenu.show, text='Web Scraping', icon2=WEB_SCRAPING_ICON,
                                       description=WEB_SCRAPING_DESCRIPTION, shortcut='Ctrl+W')
        self.dataToolbar.addAction(webScrapingAction)"""

        statistics = add_toolbar(self, command=None, icon=STATISTICS_ICON, description='', shortcut=None)

        documentation = add_toolbar(
            self, command=self.documentationMenu.show, icon=DOCUMENTATION_ICON,
            description=DOCUMENTATION_MENU_DESCRIPTION, shortcut='Ctrl+D+C'
        )

    def data_toolbar(self):
        self.dataToolbar = QtWidgets.QToolBar(self)
        self.dataToolbar.setStyleSheet(TOOLBAR_STYLE)
        self.dataToolbar.setIconSize(QtCore.QSize(150, 150))
        self.dataToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        databaseAction = add_action(
            self, command=self.databaseMenu.show, text='Database', icon=DATABASE_ICON,
            description=DATABASE_DESCRIPTION, shortcut='Ctrl+D'
        )

        searchAction = add_action(
            self, command=self.searchMenu.show, text='search Engine', icon=SEARCH_ICON,
            description=SEARCH_DESCRIPTION, shortcut='Ctrl+S'
        )

        """geoSearchAction = add_action(self, command=self.geoSearchMenu.show, text='Geographic search',
                                     icon2=GEO_SEARCH_ICON, description=GEO_SEARCH_DESCRIPTION, shortcut='Ctrl+G')
        self.dataToolbar.addAction(geoSearchAction)"""

    def __init__(self, app, title):
        super(MainMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE)
        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        self.setWindowIcon(QtGui.QIcon(WINDOW_ICON))
        self.statusBar().setStyleSheet(STATUSBAR_STYLE)
        self.databaseMenu = DatabaseMenu(self, 'Database', DATABASE_ICON)
        self.searchMenu = SearchMenu(self, 'search', SEARCH_ICON)
        self.geoSearchMenu = GeoSearchMenu(self, 'Geographic search', GEO_SEARCH_ICON)
        self.machineLearningMenu = MachineLearningMenu(self, 'Machine Learning', MACHINE_LEARNING_ICON)
        self.sentimentMenu = SentimentMenu(self, 'Sentiment Analysis', SENTIMENT_ICON)
        self.updatesMenu = UpdatesMenu(self, 'Updates', UPDATES_ICON)
        self.helpMenu = HelpMenu(self, 'Help2', HELP_ICON)
        self.plannerMenu = PlannerMenu(self, 'Planner', PLANNER_ICON)
        self.scheduleMenu = ScheduleMenu(self, 'Schedule', SCHEDULE_ICON)
        self.tasksMenu = TasksMenu(self, 'Tasks', TASKS_ICON)
        self.resourcesMenu = ResourcesMenu(self, 'Resources', RESOURCES_ICON)
        self.financeMenu = FinanceMenu(self, 'Finance', FINANCE_ICON)

        self.menu_bar()
        self.data_toolbar()
        self.plan_toolbar()
        self.assist_toolbar()
        self.show()
        sys.exit(app.exec_())

    def menu_bar(self):
        menubar = self.menuBar()
        menubar.setStyleSheet(MENUBAR_STYLE)
        self.file_dropdown(menubar)
        self.edit_dropdown(menubar)
        self.view_dropdown(menubar)

    def data_toolbar(self):
        self.dataToolbar = QtWidgets.QToolBar(self)
        self.dataToolbar.setStyleSheet(TOOLBAR_STYLE)
        self.dataToolbar.setIconSize(QtCore.QSize(100, 100))
        self.dataToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        icon = QtGui.QIcon(DATABASE_ICON)
        databaseAction = QtWidgets.QAction(icon, DATABASE_DESCRIPTION, self)
        databaseAction.setShortcut('Ctrl+D')
        databaseAction.setStatusTip(DATABASE_DESCRIPTION)
        databaseAction.triggered.connect(self.databaseMenu.show)
        databaseAction.setIconText("Database")
        self.dataToolbar.addAction(databaseAction)

        icon = QtGui.QIcon(SEARCH_ICON)
        searchAction = QtWidgets.QAction(icon, SEARCH_DESCRIPTION, self)
        searchAction.setShortcut('Ctrl+R')
        searchAction.setStatusTip(SEARCH_DESCRIPTION)
        searchAction.triggered.connect(self.searchMenu.show)
        searchAction.setIconText("search Engine")
        self.dataToolbar.addAction(searchAction)

        icon = QtGui.QIcon(GEO_SEARCH_ICON)
        geoSearchAction = QtWidgets.QAction(icon, GEO_SEARCH_DESCRIPTION, self)
        geoSearchAction.setShortcut('Ctrl+G')
        geoSearchAction.setStatusTip(GEO_SEARCH_DESCRIPTION)
        geoSearchAction.triggered.connect(self.geoSearchMenu.show)
        geoSearchAction.setIconText("Geographic search")
        self.dataToolbar.addAction(geoSearchAction)

        icon = QtGui.QIcon(MACHINE_LEARNING_ICON)
        machineLearningAction = QtWidgets.QAction(icon, MACHINE_LEARNING_DESCRIPTION, self)
        machineLearningAction.setShortcut('Ctrl+M')
        machineLearningAction.setStatusTip(MACHINE_LEARNING_DESCRIPTION)
        machineLearningAction.triggered.connect(self.machineLearningMenu.show)
        machineLearningAction.setIconText("Machine Learning")
        self.dataToolbar.addAction(machineLearningAction)

        icon = QtGui.QIcon(SENTIMENT_ICON)
        sentimentAction = QtWidgets.QAction(icon, SENTIMENT_DESCRIPTION, self)
        sentimentAction.setStatusTip(SENTIMENT_DESCRIPTION)
        sentimentAction.triggered.connect(self.sentimentMenu.show)
        sentimentAction.setIconText("Sentiment Analysis")
        self.dataToolbar.addAction(sentimentAction)

        self.addToolBar(self.dataToolbar)

    def plan_toolbar(self):
        self.planToolbar = QtWidgets.QToolBar(self)
        self.planToolbar.setStyleSheet(TOOLBAR_STYLE)
        self.planToolbar.setIconSize(QtCore.QSize(100, 100))
        self.planToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        icon = QtGui.QIcon(PLANNER_ICON)
        plannerAction = QtWidgets.QAction(icon, PLANNER_DESCRIPTION, self)
        plannerAction.setStatusTip(PLANNER_DESCRIPTION)
        plannerAction.triggered.connect(self.plannerMenu.show)
        plannerAction.setIconText("Planner")
        self.planToolbar.addAction(plannerAction)

        icon = QtGui.QIcon(SCHEDULE_ICON)
        scheduleAction = QtWidgets.QAction(icon, SCHEDULE_DESCRIPTION, self)
        scheduleAction.setShortcut('Ctrl+P')
        scheduleAction.setStatusTip(SCHEDULE_DESCRIPTION)
        scheduleAction.triggered.connect(self.scheduleMenu.show)
        scheduleAction.setIconText("Schedule")
        self.planToolbar.addAction(scheduleAction)

        icon = QtGui.QIcon(TASKS_ICON)
        tasksAction = QtWidgets.QAction(icon, TASKS_DESCRIPTION, self)
        tasksAction.setShortcut('Ctrl+T')
        tasksAction.setStatusTip(TASKS_DESCRIPTION)
        tasksAction.triggered.connect(self.tasksMenu.show)
        tasksAction.setIconText("Tasks")
        self.planToolbar.addAction(tasksAction)

        icon = QtGui.QIcon(RESOURCES_ICON)
        resourcesAction = QtWidgets.QAction(icon, RESOURCES_DESCRIPTION, self)
        resourcesAction.setShortcut('Ctrl+P')
        resourcesAction.setStatusTip(RESOURCES_DESCRIPTION)
        resourcesAction.triggered.connect(self.resourcesMenu.show)
        resourcesAction.setIconText("Resources")
        self.planToolbar.addAction(resourcesAction)

        icon = QtGui.QIcon(FINANCE_ICON)
        financeAction = QtWidgets.QAction(icon, FINANCE_DESCRIPTION, self)
        financeAction.setShortcut('Ctrl+M')
        financeAction.setStatusTip(FINANCE_DESCRIPTION)
        financeAction.triggered.connect(self.financeMenu.show)
        financeAction.setIconText("Finance")
        self.planToolbar.addAction(financeAction)

        self.addToolBar(QtCore.Qt.LeftToolBarArea, self.planToolbar)

    def assist_toolbar(self):
        self.assistToolbar = QtWidgets.QToolBar(self)
        self.assistToolbar.setStyleSheet(TOOLBAR_STYLE)
        self.assistToolbar.setIconSize(QtCore.QSize(100, 100))
        self.assistToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        icon = QtGui.QIcon(HELP_ICON)
        helpAction = QtWidgets.QAction(icon, HELP_DESCRIPTION, self)
        helpAction.setShortcut('Ctrl+H')
        helpAction.setStatusTip(HELP_DESCRIPTION)
        helpAction.triggered.connect(self.helpMenu.show)
        helpAction.setIconText("Help2")
        self.assistToolbar.addAction(helpAction)

        icon = QtGui.QIcon(UPDATES_ICON)
        updatesAction = QtWidgets.QAction(icon, UPDATES_DESCRIPTION, self)
        updatesAction.setShortcut('Ctrl+U')
        updatesAction.setStatusTip(UPDATES_DESCRIPTION)
        updatesAction.triggered.connect(self.updatesMenu.show)
        updatesAction.setIconText("Updates")
        self.assistToolbar.addAction(updatesAction)

        self.addToolBar(self.assistToolbar)

    def __init__(self, app, title):
        super(MainMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE)
        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        self.setWindowIcon(QtGui.QIcon(WINDOW_ICON))
        self.statusBar().setStyleSheet(STATUSBAR_STYLE)
        self.databaseMenu = DatabaseMenu(self, 'Database', DATABASE_ICON)
        self.searchMenu = SearchMenu(self, 'search', SEARCH_ICON)
        self.geoSearchMenu = GeoSearchMenu(self, 'Geographic search', GEO_SEARCH_ICON)
        self.machineLearningMenu = MachineLearningMenu(self, 'Machine Learning', MACHINE_LEARNING_ICON)
        self.sentimentMenu = SentimentMenu(self, 'Sentiment Analysis', SENTIMENT_ICON)
        self.updatesMenu = UpdatesMenu(self, 'Updates', UPDATES_ICON)
        self.helpMenu = HelpMenu(self, 'Help2', HELP_ICON)
        self.plannerMenu = PlannerMenu(self, 'Planner', PLANNER_ICON)
        self.scheduleMenu = ScheduleMenu(self, 'Schedule', SCHEDULE_ICON)
        self.tasksMenu = TasksMenu(self, 'Tasks', TASKS_ICON)
        self.resourcesMenu = ResourcesMenu(self, 'Resources', RESOURCES_ICON)
        self.financeMenu = FinanceMenu(self, 'Finance', FINANCE_ICON)

        self.menu_bar()
        self.data_toolbar()
        # self.plan_toolbar()
        # self.assist_toolbar()
        self.show()
        sys.exit(app.exec_())

    def menu_bar(self):
        menubar = self.menuBar()
        menubar.setStyleSheet(MENUBAR_STYLE)
        self.file_dropdown(menubar)  # self.edit_dropdown(menubar)  # self.view_dropdown(menubar)

    def file_dropdown(self, menubar):
        fileMenu = menubar.addMenu('&File')

        openFolderAction = QtWidgets.QAction(QtGui.QIcon(OPEN_FOLDER_ICON), '&Open Folder', self)
        openFolderAction.setStatusTip(OPEN_FOLDER_DESCRIPTION)
        openFolderAction.triggered.connect(lambda: open_folder(self))

        fileMenu.addAction(openFolderAction)

        saveFolderAction = QtWidgets.QAction(QtGui.QIcon(SAVE_FOLDER_ICON), '&Save Folder', self)
        saveFolderAction.setStatusTip(SAVE_FOLDER_DESCRIPTION)
        saveFolderAction.triggered.connect(lambda: open_folder(self))

        fileMenu.addAction(saveFolderAction)

        fileMenu.addSeparator()

        openFileAction = QtWidgets.QAction(QtGui.QIcon(OPEN_FILE_ICON), '&Open File', self)
        openFileAction.setShortcut('Ctrl+O')
        openFileAction.setStatusTip(OPEN_FILE_DESCRIPTION)
        openFileAction.triggered.connect(lambda: open_files(self))

        fileMenu.addAction(openFileAction)

        saveFileAction = QtWidgets.QAction(QtGui.QIcon(SAVE_FILE_ICON), '&Save File', self)
        saveFileAction.setShortcut('Ctrl+S')
        saveFileAction.setStatusTip(SAVE_FILE_DESCRIPTION)
        saveFileAction.triggered.connect(lambda: save_file(self))

        fileMenu.addAction(saveFileAction)

        fileMenu.addSeparator()

        exitAction = QtWidgets.QAction(QtGui.QIcon(EXIT_ICON), '&Exit', self)
        exitAction.setShortcut('Ctrl+Q')
        exitAction.setStatusTip(EXIT_DESCRIPTION)
        exitAction.triggered.connect(QtWidgets.qApp.quit)

        fileMenu.addAction(exitAction)

    def edit_dropdown(self, menubar):
        editMenu = menubar.addMenu('&Edit')
        exitAction = QtWidgets.QAction(QtGui.QIcon(EXIT_ICON), '&Copy', self)
        exitAction.setShortcut('Ctrl+Q')
        exitAction.setStatusTip(EXIT_DESCRIPTION)
        exitAction.triggered.connect(QtWidgets.qApp.quit)

        editMenu.addAction(exitAction)

    def view_dropdown(self, menubar):
        viewMenu = menubar.addMenu('&View')
        exitAction = QtWidgets.QAction(QtGui.QIcon(EXIT_ICON), '&Reset View', self)
        exitAction.setShortcut('Ctrl+Q')
        exitAction.setStatusTip(EXIT_DESCRIPTION)
        exitAction.triggered.connect(QtWidgets.qApp.quit)

        viewMenu.addAction(exitAction)

    def data_toolbar(self):
        self.dataToolbar = QtWidgets.QToolBar(self)
        self.dataToolbar.setStyleSheet(TOOLBAR_STYLE)
        self.dataToolbar.setIconSize(QtCore.QSize(100, 100))
        self.dataToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        icon = QtGui.QIcon(DATABASE_ICON)
        databaseAction = QtWidgets.QAction(icon, DATABASE_DESCRIPTION, self)
        databaseAction.setShortcut('Ctrl+D')
        databaseAction.setStatusTip(DATABASE_DESCRIPTION)
        databaseAction.triggered.connect(self.databaseMenu.show)
        databaseAction.setIconText("Database")
        self.dataToolbar.addAction(databaseAction)

        icon = QtGui.QIcon(SEARCH_ICON)
        searchAction = QtWidgets.QAction(icon, SEARCH_DESCRIPTION, self)
        searchAction.setShortcut('Ctrl+R')
        searchAction.setStatusTip(SEARCH_DESCRIPTION)
        searchAction.triggered.connect(self.searchMenu.show)
        searchAction.setIconText("search Engine")
        self.dataToolbar.addAction(searchAction)

        icon = QtGui.QIcon(GEO_SEARCH_ICON)
        geoSearchAction = QtWidgets.QAction(icon, GEO_SEARCH_DESCRIPTION, self)
        geoSearchAction.setShortcut('Ctrl+G')
        geoSearchAction.setStatusTip(GEO_SEARCH_DESCRIPTION)
        geoSearchAction.triggered.connect(self.geoSearchMenu.show)
        geoSearchAction.setIconText("Geographic search")
        self.dataToolbar.addAction(geoSearchAction)

        icon = QtGui.QIcon(MACHINE_LEARNING_ICON)
        machineLearningAction = QtWidgets.QAction(icon, MACHINE_LEARNING_DESCRIPTION, self)
        machineLearningAction.setShortcut('Ctrl+M')
        machineLearningAction.setStatusTip(MACHINE_LEARNING_DESCRIPTION)
        machineLearningAction.triggered.connect(self.machineLearningMenu.show)
        machineLearningAction.setIconText("Machine Learning")
        self.dataToolbar.addAction(machineLearningAction)
        """
        icon2 = QtGui.QIcon(SENTIMENT_ICON)
        sentimentAction = QtWidgets.QAction(icon2, SENTIMENT_DESCRIPTION, self)
        sentimentAction.setStatusTip(SENTIMENT_DESCRIPTION)
        sentimentAction.triggered.connect(self.sentimentMenu.show)
        sentimentAction.setIconText("Sentiment Analysis")
        self.dataToolbar.addAction(sentimentAction)
        """
        self.addToolBar(self.dataToolbar)

    def __init__(self, app, title):
        super(MainMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE)
        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        self.setWindowIcon(QtGui.QIcon(WINDOW_ICON))
        self.databaseMenu = DatabaseMenu(self, 'Database', DATABASE_ICON)
        self.geoSearchMenu = GeoSearchMenu(self, 'Geographic search', GEO_SEARCH_ICON)
        self.regressionMenu = RegressionMenu(self, 'Regression6', REGRESSION_ICON)
        self.classificationMenu = ClassificationMenu(self, 'Classification', CLASSIFICATION_ICON)
        self.mcmcMenu = MCMCMenu(self, 'Markov Chain Monte Carlo', MCMC_ICON)
        self.searchMenu = SearchMenu(self, 'search', SEARCH_ICON)
        self.webScrapingMenu = WebScrapingMenu(self, 'Web Scraping', WEB_SCRAPING_ICON)
        self.documentationMenu = DocumentationMenu(self, '1', DOCUMENTATION_ICON)
        self.data_toolbar()
        self.show()
        sys.exit(app.exec_())

    def data_toolbar(self):
        self.dataToolbar = QtWidgets.QToolBar(self)
        self.dataToolbar.setStyleSheet(TOOLBAR_STYLE)
        self.dataToolbar.setIconSize(QtCore.QSize(100, 100))
        self.dataToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        databaseAction = add_action(
            self, command=self.databaseMenu.show, text='Database', icon=DATABASE_ICON,
            description=DATABASE_DESCRIPTION, shortcut='Ctrl+D'
        )
        self.dataToolbar.addAction(databaseAction)

        searchAction = add_action(
            self, command=self.searchMenu.show, text='search Engine', icon=SEARCH_ICON,
            description=SEARCH_DESCRIPTION, shortcut='Ctrl+S'
        )
        self.dataToolbar.addAction(searchAction)

        geoSearchAction = add_action(
            self, command=self.geoSearchMenu.show, text='Geographic search',
            icon=GEO_SEARCH_ICON, description=GEO_SEARCH_DESCRIPTION, shortcut='Ctrl+G'
        )
        self.dataToolbar.addAction(geoSearchAction)

        regressionAction = add_action(
            self, command=self.regressionMenu.show, text='Regression6', icon=REGRESSION_ICON,
            description=REGRESSION_DESCRIPTION, shortcut='Ctrl+R'
        )
        self.dataToolbar.addAction(regressionAction)

        classificationAction = add_action(
            self, command=self.classificationMenu.show, text='Classification',
            icon=CLASSIFICATION_ICON, description=CLASSIFICATION_DESCRIPTION,
            shortcut='Ctrl+C'
        )
        self.dataToolbar.addAction(classificationAction)

        mcmcAction = add_action(
            self, command=self.mcmcMenu.show, text='Markov Chain Monte Carlo', icon=MCMC_ICON,
            description=MCMC_DESCRIPTION, shortcut='Ctrl+M'
        )
        self.dataToolbar.addAction(mcmcAction)

        webScrapingAction = add_action(
            self, command=self.webScrapingMenu.show, text='Web Scraping',
            icon=WEB_SCRAPING_ICON, description=WEB_SCRAPING_DESCRIPTION, shortcut='Ctrl+W'
        )
        self.dataToolbar.addAction(webScrapingAction)

        documentationAction = add_action(
            self, command=self.documentationMenu.show, text='1', icon=DOCUMENTATION_ICON,
            description=DOCUMENTATION_DESCRIPTION, shortcut='Ctrl+D+C'
        )
        self.dataToolbar.addAction(documentationAction)

        self.addToolBar(self.dataToolbar)


class MarkovChainMenu:
    def __init__(self, parent):
        self.parent = parent
        self.top = Toplevel(self.parent.master)
        self.top.title("Markov Chain Monte Carlo")
        self.settings = [True, False]
        self.figure = 1
        self.paths = 1

        self.parent.util.list_generator.setNonNoneValueList()

        # Create a Tkinter variable to store the ITEM OF INTEREST (item)
        self.item = StringVar(self.top)
        self.i_s = StringVar(self.top)

        # Dictionary with options
        self.vina = self.parent.util.list_generator.getNonNoneName()
        self.vinu = self.parent.util.list_generator.getNonNoneNumber()
        self.item.set('5A')  # set the default option
        self.i_s.set('None')

        # Loading user preferences
        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Markov_Chain_Preferences.txt",
            "r"
        ) as report_preferences:
            self.settings = [True if line.strip() == 'True' else False for line in report_preferences]

        # FILE PATHS
        label1 = Label(self.top, text="Input File Paths:")
        label1.grid(row=1, column=1, sticky=W)

        self.input_fp = Entry(self.top, width=30)
        self.input_fp.grid(row=1, column=3, columnspan=2)

        # PATH SELECTION BUTTON
        self.path_selection = Button(self.top, compound=LEFT, text="Open", command=self.load, cursor='hand2')
        self.path_selection.grid(row=1, column=5, columnspan=2)

        # ITEM OF INTEREST
        label2 = Label(self.top, text="Item of Interest:")
        label2.grid(row=self.paths + 1, column=1, sticky=W)

        popupMenu1 = OptionMenu(self.top, self.item, *self.vinu, command=self.item_selection)
        popupMenu1.grid(row=self.paths + 1, column=2, columnspan=3, sticky=W + E)

        # INITIAL STATE
        label3 = Label(self.top, text="Initial State:")
        label3.grid(row=self.paths + 2, column=1, sticky=W)
        self.item_selection('5A')

        # ITERATIONS
        label3 = Label(self.top, text="Iterations:")
        label3.grid(row=self.paths + 3, column=1, sticky=W)

        self.iterations = Entry(self.top, width=30)
        self.iterations.grid(row=self.paths + 3, column=3, columnspan=2)

        # SEPARATOR
        separator = ttk.Separator(self.top, orient=HORIZONTAL)
        separator.grid(row=self.paths + 5, column=1, columnspan=4, sticky=W + E)

        run_button = Button(self.top, text="Run", command=self.run, cursor='hand2')
        run_button.grid(row=self.paths + 6, column=4, sticky=E)

        cancel_button = Button(self.top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=self.paths + 6, column=5, sticky=E)

        self.top.grab_set()

    def item_selection(self, value):
        self.parameterNumbersDictionary = self.parent.util.list_generator.getParameterNumbersDictionary()
        self.parent.util.list_generator.valid_list_generator(self.parameterNumbersDictionary[str(self.item.get())])
        self.vs = self.parent.util.list_generator.get_valid_values_list()
        self.i_s.set(self.vs[0])

        popupMenu2 = OptionMenu(self.top, self.i_s, *self.vs)
        popupMenu2.grid(row=self.paths + 2, column=2, columnspan=3, sticky=W + E)

    def load(self):
        path = tkf.askopenfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        self.input_fp.delete(0, END)
        self.input_fp.insert(0, path)

    def toggle_csv(self):
        if self.settings[0]:
            self.settings[0] = False
        else:
            self.settings[0] = True

    def toggle_machine(self):
        if self.settings[1]:
            self.settings[1] = False
        else:
            self.settings[1] = True

    def run(self):
        self.settings[:] = []
        self.input_fp_list = []  # A list containing the file paths to be iterated over
        self.input_fp_list = [str(file) for file in re.findall(r'.+(?!,),?', self.input_fp.get())]
        self.tm_object = TransitionMatrix.TransitionMatrix(self, [str(year) for year in range(1992, 2017)])
        # The matrix of probability of transitioning between states (dictionary of dictionaries)
        self.tm = self.tm_object.get_transition_matrix()  # TRANSITION MATRIX
        self.i_sv = {}
        # The initial position of the probabilities (dictionary)
        self.i_sv = {state: 1 if state == self.i_s.get() else 0 for state in self.vs}

        # print("Initial State " + str(self.initial_state.get()))
        # print(self.initial_state_vector)
        self.model = MarkovChain.MarkovChain(self)

        ResultsMenuHome.Results_Menu(self, menuname="Markov Chain Monte Carlo Results")

    def cancel(self):
        self.settings[:] = []
        self.top.destroy()

    def get_initial_state(self):
        return {state: 1 if state == self.i_s.get() else 0 for state in self.vs}

    def __init__(self, GUI, parent, MASTERPATH):
        top = self.top = Toplevel(parent)
        self.parent = parent
        self.top.title("Markov Chain Monte Carlo")
        self.settings = [True, False]
        self.MASTERPATH = MASTERPATH
        self.figure = 1
        self.GUI = GUI
        self.paths = 1

        self.GUI.listGenerator.setNonNoneValueList()

        # Create a Tkinter variable
        self.item_of_interest = StringVar(self.top)
        self.initial_state = StringVar(self.top)

        # Dictionary with options
        self.valid_item_of_iterest_names = self.GUI.listGenerator.getNonNoneName()
        self.valid_item_of_iterest_numbers = self.GUI.listGenerator.getNonNoneNumber()
        self.item_of_interest.set('5A')  # set the default option
        self.initial_state.set('None')

        # Loading user preferences
        if True:
            with open(MASTERPATH + "\BridgeDataQuery\\Utilities1\Report_Preferences.txt", "r") as report_preferences:
                index = 0
                for line in report_preferences:
                    if line.strip() == 'True':
                        self.settings[index] = True
                    elif line.strip() == 'False':
                        self.settings[index] = False
                    index = 1

        # FILE PATHS
        label1 = Label(top, text="Input File Paths:")
        label1.grid(row=1, column=1, sticky=W)

        self.input_file_paths = Entry(top, width=30)
        self.input_file_paths.grid(row=1, column=3, columnspan=2)

        # PATH SELECTION BUTTON
        self.path_selection = Button(top, compound=LEFT, text="Open", command=self.load, cursor='hand2')
        self.path_selection.grid(row=1, column=5, columnspan=2)

        # ITEM OF INTEREST
        label2 = Label(top, text="Item of Interest:")
        label2.grid(row=self.paths + 1, column=1, sticky=W)

        popupMenu1 = OptionMenu(
            self.top, self.item_of_interest, *self.valid_item_of_iterest_numbers,
            command=self.itemSelection
        )
        popupMenu1.grid(row=self.paths + 1, column=2, columnspan=3, sticky=W + E)

        # INITIAL STATE
        label3 = Label(top, text="Initial State:")
        label3.grid(row=self.paths + 2, column=1, sticky=W)
        self.itemSelection('5A')

        # ITERATIONS
        label3 = Label(top, text="Iterations:")
        label3.grid(row=self.paths + 3, column=1, sticky=W)

        self.iterations = Entry(top, width=30)
        self.iterations.grid(row=self.paths + 3, column=3, columnspan=2)

        # SEPARATOR
        separator = ttk.Separator(top, orient=HORIZONTAL)
        separator.grid(row=self.paths + 5, column=1, columnspan=4, sticky=W + E)

        run_button = Button(top, text="Run", command=self.run, cursor='hand2')
        run_button.grid(row=self.paths + 6, column=4, sticky=E)

        cancel_button = Button(top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=self.paths + 6, column=5, sticky=E)

        self.top.grab_set()

    def itemSelection(self, value):
        self.parameterNumbersDictionary = self.GUI.listGenerator.getParameterNumbersDictionary()
        self.GUI.listGenerator.AllowableValueListGenerator(
            self.parameterNumbersDictionary[str(self.item_of_interest.get())]
        )
        self.valid_initial_states = self.GUI.listGenerator.getAllowableValuesList()
        self.initial_state.set(self.valid_initial_states[0])

        popupMenu2 = OptionMenu(self.top, self.initial_state, *self.valid_initial_states)
        popupMenu2.grid(row=self.paths + 2, column=2, columnspan=3, sticky=W + E)

    def load(self):
        path = tkf.askopenfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        self.input_file_paths.delete(0, END)
        self.input_file_paths.insert(0, path)

    def toggle_csv(self):
        if self.settings[0]:
            self.settings[0] = False
        else:
            self.settings[0] = True

    def toggle_machine(self):
        if self.settings[1]:
            self.settings[1] = False
        else:
            self.settings[1] = True

    def run(self):

        self.settings[:] = []
        self.input_file_paths_list = []  # A list containing the file paths to be iterated over

        # self.item_of_interest = self.input_item_of_interest.get()  # Reading the item of interest from the input fields

        for file in re.findall(r'.+(?!,),?', self.input_file_paths.get()):
            # print(file)
            self.input_file_paths_list.append(str(file))

        self.input_file_paths_list = [str(file) for file in re.findall(r'.+(?!,),?', self.input_file_paths.get())]

        self.transition_matrix_object = TransitionMatrix.TransitionMatrixBuilder(
            self.input_file_paths_list,
            self.item_of_interest.get(),
            [str(year) for year in
             range(1992, 2017)]
        )
        self.transition_matrix = self.transition_matrix_object.get_Transition_Matrix()
        self.initial_state_vector = {}
        self.list_of_possible_states = self.transition_matrix_object.get_List_of_Possible_States()
        self.initial_state_vector = {state: 1 if state == self.initial_state.get() else 0 for state in
                                     self.list_of_possible_states}

        # print("Initial State " + str(self.initial_state.get()))
        # print(self.initial_state_vector)

        MarkovChain.MarkovChain(self, self.initial_state_vector, self.transition_matrix)

    def cancel(self):
        self.settings[:] = []
        self.top.destroy()

    def getInitialState(self):
        self.initial_state_vector = {state: 1 if state == self.initial_state.get() else 0 for state in
                                     self.list_of_possible_states}
        return self.initial_state_vector

    def load(self):
        path = tkf.askopenfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        self.parent.util.entries[0].delete(0, END)
        self.parent.util.entries[0].insert(0, path)

    def run(self):
        self.settings[:] = []
        self.input_fp_list = [str(file) for file in re.findall(
            r'.+(?!,),?', self.parent.util.entries[
                0].get()
        )]  # A list containing the file paths to be iterated over
        # self.tm_object = TransitionMatrix.TransitionMatrix(self, [str(year) for year in range(1992, 2017)])
        # The matrix of probability of transitioning between states (dictionary of dictionaries)
        # self.tm = self.tm_object.get_transition_matrix()  # TRANSITION MATRIX
        # The initial position of the probabilities (dictionary)
        self.i_sv = {state: 1 if state == self.i_s.get() else 0 for state in self.vs}
        # self.model = MarkovChain2.MarkovChain2(self, self.i_sv)
        self.model = Model.Model(self)

        ResultsMenuHome.Results_Menu(self, menuname="Markov Chain Monte Carlo Results")

    def get_initial_state(self):
        return {state: 1 if state == self.i_s.get() else 0 for state in self.vs}

    def populate(self):
        self.settings = [True, False]
        self.paths = 1

        self.util.lists.setNonNoneValueList()
        # Create a Tkinter variable to store the item
        self.item = StringVar(self.top)
        self.i_s = StringVar(self.top)

        # Dictionary with options
        self.vina = self.util.lists.getNonNoneName()
        self.vinu = self.util.lists.getNonNoneNumber()
        self.item.set('5A')  # set the default option
        self.i_s.set('None')

        # Loading user preferences
        with open(self.util.MASTERPATH + self.util.mc_s_p, "r") as report_preferences:
            self.settings = [True if line.strip() == 'True' else False for line in report_preferences]

        # label
        self.util.name(
            container=self.top, text=["Input Paths:", "Item:", "Initial State:", "Iterations:"],
            row=[1, self.paths + 1, self.paths + 2, self.paths + 3], column=[1] * 4, columnspan=[1] * 4,
            sticky=['w'] * 5
        )
        # Entries (File Paths, Iterations)
        self.util.entry(
            container=self.top, width=[15, 15], row=[1, self.paths + 3], column=[3] * 2, columnspan=[1, 1],
            sticky=['we'] * 2
        )
        # ITEM OF INTEREST
        popupMenu1 = ttk.OptionMenu(self.top, self.item, *self.vinu, command=self.item_selection)
        popupMenu1.grid(row=self.paths + 1, column=2, columnspan=2, sticky='we')
        # INITIAL STATE
        self.item_selection('5A')
        # Separators
        self.util.separator(container=self.top, orient='h', row=self.paths + 5, column=1, columnspan=5, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=["Run", "Cancel", "Open"],
            commands=[self.run, self.cancel, self.load], cursor='hand2',
            row=[self.paths + 6, self.paths + 6, 1], column=[4, 1, 4], sticky=['e', 'e', 'e']
        )

    def item_selection(self, value):
        self.parameterNumbersDictionary = self.util.lists.getParameterNumbersDictionary()
        self.util.lists.valid_lists(self.parameterNumbersDictionary[str(self.item.get())])
        self.vs = self.util.lists.get_valid_values_list()
        self.i_s.set(self.vs[0])

        popupMenu2 = ttk.OptionMenu(self.top, self.i_s, *self.vs)
        popupMenu2.grid(row=self.paths + 2, column=2, columnspan=2, sticky='we')

    def load(self):
        path = tkf.askdirectory(parent=self.top, initialdir="/", title='Select Folder')
        self.parent.util.entries[0].delete(0, END)
        self.parent.util.entries[0].insert(0, path)

    def run(self):
        try:
            int(self.parent.util.entries[1].get())
        except:
            print("Enter integer iterations")
            return

        self.fp_list = self.parent.util.entries[0].get()
        self.iSV = np.array([1 if state == self.iS.get() else 0 for i, state in enumerate(self.vS)])
        self.model = MarkovChain.MarkovChain(self)
        self.model.train_nn()

    def get_initial_state(self):
        return {state: 1 if state == self.iS.get() else 0 for state in self.vS}

    def populate(self):
        self.settings = [BooleanVar()]
        self.settings[0].set(False)
        self.paths = 1
        self.util.lists.setNonNoneValueList()
        # Create a Tkinter variable to store the item
        self.item = StringVar(self.top)
        self.iS = StringVar(self.top)
        # Dictionary with options
        self.vina = self.util.lists.get_non_none_names()
        self.item.set('RECORD_TYPE_005A')  # set the default option
        self.iS.set('None')
        # Loading user preferences
        # with open(self.util.MASTERPATH + self.util.mc_s_p, "r") as report_preferences:
        # self.settings = [True if line.strip() == 'True' else False for line in report_preferences]
        # label
        self.util.name(
            container=self.top, text=["Input Paths:", "Item:", "Initial State:", "Iterations:"],
            row=[1, self.paths + 1, self.paths + 2, self.paths + 3], column=[1] * 4, columnspan=[1] * 4,
            sticky=['w'] * 4
        )
        # Entries (File Paths, Iterations)
        self.util.entry(
            container=self.top, width=[15, 15], row=[1, self.paths + 3], column=[3] * 2, columnspan=[1, 1],
            sticky=['we'] * 2
        )
        try:
            self.util.entries[0].insert(0, self.parent.filepath)
        except:
            pass
        # ITEM OF INTEREST
        popupMenu1 = ttk.OptionMenu(self.top, self.item, *self.vina, command=self.item_selection)
        popupMenu1.grid(row=self.paths + 1, column=2, columnspan=2, sticky='we')
        # INITIAL STATE
        self.item_selection('RECORD_TYPE_005A')
        # Radio Button
        self.util.radio_button(
            container=self.top, text=['Full', 'Clean'], variables=[self.settings[0]] * 2,
            values=[False, True], commands=[(lambda: self.toggle_radio_buttons(False)),
                                            (lambda: self.toggle_radio_buttons(True))],
            cursor='left_ptr', row=[5, 5], column=[1, 3], sticky=['e', 'e']
        )
        # Separators
        self.util.separator(container=self.top, orient='h', row=self.paths + 5, column=1, columnspan=5, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=["Run", "Cancel", "Select Folder"],
            commands=[self.run, self.cancel, self.load], cursor='hand2',
            row=[self.paths + 6, self.paths + 6, 1], column=[5, 1, 5], sticky=['e', 'e', 'e']
        )

    def item_selection(self, value):
        self.util.lists.valid_lists(str(self.item.get()))
        self.vS = self.util.lists.get_valid_values_list()
        self.iS.set(self.vS[0])
        popupMenu2 = ttk.OptionMenu(self.top, self.iS, *self.vS)
        popupMenu2.grid(row=self.paths + 2, column=2, columnspan=2, sticky='we')

    def load(self):
        # self.top.withdraw()
        path = tkf.askdirectory(parent=self.top, initialdir="/", title='Select Folder')
        self.parent.util.entries[0].delete(0, END)
        self.parent.util.entries[0].insert(0, path)

    def load_file(self):
        path = tkf.askopenfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        self.parent.util.entries[0].delete(0, END)
        self.parent.util.entries[0].insert(0, path)

    def run(self):
        self.settings[:] = []
        self.input_fp_list = [str(file) for file in re.findall(
            r'.+(?!,),?', self.parent.util.entries[
                0].get()
        )]  # A list containing the file paths to be iterated over
        # self.tm_object = TransitionMatrix.TransitionMatrix(self, [str(year) for year in range(1992, 2017)])
        # The matrix of probability of transitioning between states (dictionary of dictionaries)
        # self.tm = self.tm_object.get_transition_matrix()  # TRANSITION MATRIX
        # The initial position of the probabilities (dictionary)
        # self.model = MarkovChain2.MarkovChain2(self, self.i_sv)

        # TODO use i_sv2 instead of i_sv
        self.i_sv2 = np.array([1 if state == self.i_s.get() else 0 for i, state in enumerate(self.vs)])

        self.i_sv = {state: 1 if state == self.i_s.get() else 0 for state in self.vs}
        self.model = Model.Model(self)
        # print(self.i_sv)
        print(self.i_sv2)

        # ResultsMenuHome.Results_Menu(self, menuname="Markov Chain Monte Carlo Results")

    def get_initial_state(self):
        return {state: 1 if state == self.i_s.get() else 0 for state in self.vs}

    def populate(self):
        self.settings = [True, False]
        self.paths = 1

        self.util.lists.setNonNoneValueList()
        # Create a Tkinter variable to store the item
        self.item = StringVar(self.top)
        self.i_s = StringVar(self.top)

        # Dictionary with options
        self.vina = self.util.lists.getNonNoneName()
        self.vinu = self.util.lists.getNonNoneNumber()
        self.item.set('RECORD_TYPE_005A')  # set the default option
        self.i_s.set('None')

        # Loading user preferences
        with open(self.util.MASTERPATH + self.util.mc_s_p, "r") as report_preferences:
            self.settings = [True if line.strip() == 'True' else False for line in report_preferences]

        # label
        self.util.name(
            container=self.top, text=["Input Paths:", "Item:", "Initial State:", "Iterations:"],
            row=[1, self.paths + 1, self.paths + 2, self.paths + 3], column=[1] * 4, columnspan=[1] * 4,
            sticky=['w'] * 5
        )
        # Entries (File Paths, Iterations)
        self.util.entry(
            container=self.top, width=[15, 15], row=[1, self.paths + 3], column=[3] * 2, columnspan=[1, 1],
            sticky=['we'] * 2
        )
        # ITEM OF INTEREST
        popupMenu1 = ttk.OptionMenu(self.top, self.item, *self.vina, command=self.item_selection)
        popupMenu1.grid(row=self.paths + 1, column=2, columnspan=2, sticky='we')
        # INITIAL STATE
        self.item_selection('RECORD_TYPE_005A')
        # Separators
        self.util.separator(container=self.top, orient='h', row=self.paths + 5, column=1, columnspan=5, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=["Run", "Cancel", "Select Folder"],
            commands=[self.run, self.cancel, self.load], cursor='hand2',
            row=[self.paths + 6, self.paths + 6, 1], column=[4, 1, 4], sticky=['e', 'e', 'e']
        )

    def item_selection(self, value):
        self.parameterNumbersDictionary = self.util.lists.getParameterNumbersDictionary()
        self.util.lists.valid_lists(str(self.item.get()))
        self.vs = self.util.lists.get_valid_values_list()
        self.i_s.set(self.vs[0])

        popupMenu2 = ttk.OptionMenu(self.top, self.i_s, *self.vs)
        popupMenu2.grid(row=self.paths + 2, column=2, columnspan=2, sticky='we')

    def load(self):
        path = tkf.askdirectory(parent=self.top, initialdir="/", title='Select Folder')
        self.parent.util.entries[0].delete(0, END)
        self.parent.util.entries[0].insert(0, path)

    def run(self):
        try:
            int(self.util.entries[1].get())
        except:
            print("Enter integer iterations")
            return

        self.fp_list = self.parent.util.entries[0].get()
        self.iSV = np.array([1 if state == self.iS.get() else 0 for i, state in enumerate(self.vS)])
        self.model = MarkovChain.MarkovChain(self)
        self.model.train_nn()

    def populate(self):
        self.settings = [BooleanVar()]
        self.settings[0].set(False)
        self.util.lists.setNonNoneValueList()
        # Create a Tkinter variable to store the item
        self.item = StringVar(self.top)
        self.iS = StringVar(self.top)
        # Dictionary with options
        self.vina = self.util.lists.nonNoneName
        self.item.set(self.vina[0])  # set the default option
        # Loading user preferences
        # with open(self.util.MASTERPATH + self.util.mc_s_p, "r") as report_preferences:
        # self.settings = [True if line.strip() == 'True' else False for line in report_preferences]
        # label
        self.util.name(
            container=self.top, text=["Input Paths:", "Item:", "Initial State:", "Iterations:"],
            row=[1, 2, 3, 4], column=[1] * 4, columnspan=[1] * 4, sticky=['w'] * 4
        )
        # Entries (File Paths, Iterations)
        self.util.entry(
            container=self.top, width=[15, 15], row=[1, 4], column=[3] * 2, columnspan=[1, 1],
            sticky=['we'] * 2
        )
        try:
            self.util.entries[0].insert(0, self.parent.filepath)
        except:
            pass
        # ITEM OF INTEREST
        listMenu1 = ttk.OptionMenu(self.top, self.item, *self.vina, command=self.item_selection)
        listMenu1.grid(row=2, column=2, columnspan=2, sticky='we')
        # INITIAL STATE
        self.item_selection(self.item)
        # Radio Button
        self.util.radio_button(
            container=self.top, text=['Full', 'Clean'], variables=[self.settings[0]] * 2,
            values=[False, True],
            commands=[(lambda: self.toggle_radio(0, False)), (lambda: self.toggle_radio(0, True))],
            cursor='left_ptr', row=[5, 5], column=[1, 3], sticky=['e', 'e']
        )
        # Separators
        self.util.separator(container=self.top, orient='h', row=6, column=1, columnspan=5, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=["Run", "Cancel", "Select Folder"],
            commands=[self.run, self.cancel, self.load], cursor='hand2', row=[7, 7, 1], column=[5, 1, 5],
            sticky=['e', 'e', 'e']
        )

    def item_selection(self, value):
        self.vS = self.util.lists.get_valid_lists(str(self.item.get()))
        self.iS.set(self.vS[0])
        listMenu2 = ttk.OptionMenu(self.top, self.iS, *self.vS)
        listMenu2.grid(row=3, column=2, columnspan=2, sticky='we')


class MarkovChainResultsMenu:
    def __init__(self, MonteCarlo):
        self.MonteCarlo = MonteCarlo
        self.top = Toplevel(self.MonteCarlo.MarkovChain.CubesatAppMenu.GUI.master)
        self.top.title("Results")
        self.settings = [True, False]
        self.figure = 1
        self.plotter = Plotter.Plotter()

        self.MonteCarlo.MarkovChain.CubesatAppMenu.GUI.list_generator.setNonNoneValueList()

        # Create a Tkinter variable to store the ITEM OF INTEREST (item)
        self.item = StringVar(self.top)
        self.i_s = StringVar(self.top)

        # Dictionary with options
        self.vina = self.MonteCarlo.MarkovChain.CubesatAppMenu.GUI.list_generator.getNonNoneName()
        self.vinu = self.MonteCarlo.MarkovChain.CubesatAppMenu.GUI.list_generator.getNonNoneNumber()
        self.item.set('None')  # set the default option
        self.i_s.set('None')

        # MARKOV CHAIN PLOT
        label_1 = Label(self.top, text="Markov Chain:")
        label_1.grid(row=1, column=1, sticky=W)

        popupMenu_1 = OptionMenu(
            self.top, "Markov Chain Transition Probabilities", *["Plot"],
            command=self.markov_chain_plot
        )
        popupMenu_1.grid(row=1, column=2, columnspan=3, sticky=W + E)

        # DETERIORATION PLOTS
        label2 = Label(self.top, text="Deterioration:")
        label2.grid(row=2, column=1, sticky=W)

        popupMenu2 = OptionMenu(self.top, "Deterioration", *["Plot"], command=self.deterioration_plot)
        popupMenu2.grid(row=2, column=2, columnspan=3, sticky=W + E)

        # FREQUENCY
        label3 = Label(self.top, text="Frequency:")
        label3.grid(row=3, column=1, columnspan=3, sticky=W)
        popupMenu3 = OptionMenu(self.top, self.item, *["Plot"], command=self.histogram_plot)
        popupMenu3.grid(row=3, column=2, columnspan=3, sticky=W + E)

        # SEPARATOR
        separator = ttk.Separator(self.top, orient=HORIZONTAL)
        separator.grid(row=5, column=1, columnspan=4, sticky=W + E)

        plot_button = Button(self.top, text="Plot", command=self.plot, cursor='hand2')
        plot_button.grid(row=4, column=3, sticky=E)

        cancel_button = Button(self.top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=4, column=4, sticky=E)

        self.top.grab_set()

    def markov_chain_plot(self, value):
        # Plot the Markov Chain results (Probability vs Year)
        self.title_mctp = "Markov Chain Transition Probabilities"
        self.plotter.Plot(
            self.title_mctp, self.MonteCarlo.MarkovChain.results, 111, x_label='Time (Years)',
            y_label='Probability of State (%)', title=self.title_mctp,
            legend_labels_list=self.MonteCarlo.legend_labels
        )

    def deterioration_plot(self, value):
        # Plot the Monte Carlo simulation results in the same figure (State vs Year)
        print(self.MonteCarlo.MarkovChain.CubesatAppMenu.tm_object.get_summary())
        print(self.MonteCarlo.monte_carlo_simulation)

        self.title_p = "Deterioration Curve"
        self.plotter.Plot(
            self.title_p, self.MonteCarlo.MarkovChain.CubesatAppMenu.tm_object.get_summary(), 211, title="Raw Data",
            x_label=''
        )
        self.plotter.Plot(self.title_p, self.MonteCarlo.monte_carlo_simulation, 212, title="Monte Carlo Simulation2")

    def histogram_plot(self, value):
        for year in range(24):
            histogram_data = []
            for iteration in range(self.MonteCarlo.iterations):
                histogram_data.append(int(self.MonteCarlo.monte_carlo_simulation[iteration][year]))

            self.plotter.Histogram(self.MonteCarlo.MarkovChain.CubesatAppMenu.figure, histogram_data)

    def plot(self):
        self.plotter.display()

    def cancel(self):
        self.__del__()

    def __del__(self):
        self.MonteCarlo.MarkovChain.CubesatAppMenu.top.grab_set()
        self.top.destroy()

    def __init__(self, GUI, parent, MASTERPATH):
        top = self.top = Toplevel(parent)
        self.top.title("Markov Chain Monte Carlo")
        self.settings = [True, False]
        self.MASTERPATH = MASTERPATH
        self.figure = 1
        self.GUI = GUI
        self.paths = 1

        self.GUI.listGenerator.setNonNoneValueList()

        # Create a Tkinter variable
        self.item_of_interest = StringVar(self.top)
        self.initial_state = StringVar(self.top)

        # Dictionary with options
        self.valid_item_of_iterest_names = self.GUI.listGenerator.getNonNoneName()
        self.valid_item_of_iterest_numbers = self.GUI.listGenerator.getNonNoneNumber()
        self.item_of_interest.set('5A')  # set the default option
        self.initial_state.set('None')

        # FILE PATHS
        label1 = Label(top, text="Input File Paths:")
        label1.grid(row=1, column=1, sticky=W)

        self.input_file_paths = Entry(top, width=30)
        self.input_file_paths.grid(row=1, column=3, columnspan=2)

        # PATH SELECTION BUTTON
        self.path_selection = Button(top, compound=LEFT, text="Open", command=self.cancel, cursor='hand2')
        self.path_selection.grid(row=1, column=5, columnspan=2)

        # ITEM OF INTEREST
        label2 = Label(top, text="Item of Interest:")
        label2.grid(row=self.paths + 1, column=1, sticky=W)

        popupMenu1 = OptionMenu(
            self.top, self.item_of_interest, *self.valid_item_of_iterest_numbers,
            command=self.itemSelection
        )
        popupMenu1.grid(row=self.paths + 1, column=2, columnspan=3, sticky=W + E)

        # INITIAL STATE
        label3 = Label(top, text="Initial State:")
        label3.grid(row=self.paths + 2, column=1, sticky=W)
        self.itemSelection('5A')

        # SEPARATOR
        separator = ttk.Separator(top, orient=HORIZONTAL)
        separator.grid(row=self.paths + 5, column=1, columnspan=4, sticky=W + E)

        cancel_button = Button(top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=self.paths + 6, column=5, sticky=E)

        self.top.grab_set()

    def itemSelection(self, value):
        self.parameterNumbersDictionary = self.GUI.listGenerator.getParameterNumbersDictionary()
        self.GUI.listGenerator.AllowableValueListGenerator(
            self.parameterNumbersDictionary[str(self.item_of_interest.get())]
        )
        self.valid_initial_states = self.GUI.listGenerator.getAllowableValuesList()
        self.initial_state.set(self.valid_initial_states[0])

        popupMenu2 = OptionMenu(self.top, self.initial_state, *self.valid_initial_states)
        popupMenu2.grid(row=self.paths + 2, column=2, columnspan=3, sticky=W + E)

    def cancel(self):
        self.top.destroy()


class LogSettings:
    def __init__(self, app, parent, layout):
        try:
            self.app = app
            self.parent = parent
            self.layout = layout
            _, self.loggingRateSpinBox = self.app.assembler.pair(
                self.parent,
                pair='numerical',
                inputSettings=(
                    1,
                    1000,
                    self.app.logConfig.loggingRate,
                    1,
                ),
                command=lambda: self.update_logging_rate(),
                layout=layout,
                gbHeight=40,
                **widgetkwargs.settings.loggingRateSpinBox,
            )
            _, self.logCreationIntervalSpinBox = self.app.assembler.pair(
                self.parent,
                pair='numerical',
                inputSettings=(
                    10,
                    600,
                    self.app.logConfig.logCreationInterval,
                    1,
                ),
                command=lambda: self.update_log_creation_interval(),
                layout=layout,
                gbHeight=40,
                **widgetkwargs.settings.logCreationIntervalSpinBox,
            )
        except Exception as e:
            print(e)

    def update_logging_rate(self):
        try:
            self.app.logConfig.update('loggingRate', self.loggingRateSpinBox.value())
            self.parent.update_status('Logging rate: {}.'.format(self.app.logConfig.loggingRate), 'success')
        except Exception as e:
            statusMsg = 'Update logging rate error: {}.'.format(str(e))
            self.parent.update_status(statusMsg, 'error')

    def update_log_creation_interval(self):
        try:
            self.app.logConfig.update('logCreationInterval', self.logCreationIntervalSpinBox.value())
            self.parent.update_status(
                'Log creation interval: {} seconds.'.format(self.app.logConfig.logCreationInterval),
                'success'
            )
        except Exception as e:
            statusMsg = 'Update interface7 creation error: {}'.format(str(e))
            self.parent.update_status(statusMsg, 'error')


class MarkovChainSettings:
    def __init__(self, parent, MASTERPATH):
        top = self.top = Toplevel(parent)
        self.top.title("Markov Chain Settings")
        self.top.grab_set()
        self.MASTERPATH = MASTERPATH

        label2 = Label(top, text="Use randomly generated data to add noise:")
        label2.grid(row=2, column=1, sticky=W)

        self.noise_button = Checkbutton(top, command=self.cancel, cursor='left_ptr')
        self.noise_button.grid(row=2, column=2, sticky=E)

        label2 = Label(top, text="Automatically populate data input paths with interface7 results:")
        label2.grid(row=3, column=1, sticky=W)

        self.noise_button = Checkbutton(top, command=self.cancel, cursor='left_ptr')
        self.noise_button.grid(row=3, column=2, sticky=E)

        # SEPARATOR
        separator = ttk.Separator(top, orient=HORIZONTAL)
        separator.grid(row=4, column=1, columnspan=2, sticky=W + E)

        apply_button = Button(top, text="Apply", command=self.apply, cursor='hand2')
        apply_button.grid(row=5, column=1, sticky=E)

        cancel_button = Button(top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=5, column=2, sticky=E)

    def update_main_path_preferences(self):
        with open(
            self.MASTERPATH + "\BridgeDataQuery\\Utilities14\Markov_Chain_Preferences.txt",
            "w"
        ) as report_preferences:
            report_preferences.write('')

    def apply(self):
        self.update_main_path_preferences()
        self.top.destroy()

    def cancel(self):
        self.top.destroy()


class NameReport:
    def __init__(self, parent):
        self.parent = parent
        self.populator = PopulateNameReport.PopulateNameReport(self)

    def toggle_csv(self):
        if self.populator.settings[0]:
            self.populator.settings[0] = False
        else:
            self.populator.settings[0] = True

    def toggle_machine(self):
        if self.populator.settings[1]:
            self.populator.settings[1] = False
        else:
            self.populator.settings[1] = True

    def toggle_single(self):
        if self.populator.settings[2]:
            self.populator.settings[2] = False
        else:
            self.populator.settings[2] = True

    def toggle_multiple(self):
        if self.populator.settings[3]:
            self.populator.settings[3] = False
        else:
            self.populator.settings[3] = True

    def update_preferences(self):
        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Temporary_Report_Preferences.txt",
            "w"
        ) as report_preferences:
            for index in range(self.populator.settings.__len__()):
                report_preferences.write(str(self.populator.settings[index]) + "\n")

    def browse(self):
        path = tkf.asksaveasfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        self.populator.file_path_input.delete(0, END)
        self.populator.file_path_input.insert(0, path)

    def run(self):
        """self.progress_bar = ttk.Progressbar(self.top, mode='indeterminate', orient=HORIZONTAL)
        self.progress_bar.grid(row=6, column=1, columnspan=3, sticky=W+E)
        self.progress_bar.start(5)"""

        self.parent.set_filepath(self.populator.file_path_input.get())
        self.update_preferences()
        self.populator.settings[:] = []
        self.parent.search_resume()
        self.populator.csv_button.deselect()
        self.populator.machine_button.deselect()
        self.populator.single_file_button.deselect()
        self.populator.multiple_file_button.deselect()
        self.populator.top.destroy()

    def cancel(self):
        self.populator.csv_button.deselect()
        self.populator.machine_button.deselect()
        self.populator.single_file_button.deselect()
        self.populator.multiple_file_button.deselect()
        self.populator.settings[:] = []
        self.populator.top.destroy()

    def __init__(self, parent):
        self.parent = parent
        self.top = Toplevel(self.parent.master)
        self.top.grab_set()
        self.top.title("report_generator0 Options")
        self.settings = [True, False, False, True]

        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Report_Preferences.txt",
            "r"
        ) as report_preferences:
            index = 0
            for line in report_preferences:
                if line.strip() == 'True':
                    self.settings[index] = True
                elif line.strip() == 'False':
                    self.settings[index] = False
                index += 1

        # CSV EXPORT
        label1 = Label(self.top, text="Export as comma separated value (csv) file:")
        label1.grid(row=1, column=1, columnspan=3, sticky=W)

        self.csv_button = Checkbutton(self.top, command=self.toggle_csv, cursor='left_ptr')
        self.csv_button.grid(row=1, column=4, sticky=E)

        # MACHINE LEARNING EXPORT
        label2 = Label(self.top, text="Export as machine learning input file:")
        label2.grid(row=2, column=1, columnspan=3, sticky=W)

        self.machine_button = Checkbutton(self.top, command=self.toggle_machine, cursor='left_ptr')
        self.machine_button.grid(row=2, column=4, sticky=E)

        # SINGLE VS MULTIPLE FILE OUTPUT
        label3 = Label(self.top, text="Single file:")
        label3.grid(row=3, column=1, sticky=W)

        self.single_file_button = Checkbutton(self.top, command=self.toggle_single, cursor='left_ptr')
        self.single_file_button.grid(row=3, column=2, sticky=E)

        label3 = Label(self.top, text="Multiple Files:")
        label3.grid(row=3, column=3, sticky=W)

        self.multiple_file_button = Checkbutton(self.top, command=self.toggle_multiple, cursor='left_ptr')
        self.multiple_file_button.grid(row=3, column=4, sticky=E)

        # FILE PATH INPUT
        label4 = Label(self.top, text="File Path:")
        label4.grid(row=4, column=1, sticky=W)

        self.file_path_input = Entry(self.top, width=30)
        self.file_path_input.grid(row=4, column=2, columnspan=2, sticky=E)

        file_path_browse = Button(self.top, text="Browse", command=self.Browse, cursor='hand2')
        file_path_browse.grid(row=4, column=4, sticky=E)

        # SEPARATOR
        separator = ttk.Separator(self.top, orient=HORIZONTAL)
        separator.grid(row=5, column=1, columnspan=4, sticky=W + E)

        run_button = Button(self.top, text="Run", command=self.run, cursor='hand2')
        run_button.grid(row=6, column=3, sticky=E)

        cancel_button = Button(self.top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=6, column=4, sticky=E)

        if self.settings[0]:
            self.csv_button.select()

        if self.settings[1]:
            self.machine_button.select()

        if self.settings[2]:
            self.single_file_button.select()

        if self.settings[3]:
            self.multiple_file_button.select()

        self.top.grab_set()

    def __init__(self, parent):
        self.top = Toplevel(self.parent.master)
        self.top.grab_set()
        self.top.title("report_generator0 Options")
        self.settings = [True, False, False, True]

        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Report_Preferences.txt",
            "r"
        ) as report_preferences:
            index = 0
            for line in report_preferences:
                if line.strip() == 'True':
                    self.settings[index] = True
                elif line.strip() == 'False':
                    self.settings[index] = False
                index += 1

        # CSV EXPORT
        label1 = Label(self.top, text="Export as comma separated value (csv) file:")
        label1.grid(row=1, column=1, columnspan=3, sticky=W)

        self.csv_button = Checkbutton(self.top, command=self.toggle_csv, cursor='left_ptr')
        self.csv_button.grid(row=1, column=4, sticky=E)

        # MACHINE LEARNING EXPORT
        label2 = Label(self.top, text="Export as machine learning input file:")
        label2.grid(row=2, column=1, columnspan=3, sticky=W)

        self.machine_button = Checkbutton(self.top, command=self.toggle_machine, cursor='left_ptr')
        self.machine_button.grid(row=2, column=4, sticky=E)

        # SINGLE VS MULTIPLE FILE OUTPUT
        label3 = Label(self.top, text="Single file:")
        label3.grid(row=3, column=1, sticky=W)

        self.single_file_button = Checkbutton(self.top, command=self.toggle_single, cursor='left_ptr')
        self.single_file_button.grid(row=3, column=2, sticky=E)

        label3 = Label(self.top, text="Multiple Files:")
        label3.grid(row=3, column=3, sticky=W)

        self.multiple_file_button = Checkbutton(self.top, command=self.toggle_multiple, cursor='left_ptr')
        self.multiple_file_button.grid(row=3, column=4, sticky=E)

        # FILE PATH INPUT
        label4 = Label(self.top, text="File Path:")
        label4.grid(row=4, column=1, sticky=W)

        self.file_path_input = Entry(self.top, width=30)
        self.file_path_input.grid(row=4, column=2, columnspan=2, sticky=E)

        file_path_browse = Button(self.top, text="Browse", command=self.Browse, cursor='hand2')
        file_path_browse.grid(row=4, column=4, sticky=E)

        # SEPARATOR
        separator = ttk.Separator(self.top, orient=HORIZONTAL)
        separator.grid(row=5, column=1, columnspan=4, sticky=W + E)

        run_button = Button(self.top, text="Run", command=self.run, cursor='hand2')
        run_button.grid(row=6, column=3, sticky=E)

        cancel_button = Button(self.top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=6, column=4, sticky=E)

        if self.settings[0]:
            self.csv_button.select()

        if self.settings[1]:
            self.machine_button.select()

        if self.settings[2]:
            self.single_file_button.select()

        if self.settings[3]:
            self.multiple_file_button.select()

        self.top.grab_set()

    def toggle_csv(self):
        if self.settings[0]:
            self.settings[0] = False
        else:
            self.settings[0] = True

    def toggle_machine(self):
        if self.settings[1]:
            self.settings[1] = False
        else:
            self.settings[1] = True

    def toggle_single(self):
        if self.settings[2]:
            self.settings[2] = False
        else:
            self.settings[2] = True

    def toggle_multiple(self):
        if self.settings[3]:
            self.settings[3] = False
        else:
            self.settings[3] = True

    def update_preferences(self):
        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Temporary_Report_Preferences.txt",
            "w"
        ) as report_preferences:
            for index in range(self.settings.__len__()):
                report_preferences.write(str(self.settings[index]) + "\n")

    def Browse(self):
        path = tkf.asksaveasfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        self.file_path_input.delete(0, END)
        self.file_path_input.insert(0, path)

    def run(self):
        """self.progress_bar = ttk.Progressbar(self.top, mode='indeterminate', orient=HORIZONTAL)
        self.progress_bar.grid(row=6, column=1, columnspan=3, sticky=W+E)
        self.progress_bar.start(5)"""

        self.parent.set_filepath(self.file_path_input.get())
        self.update_preferences()
        self.settings[:] = []
        self.parent.search_resume()
        self.csv_button.deselect()
        self.machine_button.deselect()
        self.single_file_button.deselect()
        self.multiple_file_button.deselect()
        self.top.destroy()

    def cancel(self):
        self.csv_button.deselect()
        self.machine_button.deselect()
        self.single_file_button.deselect()
        self.multiple_file_button.deselect()
        self.settings[:] = []
        self.top.destroy()

    def __init__(self, parent):
        self.top = Toplevel(self.parent.master)
        self.top.grab_set()
        self.top.title("Report Options")
        self.settings = [True, False, False, True]

        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities1\Preferences\Report_Preferences.txt",
            "r"
        ) as report_preferences:
            index = 0
            for line in report_preferences:
                if line.strip() == 'True':
                    self.settings[index] = True
                elif line.strip() == 'False':
                    self.settings[index] = False
                index += 1

        # CSV EXPORT
        label1 = Label(self.top, text="Export as comma separated value (csv) file:")
        label1.grid(row=1, column=1, columnspan=3, sticky=W)

        self.csv_button = Checkbutton(self.top, command=self.toggle_csv, cursor='left_ptr')
        self.csv_button.grid(row=1, column=4, sticky=E)

        # MACHINE LEARNING EXPORT
        label2 = Label(self.top, text="Export as machine learning input file:")
        label2.grid(row=2, column=1, columnspan=3, sticky=W)

        self.machine_button = Checkbutton(self.top, command=self.toggle_machine, cursor='left_ptr')
        self.machine_button.grid(row=2, column=4, sticky=E)

        # SINGLE VS MULTIPLE FILE OUTPUT
        label3 = Label(self.top, text="Single file:")
        label3.grid(row=3, column=1, sticky=W)

        self.single_file_button = Checkbutton(self.top, command=self.toggle_single, cursor='left_ptr')
        self.single_file_button.grid(row=3, column=2, sticky=E)

        label3 = Label(self.top, text="Multiple Files:")
        label3.grid(row=3, column=3, sticky=W)

        self.multiple_file_button = Checkbutton(self.top, command=self.toggle_multiple, cursor='left_ptr')
        self.multiple_file_button.grid(row=3, column=4, sticky=E)

        # FILE PATH INPUT
        label4 = Label(self.top, text="File Path:")
        label4.grid(row=4, column=1, sticky=W)

        self.file_path_input = Entry(self.top, width=30)
        self.file_path_input.grid(row=4, column=2, columnspan=2, sticky=E)

        file_path_browse = Button(self.top, text="Browse", command=self.Browse, cursor='hand2')
        file_path_browse.grid(row=4, column=4, sticky=E)

        # SEPARATOR
        separator = ttk.Separator(self.top, orient=HORIZONTAL)
        separator.grid(row=5, column=1, columnspan=4, sticky=W + E)

        run_button = Button(self.top, text="Run", command=self.run, cursor='hand2')
        run_button.grid(row=6, column=3, sticky=E)

        cancel_button = Button(self.top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=6, column=4, sticky=E)

        if self.settings[0]:
            self.csv_button.select()

        if self.settings[1]:
            self.machine_button.select()

        if self.settings[2]:
            self.single_file_button.select()

        if self.settings[3]:
            self.multiple_file_button.select()

        self.top.grab_set()

    def toggle_csv(self):
        if self.settings[0]:
            self.settings[0] = False
        else:
            self.settings[0] = True

    def toggle_machine(self):
        if self.settings[1]:
            self.settings[1] = False
        else:
            self.settings[1] = True

    def toggle_single(self):
        if self.settings[2]:
            self.settings[2] = False
        else:
            self.settings[2] = True

    def toggle_multiple(self):
        if self.settings[3]:
            self.settings[3] = False
        else:
            self.settings[3] = True

    def update_preferences(self):
        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities1\Preferences\Temporary_Report_Preferences.txt",
            "w"
        ) as report_preferences:
            for index in range(self.settings.__len__()):
                report_preferences.write(str(self.settings[index]) + "\n")

    def Browse(self):
        path = tkf.asksaveasfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        self.file_path_input.delete(0, END)
        self.file_path_input.insert(0, path)

    def run(self):
        """self.progress_bar = ttk.Progressbar(self.top, mode='indeterminate', orient=HORIZONTAL)
        self.progress_bar.grid(row=6, column=1, columnspan=4, sticky=W+E)
        self.progress_bar.start(5)"""

        self.parent.set_filepath(self.file_path_input.get())
        self.update_preferences()
        self.settings[:] = []
        self.parent.search_resume()
        self.csv_button.deselect()
        self.machine_button.deselect()
        self.single_file_button.deselect()
        self.multiple_file_button.deselect()
        self.top.destroy()

    def cancel(self):
        self.csv_button.deselect()
        self.machine_button.deselect()
        self.single_file_button.deselect()
        self.multiple_file_button.deselect()
        self.settings[:] = []
        self.top.destroy()


class Plot:
    def __init__(self, parent, MASTERPATH):
        top = self.top = Toplevel(parent)
        self.top.title("Create Plot")
        self.top.grab_set()
        self.main_path = MASTERPATH
        Label(top, text="Figure Settings").grid(row=1, column=1, columnspan=6, sticky=W + E)
        Label(top, text="Title:").grid(row=2, column=1, sticky=W)
        self.title = Entry(top, width=19)
        self.title.grid(row=2, column=2, columnspan=2, sticky=E)
        Label(top, text="y-axis:").grid(row=3, column=1, sticky=W)
        self.y_axis_label = Entry(top, width=19)
        self.y_axis_label.grid(row=3, column=2, columnspan=2, sticky=E)
        Label(top, text="x-axis:").grid(row=4, column=1, sticky=W)
        self.x_axis_label = Entry(top, width=19)
        self.x_axis_label.grid(row=4, column=2, columnspan=2, sticky=E)
        Label(top, text="Data Settings").grid(row=6, column=1, columnspan=6, sticky=W + E)
        Label(top, text="Data Label:").grid(row=7, column=1, sticky=W)
        self.e = Entry(top, width=19)
        self.e.grid(row=7, column=2, columnspan=2, sticky=E)
        Label(top, text="y-axis:").grid(row=8, column=1, sticky=W)
        self.e = Entry(top, width=19)
        self.e.grid(row=8, column=2, columnspan=2, sticky=E)
        Label(top, text="x-axis:").grid(row=9, column=1, sticky=W)
        self.e = Entry(top, width=19)
        self.e.grid(row=9, column=2, columnspan=2, sticky=E)
        separator = ttk.Separator(top, orient=HORIZONTAL)
        separator.grid(row=10, column=1, columnspan=7, sticky=W + E)
        create_plot_button = Button(top, text="Create Plot", command=self.create_plot, cursor='hand2')
        create_plot_button.grid(row=11, column=5, sticky=E)
        cancel_button = Button(top, text="Cancel", command=self.top.destroy, cursor='hand2')
        cancel_button.grid(row=11, column=6, sticky=E)

    def create_plot(self):
        Plotter.Plotter(
            [[1, 2], [1, 2]], 1, [], 1992, self.x_axis_label.get(), self.y_axis_label.get(),
            self.title.get(), )


class PlotDude:
    """
    This dude handles the plots.
    """

    @decorators.update_list_widget_decorator('mainMenu', *status.initPlotDudeError)
    def __init__(self, app):
        self.app = app
        self.plots = []
        for plot in self.app.plotConfig.plots:
            self.add_plot(plot)
        if len(self.plots) == 0:
            self.add_plot()
        self.devicePlot = deviceplot.DevicePlot(self.app)

    @decorators.update_list_widget_decorator('plotMenu', *status.addPlotError)
    def add_plot(self, dna=None):
        if dna:
            self.plots.append(animatedplot.AnimatedPlot2D(self.app, **dna))
        else:
            n = len(self.plots)
            self.plots.append(animatedplot.AnimatedPlot2D(self.app, n))
        if len(self.app.plotConfig.plots) == 0:
            self.app.plotConfig.update('plots', [plot.dna for plot in self.plots])
            self.app.plotConfig.save_to_file()

    """
    This dude handles the plots.
    """

    def __init__(self, parent):
        self.parent = parent
        self.plots = []
        self._x, self._y, self._z = 0, 0, 0
        self.make_plot('', 'gyro vel')
        self.device = self.get_device_plot(updateFunction=self.update_animation, )

    def make_plot(self, x, y):
        n = len(self.plots)
        self.plots.append(
            self.get_plot(
                x=range(self.parent.configuration.buffer), y=self.parent.dataDude.get(y),
                updateFunction=self.plot_update, updateArgs=[n],
                plotColor=self.parent.palette.plotColors['blue'], )
        )
        self.parent.configuration.plotProperties.append(
            {
                'ymin': -100, 'ymax': 100, 'xmin': self.parent.configuration.buffer - 10,
                'xmax': self.parent.configuration.buffer, 'x': x, 'y': y,
            }
        )

    def plot_update(self, i, plot):
        if not (self.parent.plotMenu.isHidden() or self.parent.plotMenu.isMinimized()):
            ydata = self.parent.dataDude.get(self.parent.configuration.plotProperties[plot]['y'])
            self.plots[plot]['plot0'].set_xdata(range(len(ydata)))
            self.plots[plot]['plot0'].set_ydata(y=ydata)

    def device_update(self, *args):
        msg, timeMS = args
        try:
            # t = int(str(timeMS)[-3:-1])
            # msg = str(msg.split(r"b'")[1])
            # msg = str(msg.split(r'\r')[0])
            self.x, self.y, self.z = [round(float(_)) for _ in msg.split(',')]
            self.x = -0.0174533 * self.x
            self.y = -0.0174533 * self.y
            self.z = -0.0174533 * self.z
            if self.x != self._x:
                dx = self.x - self._x
                self._x = self.x
                self.x = dx
                self.parent.cubeSat.set_avc(self.x, self.y, self.z)
                self.parent.cubeSat.rotate()
                self.parent.cubeSat.set_avc(0, 0, 0)
            else:
                self._x = self.x

            if self.y != self._y:
                dy = self.y - self._y
                self._y = self.y
                self.y = dy
                self.parent.cubeSat.set_avc(self.x, self.y, self.z)
                self.parent.cubeSat.rotate()
                self.parent.cubeSat.set_avc(0, 0, 0)
            else:
                self._y = self.y
            if self.z != self._z:
                dz = self.z - self._z
                self._z = self.z
                self.z = dz
                self.parent.cubeSat.set_avc(self.x, self.y, self.z)
                self.parent.cubeSat.rotate()
                self.parent.cubeSat.set_avc(0, 0, 0)
            else:
                self._z = self.z  # if self.parent.preferences.renderAV:  #     orientation = self.parent.cubeSat.avc  #     self.graphics['avText'].set_text("Angular Velocity: {}".format(orientation))
        except Exception as e:
            print('Kinematic calculations error:  ' + str(e))

    def get_plot(self, x, y, updateFunction, updateArgs, plotColor='#e27d60'):
        fig = Figure()
        canvas = FigureCanvas(fig)
        ax = fig.add_subplot(111)
        plot, = ax.plot(x, y, color=plotColor, zorder=3, )
        anim = animation.FuncAnimation(
            fig, updateFunction, frames=self.parent.configuration.frames,
            interval=self.parent.configuration.fps, fargs=updateArgs, )
        p = {'fig': fig, 'canvas': canvas, 'ax': ax, 'plot0': plot, 'anim': anim, }
        self.format_plot(p)
        return p

    def format_plot(self, p):
        for spine in p['ax'].spines:
            p['ax'].spines[spine].set_color('w')
        p['ax'].tick_params(colors='w')
        p['fig'].patch.set_facecolor(self.parent.palette.plotBackground)
        p['ax'].set_facecolor(self.parent.palette.plotBackground)
        p['ax'].grid()

    def get_device_plot(self, updateFunction):
        fig = Figure()
        canvas = FigureCanvas(fig)
        ax = fig.add_subplot(111, projection='3d')
        self.axesQuiverVector = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], ])
        uFace, = ax.plot([], [], [], lw=self.parent.configuration.wireframeWidth, )
        dFace, = ax.plot([], [], [], lw=self.parent.configuration.wireframeWidth, )
        lFace, = ax.plot([], [], [], lw=self.parent.configuration.wireframeWidth, )
        rFace, = ax.plot([], [], [], lw=self.parent.configuration.wireframeWidth, )
        fFace, = ax.plot([], [], [], lw=self.parent.configuration.wireframeWidth, )
        bFace, = ax.plot([], [], [], lw=self.parent.configuration.wireframeWidth, )
        avText = ax.text(-1, -1, -1, '', color='white')
        thrusterRF, = ax.plot(
            [], [], [], self.parent.palette.thrusterColor, marker='$rf$',
            markersize=self.parent.configuration.ms, )
        thrusterRB, = ax.plot(
            [], [], [], self.parent.palette.thrusterColor, marker='$rb$',
            markersize=self.parent.configuration.ms, )
        thrusterLF, = ax.plot(
            [], [], [], self.parent.palette.thrusterColor, marker='$lf$',
            markersize=self.parent.configuration.ms, )
        thrusterLB, = ax.plot(
            [], [], [], self.parent.palette.thrusterColor, marker='$lb$',
            markersize=self.parent.configuration.ms, )
        axesQuiverPositive = ax.quiver([], [], [])
        axesQuiverNegative = ax.quiver([], [], [])
        cubeQuiverPositive = ax.quiver([], [], [])
        cubeQuiverNegative = ax.quiver([], [], [])
        faces = {'up': uFace, 'down': dFace, 'left': lFace, 'right': rFace, 'back': bFace, 'front': fFace, }
        self.thrusterPoints = {'rf': thrusterRF, 'rb': thrusterRB, 'lf': thrusterLF, 'lb': thrusterLB, }

        poly = Poly3DCollection([], facecolors=self.parent.cubeSat.facecolors, )
        ax.add_collection3d(poly, zs=range(6))
        anim = animation.FuncAnimation(
            fig, updateFunction, frames=self.parent.configuration.frames,
            interval=self.parent.configuration.fps, )
        p = {'fig': fig, 'canvas': canvas, 'ax': ax, 'anim': anim, }
        self.format_cube_plot(p)
        self.graphics = {
            'ax':                 ax, 'faces': faces, 'poly': poly, 'avText': avText,
            'axesQuiverNegative': axesQuiverNegative, 'axesQuiverPositive': axesQuiverPositive,
            'cubeQuiverNegative': cubeQuiverNegative, 'cubeQuiverPositive': cubeQuiverPositive,
        }
        self._x, self._y, self._z = 0, 0, 0
        if self.parent.configuration.renderAxesQuiver == False:
            self.remove_axes_quiver()
        if self.parent.configuration.renderCubeQuiver == False:
            self.remove_cube_quiver()
        if self.parent.configuration.renderFaces == False:
            self.remove_cube_faces()
        return p

    def update_animation(self, i):
        if not self.parent.deviceMenu.isHidden() and self.parent.configuration.transceiverActive:
            try:
                msg = self.parent.controller.check_press()
                if self.parent.configuration.posX not in [None, 'None', '']:
                    x = self.parent.dataDude.get(self.parent.configuration.posX)[self.parent.configuration.buffer]
                else:
                    x = 0
                if self.parent.configuration.posY not in [None, 'None', '']:
                    y = self.parent.dataDude.get(self.parent.configuration.posY)[self.parent.configuration.buffer]
                else:
                    y = 0
                if self.parent.configuration.posZ not in [None, 'None', '']:
                    z = self.parent.dataDude.get(self.parent.configuration.posZ)[self.parent.configuration.buffer]
                else:
                    z = 0
                self.device_update('{},{},{}'.format(x, y, z), 10)
                if self.parent.cubeSat.atc == self.parent.cubeSat.atcm:
                    self.reset_thruster_img(self.parent.cubeSat.activeThruster)
                if (self.parent.cubeSat.activeThruster != None) and (self.parent.cubeSat.atc == 1):
                    for thruster in self.thrusterPoints:
                        self.reset_thruster_img(thruster)
                    self.fire_thruster_img(
                        self.parent.cubeSat.activeThruster,
                        self.parent.cubeSat.thrusters[self.parent.cubeSat.activeThruster].location.z
                    )

                self.parent.cubeSat.rotate()
                if self.parent.configuration.renderWireframe:
                    self.draw_wireframe()
                if self.parent.configuration.renderThrusters:
                    self.draw_thrusters()
                if self.parent.configuration.renderAxesQuiver:
                    self.remove_axes_quiver()
                    self.draw_axes_quiver()
                if self.parent.configuration.renderCubeQuiver:
                    self.remove_cube_quiver()
                    self.draw_cube_quiver()
                if self.parent.configuration.renderAV:
                    orientation = self.parent.cubeSat.avc
                    self.graphics['avText'].set_text("Angular Velocity: {}".format(orientation))
                if self.parent.configuration.renderFaces:
                    self.draw_cube_faces()
            except Exception as e:
                print('Update animation error ' + str(e))

    def reset_thruster_img(self, thruster):
        self.thrusterPoints[thruster].set_color(self.parent.configuration.thrusterColor)
        self.thrusterPoints[thruster].set_marker('${}$'.format(thruster))
        self.thrusterPoints[thruster].set_markersize(self.parent.configuration.ms)

    def fire_thruster_img(self, thruster, pos):
        self.thrusterPoints[thruster].set_color('r')
        if pos > 0:
            shape = "^"
        else:
            shape = "v"
        self.thrusterPoints[thruster].set_marker(shape)
        self.thrusterPoints[thruster].set_markersize(self.parent.configuration.ms * 2)

    def remove_axes_quiver(self):
        self.graphics['axesQuiverNegative'].remove()
        self.graphics['axesQuiverPositive'].remove()

    def draw_cube_faces(self):
        self.graphics['poly'].set_verts(self.parent.cubeSat.verts)

    def remove_cube_faces(self):
        self.graphics['poly'].set_verts([])

    def remove_cube_quiver(self):
        self.graphics['cubeQuiverNegative'].remove()
        self.graphics['cubeQuiverPositive'].remove()

    def draw_axes_quiver(self):
        self.graphics['axesQuiverNegative'] = self.graphics['ax'].quiver(
            *-self.axesQuiverVector,
            arrow_length_ratio=0.1, color='yellow',
            lw=self.parent.configuration.axesQuiverWidth,
            linestyle=(0, (2, 5)), )
        self.graphics['axesQuiverPositive'] = self.graphics['ax'].quiver(
            *self.axesQuiverVector, arrow_length_ratio=0.1,
            color='green',
            lw=self.parent.configuration.axesQuiverWidth,
            linestyle=(0, (2, 5)), )

    def draw_cube_quiver(self):
        self.graphics['cubeQuiverNegative'] = self.graphics['ax'].quiver(
            *self.parent.cubeSat.cubeQuiverVector,
            arrow_length_ratio=0.15, color='blue',
            lw=self.parent.configuration.cubeQuiverWidth,
            zorder=100, )
        self.graphics['cubeQuiverPositive'] = self.graphics['ax'].quiver(
            *-self.parent.cubeSat.cubeQuiverVector,
            arrow_length_ratio=0.15, color='red',
            lw=self.parent.configuration.cubeQuiverWidth,
            zorder=100, )

    def draw_thrusters(self, ):
        for thruster in self.parent.cubeSat.thrusters:
            x, y, z = self.parent.cubeSat.thrusters[thruster].location.as_list()
            self.thrusterPoints[thruster].set_data(x, y)
            self.thrusterPoints[thruster].set_3d_properties(z)

    def hide_thrusters(self):
        try:
            for thruster in self.parent.cubeSat.thrusters:
                self.parent.plotDude.thrusterPoints[thruster].set_color((0, 0, 0, 0))
        except Exception as e:
            print('Hide thruster error: ' + str(e))

    def show_thrusters(self):
        for thruster in self.parent.cubeSat.thrusters:
            self.parent.plotDude.thrusterPoints[thruster].set_color(self.parent.palette.thrusterColor)

    def draw_wireframe(self):
        for face in self.graphics['faces']:
            x, y, z = self.parent.cubeSat.wf(face)
            self.graphics['faces'][face].set_data(x, y)
            self.graphics['faces'][face].set_3d_properties(z)

    def remove_wireframe(self):
        for face in self.parent.plotDude.graphics['faces']:
            self.parent.plotDude.graphics['faces'][face].set_data(0, 0)
            self.parent.plotDude.graphics['faces'][face].set_3d_properties(0)

    def format_cube_plot(self, p):
        for spine in p['ax'].spines:
            p['ax'].spines[spine].set_color('w')
        p['ax'].tick_params(colors='w')
        p['fig'].patch.set_facecolor(self.parent.palette.plotCanvas)
        p['ax'].set_facecolor(self.parent.palette.plotBackground)
        p['ax'].xaxis.set_major_locator(MaxNLocator(integer=True))
        p['ax'].yaxis.set_major_locator(MaxNLocator(integer=True))
        p['ax'].zaxis.set_major_locator(MaxNLocator(integer=True))
        p['ax'].set_xlim3d(self.parent.configuration.lims)
        p['ax'].set_xlabel('x', color='w')
        p['ax'].set_ylim3d(self.parent.configuration.lims)
        p['ax'].set_ylabel('y', color='w')
        p['ax'].set_zlim3d(self.parent.configuration.lims)
        p['ax'].set_zlabel('z', color='w')
        # p['ax'].set_title('OF-CG Attitude Control', color='w')
        p['ax'].w_xaxis.set_pane_color((1, 1, 1, 0.1))
        p['ax'].w_yaxis.set_pane_color((1, 1, 1, 0.1))
        p['ax'].w_zaxis.set_pane_color((1, 1, 1, 0.1))

    """
    This dude handles the plots.
    """

    def __init__(self, app):
        try:
            self.app = app
            self.plots = []
            for plot in self.app.plotConfig.plots:
                self.add_plot(plot)
            self.devicePlot = deviceplot.DevicePlot(self.app)
        except Exception as e:
            print('Init plot0 dude error: {}.'.format(e))

    def add_plot(self, dna):
        try:
            if dna:
                self.plots.append(animatedplot.AnimatedPlot2D(self.app, **dna))
            else:
                n = len(self.plots)
                self.plots.append(animatedplot.AnimatedPlot2D(self.app, n))
            if len(self.app.plotConfig.plots) == 0:
                self.app.plotConfig.update('plots', [plot.dna for plot in self.plots])
                self.app.plotConfig.save_to_file()
        except Exception as e:
            print(e)


class PopulateGradationMenu:
    def __init__(self, parent):
        self.parent = parent
        self.frame = VerticalScrolledFrame.VerticalScrolledFrame(self.parent.container)
        self.frame.grid(row=0, column=0, sticky=NSEW)
        self.parent.util.add_label(
            container=self.frame.interior, text=SS,
            row=[i for i in range(gradationMatrixStartingRow, gradationMatrixStartingRow + 10)],
            column=[0 for i in range(gradationMatrixStartingColumn, gradationMatrixStartingColumn + 10)],
            columnspan=[1 for i in range(gradationMatrixStartingColumn, gradationMatrixStartingColumn + 10)],
            sticky=['e' for i in range(gradationMatrixStartingColumn, gradationMatrixStartingColumn + 10)]
        )
        for column in range(gradationMatrixStartingColumn + 1, gradationMatrixStartingColumn + 11):
            for row in range(gradationMatrixStartingRow, gradationMatrixStartingRow + 10):
                self.parent.util.add_entry(
                    container=self.frame.interior,
                    labels=["Row  " + str(row) + ", Column " + str(column)], width=[10],
                    row=[row], column=[column], columnspan=[1], sticky=['e']
                )
        print(self.parent.util.entries)

    def __init__(self, parent):
        self.parent = parent
        self.frame = VerticalScrolledFrame.VerticalScrolledFrame(self.parent.container)
        self.frame.grid(row=0, column=0, sticky=NSEW)

        """PERCENTAGES VECTOR"""
        self.parent.util.name(
            container=self.frame.interior, text=['Percent:'] + SS,
            row=[1] + [i for i in range(gradationMatrixStartingRow + 1, gradationMatrixStartingRow + 11)],
            column=[0] + [0 for i in range(gradationMatrixStartingColumn, gradationMatrixStartingColumn + 10)],
            columnspan=[1] + [1 for i in range(gradationMatrixStartingColumn, gradationMatrixStartingColumn + 10)],
            sticky=['w'] + ['w' for i in range(gradationMatrixStartingColumn, gradationMatrixStartingColumn + 10)]
        )
        self.parent.util.entry(
            name='Percentages', container=self.frame.interior,
            labels=[['Percentage'], ['Bin ' + str(i) for i in range(10)]], width=[10] * 10, row=[1],
            column=[column for column in range(gradationMatrixStartingColumn + 1, gradationMatrixStartingColumn + 11)],
            columnspan=[1] * 10,
            sticky=['e'] * 10
        )

        self.parent.util.separator(
            container=self.frame.interior, orient='h', row=13, column=0, columnspan=11,
            sticky='we', pady=5
        )

        """CUMMULATIVE PERCENT PASSING VECTOR"""
        self.parent.util.name(
            container=self.frame.interior, text=['Passing:'], row=[2], column=[11], columnspan=[1],
            sticky=['e']
        )
        self.parent.util.entry(
            name='Passing', container=self.frame.interior,
            labels=[['Sieve: ' + str(j) for j in SS], ['Passing']], width=[10] * len(SS),
            row=[row for row in range(gradationMatrixStartingRow + 1, gradationMatrixStartingRow + 1 + len(SS))],
            column=[11],
            columnspan=[1] * len(SS), sticky=['e'] * len(SS)
        )

        """GRADATION MATRIX"""
        self.parent.util.name(
            container=self.frame.interior, text=['Bin ' + str(i) for i in range(10)], row=[0] * 10,
            column=[i for i in range(1, 11)], columnspan=[1] * 10, sticky=['w'] * 10, padx=20
        )
        self.parent.util.entry(
            name='Gradation Matrix', container=self.frame.interior,
            labels=[['Sieve: ' + str(j) for j in SS], ['Bin: ' + str(i) for i in range(10)]],
            width=[10] * 10,
            row=[row for row in range(gradationMatrixStartingRow + 1, gradationMatrixStartingRow + 11)],
            column=[column for column in range(gradationMatrixStartingColumn + 1, gradationMatrixStartingColumn + 11)],
            columnspan=[1] * 10,
            sticky=['e'] * 10
        )

        self.parent.util.separator(
            container=self.frame.interior, orient='h', row=2, column=0, columnspan=11,
            sticky='we', pady=5
        )

        """NMAS"""
        self.parent.util.name(
            container=self.frame.interior, text=['NMAS:'], row=[14], column=[0], columnspan=[1],
            sticky=['w']
        )
        # self.parent.util.entry(name='NMAS', container=self.frame.interior, labels=[['NMAS']], width=[10], row = [14], column=[1], columnspan=[1], sticky=['w'])
        self.NMAS = StringVar(self.frame.interior)
        self.NMAS.set(SS[0])
        popupMenu1 = ttk.OptionMenu(self.frame.interior, self.NMAS, *SS, command=self.update_PCS)
        popupMenu1.grid(row=14, column=1, columnspan=2, sticky='w')

        self.parent.util.separator(
            container=self.frame.interior, orient='h', row=15, column=0, columnspan=11,
            sticky='we', pady=5
        )

        """PCS"""
        self.PCS = StringVar(self.frame.interior)
        self.SCS = StringVar(self.frame.interior)
        self.TCS = StringVar(self.frame.interior)
        ttk.Label(self.frame.interior, text='Control Sieves').grid(row=16, column=4, columnspan=3)
        self.parent.util.name(
            container=self.frame.interior, text=['Primary:', 'Secondary:', 'Tertiary:'],
            row=[17] * 3, column=[0, 2, 4], columnspan=[1] * 3, sticky=['w'] * 3
        )
        self.pcs_label = ttk.Label(self.frame.interior, text=self.PCS.get())
        self.scs_label = ttk.Label(self.frame.interior, text=self.SCS.get())
        self.tcs_label = ttk.Label(self.frame.interior, text=self.TCS.get())

        self.parent.util.drop_down_menu(
            parent=self.parent, menus=["File", "Optimization", "Help"], tearoff=[0, 0, 0],
            labels=[
                ["Open Search", "Save Search As", "separator()", "Settings", "separator()",
                 "Exit"], ["Victor-Christian Method"], ["Help"]], commands=[
                [self.parent.load, self.parent.save, self.parent.report_settings, self.parent.destroy],
                [self.parent.markov_chain_menu], [self.parent.help]]
        )

        self.test = ttk.Button(self.frame.interior, text="Test", command=self.test, state='enabled')
        self.test.grid(row=20, column=0, sticky='e')

    def update_PCS(self, value):
        v = self.convert(self.NMAS.get().strip('"'))
        self.PCS.set(str(round(v * 0.22, 4)) + '"')
        self.SCS.set(str(round(v * 0.22 ** 2, 4)) + '"')
        self.TCS.set(str(round(v * 0.22 ** 3, 4)) + '"')

        self.pcs_label.destroy()
        self.pcs_label = ttk.Label(self.frame.interior, text=self.PCS.get(), relief='sunken')
        self.pcs_label.grid(row=17, column=1, columnspan=1, sticky='w')

        self.scs_label.destroy()
        self.scs_label = ttk.Label(self.frame.interior, text=self.SCS.get(), relief='sunken')
        self.scs_label.grid(row=17, column=3, columnspan=1, sticky='w')

        self.tcs_label.destroy()
        self.tcs_label = ttk.Label(self.frame.interior, text=self.TCS.get(), relief='sunken')
        self.tcs_label.grid(row=17, column=5, columnspan=1, sticky='w')

    def convert(self, s):
        try:
            return float(s)
        except ValueError:
            num, denom = s.split('/')
            return float(num) / float(denom)

    def test(self):
        pass
        """for entry in self.parent.util.entry_groups['NMAS'].entries:
            print(self.parent.util.entry_groups['NMAS'].entries[entry].get())"""

        # for entry in self.parent.util.entry_groups['Gradation Matrix'].entries:  # print(entry + '      >>       ' + self.parent.util.entry_groups['Gradation Matrix'].entries[entry].get())


class PopulateMarkovChainMenu:
    def __init__(self, parent):
        self.parent = parent
        self.top = Toplevel(self.parent.parent.container)
        self.frame = self.parent.parent.container
        self.top.title("report_generator0 Settings")

        self.settings = [True, False]
        self.figure = 1
        self.paths = 1

        self.parent.parent.util.list_generator.setNonNoneValueList()

        # Create a Tkinter variable to store the ITEM OF INTEREST (item)
        self.item = StringVar(self.top)
        self.i_s = StringVar(self.top)

        # Dictionary with options
        self.vina = self.parent.parent.util.list_generator.getNonNoneName()
        self.vinu = self.parent.parent.util.list_generator.getNonNoneNumber()
        self.item.set('5A')  # set the default option
        self.i_s.set('None')

        # Loading user preferences
        with open(
            self.parent.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Markov_Chain_Preferences.txt",
            "r"
        ) as report_preferences:
            self.settings = [True if line.strip() == 'True' else False for line in report_preferences]

        self.parent.parent.util.set_active(self.top)

        self.parent.parent.util.add_label(
            self.top, amount=4,
            text=["Input File Paths:", "Item of Interest:", "Initial State:",
                  "Iterations:"], row=[1, self.paths + 1, self.paths + 2, self.paths + 3],
            column=[1, 1, 1, 1], columnspan=[1, 1, 1, 1],
            sticky=['w', 'w', 'w', 'w', 'w']
        )
        # FILE PATHS
        self.input_fp = Entry(self.top, width=30)
        self.input_fp.grid(row=1, column=3, columnspan=2)
        # PATH SELECTION BUTTON
        self.path_selection = Button(self.top, compound=LEFT, text="Open", command=self.parent.load, cursor='hand2')
        self.path_selection.grid(row=1, column=5, columnspan=2)
        # ITEM OF INTEREST
        popupMenu1 = OptionMenu(self.top, self.item, *self.vinu, command=self.parent.item_selection)
        popupMenu1.grid(row=self.paths + 1, column=2, columnspan=3, sticky=W + E)
        # INITIAL STATE
        self.parent.item_selection('5A')
        # ITERATIONS
        self.iterations = Entry(self.top, width=30)
        self.iterations.grid(row=self.paths + 3, column=3, columnspan=2)
        self.parent.util.add_separator(
            container=self.top, orient='h', row=self.paths + 5, column=1, columnspan=5,
            sticky='we'
        )
        self.parent.util.add_button(
            container=self.top, amount=2, text=["Run", "Cancel"],
            commands=[self.parent.train_nn, self.parent.cancel], cursor='hand2',
            row=[self.paths + 6, self.paths + 6], column=[4, 1], sticky=['e', 'e']
        )


class PopulateMarkovChainMenu(Menu):
    def populate(self):
        self.settings = [True, False]
        self.paths = 1

        self.util.lists.setNonNoneValueList()
        # Create a Tkinter variable to store the item
        self.item = StringVar(self.top)
        self.i_s = StringVar(self.top)

        # Dictionary with options
        self.vina = self.util.lists.getNonNoneName()
        self.vinu = self.util.lists.getNonNoneNumber()
        self.item.set('5A')  # set the default option
        self.i_s.set('None')

        # Loading user preferences
        with open(self.util.MASTERPATH + self.util.mc_s_p, "r") as report_preferences:
            self.settings = [True if line.strip() == 'True' else False for line in report_preferences]

        # Labels2
        self.util.label(
            container=self.top, text=["Input Paths:", "Item:", "Initial State:", "Iterations:"],
            row=[1, self.paths + 1, self.paths + 1, self.paths + 2], column=[1] * 3, columnspan=[1] * 3,
            sticky=['w'] * 5
        )
        # Entries (File Paths, Iterations)
        self.util.entry(
            container=self.top, width=[15, 15], row=[1, self.paths + 2], column=[2] * 1, columnspan=[1, 1],
            sticky=['we'] * 1
        )
        # ITEM OF INTEREST
        popupMenu1 = ttk.OptionMenu(self.top, self.item, *self.vinu, command=self.item_selection)
        popupMenu1.grid(row=self.paths + 1, column=1, columnspan=1, sticky='we')
        # INITIAL STATE
        self.item_selection('5A')
        # Separators
        self.util.separator(container=self.top, orient='h', row=self.paths + 5, column=1, columnspan=5, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=["Run", "Cancel", "Open"],
            commands=[self.parent.run, self.cancel, self.parent.load], cursor='hand2',
            row=[self.paths + 6, self.paths + 6, 1], column=[3, 1, 3], sticky=['e', 'e', 'e']
        )

    def item_selection(self, value):
        self.parameterNumbersDictionary = self.util.lists.getParameterNumbersDictionary()
        self.util.lists.valid_lists(self.parameterNumbersDictionary[str(self.item.get())])
        self.vs = self.util.lists.get_valid_values_list()
        self.i_s.set(self.vs[0])

        popupMenu2 = ttk.OptionMenu(self.top, self.i_s, *self.vs)
        popupMenu2.grid(row=self.paths + 1, column=1, columnspan=1, sticky='we')


class PopulateNameReport:
    def __init__(self, parent):
        self.parent = parent
        self.top = Toplevel(self.parent.parent.container)
        self.frame = self.parent.parent.container
        self.top.title("report_generator0 Settings")
        self.settings = [True, False, False, True]

        """Load report preferences"""
        with open(
            self.parent.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Report_Preferences.txt",
            "r"
        ) as report_preferences:
            for index, line in enumerate(report_preferences):
                if line.strip() == 'True':
                    self.settings[index] = True
                elif line.strip() == 'False':
                    self.settings[index] = False

        self.populate_settings()
        self.parent.parent.util.set_active(self.top)

    def populate_settings(self):
        self.parent.parent.util.add_label(
            self.top, amount=5, text=["Export as comma separated value (csv) file:",
                                      "Export as machine learning input file:",
                                      "Single file:", "Multiple files:", "File path:"],
            row=[1, 2, 3, 3, 4], column=[1, 1, 1, 3, 1], columnspan=[3, 3, 1, 1, 1],
            sticky=['w', 'w', 'w', 'w', 'w']
        )
        # EXPORT FILE TYPE
        self.csv_button = Checkbutton(self.top, command=self.parent.toggle_csv, cursor='left_ptr')
        self.csv_button.grid(row=1, column=4, sticky='e')
        self.machine_button = Checkbutton(self.top, command=self.parent.toggle_machine, cursor='left_ptr')
        self.machine_button.grid(row=2, column=4, sticky='e')
        # SINGLE VS MULTIPLE FILE OUTPUT
        self.single_file_button = Checkbutton(self.top, command=self.parent.toggle_single, cursor='left_ptr')
        self.single_file_button.grid(row=3, column=2, sticky='e')
        self.multiple_file_button = Checkbutton(self.top, command=self.parent.toggle_multiple, cursor='left_ptr')
        self.multiple_file_button.grid(row=3, column=4, sticky='e')
        self.file_path_input = Entry(self.top, width=30)
        self.file_path_input.grid(row=4, column=2, columnspan=2, sticky='e')

        self.parent.parent.util.add_separator(
            container=self.top, orient='h', row=5, column=1, columnspan=4,
            sticky='we'
        )
        self.parent.parent.util.add_button(
            container=self.top, amount=3, text=["Browse", "Run", "Cancel"],
            commands=[self.parent.browse, self.parent.train_nn, self.parent.cancel],
            cursor='hand2', row=[4, 6, 6], column=[4, 4, 1], sticky=['e', 'e', 'e']
        )
        if self.settings[0]:
            self.csv_button.select()

        if self.settings[1]:
            self.machine_button.select()

        if self.settings[2]:
            self.single_file_button.select()

        if self.settings[3]:
            self.multiple_file_button.select()


class PlotterSettings:
    def __init__(self, parent, MASTERPATH):
        top = self.top = Toplevel(parent)
        self.top.title("Plotter Settings")
        self.top.grab_set()
        self.main_path = MASTERPATH
        Label(top, text="Length:").grid(row=1, column=1, sticky=W)
        self.e = Entry(top, width=5)
        self.e.grid(row=1, column=2, columnspan=1, sticky=E)
        separator = ttk.Separator(top, orient=HORIZONTAL)
        separator.grid(row=3, column=1, columnspan=3, sticky=W + E)

    def __init__(self, parent, MASTERPATH):
        top = self.top = Toplevel(parent)
        self.top.title("Plotter Settings")
        self.top.grab_set()
        self.main_path = MASTERPATH
        Label(top, text="Length:").grid(row=1, column=1, sticky=W)
        self.e = Entry(top, width=5)
        self.e.grid(row=1, column=2, columnspan=1, sticky=E)
        # SEPARATOR
        separator = ttk.Separator(top, orient=HORIZONTAL)
        separator.grid(row=3, column=1, columnspan=3, sticky=W + E)


class PopulateReportMenu(Menu):
    def populate(self):
        self.settings = [True, False, False, True]
        """Load report preferences"""
        with open(self.util.MASTERPATH + self.util.r_s_p, "r") as report_settings:
            for i, line in enumerate(report_settings):
                self.settings[i] = True if line.strip() == 'True' else False

        if self.parent.indicator == 0:
            # Entries
            self.util.entry(container=self.top, width=[20], row=[2], column=[1], columnspan=[1], sticky='e')
            self.bt, self.bcmds, self.br, self.bc, self.bs = ["Browse", "Run", "Cancel"], [self.parent.browse,
                                                                                           self.parent.run,
                                                                                           self.cancel], [2, 5, 5], [3,
                                                                                                                     3,
                                                                                                                     1], [
                'w', 'w', 'e']
            self.lt, self.lr, self.lc, self.lcs, self.ls = ["CSV:", "Dictionary:", "Single file:", "Multiple files:",
                                                            "File path:"], [1, 1, 1, 1, 2], [1, 2, 1, 2, 1], [2, 2, 1,
                                                                                                              1, 1], [
                                                                                                                         'w'] * 5

        elif self.parent.indicator == 1:
            self.bt, self.bcmds, self.br, self.bc, self.bs = ["Apply", "Cancel"], [self.parent.apply, self.cancel], [5,
                                                                                                                     5], [
                3, 1], ['w', 'e']
            self.lt, self.lr, self.lc, self.lcs, self.ls = ["CSV:", "Dictionary:", "Single file:", "Multiple files:"], [
                1, 1, 1, 1], [1, 2, 1, 2], [2, 2, 1, 1], ['w'] * 3

        # Labels2
        self.util.label(self.top, text=self.lt, row=self.lr, column=self.lc, columnspan=self.lcs, sticky=self.ls)
        # Separators
        self.util.separator(container=self.top, orient='h', row=3, column=1, columnspan=3, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=self.bt, commands=self.bcmds, cursor='hand2', row=self.br, column=self.bc,
            sticky=self.bs
        )
        # Check Buttons
        self.util.check_button(
            container=self.top, commands=[(lambda: self.toggle_check_button(0)), (lambda: self.toggle_check_button(1)),
                                          (lambda: self.toggle_check_button(1)), (lambda: self.toggle_check_button(2))],
            cursor='left_ptr', row=[1, 1, 1, 1], column=[1, 3, 1, 3], sticky=['e', 'e', 'e', 'e']
        )

        for i in range(3):
            if self.settings[i]:
                self.select_check_button(i)


class PopulateReportSettings:
    def __init__(self, parent):
        self.parent = parent
        self.top = Toplevel(self.parent.parent.container)
        self.frame = self.parent.parent.container
        self.top.title("report_generator0 Settings")
        self.settings = [True, False, False, True]

        with open(
            self.parent.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Report_Preferences.txt",
            "r"
        ) as report_preferences:
            for index, line in enumerate(report_preferences):
                if line.strip() == 'True':
                    self.settings[index] = True
                elif line.strip() == 'False':
                    self.settings[index] = False

            self.populate_settings()
            self.parent.parent.util.set_active(self.top)

    def populate_settings(self):
        self.parent.parent.util.add_label(
            self.top, amount=4, text=["Export as comma separated value (csv) file:",
                                      "Export as machine learning input file:",
                                      "Single file:", "Multiple files:"],
            row=[1, 2, 3, 3], column=[1, 1, 1, 3], columnspan=[3, 3, 1, 1],
            sticky=['w', 'w', 'w', 'w']
        )
        # EXPORT FILE TYPE
        self.csv_button = Checkbutton(self.top, command=self.parent.toggle_csv, cursor='left_ptr')
        self.csv_button.grid(row=1, column=4, sticky='e')
        self.machine_button = Checkbutton(self.top, command=self.parent.toggle_machine, cursor='left_ptr')
        self.machine_button.grid(row=2, column=4, sticky='e')
        # SINGLE VS MULTIPLE FILE OUTPUT
        self.single_file_button = Checkbutton(self.top, command=self.parent.toggle_single, cursor='left_ptr')
        self.single_file_button.grid(row=3, column=2, sticky='e')
        self.multiple_file_button = Checkbutton(self.top, command=self.parent.toggle_multiple, cursor='left_ptr')
        self.multiple_file_button.grid(row=3, column=4, sticky='e')

        self.parent.parent.util.add_separator(
            container=self.top, orient='h', row=5, column=1, columnspan=5,
            sticky='we'
        )
        self.parent.parent.util.add_button(
            container=self.top, amount=2, text=["Apply", "Cancel"],
            commands=[self.parent.apply, self.parent.cancel], cursor='hand2', row=[6, 6],
            column=[3, 1], sticky=['e', 'e']
        )

        if self.settings[0]:
            self.csv_button.select()

        if self.settings[1]:
            self.machine_button.select()

        if self.settings[2]:
            self.single_file_button.select()

        if self.settings[3]:
            self.multiple_file_button.select()


class PopulateSearch:
    def __init__(self, parent):
        self.parent = parent
        self.frame = VerticalScrolledFrame.VerticalScrolledFrame(self.parent.container)
        self.frame.grid(row=0, column=0, sticky=NSEW)
        # DECLARING THE LISTS AND DICTIONARIES THAT WILL HOLD INFORMATION
        self.parameterLabel, self.parameterLabel2 = [], []  # This list will hold the labels
        self.label_text_List, self.label_text_List2 = [], []  # This list will hold the text which will go on each label
        self.entries = []
        self.query = {}
        # DICTIONARIES HOLD THE PARAMETER NUMBERS, NAMES, AND THE ENTRY TEXT FIELDS
        self.parameterNumbers = self.parent.util.list_generator.getParameterNumbers()
        self.parameterNames = self.parent.util.list_generator.getParameterNames(self)
        self.entryList = self.parent.util.list_generator.getEntryList()
        # Populating the window with the interface7 menu.
        self.populate_search_field()
        self.add_separator()
        self.populate_buttons()
        self.populate_drop_down_menu()  # self.list_generator.getParameterNamesWithRespectToNumber()

    def populate_search_field(self):
        # POPULATING THE DICTIONARY WHICH WILL HOLD THE VALIDATION INFORMATION
        for i in range(self.parent.util.number_of_items):
            # Creating lists of stringvars
            self.create_label_holders(i)
            # SETTING THE ENTRY TEXT FIELDS
            self.populate_entries(i)

    def create_label_holders(self, i):
        self.label_text_List.append(StringVar())
        self.parameterLabel.append(Label(self.frame.interior, textvariable=self.label_text_List[i]))
        self.label_text_List2.append(StringVar())
        self.parameterLabel2.append(Label(self.frame.interior, textvariable=self.label_text_List2[i]))

    def populate_entries(self, i):
        if self.parameterNames[i + 0] != '(Reserved)':
            self.label = Label(self.frame.interior, text=self.parameterNumbers[i])
            self.label.grid(row=i + 3, column=0, sticky=W)
            self.label = Label(self.frame.interior, text=self.parameterNames[i])
            self.label.grid(row=i + 3, column=1, sticky=W)
            self.entry = self.entryList[self.parameterNames[i + 0]]
            self.entries.append(self.entry)
            self.entry.grid(row=i + 3, column=2, columnspan=1, sticky=E)
            self.entryList[self.parameterNames[i]].insert(0, '')

    def add_separator(self):
        """Adds a separator"""
        separator = ttk.Separator(self.parent.container, orient=HORIZONTAL)
        separator.grid(row=2, column=0, columnspan=5, sticky=W + E)

    def populate_buttons(self):
        """Setting the buttons."""
        self.search_button = Button(self.parent.container, text="search", command=self.parent.search, cursor='hand2')
        self.search_button.grid(row=3, column=2, sticky=SE)
        self.clear_button = Button(self.parent.container, text="Clear", command=self.parent.clear, cursor='hand2')
        self.clear_button.grid(row=3, column=0, sticky=SW)

    def populate_drop_down_menu(self):
        menubar = Menu(self.frame.interior)

        # create a pulldown menu, and add it to the menu bar
        filemenu = Menu(menubar, tearoff=0)
        filemenu.add_command(label="Open search", command=self.parent.load)
        filemenu.add_command(label="Save search As", command=self.parent.save)
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=self.parent.destroy)
        menubar.add_cascade(label="File", menu=filemenu)

        # PREFERENCES OPTIONS
        preferences = Menu(menubar, tearoff=0)
        preferences.add_command(label="report_generator0 Settings", command=self.parent.report_settings)
        menubar.add_cascade(label="Preferences", menu=preferences)

        # MACHINE LEARNING OPTIONS
        machine_learning = Menu(menubar, tearoff=1)
        machine_learning.add_command(label="Markov Chain", command=self.parent.markov_chain_menu)
        menubar.add_cascade(label="Machine Learning", menu=machine_learning)

        # HELP MENU
        helpmenu = Menu(menubar, tearoff=0)
        helpmenu.add_command(label="About", command=self.parent.help)
        menubar.add_cascade(label="Help2", menu=helpmenu)

        # display the menu
        self.parent.config(menu=menubar)

    def __init__(self, parent):
        self.parent = parent
        self.frame = VerticalScrolledFrame.VerticalScrolledFrame(self.parent.container)
        self.frame.grid(row=0, column=0, columnspan=3, sticky="nsew")
        # DECLARING THE LISTS AND DICTIONARIES THAT WILL HOLD INFORMATION
        self.query = {}
        # DICTIONARIES HOLD THE PARAMETER NUMBERS, NAMES, AND THE ENTRY TEXT FIELDS
        self.parameterNumbers = self.parent.util.lists.getParameterNumbers()
        self.parameterNames = self.parent.util.lists.getParameterNames(self)
        self.entryList = self.parent.util.lists.getEntryList()
        # Populating the window with the interface7 menu.
        self.populate_search_field()
        # Separators
        self.parent.util.separator(
            container=self.parent.container, orient='h', row=2, column=0, columnspan=3,
            sticky='we'
        )
        # Buttons
        self.parent.util.button(
            container=self.parent.container, text=["search", "Clear"],
            commands=[self.parent.search, self.parent.clear], cursor='hand2', row=[3, 3],
            column=[2, 0], sticky=['se', 'sw']
        )
        # Drop Down Menu
        self.parent.util.drop_down_menu(
            parent=self.parent, menus=["File", "Machine Learning", "help"],
            tearoff=[0, 0, 0], labels=[
                ["Open search", "Save search As", "separator()", "Settings", "separator()", "Exit"],
                ["Markov Chain Monte Carlo"], ["help"]], commands=[
                [self.parent.load, self.parent.save, self.parent.report_settings, self.parent.destroy],
                [self.parent.markov_chain_menu], [self.parent.help]]
        )

    def populate_search_field(self):
        # SETTING THE ENTRY TEXT FIELDS
        for i in range(self.parent.util.number_of_items):
            self.populate_entries(i, [self.parameterNumbers[i], self.parameterNames[i]])

    def populate_entries(self, i, labels):
        if self.parameterNames[i] != '(Reserved)':
            for label in labels:
                ttk.Label(self.frame.interior, text=label).grid(row=i + 3, column=labels.index(label), sticky='w')
            self.entryList[self.parameterNames[i + 0]].grid(row=i + 3, column=2, columnspan=1, sticky='e')
            self.entryList[self.parameterNames[i]].insert(0, '')

    def __init__(self, parent):
        self.parent = parent
        self.frame = VerticalScrolledFrame(self.parent.container)
        self.frame.grid(row=0, column=0, columnspan=3, sticky="nsew")
        # DECLARING THE LISTS AND DICTIONARIES THAT WILL HOLD INFORMATION
        self.query = {}
        # DICTIONARIES HOLD THE PARAMETER NUMBERS, NAMES, AND THE ENTRY TEXT FIELDS
        self.parent.util.lists.setSearchMenuLists(self)
        self.parameterNumbers = self.parent.util.lists.numbers
        self.parameterNames = self.parent.util.lists.names
        self.entryList = self.parent.util.lists.entryList
        # Populating the window with the interface7 menu.
        self.populate_search_field()
        # Separators
        self.parent.util.separator(
            container=self.parent.container, orient='h', row=2, column=0, columnspan=3,
            sticky='we'
        )
        # Buttons
        self.parent.util.button(
            container=self.parent.container, text=["search", "Clear"],
            commands=[self.parent.search, self.parent.clear], cursor='hand2', row=[3, 3],
            column=[2, 0], sticky=['se', 'sw']
        )
        # Drop Down Menu
        self.parent.util.drop_down_menu(
            parent=self.parent,
            menus=["File", "Machine Learning", "Geographic search", "Help2"],
            tearoff=[0, 0, 0, 0], labels=[
                ["Open search", "Save search As", "separator()", "Settings", "separator()", "Exit"],
                ["Markov Chain Monte Carlo"], ["Geographic search"], ["Help2"]], commands=[
                [self.parent.load, self.parent.save, self.parent.report_settings, self.parent.destroy],
                [self.parent.markov_chain_menu], [self.parent.radial_search], [self.parent.help]]
        )

    def populate_search_field(self):
        # SETTING THE ENTRY TEXT FIELDS
        for i, line in enumerate(self.entryList):
            self.populate_entries(i, line)  # self.populate_entries(i, [self.parameterNumbers[line], line])

    def populate_entries(self, i, labels):
        ttk.Label(self.frame.interior, text=labels).grid(row=i + 3, column=0, sticky='w', pady=5)
        # for label in labels:
        # ttk.Label(self.frame.interior, text=label).grid(row=i + 2, column=labels.index(label), sticky='w')
        self.entryList[self.parameterNames[i]].grid(row=i + 3, column=2, columnspan=1, sticky='e')
        self.entryList[self.parameterNames[i]].insert(0, '')

    def __init__(self, parent):
        self.parent = parent
        self.frame = VerticalScrolledFrame(self.parent.container)
        self.frame.grid(row=0, column=0, columnspan=3, sticky="nsew")
        # DECLARING THE LISTS AND DICTIONARIES THAT WILL HOLD INFORMATION
        self.query = {}
        # DICTIONARIES HOLD THE PARAMETER NUMBERS, NAMES, AND THE ENTRY TEXT FIELDS
        self.parent.util.lists.setSearchMenuLists(self)
        self.parameterNumbers = self.parent.util.lists.get_parameter_numbers()
        self.parameterNames = self.parent.util.lists.get_parameter_names()
        self.entryList = self.parent.util.lists.get_entry_list()
        # Populating the window with the interface7 menu.
        self.populate_search_field()
        # Separators
        self.parent.util.separator(
            container=self.parent.container, orient='h', row=2, column=0, columnspan=3,
            sticky='we'
        )
        # Buttons
        self.parent.util.button(
            container=self.parent.container, text=["search", "Clear"],
            commands=[self.parent.search, self.parent.clear], cursor='hand2', row=[3, 3],
            column=[2, 0], sticky=['se', 'sw']
        )
        # Drop Down Menu
        self.parent.util.drop_down_menu(
            parent=self.parent, menus=["File", "Machine Learning", "Help2"],
            tearoff=[0, 0, 0], labels=[
                ["Open search", "Save search As", "separator()", "Settings", "separator()", "Exit"],
                ["Markov Chain Monte Carlo"], ["Help2"]], commands=[
                [self.parent.load, self.parent.save, self.parent.report_settings, self.parent.destroy],
                [self.parent.markov_chain_menu], [self.parent.help]]
        )

    def populate_search_field(self):
        # SETTING THE ENTRY TEXT FIELDS
        for i, line in enumerate(self.entryList):
            self.populate_entries(i, line)  # self.populate_entries(i, [self.parameterNumbers[line], line])

    def populate_entries(self, i, labels):
        ttk.Label(self.frame.interior, text=labels).grid(row=i + 3, column=0, sticky='w', pady=5)
        # for label in labels:
        # ttk.Label(self.frame.interior, text=label).grid(row=i + 2, column=labels.index(label), sticky='w')
        self.entryList[self.parameterNames[i]].grid(row=i + 3, column=2, columnspan=1, sticky='e')
        self.entryList[self.parameterNames[i]].insert(0, '')

    def __init__(self, parent):
        self.parent = parent
        self.frame = VerticalScrolledFrame.VerticalScrolledFrame(self.parent.container)
        self.frame.grid(row=0, column=0, sticky=NSEW)
        # DECLARING THE LISTS AND DICTIONARIES THAT WILL HOLD INFORMATION
        self.query = {}
        # DICTIONARIES HOLD THE PARAMETER NUMBERS, NAMES, AND THE ENTRY TEXT FIELDS
        self.parameterNumbers = self.parent.util.list_generator.getParameterNumbers()
        self.parameterNames = self.parent.util.list_generator.getParameterNames(self)
        self.entryList = self.parent.util.list_generator.getEntryList()
        # Populating the window with the interface7 menu.
        self.populate_search_field()
        self.parent.util.add_separator(
            container=self.parent.container, orient='h', row=2, column=0, columnspan=5,
            sticky='we'
        )
        self.parent.util.add_button(
            container=self.parent.container, amount=2, text=["search", "Clear"],
            commands=[self.parent.search, self.parent.clear], cursor='hand2', row=[3, 3],
            column=[2, 0], sticky=['se', 'sw']
        )
        self.parent.util.add_drop_down_menu(
            parent=self.parent, menus=["File", "Machine Learning", "Help2"],
            tearoff=[0, 0, 0], labels=[
                ["Open search", "Save search As", "add_separator()", "Settings", "add_separator()", "Exit"],
                ["Markov Chain Monte Carlo"], ["Help2"]], commands=[
                [self.parent.load, self.parent.save, self.parent.report_settings, self.parent.destroy],
                [self.parent.markov_chain_menu], [self.parent.help]]
        )

    def populate_search_field(self):
        # SETTING THE ENTRY TEXT FIELDS
        for i in range(self.parent.util.number_of_items):
            self.populate_entries(i, [self.parameterNumbers[i], self.parameterNames[i]])

    def populate_entries(self, i, labels):
        if self.parameterNames[i + 0] != '(Reserved)':
            for label in labels:
                Label(self.frame.interior, text=label).grid(row=i + 3, column=labels.index(label), sticky='w')
            self.entryList[self.parameterNames[i + 0]].grid(row=i + 3, column=2, columnspan=1, sticky='e')
            self.entryList[self.parameterNames[i]].insert(0, '')

    def __init__(self, parent):
        self.parent = parent
        self.frame = VerticalScrolledFrame.VerticalScrolledFrame(self.parent.container)
        self.frame.grid(row=0, column=0, columnspan=3, sticky="nsew")
        # DECLARING THE LISTS AND DICTIONARIES THAT WILL HOLD INFORMATION
        self.query = {}
        # DICTIONARIES HOLD THE PARAMETER NUMBERS, NAMES, AND THE ENTRY TEXT FIELDS
        self.parameterNumbers = self.parent.util.lists.getParameterNumbers()
        self.parameterNames = self.parent.util.lists.getParameterNames(self)
        self.entryList = self.parent.util.lists.getEntryList()
        # Populating the window with the interface7 menu.
        self.populate_search_field()
        # Separators
        self.parent.util.separator(
            container=self.parent.container, orient='h', row=2, column=0, columnspan=3,
            sticky='we'
        )
        # Buttons
        self.parent.util.button(
            container=self.parent.container, text=["search", "Clear"],
            commands=[self.parent.search, self.parent.clear], cursor='hand2', row=[3, 3],
            column=[2, 0], sticky=['se', 'sw']
        )
        # Drop Down Menu
        self.parent.util.drop_down_menu(
            parent=self.parent, menus=["File", "Machine Learning", "Help2"],
            tearoff=[0, 0, 0], labels=[
                ["Open search", "Save search As", "separator()", "Settings", "separator()", "Exit"],
                ["Markov Chain Monte Carlo"], ["Help2"]], commands=[
                [self.parent.load, self.parent.save, self.parent.report_settings, self.parent.destroy],
                [self.parent.markov_chain_menu], [self.parent.help]]
        )

    def populate_search_field(self):
        # SETTING THE ENTRY TEXT FIELDS
        for i in range(self.parent.util.number_of_items):
            self.populate_entries(i, [self.parameterNumbers[i], self.parameterNames[i]])

    def populate_entries(self, i, labels):
        if self.parameterNames[i] != '(Reserved)':
            for label in labels:
                ttk.Label(self.frame.interior, text=label).grid(row=i + 3, column=labels.index(label), sticky='w')
            self.entryList[self.parameterNames[i + 0]].grid(row=i + 3, column=2, columnspan=1, sticky='e')
            self.entryList[self.parameterNames[i]].insert(0, '')


# TODO write descriptions for ab, en, gp, sgd options
# TODO add option for mlp number of layers
class RegressionMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        if True:
            self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
            self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
            top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
            self.readLabel.setText(self.parent.databaseMenu.dataSource)

            self.columnGrid = make_group_box(
                self.container, layout=make_grid(), text='y', row=1, column=2, width=205,
                height=225
            )

            self.indexGrid = make_group_box(
                self.container, layout=make_grid(), text='x', row=0, column=2, width=205,
                height=225
            )

            self.runButton = make_button(
                self, command=self.run, text='Run', layout=self.topRightLayout, row=3,
                column=0, description=RUN_REGRESSION_DESCRIPTION
            )

            self.analysisTab, self.parametersTab, self.exportTab = set_tabs(
                self, ('Analysis', 'Parameters', 'Export'),
                layout=self.topRightLayout
            )

            """ANALYSIS"""
            self.modelSelection = set_models(REGRESSORS_NAMES, self.analysisTab, multiSelect=True)

            self.modeGrid = make_group_box(
                self.analysisTab, layout=make_grid(), text='Mode', row=0, column=1, width=75,
                height=75
            )

            self.mode = make_list(
                items=('Series', 'Parallel'), default=0, layout=self.modeGrid, row=0, column=0,
                width=50, height=36
            )

            self.siteContainer = make_browser(layout=self.bottomLayout, file=REGRESSION_GRAPH)
            try:
                self.combos()
            except Exception as e:
                print(e)
        if True:
            """PARAMETERS"""
            self.modelParameterSelection = set_models(
                REGRESSORS_NAMES, self.parametersTab,
                command=self.set_parameters_layout, multiSelect=False
            )

            self.parametersGrid = make_group_box(
                self.parametersTab, layout=make_grid(), text='Settings', row=0,
                column=1, width=205, height=225
            )

            self.regressionLayouts = {name: make_grid() for name in REGRESSORS_NAMES}
            self.set_regressors()
            self.set_parameters_tab()

            self.autoTuneGrid = make_group_box(
                self.parametersTab, layout=make_grid(), text='Tune', row=0, column=3,
                width=45, height=45
            )

            self.autoCheck = make_button(
                type='check', layout=self.autoTuneGrid,
                description=AUTOMATIC_TUNING_DESCRIPTION
            )

            """EXPORT"""
            set_export_options(self)

    def get_options(self):
        options = {
            'abrEstimators':                    self.ABestimatorsDial.value(),
            'abrLearningRate':                  self.ABlearningRateDial.value() / 10.0,
            'abrLoss':                          self.ABlossCombo.currentText(),

            'dtrCriterion':                     self.DTcriterionCombo.currentText(),
            'dtrMaximumDepth':                  self.DTmaxDepthDial.value(),
            'dtrMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
            'dtrMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
            'dtrMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
            'dtrMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
            'dtrMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
            'dtrPresort':                       self.DTpresortCheck.isChecked(),
            'dtrRandomState':                   self.DTrandomStateEntry.text(),
            'dtrSplitter':                      self.DTsplitterCombo.currentText(),

            'enrAlpha':                         self.ENalphaDial.value() / 10.0,
            # 'enrFitIntercept': self.ENfitInterceptCheck.isChecked(),
            'enrL1Ratio':                       self.ENl1RatioDial.value() / 10.0,
            'enrNormalize':                     self.ENnormalizeCheck.isChecked(),
            'enrPositive':                      self.ENpositiveCheck.isChecked(),
            'enrSelection':                     self.ENselectionCombo.currentText(),
            'enrTolerance':                     self.ENtolDial.value() / 100.0,
            'enrWarmStart':                     self.ENwarmStartCheck.isChecked(),

            'gprAlpha':                         self.GPalphaDial.value() / 100.0,
            # 'gprKernel': self.GPkernelCombo.currentText(),
            'gprNormalize':                     self.GPnormalizeCheck.isChecked(),
            # 'gprOptimizer': self.GPoptimizerCombo.currentText(),

            'knnrAlgorithm':                    self.KNNalgorithmCombo.currentText(),
            'knnrLeafSize':                     self.KNNleafSizeDial.value(),
            'knnrMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
            'knnrNumberOfNeighbors':            self.KNNneighborsDial.value(),
            'knnrWeightsFunction':              self.KNNweightsCombo.currentText(),

            'krrAlpha':                         self.KRalphaDial.value() / 10.0,
            'krrCoefficient0':                  self.KRcoef0Dial.value() / 10.0,
            'krrGamma':                         self.KRgammaDial.value() / 10.0,
            'krrKernel':                        self.KRkernelCombo.currentText(),
            'krrPolynomialDegree':              self.KRdegreeCombo.currentText(),

            'mlprActivationFunction':           self.MLPactivationCombo.currentText(),
            # 'mlprBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
            'mlprEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
            'mlprFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
            'mlprHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
            'mlprInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
            'mlprLearningRate':                 self.MLPlearningRateCombo.currentText(),
            'mlprMaximumIterations':            self.MLPmaxIterDial.value(),
            'mlprMomentum':                     self.MLPmomentumDial.value() / 10.0,
            'mlprNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
            'mlprNumericalStability':           self.MLPepsilonDial.value() / 100.0,
            'mlprPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
            'mlprPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
            'mlprRandomState':                  self.MLPrandomStateEntry.text(),
            'mlprShuffle':                      self.MLPshuffleCheck.isChecked(),
            'mlprSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
            'mlprTolerance':                    self.MLPtolDial.value() / 100.0,
            'mlprValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
            'mlprWarmStart':                    self.MLPwarmStartCheck.isChecked(),
            'mlprWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

            'rfrBootstrap':                     self.RFbootstrapCheck.isChecked(),
            'rfrCriterion':                     self.RFcriterionCombo.currentText(),
            'rfrMaximumDepth':                  self.RFmaxDepthDial.value(),
            'rfrMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
            'rfrMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
            'rfrMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
            'rfrMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
            'rfrMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
            'rfrMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
            'rfrNumberOfTrees':                 self.RFestimatorsDial.value(),
            'rfrOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
            'rfrRandomState':                   self.RFrandomStateEntry.text(),
            'rfrWarmStart':                     self.RFwarmStartCheck.isChecked(),

            'sgdrAlpha':                        self.SGDalphaDial.value() / 100000,
            'sgdrAverage':                      self.SGDaverageCheck.isChecked(),
            'sgdrEta0':                         self.SGDeta0Dial.value() / 10.0,
            'sgdrFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
            'sgdrLearningRate':                 self.SGDlearningRateCombo.currentText(),
            'sgdrLoss':                         self.SGDlossCombo.currentText(),
            'sgdrL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
            'sgdrMaxIterations':                self.SGDmaxIterationsDial.value(),
            'sgdrPenalty':                      self.SGDpenaltyCombo.currentText(),
            'sgdrPowerT':                       self.SGDpowerTDial.value() / 10.0,
            'sgdrShuffle':                      self.SGDshuffleCheck.isChecked(),
            'sgdrTolerance':                    self.SGDtolDial.value() / 100.0,
            'sgdrWarmStart':                    self.SGDwarmStartCheck.isChecked(),

            'svmrC':                            dh.nonize(self.SVMCDial.value()),
            # 'svmrCacheSize': self.SVMcacheSizeDial.value(),
            'svmrCoefficient0':                 self.SVMcoef0Dial.value() / 10.0,
            'svmrEpsilon':                      self.SVMepsilonDial.value() / 10.0,
            'svmrGamma':                        self.SVMgammaDial.value(),
            'svmrKernel':                       self.SVMkernelCombo.currentText(),
            'svmrMaximumIterations':            self.SVMmaxIterDial.value(),
            'svmrPolynomialDegree':             self.SVMdegreeCombo.currentText(),
            'svmrShrinking':                    self.SVMshrinkingCheck.isChecked(),
            'svmrTolerance':                    self.SVMtolDial.value() / 100.0,
        }

        return options

    def set_parameters_tab(self):
        self.parametersSelection = make_scroll_area(self.regressionLayouts['Adaptive Boost'], width=275)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_parameters_layout(self):
        self.parametersGrid.removeWidget(self.parametersSelection)
        self.parametersSelection = make_scroll_area(
            self.regressionLayouts[self.modelParameterSelection.currentItem().text()], width=275
        )
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_regressors(self):
        self.set_ab_regressor()
        self.set_dt_regressor()
        self.set_en_regressor()
        self.set_gp_regressor()
        self.set_knn_regressor()
        self.set_kr_regressor()
        self.set_mlp_regressor()
        self.set_rf_regressor()
        self.set_sgd_regressor()
        self.set_svm_regressor()

    def set_ab_regressor(self):
        layout = self.regressionLayouts['Adaptive Boost']
        _, self.ABestimatorsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
            layout=layout, row=1, column=0, description=''
        )

        _, self.ABlearningRateDial = make_pair(
            pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
            layout=layout, row=2, column=0, description=''
        )

        _, self.ABlossCombo = make_pair(
            pair='combo', comboItems=('linear', 'square', 'exponential'), text='Loss:',
            layout=layout, row=3, column=0, pairWidth=100, description=''
        )

        _, self.ABrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=4, column=0,
            labelWidth=125, pairWidth=50, description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

    def set_dt_regressor(self):
        layout = self.regressionLayouts['Decision Tree']
        _, self.DTcriterionCombo = make_pair(
            pair='combo', comboItems=('mse', 'friedman_mse', 'mae'), text='Criterion:',
            layout=layout, row=1, column=0, labelWidth=200, pairWidth=100,
            description=CRITERION_DESCRIPTION
        )

        _, self.DTmaxDepthDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=2, column=0, labelWidth=125,
            description=MAX_DEPTH_DESCRIPTION
        )

        _, self.DTmaxFeaturesCombo = make_pair(
            pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=3, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        # self.DTminImpurityDecreaseLabel = make_label(self, text='Minimum Impurity Decrease:', layout=self.dtTab,
        #                                             row=30, column=0, width=200,
        #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)
        # self.DTminImpurityDecreaseDial = make_dial(self, layout=self.dtTab,
        #                                             row=30, column=1, width=50,
        #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)

        _, self.DTminSamplesLeafDial = make_pair(
            pair='dial', dialSettings=(1, 4, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=6, column=0,
            labelWidth=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        _, self.DTminSamplesSplitDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=7, column=0,
            labelWidth=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        _, self.DTminWeightFractionLeafDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=8,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        _, self.DTpresortCheck = make_pair(
            pair='check', text='Presort Data:', layout=layout, row=9, column=0,
            labelWidth=200, description=PRESORT_DESCRIPTION
        )

        _, self.DTrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=10, column=0,
            labelWidth=125, pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )

        _, self.DTsplitterCombo = make_pair(
            pair='combo', comboItems=('best', 'random'), text='Splitter:',
            layout=layout, row=11, column=0, pairWidth=75,
            description=SPLITTER_DESCRIPTION
        )

    def set_en_regressor(self):
        layout = self.regressionLayouts['Elastic Net']
        _, self.ENalphaDial = make_pair(
            pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=''
        )

        # self.ENfitInterceptLabel = make_label(self, text='Fit Intercept:', layout=self.layouts['Elastic Net'],
        #                                      row=1, column=0,
        #                                      description='')
        # self.ENfitInterceptCheck = make_button(self, type='check', layout=self.layouts['Elastic Net'],
        #                                       row=1, column=1,
        #                                       description='')

        _, self.ENl1RatioDial = make_pair(
            pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
            row=2, column=0, description=''
        )

        _, self.ENnormalizeCheck = make_pair(
            pair='check', text='Normalize:', layout=layout, row=3, column=0,
            description=''
        )

        _, self.ENpositiveCheck = make_pair(
            pair='check', text='Positive:', layout=layout, row=4, column=0,
            description=''
        )

        _, self.ENselectionCombo = make_pair(
            pair='combo', comboItems=('cyclic', 'random'), text='Selection:',
            layout=layout, row=5, column=0, description=''
        )

        _, self.ENtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=6, column=0, description=''
        )

        _, self.ENwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=7, column=0,
            description=''
        )

    def set_gp_regressor(self):
        layout = self.regressionLayouts['Gaussian Process']
        _, self.GPalphaDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=''
        )

        _, self.GPnormalizeCheck = make_pair(
            pair='check', text='Normalize:', layout=layout, row=2, column=0,
            description=''
        )

        _, self.ABrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=3, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

    def set_knn_regressor(self):
        layout = self.regressionLayouts['Nearest Neighbors']
        _, self.KNNalgorithmCombo = make_pair(
            pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
            text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
            description=ALGORITHM_DESCRIPTION
        )

        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

        _, self.KNNleafSizeDial = make_pair(
            pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:', layout=layout,
            row=2, column=0, description=LEAF_SIZE_DESCRIPTION
        )

        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

        _, self.KNNminkowskiPowerDial = make_pair(
            pair='dial', dialSettings=(1, 100, 2, 1), text='Minkowski Power:',
            layout=layout, row=3, column=0, description=P_DESCRIPTION
        )

        _, self.KNNneighborsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 5, 1), text='Number of Neighbors:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=N_NEIGHBORS_DESCRIPTION
        )

        _, self.KNNweightsCombo = make_pair(
            pair='combo', comboItems=('uniform', 'distance'), text='Weights Function:',
            layout=layout, row=5, column=0, labelWidth=200, pairWidth=100,
            description=WEIGHTS_DESCRIPTION
        )

    def set_kr_regressor(self):
        layout = self.regressionLayouts['Kernel Ridge']
        _, self.KRalphaDial = make_pair(
            pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=ALPHA_DESCRIPTION
        )
        _, self.KRcoef0Dial = make_pair(
            pair='dial', dialSettings=(0, 10, 10, 1), text='Coefficient 0:', layout=layout,
            row=2, column=0, description=COEF0_DESCRIPTION
        )

        _, self.KRdegreeCombo = make_pair(
            pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:', layout=layout,
            row=3, column=0, description=DEGREE_DESCRIPTION
        )

        _, self.KRgammaDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout, row=4,
            column=0, description=GAMMA_DESCRIPTION
        )

        _, self.KRkernelCombo = make_pair(
            pair='combo', comboItems=('linear', 'poly', 'rbf'), text='Kernel:',
            layout=layout, row=5, column=0, description=KERNEL_DESCRIPTION
        )

    def set_mlp_regressor(self):
        layout = self.regressionLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )

        _, self.MLPalphaDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha (Penalty Parameter):',
            layout=layout, row=2, column=0, labelWidth=200,
            description=MLP_ALPHA_DESCRIPTION
        )

        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)

        _, self.MLPbeta1Dial = make_pair(
            pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )

        _, self.MLPbeta2Dial = make_pair(
            pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )

        _, self.MLPearlyStoppingCheck = make_pair(
            pair='check', text='Early Stopping:', layout=layout, row=5, column=0,
            labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )

        _, self.MLPepsilonDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )

        _, self.MLPhiddenLayerSizesEntry = make_pair(
            pair='entry', text='Hidden Layer Sizes:', layout=layout, row=7,
            column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

        _, self.MLPinitLearningRateDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )

        _, self.MLPlearningRateCombo = make_pair(
            pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )

        _, self.MLPmaxIterDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
            layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )

        _, self.MLPmomentumDial = make_pair(
            pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:', layout=layout,
            row=11, column=0, description=MOMENTUM_DESCRIPTION
        )

        _, self.MLPnesterovsMomentumCheck = make_pair(
            pair='check', text='Nesterov\'s Momentum:', layout=layout, row=12,
            column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )

        _, self.MLPpowerTDial = make_pair(
            pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )

        _, self.MLPrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=14, column=0,
            pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )

        _, self.MLPshuffleCheck = make_pair(
            pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )

        _, self.MLPsolverCombo = make_pair(
            pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )

        _, self.MLPtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=17, column=0, description=MLP_TOL_DESCRIPTION
        )

        _, self.MLPvalidationFractionDial = make_pair(
            pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )

        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

        _, self.MLPwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def set_rf_regressor(self):
        layout = self.regressionLayouts['Random Forest']
        _, self.RFbootstrapCheck = make_pair(
            pair='check', text='Bootstrap:', layout=layout, row=1, column=0,
            description=BOOTSTRAP_DESCRIPTION
        )

        _, self.RFcriterionCombo = make_pair(
            pair='combo', comboItems=('mse', 'mae'), text='Criterion:', layout=layout,
            row=2, column=0, pairWidth=50, description=CRITERION_DESCRIPTION
        )

        _, self.RFmaxDepthDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=3, column=0, description=MAX_DEPTH_DESCRIPTION
        )

        _, self.RFmaxFeaturesCombo = make_pair(
            pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=4, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.RFmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=5, column=0, labelWidth=220,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.RFminImpurityDecreaseDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Impurity Decrease:', layout=layout, row=6, column=0,
            labelWidth=220, description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        _, self.RFminSamplesLeafDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=7, column=0,
            labelWidth=220, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        _, self.RFminSamplesSplitDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=8, column=0,
            labelWidth=175, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        _, self.RFminWeightFractionLeafDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=9,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        _, self.RFestimatorsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
            layout=layout, row=10, column=0, labelWidth=200,
            description=N_ESTIMATORS_DESCRIPTION
        )

        _, self.RFoobScoreCheck = make_pair(
            pair='check', text='Out-of-Bag Samples:', layout=layout, row=11, column=0,
            labelWidth=200, description=OOB_SCORE_DESCRIPTION
        )

        # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
        # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)

        # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
        # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
        _, self.RFrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=12, column=0,
            pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )

        _, self.RFwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=13, column=0,
            labelWidth=200, description=WARM_START_DESCRIPTION
        )

    def set_sgd_regressor(self):
        layout = self.regressionLayouts['Stochastic Gradient Descent']
        _, self.SGDalphaDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=''
        )

        _, self.SGDaverageCheck = make_pair(
            pair='check', text='Average:', layout=layout, row=2, column=0,
            description=''
        )

        _, self.SGDeta0Dial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout, row=3,
            column=0, description=''
        )

        _, self.SGDfitInterceptCheck = make_pair(
            pair='check', text='Fit Intercept:', layout=layout, row=4, column=0,
            description=''
        )

        _, self.SGDlearningRateCombo = make_pair(
            pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
            text='Learning Rate:', layout=layout, row=5, column=0, pairWidth=100,
            description=''
        )

        _, self.SGDlossCombo = make_pair(
            pair='combo', comboItems=(
                'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
            layout=layout,
            row=6, column=0, pairWidth=100, description=''
        )

        _, self.SGDl1RatioDial = make_pair(
            pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
            row=7, column=0, description=''
        )

        _, self.SGDmaxIterationsDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=8, column=0,
            description=''
        )

        _, self.SGDpenaltyCombo = make_pair(
            pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
            text='Penalty:', layout=layout, row=9, column=0, pairWidth=100,
            description=''
        )

        _, self.SGDpowerTDial = make_pair(
            pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
            row=10, column=0, description=''
        )

        _, self.SGDshuffleCheck = make_pair(
            pair='check', text='Shuffle:', layout=layout, row=11, column=0,
            description=''
        )

        _, self.SGDtolDial = make_pair(
            pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:', layout=layout,
            row=12, column=0, description=''
        )

        _, self.SGDwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=13, column=0,
            description=''
        )

    def set_svm_regressor(self):
        layout = self.regressionLayouts['Support Vector Machine']
        _, self.SVMCDial = make_pair(
            pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
            column=0, description=C_DESCRIPTION
        )

        # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=0,
        #                                    description=CACHE_SIZE_DESCRIPTION)
        # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=1, width=50,
        #                                    description=CACHE_SIZE_DESCRIPTION)

        _, self.SVMcoef0Dial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:', layout=layout,
            row=2, column=0, description=COEF0_DESCRIPTION
        )

        _, self.SVMdegreeCombo = make_pair(
            pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:', layout=layout,
            row=3, column=0, pairWidth=100, description=DEGREE_DESCRIPTION
        )

        _, self.SVMepsilonDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:', layout=layout,
            row=4, column=0, description=EPSILON_DESCRIPTION
        )

        _, self.SVMgammaDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout, row=5,
            column=0, description=GAMMA_DESCRIPTION
        )

        _, self.SVMkernelCombo = make_pair(
            pair='combo', comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
            text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
            description=KERNEL_DESCRIPTION
        )

        _, self.SVMmaxIterDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
            layout=layout, row=7, column=0, labelWidth=200,
            description=MAX_ITER_DESCRIPTION
        )

        _, self.SVMshrinkingCheck = make_pair(
            pair='check', text='Shrinking:', layout=layout, row=8, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=9, column=0, description=TOL_DESCRIPTION
        )

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, row=0, column=0,
            width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        mode = self.mode.selectedItems()[0].text().lower()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        data, xKeys, yKeys = dh.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            REGRESSION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
        )
        self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)

    def run(self):
        try:
            mode = self.mode.selectedItems()[0].text().lower()
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            models = self.get_models()
            xLabel = index if mode == 'series' else 'Time Step'
            if self.validate(models, mode):
                x, y, xKeys, yKeys = Regressors.train_nn(dir, index, column, models, mode)
                Regressors.plot_regression(x, y, xLabel=xLabel, yLabel=column, xKeys=xKeys, yKeys=yKeys)
                self.siteContainer = load_browser(
                    self.siteContainer,
                    REGRESSION_GRAPH
                )  # TODO self.results = (dh.denumerify(x, y, xKeys, yKeys), index, column)
        except Exception as e:
            print(e)

    def get_models(self):
        checks = [x.text() for x in self.modelSelection.selectedItems()]
        if self.autoCheck.isChecked():
            models = Regressors.cross_validation_regression_models(checks)
        else:
            options = self.get_options()
            models = Regressors.regression_models(checks, options)
        return models

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    # TODO must assemble dataframe to prepare export
    def export_results(self):
        dh.export_data(self.results, 'test', self.csvCheck.isChecked())

    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, REGRESSORS_NAMES, REGRESSION_GRAPH, Regressors)
        self.resultsSuffix = ' Regression6 results'
        self.parent = parent
        self.title = title
        self.icon = icon

    def get_options(self):
        options = {name: None for name in REGRESSORS_NAMES}

        options['Adaptive Boost'] = {
            'learning_rate': self.ABlearningRateDial.value() / 10.0,
            'loss':          self.ABlossCombo.currentText(),
            'n_estimators':  self.ABestimatorsDial.value()
        }

        options['Decision Tree'] = {
            'criterion':                self.DTcriterionCombo.currentText(),
            'max_depth':                self.DTmaxDepthDial.value(),
            'max_features':             self.DTmaxFeaturesCombo.currentText(),
            'max_leaf_nodes':           self.DTmaxLeafNodesDial.value(),
            'min_samples_leaf':         self.DTminSamplesLeafDial.value() / 10.0,
            'min_weight_fraction_leaf': self.DTminWeightFractionLeafDial.value() / 10.0,
            'splitter':                 self.DTsplitterCombo.currentText()
        }

        options['Elastic Net'] = {
            'alpha':      self.ENalphaDial.value() / 10.0,
            'l1_ratio':   self.ENl1RatioDial.value() / 10.0,
            'normalize':  self.ENnormalizeCheck.isChecked(),
            'positive':   self.ENpositiveCheck.isChecked(),
            'selection':  self.ENselectionCombo.currentText(),
            'tol':        self.ENtolDial.value() / 100.0,
            'warm_start': self.ENwarmStartCheck.isChecked()
        }

        options['Gaussian Process'] = {
            'alpha':       self.GPalphaDial.value() / 100.0,
            'normalize_y': self.GPnormalizeCheck.isChecked(),
        }

        options['Nearest Neighbors'] = {
            'algorithm':   self.KNNalgorithmCombo.currentText(),
            'leaf_size':   self.KNNleafSizeDial.value(),
            'n_neighbors': self.KNNneighborsDial.value(),
            'p':           self.KNNminkowskiPowerDial.value(),
            'weights':     self.KNNweightsCombo.currentText(),
        }

        options['Kernel Ridge'] = {
            'alpha':  self.KRalphaDial.value() / 10.0, 'coef0': self.KRcoef0Dial.value() / 10.0,
            'degree': self.KRdegreeCombo.currentText(), 'gamma': self.KRgammaDial.value() / 10.0,
            'kernel': self.KRkernelCombo.currentText()
        }

        options['Multilayer Perceptron'] = {
            'activation':          self.MLPactivationCombo.currentText(),
            'alpha':               self.MLPalphaDial.value() / 100000.0,
            'beta_1':              self.MLPbeta1Dial.value() / 100.0,
            'beta_2':              self.MLPbeta2Dial.value() / 100.0,
            'early_stopping':      self.MLPearlyStoppingCheck.isChecked(),
            'epsilon':             self.MLPepsilonDial.value() / 100.0,
            'hidden_layer_sizes':  self.MLPhiddenLayerSizesEntry.text(),
            'learning_rate':       self.MLPlearningRateCombo.currentText(),
            'learning_rate_init':  self.MLPinitLearningRateDial.value() / 10.0,
            'max_iter':            self.MLPmaxIterDial.value(),
            'momentum':            self.MLPmomentumDial.value() / 10.0,
            'nesterovs_momentum':  self.MLPnesterovsMomentumCheck.isChecked(),
            'power_t':             self.MLPpowerTDial.value() / 10.0,
            'shuffle':             self.MLPshuffleCheck.isChecked(),
            'solver':              self.MLPsolverCombo.currentText(),
            'tol':                 self.MLPtolDial.value() / 100.0,
            'validation_fraction': self.MLPvalidationFractionDial.value() / 10.0,
            'warm_start':          self.MLPwarmStartCheck.isChecked()
        }

        options['Random Forest'] = {
            'bootstrap2':                self.RFbootstrapCheck.isChecked(),
            'criterion':                self.RFcriterionCombo.currentText(),
            'max_depth':                self.RFmaxDepthDial.value(),
            'max_features':             self.RFmaxFeaturesCombo.currentText(),
            'max_leaf_nodes':           self.RFmaxLeafNodesDial.value(),
            'min_samples_leaf':         self.RFminSamplesLeafDial.value() / 10.0,
            'min_samples_split':        self.RFminSamplesSplitDial.value() / 10.0,
            'min_weight_fraction_leaf': self.RFminWeightFractionLeafDial.value() / 10.0,
            'n_estimators':             self.RFestimatorsDial.value(),
            'oob_score':                self.RFoobScoreCheck.isChecked(),
            'warm_start':               self.RFwarmStartCheck.isChecked()
        }

        options['Stochastic Gradient Descent'] = {
            'alpha':         self.SGDalphaDial.value() / 10000,
            'average':       self.SGDaverageCheck.isChecked(),
            'eta0':          self.SGDeta0Dial.value() / 100.0,
            'fit_intercept': self.SGDfitInterceptCheck.isChecked(),
            'learning_rate': self.SGDlearningRateCombo.currentText(),
            'loss':          self.SGDlossCombo.currentText(),
            'l1_ratio':      self.SGDl1RatioDial.value() / 100.0,
            'max_iter':      self.SGDmaxIterationsDial.value(),
            'penalty':       self.SGDpenaltyCombo.currentText(),
            'power_t':       self.SGDpowerTDial.value() / 100.0,
            'shuffle':       self.SGDshuffleCheck.isChecked(),
            'tol':           self.SGDtolDial.value() / 10000.0,
            'warm_start':    self.SGDwarmStartCheck.isChecked()
        }

        options['Support Vector Machine'] = {
            'C':         dh.nonize(self.SVMCDial.value()),
            'coef0':     self.SVMcoef0Dial.value() / 10.0,
            'degree':    self.SVMdegreeCombo.currentText(),
            'epsilon':   self.SVMepsilonDial.value() / 10.0,
            'gamma':     self.SVMgammaDial.value(),
            'kernel':    self.SVMkernelCombo.currentText(),
            'max_iter':  self.SVMmaxIterDial.value(),
            'shrinking': self.SVMshrinkingCheck.isChecked(),
            'tol':       self.SVMtolDial.value() / 100.0
        }

        return options

    def set_algorithms(self):
        def set_ab_regressor(self):
            from Utilities.ToolTips.Regression import AdaptiveBoost
            layout = self.optionLayouts['Adaptive Boost']
            _, self.ABestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators',
                layout=layout, row=0, column=0,
                description=AdaptiveBoost.ESTIMATORS_DESCRIPTION
            )

            _, self.ABlearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate',
                layout=layout, row=0, column=1,
                description=AdaptiveBoost.LEARNING_RATE_DESCRIPTION
            )

            _, self.ABlossCombo = make_pair(
                pair='combo', comboItems=('linear', 'square', 'exponential'), text='Loss',
                layout=layout, row=0, column=2, pairWidth=100,
                description=AdaptiveBoost.LOSS_DESCRIPTION
            )

            """_, self.ABrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=1, column=1, labelWidth=125, pairWidth=50,
                                                   description=HIDDEN_LAYER_SIZES_DESCRIPTION)"""

        def set_dt_regressor(self):
            from Utilities.ToolTips.Regression import DecisionTree
            layout = self.optionLayouts['Decision Tree']
            _, self.DTcriterionCombo = make_pair(
                pair='combo', comboItems=('mse', 'friedman_mse', 'mae'),
                text='Criterion:', layout=layout, row=0, column=0, labelWidth=200,
                pairWidth=100, description=DecisionTree.CRITERION_DESCRIPTION
            )

            _, self.DTmaxDepthDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='Maximum Depth:',
                layout=layout, row=0, column=1, labelWidth=125,
                description=DecisionTree.MAX_DEPTH_DESCRIPTION
            )

            _, self.DTmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=0, column=2,
                labelWidth=200, pairWidth=50,
                description=DecisionTree.MAX_FEATURES_DESCRIPTION
            )

            _, self.DTmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=1, column=0, labelWidth=200,
                description=DecisionTree.MAX_LEAF_NODES_DESCRIPTION
            )

            # self.DTminImpurityDecreaseLabel = make_label(self, text='Minimum Impurity Decrease:', layout=self.dtTab,
            #                                             row=30, column=0, width=200,
            #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)
            # self.DTminImpurityDecreaseDial = make_dial(self, layout=self.dtTab,
            #                                             row=30, column=1, width=50,
            #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)

            _, self.DTminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 4, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=1, column=1,
                labelWidth=200,
                description=DecisionTree.MIN_SAMPLES_LEAF_DESCRIPTION
            )

            _, self.DTminSamplesSplitDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Minimum Samples Split:', layout=layout, row=1, column=2,
                labelWidth=150,
                description=DecisionTree.MIN_SAMPLES_SPLIT_DESCRIPTION
            )

            _, self.DTminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 5, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=2,
                column=1, labelWidth=220,
                description=DecisionTree.MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
            )

            """_, self.DTpresortCheck = make_pair(pair='check',
                                               text='Presort Data:',
                                               layout=layout,
                                               row=1, column=1, labelWidth=200,
                                               description=PRESORT_DESCRIPTION)"""

            """_, self.DTrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=2, column=1, labelWidth=125, pairWidth=50,
                                                   description=RANDOM_STATE_DESCRIPTION)"""

            _, self.DTsplitterCombo = make_pair(
                pair='combo', comboItems=('best', 'random'), text='Splitter:',
                layout=layout, row=2, column=2, pairWidth=75,
                description=DecisionTree.SPLITTER_DESCRIPTION
            )

        def set_en_regressor(self):
            layout = self.optionLayouts['Elastic Net']
            _, self.ENalphaDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
                row=0, column=0, description=''
            )

            # self.ENfitInterceptLabel = make_label(self, text='Fit Intercept:', layout=self.layouts['Elastic Net'],
            #                                      row=1, column=0,
            #                                      description='')
            # self.ENfitInterceptCheck = make_button(self, type='check', layout=self.layouts['Elastic Net'],
            #                                       row=1, column=1,
            #                                       description='')

            _, self.ENl1RatioDial = make_pair(
                pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
                row=0, column=1, description=''
            )

            _, self.ENnormalizeCheck = make_pair(
                pair='check', text='Normalize:', layout=layout, row=0, column=2,
                description=''
            )

            _, self.ENpositiveCheck = make_pair(
                pair='check', text='Positive:', layout=layout, row=1, column=0,
                description=''
            )

            _, self.ENselectionCombo = make_pair(
                pair='combo', comboItems=('cyclic', 'random'), text='Selection:',
                layout=layout, row=1, column=1, description=''
            )

            _, self.ENtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=1, column=2, description=''
            )

            _, self.ENwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=2, column=1,
                description=''
            )

        def set_gp_regressor(self):
            layout = self.optionLayouts['Gaussian Process']
            _, self.GPalphaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Alpha:', layout=layout,
                row=0, column=0, description=''
            )

            _, self.GPnormalizeCheck = make_pair(
                pair='check', text='Normalize:', layout=layout, row=0, column=1,
                description=''
            )

            """_, self.ABrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=2, column=0, labelWidth=125, pairWidth=50,
                                                   description='')"""

        def set_knn_regressor(self):
            layout = self.optionLayouts['Nearest Neighbors']
            _, self.KNNalgorithmCombo = make_pair(
                pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
                text='Algorithm:', layout=layout, row=0, column=0, pairWidth=100,
                description=ALGORITHM_DESCRIPTION
            )

            # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
            # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

            _, self.KNNleafSizeDial = make_pair(
                pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:',
                layout=layout, row=0, column=1, description=LEAF_SIZE_DESCRIPTION
            )

            # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
            # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

            # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
            # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

            _, self.KNNminkowskiPowerDial = make_pair(
                pair='dial', dialSettings=(1, 100, 2, 1), text='Minkowski Power:',
                layout=layout, row=0, column=2, description=''
            )

            _, self.KNNneighborsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 5, 1), text='Number of Neighbors:',
                layout=layout, row=1, column=0, labelWidth=200, description=''
            )

            _, self.KNNweightsCombo = make_pair(
                pair='combo', comboItems=('uniform', 'distance'),
                text='Weights Function:', layout=layout, row=1, column=2,
                labelWidth=200, pairWidth=100, description=''
            )

        def set_kr_regressor(self):
            layout = self.optionLayouts['Kernel Ridge']
            _, self.KRalphaDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
                row=0, column=0, description=ALPHA_DESCRIPTION
            )
            _, self.KRcoef0Dial = make_pair(
                pair='dial', dialSettings=(0, 10, 10, 1), text='Coefficient 0:',
                layout=layout, row=0, column=1, description=''
            )

            _, self.KRdegreeCombo = make_pair(
                pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
                layout=layout, row=0, column=2, description=''
            )

            _, self.KRgammaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
                row=1, column=0, description=GAMMA_DESCRIPTION
            )

            _, self.KRkernelCombo = make_pair(
                pair='combo', comboItems=('linear', 'poly', 'rbf'), text='Kernel:',
                layout=layout, row=1, column=2, description=KERNEL_DESCRIPTION
            )

        def set_mlp_regressor(self):
            layout = self.optionLayouts['Multilayer Perceptron']
            _, self.MLPactivationCombo = make_pair(
                pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
                text='Activation Function:', layout=layout, row=0, column=0,
                labelWidth=200, pairWidth=100, description=''
            )

            _, self.MLPalphaDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1),
                text='Alpha (Penalty Parameter):', layout=layout, row=0, column=1,
                labelWidth=200, description=''
            )

            # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=0, width=200,
            #                                    description=BATCH_SIZE_DESCRIPTION)
            # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=1, width=50,
            #                                    description=BATCH_SIZE_DESCRIPTION)

            _, self.MLPbeta1Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=0,
                column=2, labelWidth=250, description=''
            )

            _, self.MLPbeta2Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=1,
                column=0, labelWidth=250, description=''
            )

            _, self.MLPearlyStoppingCheck = make_pair(
                pair='check', text='Early Stopping:', layout=layout, row=1,
                column=1, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
            )

            _, self.MLPepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Epsilon (Numerical Stability):', layout=layout, row=1, column=2,
                labelWidth=200, description=''
            )

            _, self.MLPhiddenLayerSizesEntry = make_pair(
                pair='entry', text='Hidden Layer Sizes:', layout=layout, row=2,
                column=0, labelWidth=200, pairWidth=50,
                description=HIDDEN_LAYER_SIZES_DESCRIPTION
            )

            _, self.MLPinitLearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Initial Learning Rate:', layout=layout, row=2, column=1,
                labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
            )

            _, self.MLPlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
                text='Learning Rate:', layout=layout, row=2, column=2,
                labelWidth=200, pairWidth=100,
                description=LEARNING_RATE_DESCRIPTION
            )

            _, self.MLPmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=3, column=0, labelWidth=250, description=''
            )

            _, self.MLPmomentumDial = make_pair(
                pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
                layout=layout, row=3, column=1, description=MOMENTUM_DESCRIPTION
            )

            _, self.MLPnesterovsMomentumCheck = make_pair(
                pair='check', text='Nesterov\'s Momentum:', layout=layout,
                row=3, column=2, labelWidth=200,
                description=NESTEROVS_MOMENTUM_DESCRIPTION
            )

            _, self.MLPpowerTDial = make_pair(
                pair='dial', dialSettings=(1, 10, 5, 1),
                text='Power for Inverse Learning Rate:', layout=layout, row=4, column=0,
                labelWidth=250, description=POWER_T_DESCRIPTION
            )

            """_, self.MLPrandomStateEntry = make_pair(pair='entry',
                                                    text='Random State:',
                                                    layout=layout,
                                                    row=14, column=0, pairWidth=50,
                                                    description=MLP_RANDOM_STATE_DESCRIPTION)"""

            _, self.MLPshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=4, column=1,
                description=SHUFFLE_DESCRIPTION
            )

            _, self.MLPsolverCombo = make_pair(
                pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
                text='Solver (Weight Optimization):', layout=layout, row=4, column=2,
                labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
            )

            _, self.MLPtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=5, column=0, description=''
            )

            _, self.MLPvalidationFractionDial = make_pair(
                pair='dial', dialSettings=(1, 9, 9, 1),
                text='Validation Fraction:', layout=layout, row=5, column=1,
                labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
            )

            # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
            # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

            _, self.MLPwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=5, column=2,
                labelWidth=200, description=''
            )

        def set_rf_regressor(self):
            layout = self.optionLayouts['Random Forest']
            _, self.RFbootstrapCheck = make_pair(
                pair='check', text='Bootstrap:', layout=layout, row=0, column=0,
                description=BOOTSTRAP_DESCRIPTION
            )

            _, self.RFcriterionCombo = make_pair(
                pair='combo', comboItems=('mse', 'mae'), text='Criterion:',
                layout=layout, row=0, column=1, pairWidth=50,
                description=CRITERION_DESCRIPTION
            )

            _, self.RFmaxDepthDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='Maximum Depth:',
                layout=layout, row=0, column=2, description=''
            )

            _, self.RFmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=1, column=0,
                labelWidth=200, pairWidth=50, description=''
            )

            _, self.RFmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(2, 100, 2, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=1, column=1, labelWidth=220, description=''
            )

            _, self.RFminImpurityDecreaseDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Minimum Impurity Decrease:', layout=layout, row=1,
                column=2, labelWidth=220, description=''
            )

            _, self.RFminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 5, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=2, column=0,
                labelWidth=220, description=''
            )

            _, self.RFminSamplesSplitDial = make_pair(
                pair='dial', dialSettings=(1, 10, 2, 1),
                text='Minimum Samples Split:', layout=layout, row=2, column=1,
                labelWidth=175, description=''
            )

            _, self.RFminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 5, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=2,
                column=2, labelWidth=220, description=''
            )

            _, self.RFestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
                layout=layout, row=3, column=0, labelWidth=200, description=''
            )

            _, self.RFoobScoreCheck = make_pair(
                pair='check', text='Out-of-Bag Samples:', layout=layout, row=3,
                column=1, labelWidth=200, description=''
            )

            # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
            # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)

            # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
            # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
            """_, self.RFrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=12, column=0, pairWidth=50,
                                                   description=RANDOM_STATE_DESCRIPTION)"""

            _, self.RFwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=3, column=2,
                labelWidth=200, description=WARM_START_DESCRIPTION
            )

        def set_sgd_regressor(self):
            layout = self.optionLayouts['Stochastic Gradient Descent']
            _, self.SGDalphaDial = make_pair(
                pair='dial', dialSettings=(1, 10000, 1, 1), text='Alpha:', layout=layout,
                row=0, column=0, description=''
            )

            _, self.SGDaverageCheck = make_pair(
                pair='check', text='Average:', layout=layout, row=0, column=1,
                description=''
            )

            _, self.SGDeta0Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='Eta 0:', layout=layout,
                row=0, column=2, description=''
            )

            _, self.SGDfitInterceptCheck = make_pair(
                pair='check', text='Fit Intercept:', layout=layout, row=1,
                column=0, description=''
            )
            self.SGDfitInterceptCheck.setChecked(True)

            _, self.SGDlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
                text='Learning Rate:', layout=layout, row=1, column=1,
                pairWidth=100, description=''
            )

            self.SGDlearningRateCombo.setCurrentText('constant')

            _, self.SGDlossCombo = make_pair(
                pair='combo', comboItems=(
                    'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
                layout=layout, row=1, column=2, pairWidth=100, description=''
            )

            _, self.SGDl1RatioDial = make_pair(
                pair='dial', dialSettings=(0, 100, 15, 1), text='L1 Ratio:',
                layout=layout, row=2, column=0, description=''
            )

            _, self.SGDmaxIterationsDial = make_pair(
                pair='dial', dialSettings=(1, 100000, 1000, 1),
                text='Maximum Iterations:', layout=layout, row=2, column=1,
                description=''
            )

            _, self.SGDpenaltyCombo = make_pair(
                pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
                text='Penalty:', layout=layout, row=2, column=2, pairWidth=100,
                description=''
            )

            self.SGDpenaltyCombo.setCurrentText('l2')

            _, self.SGDpowerTDial = make_pair(
                pair='dial', dialSettings=(0, 100, 25, 1), text='Power T:', layout=layout,
                row=3, column=0, description=''
            )

            _, self.SGDshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=3, column=1,
                description=''
            )
            self.SGDshuffleCheck.setChecked(True)

            _, self.SGDtolDial = make_pair(
                pair='dial', dialSettings=(0, 10000, 1, 1), text='Tolerance:', layout=layout,
                row=3, column=2, description=''
            )

            _, self.SGDwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=4, column=1,
                description=''
            )

        def set_svm_regressor(self):
            layout = self.optionLayouts['Support Vector Machine']
            _, self.SVMCDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=0,
                column=0, description=C_DESCRIPTION
            )

            # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=0,
            #                                    description=CACHE_SIZE_DESCRIPTION)
            # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=1, width=50,
            #                                    description=CACHE_SIZE_DESCRIPTION)

            _, self.SVMcoef0Dial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
                layout=layout, row=0, column=1, description=''
            )

            _, self.SVMdegreeCombo = make_pair(
                pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
                layout=layout, row=0, column=2, pairWidth=100, description=''
            )

            _, self.SVMepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:', layout=layout,
                row=1, column=0, description=EPSILON_DESCRIPTION
            )

            _, self.SVMgammaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
                row=1, column=1, description=GAMMA_DESCRIPTION
            )

            _, self.SVMkernelCombo = make_pair(
                pair='combo',
                comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
                text='Kernel:', layout=layout, row=1, column=2, pairWidth=100,
                description=KERNEL_DESCRIPTION
            )

            _, self.SVMmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=2, column=0, labelWidth=200, description=''
            )

            _, self.SVMshrinkingCheck = make_pair(
                pair='check', text='Shrinking:', layout=layout, row=2, column=1,
                description=SHRINKING_DESCRIPTION
            )

            _, self.SVMtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=2, column=2, description=''
            )

        set_ab_regressor(self)
        set_dt_regressor(self)
        set_en_regressor(self)
        set_gp_regressor(self)
        set_knn_regressor(self)
        set_kr_regressor(self)
        set_mlp_regressor(self)
        set_rf_regressor(self)
        set_sgd_regressor(self)
        set_svm_regressor(self)

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, row=0, column=0,
            width=200, description=''
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        remove_tabs(self.tabs)
        self.inputsSelection.clear()
        self.inputsSelection.addItems([h for h in self.headers if h != self.columnCombo.currentText()])
        self.results = None

        mode, index, column, dir, _, _ = self.get_parameters()

        data, xKeys, yKeys = dh.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            REGRESSION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,),
            colors=(((CONTRASTED_COLOR,),),)
        )
        self.mainPlotContainer = load_browser(self.mainPlotContainer, REGRESSION_GRAPH)

    def run(self):
        try:
            remove_tabs(self.tabs)
            mode, index, column, dir, models, scaler = self.get_parameters()
            inputs = self.get_inputs()
            if len(inputs) == 0:
                inputs = [index]
            if self.validate(models, mode):
                x, y, results, xKeys, yKeys = Regressors.train_nn(
                    self, dir, index, [column] + inputs, column, models,
                    scaler, mode
                )

                if True:
                    m = [index] if index else []
                    for c in x.columns:
                        if c != index:
                            m.append(c)
                    for c in results.columns:
                        m.append(c)  # TODO categorical results are not denumerified yet
                # self.results = pd.DataFrame(results.reset_index().values if index else results.values,
                #                            index=y.index, columns=m)

                for i, input in enumerate(inputs):
                    data, xKeys, yKeys = dh.process_regression_data(dir, input, column, mode)
                    data = pd.DataFrame(data, columns=(column,), index=data.index)
                    tempPlot = os.path.join(REGRESSION_GRAPHS, 'temp' + str(i) + '.html')
                    tempTab = make_tab(self, input, self.tabs)
                    Regressors.plot_regression(
                        data, results, xLabel=input, yLabel=column, xKeys=xKeys, yKeys=yKeys,
                        file=tempPlot, title=column + ' vs ' + input
                    )
                    tempContainer = make_browser(layout=tempTab, file=tempPlot)
                self.progressBar.setValue(100)
                self.progressBar.setValue(0)

        except Exception as e:
            print(e)

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, REGRESSORS_NAMES, REGRESSION_GRAPH, Regressors)

    def get_options(self):
        options = {name: None for name in REGRESSORS_NAMES}
        options['Adaptive Boost'] = {
            'n_estimators':  self.ABestimatorsDial.value(),
            'learning_rate': self.ABlearningRateDial.value() / 10.0,
            'loss':          self.ABlossCombo.currentText()
        }
        options['Decision Tree'] = {
            'criterion':                self.DTcriterionCombo.currentText(),
            'max_depth':                self.DTmaxDepthDial.value(),
            'max_leaf_nodes':           self.DTmaxLeafNodesDial.value(),
            'max_features':             self.DTmaxFeaturesCombo.currentText(),
            'min_samples_leaf':         self.DTminSamplesLeafDial.value() / 10.0,
            'min_weight_fraction_leaf': self.DTminWeightFractionLeafDial.value() / 10.0,
            'splitter':                 self.DTsplitterCombo.currentText(),
        }
        """options = {
            'abrEstimators': self.ABestimatorsDial.value(),
            'abrLearningRate': self.ABlearningRateDial.value() / 10.0,
            'abrLoss': self.ABlossCombo.currentText(),

            'dtrCriterion': self.DTcriterionCombo.currentText(),
            'dtrMaximumDepth': self.DTmaxDepthDial.value(),
            'dtrMaximumLeafNodes': self.DTmaxLeafNodesDial.value(),
            'dtrMaximumFeatures': self.DTmaxFeaturesCombo.currentText(),
            'dtrMinimumSamplesLeaf': self.DTminSamplesLeafDial.value() / 10.0,
            'dtrMinimumSamplesSplit': self.DTminSamplesSplitDial.value() / 10.0,
            'dtrMinimumWeightFractionLeaf': self.DTminWeightFractionLeafDial.value() / 10.0,
            #'dtrPresort': self.DTpresortCheck.isChecked(),
            #'dtrRandomState': self.DTrandomStateEntry.text(),
            'dtrSplitter': self.DTsplitterCombo.currentText(),

            'enrAlpha': self.ENalphaDial.value() / 10.0,
            # 'enrFitIntercept': self.ENfitInterceptCheck.isChecked(),
            'enrL1Ratio': self.ENl1RatioDial.value() / 10.0,
            'enrNormalize': self.ENnormalizeCheck.isChecked(),
            'enrPositive': self.ENpositiveCheck.isChecked(),
            'enrSelection': self.ENselectionCombo.currentText(),
            'enrTolerance': self.ENtolDial.value() / 100.0,
            'enrWarmStart': self.ENwarmStartCheck.isChecked(),

            'gprAlpha': self.GPalphaDial.value() / 100.0,
            # 'gprKernel': self.GPkernelCombo.currentText(),
            'gprNormalize': self.GPnormalizeCheck.isChecked(),
            # 'gprOptimizer': self.GPoptimizerCombo.currentText(),

            'knnrAlgorithm': self.KNNalgorithmCombo.currentText(),
            'knnrLeafSize': self.KNNleafSizeDial.value(),
            'knnrMinkowskiPower': self.KNNminkowskiPowerDial.value(),
            'knnrNumberOfNeighbors': self.KNNneighborsDial.value(),
            'knnrWeightsFunction': self.KNNweightsCombo.currentText(),

            'krrAlpha': self.KRalphaDial.value() / 10.0,
            'krrCoefficient0': self.KRcoef0Dial.value() / 10.0,
            'krrGamma': self.KRgammaDial.value() / 10.0,
            'krrKernel': self.KRkernelCombo.currentText(),
            'krrPolynomialDegree': self.KRdegreeCombo.currentText(),

            'mlprActivationFunction': self.MLPactivationCombo.currentText(),
            # 'mlprBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
            'mlprEarlyStopping': self.MLPearlyStoppingCheck.isChecked(),
            'mlprFirstMomentExponentialDecay': self.MLPbeta1Dial.value() / 100.0,
            'mlprHiddenLayerSizes': self.MLPhiddenLayerSizesEntry.text(),
            'mlprInitialLearningRate': self.MLPinitLearningRateDial.value() / 10.0,
            'mlprLearningRate': self.MLPlearningRateCombo.currentText(),
            'mlprMaximumIterations': self.MLPmaxIterDial.value(),
            'mlprMomentum': self.MLPmomentumDial.value() / 10.0,
            'mlprNesterovsMomentum': self.MLPnesterovsMomentumCheck.isChecked(),
            'mlprNumericalStability': self.MLPepsilonDial.value() / 100.0,
            'mlprPenaltyParameter': self.MLPalphaDial.value() / 100000.0,
            'mlprPowerForInverseLearningRate': self.MLPpowerTDial.value() / 10.0,
            'mlprRandomState': self.MLPrandomStateEntry.text(),
            'mlprShuffle': self.MLPshuffleCheck.isChecked(),
            'mlprSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
            'mlprTolerance': self.MLPtolDial.value() / 100.0,
            'mlprValidationFraction': self.MLPvalidationFractionDial.value() / 10.0,
            'mlprWarmStart': self.MLPwarmStartCheck.isChecked(),
            'mlprWeightOptimizationSolver': self.MLPsolverCombo.currentText(),

            'rfrBootstrap': self.RFbootstrapCheck.isChecked(),
            'rfrCriterion': self.RFcriterionCombo.currentText(),
            'rfrMaximumDepth': self.RFmaxDepthDial.value(),
            'rfrMaximumFeatures': self.RFmaxFeaturesCombo.currentText(),
            'rfrMaximumLeafNodes': self.RFmaxLeafNodesDial.value(),
            'rfrMinimumImpurityDecrease': self.RFminImpurityDecreaseDial.value() / 10.0,
            'rfrMinimumSamplesAtLeaf': self.RFminSamplesLeafDial.value() / 10.0,
            'rfrMinimumSamplesSplit': self.RFminSamplesSplitDial.value() / 10.0,
            'rfrMinimumSumWeightedFraction': self.RFminWeightFractionLeafDial.value() / 10.0,
            'rfrNumberOfTrees': self.RFestimatorsDial.value(),
            'rfrOutOfBagSamples': self.RFoobScoreCheck.isChecked(),
            'rfrRandomState': self.RFrandomStateEntry.text(),
            'rfrWarmStart': self.RFwarmStartCheck.isChecked(),

            'sgdrAlpha': self.SGDalphaDial.value() / 100000,
            'sgdrAverage': self.SGDaverageCheck.isChecked(),
            'sgdrEta0': self.SGDeta0Dial.value() / 10.0,
            'sgdrFitIntercept': self.SGDfitInterceptCheck.isChecked(),
            'sgdrLearningRate': self.SGDlearningRateCombo.currentText(),
            'sgdrLoss': self.SGDlossCombo.currentText(),
            'sgdrL1Ratio': self.SGDl1RatioDial.value() / 10.0,
            'sgdrMaxIterations': self.SGDmaxIterationsDial.value(),
            'sgdrPenalty': self.SGDpenaltyCombo.currentText(),
            'sgdrPowerT': self.SGDpowerTDial.value() / 10.0,
            'sgdrShuffle': self.SGDshuffleCheck.isChecked(),
            'sgdrTolerance': self.SGDtolDial.value() / 100.0,
            'sgdrWarmStart': self.SGDwarmStartCheck.isChecked(),

            'svmrC': dh.nonize(self.SVMCDial.value()),
            # 'svmrCacheSize': self.SVMcacheSizeDial.value(),
            'svmrCoefficient0': self.SVMcoef0Dial.value() / 10.0,
            'svmrEpsilon': self.SVMepsilonDial.value() / 10.0,
            'svmrGamma': self.SVMgammaDial.value(),
            'svmrKernel': self.SVMkernelCombo.currentText(),
            'svmrMaximumIterations': self.SVMmaxIterDial.value(),
            'svmrPolynomialDegree': self.SVMdegreeCombo.currentText(),
            'svmrShrinking': self.SVMshrinkingCheck.isChecked(),
            'svmrTolerance': self.SVMtolDial.value() / 100.0,
        }"""

        return options

    def set_algorithms(self):
        def set_ab_regressor(self):
            layout = self.optionLayouts['Adaptive Boost']
            _, self.ABestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
                layout=layout, row=0, column=0, description=''
            )

            _, self.ABlearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
                layout=layout, row=0, column=1, description=''
            )

            _, self.ABlossCombo = make_pair(
                pair='combo', comboItems=('linear', 'square', 'exponential'), text='Loss:',
                layout=layout, row=0, column=2, pairWidth=100, description=''
            )

            """_, self.ABrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=1, column=1, labelWidth=125, pairWidth=50,
                                                   description=HIDDEN_LAYER_SIZES_DESCRIPTION)"""

        def set_dt_regressor(self):
            layout = self.optionLayouts['Decision Tree']
            _, self.DTcriterionCombo = make_pair(
                pair='combo', comboItems=('mse', 'friedman_mse', 'mae'),
                text='Criterion:', layout=layout, row=0, column=0, labelWidth=200,
                pairWidth=100, description=CRITERION_DESCRIPTION
            )

            _, self.DTmaxDepthDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
                layout=layout, row=0, column=1, labelWidth=125,
                description=MAX_DEPTH_DESCRIPTION
            )

            _, self.DTmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=0, column=2,
                labelWidth=200, pairWidth=50, description=MAX_FEATURES_DESCRIPTION
            )

            _, self.DTmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=1, column=0, labelWidth=200,
                description=MAX_LEAF_NODES_DESCRIPTION
            )

            _, self.DTmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=1, column=1, labelWidth=200,
                description=MAX_LEAF_NODES_DESCRIPTION
            )

            # self.DTminImpurityDecreaseLabel = make_label(self, text='Minimum Impurity Decrease:', layout=self.dtTab,
            #                                             row=30, column=0, width=200,
            #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)
            # self.DTminImpurityDecreaseDial = make_dial(self, layout=self.dtTab,
            #                                             row=30, column=1, width=50,
            #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)

            _, self.DTminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 4, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=1, column=2,
                labelWidth=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
            )

            _, self.DTminSamplesSplitDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Minimum Samples Split:', layout=layout, row=2, column=0,
                labelWidth=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
            )

            _, self.DTminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=2,
                column=1, labelWidth=220,
                description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
            )

            """_, self.DTpresortCheck = make_pair(pair='check',
                                               text='Presort Data:',
                                               layout=layout,
                                               row=1, column=1, labelWidth=200,
                                               description=PRESORT_DESCRIPTION)"""

            """_, self.DTrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=2, column=1, labelWidth=125, pairWidth=50,
                                                   description=RANDOM_STATE_DESCRIPTION)"""

            _, self.DTsplitterCombo = make_pair(
                pair='combo', comboItems=('best', 'random'), text='Splitter:',
                layout=layout, row=2, column=2, pairWidth=75,
                description=SPLITTER_DESCRIPTION
            )

        def set_en_regressor(self):
            layout = self.optionLayouts['Elastic Net']
            _, self.ENalphaDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
                row=1, column=0, description=''
            )

            # self.ENfitInterceptLabel = make_label(self, text='Fit Intercept:', layout=self.layouts['Elastic Net'],
            #                                      row=1, column=0,
            #                                      description='')
            # self.ENfitInterceptCheck = make_button(self, type='check', layout=self.layouts['Elastic Net'],
            #                                       row=1, column=1,
            #                                       description='')

            _, self.ENl1RatioDial = make_pair(
                pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
                row=2, column=0, description=''
            )

            _, self.ENnormalizeCheck = make_pair(
                pair='check', text='Normalize:', layout=layout, row=3, column=0,
                description=''
            )

            _, self.ENpositiveCheck = make_pair(
                pair='check', text='Positive:', layout=layout, row=4, column=0,
                description=''
            )

            _, self.ENselectionCombo = make_pair(
                pair='combo', comboItems=('cyclic', 'random'), text='Selection:',
                layout=layout, row=5, column=0, description=''
            )

            _, self.ENtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=6, column=0, description=''
            )

            _, self.ENwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=7, column=0,
                description=''
            )

        def set_gp_regressor(self):
            layout = self.optionLayouts['Gaussian Process']
            _, self.GPalphaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Alpha:', layout=layout,
                row=1, column=0, description=''
            )

            _, self.GPnormalizeCheck = make_pair(
                pair='check', text='Normalize:', layout=layout, row=2, column=0,
                description=''
            )

            _, self.ABrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=3, column=0,
                labelWidth=125, pairWidth=50, description=''
            )

        def set_knn_regressor(self):
            layout = self.optionLayouts['Nearest Neighbors']
            _, self.KNNalgorithmCombo = make_pair(
                pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
                text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
                description=ALGORITHM_DESCRIPTION
            )

            # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
            # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

            _, self.KNNleafSizeDial = make_pair(
                pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:',
                layout=layout, row=2, column=0, description=LEAF_SIZE_DESCRIPTION
            )

            # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
            # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

            # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
            # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

            _, self.KNNminkowskiPowerDial = make_pair(
                pair='dial', dialSettings=(1, 100, 2, 1), text='Minkowski Power:',
                layout=layout, row=3, column=0, description=P_DESCRIPTION
            )

            _, self.KNNneighborsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 5, 1), text='Number of Neighbors:',
                layout=layout, row=4, column=0, labelWidth=200,
                description=N_NEIGHBORS_DESCRIPTION
            )

            _, self.KNNweightsCombo = make_pair(
                pair='combo', comboItems=('uniform', 'distance'),
                text='Weights Function:', layout=layout, row=5, column=0,
                labelWidth=200, pairWidth=100, description=WEIGHTS_DESCRIPTION
            )

        def set_kr_regressor(self):
            layout = self.optionLayouts['Kernel Ridge']
            _, self.KRalphaDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
                row=1, column=0, description=ALPHA_DESCRIPTION
            )
            _, self.KRcoef0Dial = make_pair(
                pair='dial', dialSettings=(0, 10, 10, 1), text='Coefficient 0:',
                layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
            )

            _, self.KRdegreeCombo = make_pair(
                pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
                layout=layout, row=3, column=0, description=DEGREE_DESCRIPTION
            )

            _, self.KRgammaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
                row=4, column=0, description=GAMMA_DESCRIPTION
            )

            _, self.KRkernelCombo = make_pair(
                pair='combo', comboItems=('linear', 'poly', 'rbf'), text='Kernel:',
                layout=layout, row=5, column=0, description=KERNEL_DESCRIPTION
            )

        def set_mlp_regressor(self):
            layout = self.optionLayouts['Multilayer Perceptron']
            _, self.MLPactivationCombo = make_pair(
                pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
                text='Activation Function:', layout=layout, row=1, column=0,
                labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
            )

            _, self.MLPalphaDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1),
                text='Alpha (Penalty Parameter):', layout=layout, row=2, column=0,
                labelWidth=200, description=MLP_ALPHA_DESCRIPTION
            )

            # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=0, width=200,
            #                                    description=BATCH_SIZE_DESCRIPTION)
            # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=1, width=50,
            #                                    description=BATCH_SIZE_DESCRIPTION)

            _, self.MLPbeta1Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
                column=0, labelWidth=250, description=BETA_1_DESCRIPTION
            )

            _, self.MLPbeta2Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
                column=0, labelWidth=250, description=BETA_2_DESCRIPTION
            )

            _, self.MLPearlyStoppingCheck = make_pair(
                pair='check', text='Early Stopping:', layout=layout, row=5,
                column=0, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
            )

            _, self.MLPepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
                labelWidth=200, description=MLP_EPSILON_DESCRIPTION
            )

            _, self.MLPhiddenLayerSizesEntry = make_pair(
                pair='entry', text='Hidden Layer Sizes:', layout=layout, row=7,
                column=0, labelWidth=200, pairWidth=50,
                description=HIDDEN_LAYER_SIZES_DESCRIPTION
            )

            _, self.MLPinitLearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Initial Learning Rate:', layout=layout, row=8, column=0,
                labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
            )

            _, self.MLPlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
                text='Learning Rate:', layout=layout, row=9, column=0,
                labelWidth=200, pairWidth=100,
                description=LEARNING_RATE_DESCRIPTION
            )

            _, self.MLPmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=10, column=0, labelWidth=250,
                description=MLP_MAX_ITER_DESCRIPTION
            )

            _, self.MLPmomentumDial = make_pair(
                pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
                layout=layout, row=11, column=0, description=MOMENTUM_DESCRIPTION
            )

            _, self.MLPnesterovsMomentumCheck = make_pair(
                pair='check', text='Nesterov\'s Momentum:', layout=layout,
                row=12, column=0, labelWidth=200,
                description=NESTEROVS_MOMENTUM_DESCRIPTION
            )

            _, self.MLPpowerTDial = make_pair(
                pair='dial', dialSettings=(1, 10, 5, 1),
                text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
                labelWidth=250, description=POWER_T_DESCRIPTION
            )

            _, self.MLPrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=14, column=0,
                pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
            )

            _, self.MLPshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=15, column=0,
                description=SHUFFLE_DESCRIPTION
            )

            _, self.MLPsolverCombo = make_pair(
                pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
                text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
                labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
            )

            _, self.MLPtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=17, column=0, description=MLP_TOL_DESCRIPTION
            )

            _, self.MLPvalidationFractionDial = make_pair(
                pair='dial', dialSettings=(1, 9, 9, 1),
                text='Validation Fraction:', layout=layout, row=18, column=0,
                labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
            )

            # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
            # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

            _, self.MLPwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=19, column=0,
                labelWidth=200, description=MLP_WARM_START_DESCRIPTION
            )

        def set_rf_regressor(self):
            layout = self.optionLayouts['Random Forest']
            _, self.RFbootstrapCheck = make_pair(
                pair='check', text='Bootstrap:', layout=layout, row=1, column=0,
                description=BOOTSTRAP_DESCRIPTION
            )

            _, self.RFcriterionCombo = make_pair(
                pair='combo', comboItems=('mse', 'mae'), text='Criterion:',
                layout=layout, row=2, column=0, pairWidth=50,
                description=CRITERION_DESCRIPTION
            )

            _, self.RFmaxDepthDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
                layout=layout, row=3, column=0, description=MAX_DEPTH_DESCRIPTION
            )

            _, self.RFmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=4, column=0,
                labelWidth=200, pairWidth=50, description=MAX_FEATURES_DESCRIPTION
            )

            _, self.RFmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=5, column=0, labelWidth=220,
                description=MAX_LEAF_NODES_DESCRIPTION
            )

            _, self.RFminImpurityDecreaseDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Minimum Impurity Decrease:', layout=layout, row=6,
                column=0, labelWidth=220,
                description=MIN_IMPURITY_DECREASE_DESCRIPTION
            )

            _, self.RFminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=7, column=0,
                labelWidth=220, description=MIN_SAMPLES_LEAF_DESCRIPTION
            )

            _, self.RFminSamplesSplitDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Minimum Samples Split:', layout=layout, row=8, column=0,
                labelWidth=175, description=MIN_SAMPLES_SPLIT_DESCRIPTION
            )

            _, self.RFminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=9,
                column=0, labelWidth=220,
                description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
            )

            _, self.RFestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
                layout=layout, row=10, column=0, labelWidth=200,
                description=N_ESTIMATORS_DESCRIPTION
            )

            _, self.RFoobScoreCheck = make_pair(
                pair='check', text='Out-of-Bag Samples:', layout=layout, row=11,
                column=0, labelWidth=200, description=OOB_SCORE_DESCRIPTION
            )

            # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
            # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)

            # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
            # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
            _, self.RFrandomStateEntry = make_pair(
                pair='entry', text='Random State:', layout=layout, row=12, column=0,
                pairWidth=50, description=RANDOM_STATE_DESCRIPTION
            )

            _, self.RFwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=13, column=0,
                labelWidth=200, description=WARM_START_DESCRIPTION
            )

        def set_sgd_regressor(self):
            layout = self.optionLayouts['Stochastic Gradient Descent']
            _, self.SGDalphaDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout,
                row=1, column=0, description=''
            )

            _, self.SGDaverageCheck = make_pair(
                pair='check', text='Average:', layout=layout, row=2, column=0,
                description=''
            )

            _, self.SGDeta0Dial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout,
                row=3, column=0, description=''
            )

            _, self.SGDfitInterceptCheck = make_pair(
                pair='check', text='Fit Intercept:', layout=layout, row=4,
                column=0, description=''
            )

            _, self.SGDlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
                text='Learning Rate:', layout=layout, row=5, column=0,
                pairWidth=100, description=''
            )

            _, self.SGDlossCombo = make_pair(
                pair='combo', comboItems=(
                    'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
                layout=layout, row=6, column=0, pairWidth=100, description=''
            )

            _, self.SGDl1RatioDial = make_pair(
                pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
                row=7, column=0, description=''
            )

            _, self.SGDmaxIterationsDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1),
                text='Maximum Iterations:', layout=layout, row=8, column=0,
                description=''
            )

            _, self.SGDpenaltyCombo = make_pair(
                pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
                text='Penalty:', layout=layout, row=9, column=0, pairWidth=100,
                description=''
            )

            _, self.SGDpowerTDial = make_pair(
                pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
                row=10, column=0, description=''
            )

            _, self.SGDshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=11, column=0,
                description=''
            )

            _, self.SGDtolDial = make_pair(
                pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:', layout=layout,
                row=12, column=0, description=''
            )

            _, self.SGDwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=13, column=0,
                description=''
            )

        def set_svm_regressor(self):
            layout = self.optionLayouts['Support Vector Machine']
            _, self.SVMCDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
                column=0, description=C_DESCRIPTION
            )

            # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=0,
            #                                    description=CACHE_SIZE_DESCRIPTION)
            # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=1, width=50,
            #                                    description=CACHE_SIZE_DESCRIPTION)

            _, self.SVMcoef0Dial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
                layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
            )

            _, self.SVMdegreeCombo = make_pair(
                pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
                layout=layout, row=3, column=0, pairWidth=100,
                description=DEGREE_DESCRIPTION
            )

            _, self.SVMepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:', layout=layout,
                row=4, column=0, description=EPSILON_DESCRIPTION
            )

            _, self.SVMgammaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
                row=5, column=0, description=GAMMA_DESCRIPTION
            )

            _, self.SVMkernelCombo = make_pair(
                pair='combo',
                comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
                text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
                description=KERNEL_DESCRIPTION
            )

            _, self.SVMmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=7, column=0, labelWidth=200,
                description=MAX_ITER_DESCRIPTION
            )

            _, self.SVMshrinkingCheck = make_pair(
                pair='check', text='Shrinking:', layout=layout, row=8, column=0,
                description=SHRINKING_DESCRIPTION
            )

            _, self.SVMtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=9, column=0, description=TOL_DESCRIPTION
            )

        set_ab_regressor(self)
        set_dt_regressor(self)
        set_en_regressor(self)
        set_gp_regressor(self)
        set_knn_regressor(self)
        set_kr_regressor(self)
        set_mlp_regressor(self)
        set_rf_regressor(self)
        set_sgd_regressor(self)
        set_svm_regressor(self)

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, row=0, column=0,
            width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        mode = self.mode.selectedItems()[0].text().lower()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        data, xKeys, yKeys = dh.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            REGRESSION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
        )
        self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)

    def run(self):
        try:
            mode = self.mode.selectedItems()[0].text().lower()
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            models = self.get_models()
            xLabel = index if mode == 'series' else 'Time Step'
            if self.validate(models, mode):
                x, y, xKeys, yKeys = Regressors.train_nn(dir, index, column, models, mode)
                Regressors.plot_regression(x, y, xLabel=xLabel, yLabel=column, xKeys=xKeys, yKeys=yKeys)
                self.siteContainer = load_browser(
                    self.siteContainer,
                    REGRESSION_GRAPH
                )  # TODO self.results = (dh.denumerify(x, y, xKeys, yKeys), index, column)
        except Exception as e:
            print(e)

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, REGRESSORS_NAMES, REGRESSION_GRAPH, Regressors)
        self.resultsSuffix = ' Regression6 results'

    def graph_raw(self):
        self.results = None
        mode = self.mode.selectedItems()[0].text().lower()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        data, xKeys, yKeys = dh.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            REGRESSION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,),
            colors=(((CONTRASTED_COLOR,),),)
        )
        self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)

    def run(self):
        try:
            mode = self.mode.selectedItems()[0].text().lower()
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            models = self.get_models()
            scaler = self.get_scaler()
            xLabel = index if mode == 'series' else 'Time Step'
            if self.validate(models, mode):
                x, y, xKeys, yKeys = Regressors.train_nn(dir, index, column, models, scaler, mode)
                Regressors.plot_regression(x, y, xLabel=xLabel, yLabel=column, xKeys=xKeys, yKeys=yKeys)
                self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)
                m = [index] if index else []
                for c in y[0][1].columns:
                    m.append(c)  # TODO categorical results are not denumerified yet

                self.results = pd.DataFrame(
                    y[0][1].reset_index().values if index else y[0][1].values, index=x[0][1],
                    columns=m
                )
        except Exception as e:
            print(e)

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        MachineLearningMenu.__init__(self, parent, title, icon, REGRESSORS_NAMES, REGRESSION_GRAPH, Regressors)
        self.analysisMenu = AnalysisMenu(self, 'Analysis', REGRESSION_ICON, REGRESSORS_NAMES)
        self.settingsMenu = SettingsMenu(self, 'Settings', REGRESSION_ICON, REGRESSORS_NAMES)
        self.exportMenu = ExportMenu(self, 'Export', REGRESSION_ICON)
        graph = REGRESSION_GRAPH

        analysisAction = add_action(
            self, command=self.analysisMenu.show, text='Analysis', icon=REGRESSION_ICON,
            description='Select models, scalers, and file reading mode.'
        )
        settingsAction = add_action(
            self, command=self.settingsMenu.show, text='Settings', icon=REGRESSION_ICON,
            description='Change the model hyperparameters.'
        )
        exportAction = add_action(
            self, command=self.exportMenu.show, text='Export', icon=REGRESSION_ICON,
            description='Export results.'
        )

        self.toolbar.addAction(analysisAction)
        self.toolbar.addAction(settingsAction)
        self.toolbar.addAction(exportAction)
        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.toolbar, row=3, column=0,
            description=REGRESSION_RUN_DESCRIPTION
        )
        self.optionLayouts = self.settingsMenu.optionLayouts
        self.set_algorithms()
        self.mode = self.analysisMenu.set_mode()
        set_export_options(self.exportMenu, self.exportMenu.hbox)
        try:
            self.bottomLayout = make_grid(make_frame(self))
            if graph:
                self.siteContainer = make_browser(layout=self.hbox, file=graph)

            self.combos()
            self.settingsMenu.modelParameterSelection.setCurrentRow(0)
        except Exception as e:
            print(e)

    def get_options(self):
        options = {name: None for name in REGRESSORS_NAMES}

        options['Adaptive Boost'] = {
            'learning_rate': self.ABlearningRateDial.value() / 10.0,
            'loss':          self.ABlossCombo.currentText(),
            'n_estimators':  self.ABestimatorsDial.value()
        }

        options['Decision Tree'] = {
            'criterion':                self.DTcriterionCombo.currentText(),
            'max_depth':                self.DTmaxDepthDial.value(),
            'max_features':             self.DTmaxFeaturesCombo.currentText(),
            'max_leaf_nodes':           self.DTmaxLeafNodesDial.value(),
            'min_samples_leaf':         self.DTminSamplesLeafDial.value() / 10.0,
            'min_weight_fraction_leaf': self.DTminWeightFractionLeafDial.value() / 10.0,
            'splitter':                 self.DTsplitterCombo.currentText()
        }

        options['Elastic Net'] = {
            'alpha':      self.ENalphaDial.value() / 10.0,
            'l1_ratio':   self.ENl1RatioDial.value() / 10.0,
            'normalize':  self.ENnormalizeCheck.isChecked(),
            'positive':   self.ENpositiveCheck.isChecked(),
            'selection':  self.ENselectionCombo.currentText(),
            'tol':        self.ENtolDial.value() / 100.0,
            'warm_start': self.ENwarmStartCheck.isChecked()
        }

        options['Gaussian Process'] = {
            'alpha':       self.GPalphaDial.value() / 100.0,
            'normalize_y': self.GPnormalizeCheck.isChecked(),
        }

        options['Nearest Neighbors'] = {
            'algorithm':   self.KNNalgorithmCombo.currentText(),
            'leaf_size':   self.KNNleafSizeDial.value(),
            'n_neighbors': self.KNNneighborsDial.value(),
            'p':           self.KNNminkowskiPowerDial.value(),
            'weights':     self.KNNweightsCombo.currentText(),
        }

        options['Kernel Ridge'] = {
            'alpha':  self.KRalphaDial.value() / 10.0, 'coef0': self.KRcoef0Dial.value() / 10.0,
            'degree': self.KRdegreeCombo.currentText(), 'gamma': self.KRgammaDial.value() / 10.0,
            'kernel': self.KRkernelCombo.currentText()
        }

        options['Multilayer Perceptron'] = {
            'activation':          self.MLPactivationCombo.currentText(),
            'alpha':               self.MLPalphaDial.value() / 100000.0,
            'beta_1':              self.MLPbeta1Dial.value() / 100.0,
            'beta_2':              self.MLPbeta2Dial.value() / 100.0,
            'early_stopping':      self.MLPearlyStoppingCheck.isChecked(),
            'epsilon':             self.MLPepsilonDial.value() / 100.0,
            'hidden_layer_sizes':  self.MLPhiddenLayerSizesEntry.text(),
            'learning_rate':       self.MLPlearningRateCombo.currentText(),
            'learning_rate_init':  self.MLPinitLearningRateDial.value() / 10.0,
            'max_iter':            self.MLPmaxIterDial.value(),
            'momentum':            self.MLPmomentumDial.value() / 10.0,
            'nesterovs_momentum':  self.MLPnesterovsMomentumCheck.isChecked(),
            'power_t':             self.MLPpowerTDial.value() / 10.0,
            'shuffle':             self.MLPshuffleCheck.isChecked(),
            'solver':              self.MLPsolverCombo.currentText(),
            'tol':                 self.MLPtolDial.value() / 100.0,
            'validation_fraction': self.MLPvalidationFractionDial.value() / 10.0,
            'warm_start':          self.MLPwarmStartCheck.isChecked()
        }

        options['Random Forest'] = {
            'bootstrap2':                self.RFbootstrapCheck.isChecked(),
            'criterion':                self.RFcriterionCombo.currentText(),
            'max_depth':                self.RFmaxDepthDial.value(),
            'max_features':             self.RFmaxFeaturesCombo.currentText(),
            'max_leaf_nodes':           self.RFmaxLeafNodesDial.value(),
            'min_samples_leaf':         self.RFminSamplesLeafDial.value() / 10.0,
            'min_samples_split':        self.RFminSamplesSplitDial.value() / 10.0,
            'min_weight_fraction_leaf': self.RFminWeightFractionLeafDial.value() / 10.0,
            'n_estimators':             self.RFestimatorsDial.value(),
            'oob_score':                self.RFoobScoreCheck.isChecked(),
            'warm_start':               self.RFwarmStartCheck.isChecked()
        }

        options['Stochastic Gradient Descent'] = {
            'alpha':         self.SGDalphaDial.value() / 100000,
            'average':       self.SGDaverageCheck.isChecked(),
            'eta0':          self.SGDeta0Dial.value() / 10.0,
            'fit_intercept': self.SGDfitInterceptCheck.isChecked(),
            'learning_rate': self.SGDlearningRateCombo.currentText(),
            'loss':          self.SGDlossCombo.currentText(),
            'l1_ratio':      self.SGDl1RatioDial.value() / 10.0,
            'max_iter':      self.SGDmaxIterationsDial.value(),
            'penalty':       self.SGDpenaltyCombo.currentText(),
            'power_t':       self.SGDpowerTDial.value() / 10.0,
            'shuffle':       self.SGDshuffleCheck.isChecked(),
            'tol':           self.SGDtolDial.value() / 100.0,
            'warm_start':    self.SGDwarmStartCheck.isChecked()
        }

        options['Support Vector Machine'] = {
            'C':         dh.nonize(self.SVMCDial.value()),
            'coef0':     self.SVMcoef0Dial.value() / 10.0,
            'degree':    self.SVMdegreeCombo.currentText(),
            'epsilon':   self.SVMepsilonDial.value() / 10.0,
            'gamma':     self.SVMgammaDial.value(),
            'kernel':    self.SVMkernelCombo.currentText(),
            'max_iter':  self.SVMmaxIterDial.value(),
            'shrinking': self.SVMshrinkingCheck.isChecked(),
            'tol':       self.SVMtolDial.value() / 100.0
        }

        return options

    def set_algorithms(self):
        def set_ab_regressor(self):
            from Utilities.ToolTips.Regression import AdaptiveBoost
            layout = self.optionLayouts['Adaptive Boost']
            _, self.ABestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators',
                layout=layout, row=0, column=0,
                description=AdaptiveBoost.ESTIMATORS_DESCRIPTION
            )

            _, self.ABlearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate',
                layout=layout, row=0, column=1,
                description=AdaptiveBoost.LEARNING_RATE_DESCRIPTION
            )

            _, self.ABlossCombo = make_pair(
                pair='combo', comboItems=('linear', 'square', 'exponential'), text='Loss',
                layout=layout, row=0, column=2, pairWidth=100,
                description=AdaptiveBoost.LOSS_DESCRIPTION
            )

            """_, self.ABrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=1, column=1, labelWidth=125, pairWidth=50,
                                                   description=HIDDEN_LAYER_SIZES_DESCRIPTION)"""

        def set_dt_regressor(self):
            from Utilities.ToolTips.Regression import DecisionTree
            layout = self.optionLayouts['Decision Tree']
            _, self.DTcriterionCombo = make_pair(
                pair='combo', comboItems=('mse', 'friedman_mse', 'mae'),
                text='Criterion:', layout=layout, row=0, column=0, labelWidth=200,
                pairWidth=100, description=DecisionTree.CRITERION_DESCRIPTION
            )

            _, self.DTmaxDepthDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='Maximum Depth:',
                layout=layout, row=0, column=1, labelWidth=125,
                description=DecisionTree.MAX_DEPTH_DESCRIPTION
            )

            _, self.DTmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=0, column=2,
                labelWidth=200, pairWidth=50,
                description=DecisionTree.MAX_FEATURES_DESCRIPTION
            )

            _, self.DTmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=1, column=0, labelWidth=200,
                description=DecisionTree.MAX_LEAF_NODES_DESCRIPTION
            )

            # self.DTminImpurityDecreaseLabel = make_label(self, text='Minimum Impurity Decrease:', layout=self.dtTab,
            #                                             row=30, column=0, width=200,
            #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)
            # self.DTminImpurityDecreaseDial = make_dial(self, layout=self.dtTab,
            #                                             row=30, column=1, width=50,
            #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)

            _, self.DTminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 4, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=1, column=1,
                labelWidth=200,
                description=DecisionTree.MIN_SAMPLES_LEAF_DESCRIPTION
            )

            _, self.DTminSamplesSplitDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Minimum Samples Split:', layout=layout, row=1, column=2,
                labelWidth=150,
                description=DecisionTree.MIN_SAMPLES_SPLIT_DESCRIPTION
            )

            _, self.DTminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 5, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=2,
                column=1, labelWidth=220,
                description=DecisionTree.MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
            )

            """_, self.DTpresortCheck = make_pair(pair='check',
                                               text='Presort Data:',
                                               layout=layout,
                                               row=1, column=1, labelWidth=200,
                                               description=PRESORT_DESCRIPTION)"""

            """_, self.DTrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=2, column=1, labelWidth=125, pairWidth=50,
                                                   description=RANDOM_STATE_DESCRIPTION)"""

            _, self.DTsplitterCombo = make_pair(
                pair='combo', comboItems=('best', 'random'), text='Splitter:',
                layout=layout, row=2, column=2, pairWidth=75,
                description=DecisionTree.SPLITTER_DESCRIPTION
            )

        def set_en_regressor(self):
            layout = self.optionLayouts['Elastic Net']
            _, self.ENalphaDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
                row=0, column=0, description=''
            )

            # self.ENfitInterceptLabel = make_label(self, text='Fit Intercept:', layout=self.layouts['Elastic Net'],
            #                                      row=1, column=0,
            #                                      description='')
            # self.ENfitInterceptCheck = make_button(self, type='check', layout=self.layouts['Elastic Net'],
            #                                       row=1, column=1,
            #                                       description='')

            _, self.ENl1RatioDial = make_pair(
                pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
                row=0, column=1, description=''
            )

            _, self.ENnormalizeCheck = make_pair(
                pair='check', text='Normalize:', layout=layout, row=0, column=2,
                description=''
            )

            _, self.ENpositiveCheck = make_pair(
                pair='check', text='Positive:', layout=layout, row=1, column=0,
                description=''
            )

            _, self.ENselectionCombo = make_pair(
                pair='combo', comboItems=('cyclic', 'random'), text='Selection:',
                layout=layout, row=1, column=1, description=''
            )

            _, self.ENtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=1, column=2, description=''
            )

            _, self.ENwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=2, column=1,
                description=''
            )

        def set_gp_regressor(self):
            layout = self.optionLayouts['Gaussian Process']
            _, self.GPalphaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Alpha:', layout=layout,
                row=0, column=0, description=''
            )

            _, self.GPnormalizeCheck = make_pair(
                pair='check', text='Normalize:', layout=layout, row=0, column=1,
                description=''
            )

            """_, self.ABrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=2, column=0, labelWidth=125, pairWidth=50,
                                                   description='')"""

        def set_knn_regressor(self):
            layout = self.optionLayouts['Nearest Neighbors']
            _, self.KNNalgorithmCombo = make_pair(
                pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
                text='Algorithm:', layout=layout, row=0, column=0, pairWidth=100,
                description=ALGORITHM_DESCRIPTION
            )

            # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
            # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

            _, self.KNNleafSizeDial = make_pair(
                pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:',
                layout=layout, row=0, column=1, description=LEAF_SIZE_DESCRIPTION
            )

            # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
            # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

            # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
            # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

            _, self.KNNminkowskiPowerDial = make_pair(
                pair='dial', dialSettings=(1, 100, 2, 1), text='Minkowski Power:',
                layout=layout, row=0, column=2, description=''
            )

            _, self.KNNneighborsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 5, 1), text='Number of Neighbors:',
                layout=layout, row=1, column=0, labelWidth=200, description=''
            )

            _, self.KNNweightsCombo = make_pair(
                pair='combo', comboItems=('uniform', 'distance'),
                text='Weights Function:', layout=layout, row=1, column=2,
                labelWidth=200, pairWidth=100, description=''
            )

        def set_kr_regressor(self):
            layout = self.optionLayouts['Kernel Ridge']
            _, self.KRalphaDial = make_pair(
                pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
                row=0, column=0, description=ALPHA_DESCRIPTION
            )
            _, self.KRcoef0Dial = make_pair(
                pair='dial', dialSettings=(0, 10, 10, 1), text='Coefficient 0:',
                layout=layout, row=0, column=1, description=''
            )

            _, self.KRdegreeCombo = make_pair(
                pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
                layout=layout, row=0, column=2, description=''
            )

            _, self.KRgammaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
                row=1, column=0, description=GAMMA_DESCRIPTION
            )

            _, self.KRkernelCombo = make_pair(
                pair='combo', comboItems=('linear', 'poly', 'rbf'), text='Kernel:',
                layout=layout, row=1, column=2, description=KERNEL_DESCRIPTION
            )

        def set_mlp_regressor(self):
            layout = self.optionLayouts['Multilayer Perceptron']
            _, self.MLPactivationCombo = make_pair(
                pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
                text='Activation Function:', layout=layout, row=0, column=0,
                labelWidth=200, pairWidth=100, description=''
            )

            _, self.MLPalphaDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1),
                text='Alpha (Penalty Parameter):', layout=layout, row=0, column=1,
                labelWidth=200, description=''
            )

            # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=0, width=200,
            #                                    description=BATCH_SIZE_DESCRIPTION)
            # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
            #                                    row=5, column=1, width=50,
            #                                    description=BATCH_SIZE_DESCRIPTION)

            _, self.MLPbeta1Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=0,
                column=2, labelWidth=250, description=''
            )

            _, self.MLPbeta2Dial = make_pair(
                pair='dial', dialSettings=(1, 100, 99, 1),
                text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=1,
                column=0, labelWidth=250, description=''
            )

            _, self.MLPearlyStoppingCheck = make_pair(
                pair='check', text='Early Stopping:', layout=layout, row=1,
                column=1, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
            )

            _, self.MLPepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Epsilon (Numerical Stability):', layout=layout, row=1, column=2,
                labelWidth=200, description=''
            )

            _, self.MLPhiddenLayerSizesEntry = make_pair(
                pair='entry', text='Hidden Layer Sizes:', layout=layout, row=2,
                column=0, labelWidth=200, pairWidth=50,
                description=HIDDEN_LAYER_SIZES_DESCRIPTION
            )

            _, self.MLPinitLearningRateDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1),
                text='Initial Learning Rate:', layout=layout, row=2, column=1,
                labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
            )

            _, self.MLPlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
                text='Learning Rate:', layout=layout, row=2, column=2,
                labelWidth=200, pairWidth=100,
                description=LEARNING_RATE_DESCRIPTION
            )

            _, self.MLPmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=3, column=0, labelWidth=250, description=''
            )

            _, self.MLPmomentumDial = make_pair(
                pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
                layout=layout, row=3, column=1, description=MOMENTUM_DESCRIPTION
            )

            _, self.MLPnesterovsMomentumCheck = make_pair(
                pair='check', text='Nesterov\'s Momentum:', layout=layout,
                row=3, column=2, labelWidth=200,
                description=NESTEROVS_MOMENTUM_DESCRIPTION
            )

            _, self.MLPpowerTDial = make_pair(
                pair='dial', dialSettings=(1, 10, 5, 1),
                text='Power for Inverse Learning Rate:', layout=layout, row=4, column=0,
                labelWidth=250, description=POWER_T_DESCRIPTION
            )

            """_, self.MLPrandomStateEntry = make_pair(pair='entry',
                                                    text='Random State:',
                                                    layout=layout,
                                                    row=14, column=0, pairWidth=50,
                                                    description=MLP_RANDOM_STATE_DESCRIPTION)"""

            _, self.MLPshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=4, column=1,
                description=SHUFFLE_DESCRIPTION
            )

            _, self.MLPsolverCombo = make_pair(
                pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
                text='Solver (Weight Optimization):', layout=layout, row=4, column=2,
                labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
            )

            _, self.MLPtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=5, column=0, description=''
            )

            _, self.MLPvalidationFractionDial = make_pair(
                pair='dial', dialSettings=(1, 9, 9, 1),
                text='Validation Fraction:', layout=layout, row=5, column=1,
                labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
            )

            # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
            # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

            _, self.MLPwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=5, column=2,
                labelWidth=200, description=''
            )

        def set_rf_regressor(self):
            layout = self.optionLayouts['Random Forest']
            _, self.RFbootstrapCheck = make_pair(
                pair='check', text='Bootstrap:', layout=layout, row=0, column=0,
                description=BOOTSTRAP_DESCRIPTION
            )

            _, self.RFcriterionCombo = make_pair(
                pair='combo', comboItems=('mse', 'mae'), text='Criterion:',
                layout=layout, row=0, column=1, pairWidth=50,
                description=CRITERION_DESCRIPTION
            )

            _, self.RFmaxDepthDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='Maximum Depth:',
                layout=layout, row=0, column=2, description=''
            )

            _, self.RFmaxFeaturesCombo = make_pair(
                pair='combo', comboItems=('auto', 'sqrt', 'log2'),
                text='Maximum Features:', layout=layout, row=1, column=0,
                labelWidth=200, pairWidth=50, description=''
            )

            _, self.RFmaxLeafNodesDial = make_pair(
                pair='dial', dialSettings=(2, 100, 2, 1), text='Maximum Leaf Nodes:',
                layout=layout, row=1, column=1, labelWidth=220, description=''
            )

            _, self.RFminImpurityDecreaseDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1),
                text='Minimum Impurity Decrease:', layout=layout, row=1,
                column=2, labelWidth=220, description=''
            )

            _, self.RFminSamplesLeafDial = make_pair(
                pair='dial', dialSettings=(1, 5, 1, 1),
                text='Minimum Samples at Leaf:', layout=layout, row=2, column=0,
                labelWidth=220, description=''
            )

            _, self.RFminSamplesSplitDial = make_pair(
                pair='dial', dialSettings=(1, 10, 2, 1),
                text='Minimum Samples Split:', layout=layout, row=2, column=1,
                labelWidth=175, description=''
            )

            _, self.RFminWeightFractionLeafDial = make_pair(
                pair='dial', dialSettings=(0, 5, 0, 1),
                text='Minimum Sum Weighted Fraction:', layout=layout, row=2,
                column=2, labelWidth=220, description=''
            )

            _, self.RFestimatorsDial = make_pair(
                pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
                layout=layout, row=3, column=0, labelWidth=200, description=''
            )

            _, self.RFoobScoreCheck = make_pair(
                pair='check', text='Out-of-Bag Samples:', layout=layout, row=3,
                column=1, labelWidth=200, description=''
            )

            # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
            # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)

            # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
            # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
            """_, self.RFrandomStateEntry = make_pair(pair='entry',
                                                   text='Random State:',
                                                   layout=layout,
                                                   row=12, column=0, pairWidth=50,
                                                   description=RANDOM_STATE_DESCRIPTION)"""

            _, self.RFwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=3, column=2,
                labelWidth=200, description=WARM_START_DESCRIPTION
            )

        def set_sgd_regressor(self):
            layout = self.optionLayouts['Stochastic Gradient Descent']
            _, self.SGDalphaDial = make_pair(
                pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout,
                row=0, column=0, description=''
            )

            _, self.SGDaverageCheck = make_pair(
                pair='check', text='Average:', layout=layout, row=0, column=1,
                description=''
            )

            _, self.SGDeta0Dial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout,
                row=0, column=2, description=''
            )

            _, self.SGDfitInterceptCheck = make_pair(
                pair='check', text='Fit Intercept:', layout=layout, row=1,
                column=0, description=''
            )

            _, self.SGDlearningRateCombo = make_pair(
                pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
                text='Learning Rate:', layout=layout, row=1, column=1,
                pairWidth=100, description=''
            )

            _, self.SGDlossCombo = make_pair(
                pair='combo', comboItems=(
                    'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
                layout=layout, row=1, column=2, pairWidth=100, description=''
            )

            _, self.SGDl1RatioDial = make_pair(
                pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
                row=2, column=0, description=''
            )

            _, self.SGDmaxIterationsDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1),
                text='Maximum Iterations:', layout=layout, row=2, column=1,
                description=''
            )

            _, self.SGDpenaltyCombo = make_pair(
                pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
                text='Penalty:', layout=layout, row=2, column=2, pairWidth=100,
                description=''
            )

            _, self.SGDpowerTDial = make_pair(
                pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
                row=3, column=0, description=''
            )

            _, self.SGDshuffleCheck = make_pair(
                pair='check', text='Shuffle:', layout=layout, row=3, column=1,
                description=''
            )

            _, self.SGDtolDial = make_pair(
                pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:', layout=layout,
                row=3, column=2, description=''
            )

            _, self.SGDwarmStartCheck = make_pair(
                pair='check', text='Warm Start:', layout=layout, row=4, column=1,
                description=''
            )

        def set_svm_regressor(self):
            layout = self.optionLayouts['Support Vector Machine']
            _, self.SVMCDial = make_pair(
                pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=0,
                column=0, description=C_DESCRIPTION
            )

            # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=0,
            #                                    description=CACHE_SIZE_DESCRIPTION)
            # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
            #                                    row=5, column=1, width=50,
            #                                    description=CACHE_SIZE_DESCRIPTION)

            _, self.SVMcoef0Dial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
                layout=layout, row=0, column=1, description=''
            )

            _, self.SVMdegreeCombo = make_pair(
                pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
                layout=layout, row=0, column=2, pairWidth=100, description=''
            )

            _, self.SVMepsilonDial = make_pair(
                pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:', layout=layout,
                row=1, column=0, description=EPSILON_DESCRIPTION
            )

            _, self.SVMgammaDial = make_pair(
                pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
                row=1, column=1, description=GAMMA_DESCRIPTION
            )

            _, self.SVMkernelCombo = make_pair(
                pair='combo',
                comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
                text='Kernel:', layout=layout, row=1, column=2, pairWidth=100,
                description=KERNEL_DESCRIPTION
            )

            _, self.SVMmaxIterDial = make_pair(
                pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
                layout=layout, row=2, column=0, labelWidth=200, description=''
            )

            _, self.SVMshrinkingCheck = make_pair(
                pair='check', text='Shrinking:', layout=layout, row=2, column=1,
                description=SHRINKING_DESCRIPTION
            )

            _, self.SVMtolDial = make_pair(
                pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
                row=2, column=2, description=''
            )

        set_ab_regressor(self)
        set_dt_regressor(self)
        set_en_regressor(self)
        set_gp_regressor(self)
        set_knn_regressor(self)
        set_kr_regressor(self)
        set_mlp_regressor(self)
        set_rf_regressor(self)
        set_sgd_regressor(self)
        set_svm_regressor(self)

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, row=0, column=0,
            width=200, description=''
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        self.results = None
        mode = self.mode.selectedItems()[0].text().lower()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        data, xKeys, yKeys = dh.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            REGRESSION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
        )
        self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)

    def run(self):
        try:
            mode = self.mode.selectedItems()[0].text().lower()
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            models = self.get_models()
            scaler = self.get_scaler()
            xLabel = index if mode == 'series' else 'Time Step'
            if self.validate(models, mode):
                x, y, xKeys, yKeys = Regressors.train_nn(dir, index, column, models, scaler, mode)
                Regressors.plot_regression(x, y, xLabel=xLabel, yLabel=column, xKeys=xKeys, yKeys=yKeys)
                self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)
                m = [index] if index else []
                for c in y[0][0].columns:
                    m.append(c)  # TODO categorical results are not denumerified yet

                self.results = pd.DataFrame(
                    y[0][0].reset_index().values if index else y[0][0].values, index=x[0][0],
                    columns=m
                )
        except Exception as e:
            print(e)

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    def run(self):
        try:
            remove_tabs(self.tabs)
            mode, index, column, dir, models, scaler = self.get_parameters()
            inputs = self.get_inputs()
            if len(inputs) == 0:
                inputs = [index]
            if self.validate(models, mode):
                x, y, results, xKeys, yKeys = Regressors.train_nn(
                    self, dir, index, [column] + inputs, column, models,
                    scaler, mode
                )

                if True:
                    m = [index] if index else []
                    for c in x.columns:
                        if c != index:
                            m.append(c)
                    for c in results.columns:
                        m.append(c)  # TODO categorical results are not denumerified yet
                # self.results = pd.DataFrame(results.reset_index().values if index else results.values,
                #                            index=y.index, columns=m)

                for i, input in enumerate(inputs):
                    data, xKeys, yKeys = DataProcessor.process_regression_data(dir, input, column, mode)
                    data = pd.DataFrame(data, columns=(column,), index=data.index)
                    tempPlot = os.path.join(REGRESSION_GRAPHS, 'temp' + str(i) + '.html')
                    tempTab = make_tab(self, input, self.tabs)
                    Regressors.plot_regression(
                        data, results, xLabel=input, yLabel=column, xKeys=xKeys, yKeys=yKeys,
                        file=tempPlot, title=column + ' vs ' + input
                    )
                    tempContainer = make_browser(layout=tempTab, file=tempPlot)
                self.progressBar.setValue(100)
                self.progressBar.setValue(0)

        except Exception as e:
            print(e)

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if DataProcessor.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    def graph_raw(self):
        remove_tabs(self.tabs)
        self.inputsSelection.clear()
        self.inputsSelection.addItems([h for h in self.headers if h != self.columnCombo.currentText()])
        self.results = None

        mode, index, column, dir, _, _ = self.get_parameters()

        data, xKeys, yKeys = DataProcessor.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        DynamicPlotGenerator.make_plot(
            REGRESSION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,),
            lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,),
            yKeys=(yKeys,), colors=(((CONTRASTED_COLOR,),),)
        )
        self.mainPlotContainer = load_browser(self.mainPlotContainer, REGRESSION_GRAPH)

    def run(self):
        try:
            remove_tabs(self.tabs)
            mode, index, column, dir, models, scaler = self.get_parameters()
            inputs = self.get_inputs()
            if len(inputs) == 0:
                inputs = [index]
            if self.validate(models, mode):
                x, y, results, xKeys, yKeys = Regressors.train_nn(
                    dir=dir, columns=[column] + inputs, index=index,
                    target=column, models=models, scaler=scaler, mode=mode
                )

                if True:
                    m = [index] if index else []
                    for c in x.columns:
                        if c != index:
                            m.append(c)
                    for c in results.columns:
                        m.append(c)  # TODO categorical results are not denumerified yet
                # self.results = pd.DataFrame(results.reset_index().values if index else results.values,
                #                            index=y.index, columns=m)

                for i, input in enumerate(inputs):
                    data, xKeys, yKeys = DataProcessor.process_regression_data(dir, input, column, mode)
                    data = pd.DataFrame(data, columns=(column,), index=data.index)
                    tempPlot = os.path.join(REGRESSION_GRAPHS, 'temp' + str(i) + '.html')
                    tempTab = make_tab(self, input, self.tabs)
                    Regressors.plot_regression(
                        data, results, xLabel=input, yLabel=column, xKeys=xKeys, yKeys=yKeys,
                        file=tempPlot, title=column + ' vs ' + input
                    )
                    tempContainer = make_browser(layout=tempTab, file=tempPlot)
                self.progressBar.setValue(100)
                self.progressBar.setValue(0)

        except Exception as e:
            print(e)

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if DataProcessor.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        if True:
            self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
            self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
            top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
            self.readLabel.setText(self.parent.databaseMenu.dataSource)

            self.columnGrid = make_group_box(
                self.container, layout=make_grid(), text='y', row=1, column=2, width=205,
                height=225
            )

            self.indexGrid = make_group_box(
                self.container, layout=make_grid(), text='x', row=0, column=2, width=205,
                height=225
            )

            self.runButton = make_button(
                self, command=self.run, text='Run', layout=self.topRightLayout, row=3,
                column=0, description=RUN_REGRESSION_DESCRIPTION
            )

            self.analysisTab, self.parametersTab, self.exportTab = set_tabs(
                self, ('Analysis', 'Parameters', 'Export'),
                layout=self.topRightLayout
            )

            """ANALYSIS"""
            self.modelSelection = set_models(REGRESSORS_NAMES, self.analysisTab, multiSelect=True)

            self.modeGrid = make_group_box(
                self.analysisTab, layout=make_grid(), text='Mode', row=0, column=1, width=75,
                height=75
            )

            self.mode = make_list(
                items=('Series', 'Parallel'), default=0, layout=self.modeGrid, row=0, column=0,
                width=50, height=36
            )

            self.siteContainer = make_browser(layout=self.bottomLayout, file=REGRESSION_GRAPH)
            try:
                self.combos()
            except Exception as e:
                print(e)
        if True:
            """PARAMETERS"""
            self.modelParameterSelection = set_models(
                REGRESSORS_NAMES, self.parametersTab,
                command=self.set_parameters_layout, multiSelect=False
            )

            self.parametersGrid = make_group_box(
                self.parametersTab, layout=make_grid(), text='Settings', row=0,
                column=1, width=205, height=225
            )

            self.regressionLayouts = {name: make_grid() for name in REGRESSORS_NAMES}
            self.set_regressors()
            self.set_parameters_tab()

            self.autoTuneGrid = make_group_box(
                self.parametersTab, layout=make_grid(), text='Tune', row=0, column=3,
                width=45, height=45
            )

            self.autoCheck = make_button(
                type='check', layout=self.autoTuneGrid,
                description=AUTOMATIC_TUNING_DESCRIPTION
            )

            """EXPORT"""
            set_export_options(self)

    def get_options(self):
        options = {
            'abrEstimators':                    self.ABestimatorsDial.value(),
            'abrLearningRate':                  self.ABlearningRateDial.value() / 10.0,
            'abrLoss':                          self.ABlossCombo.currentText(),

            'dtrCriterion':                     self.DTcriterionCombo.currentText(),
            'dtrMaximumDepth':                  self.DTmaxDepthDial.value(),
            'dtrMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
            'dtrMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
            'dtrMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
            'dtrMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
            'dtrMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
            'dtrPresort':                       self.DTpresortCheck.isChecked(),
            'dtrRandomState':                   self.DTrandomStateEntry.text(),
            'dtrSplitter':                      self.DTsplitterCombo.currentText(),

            'enrAlpha':                         self.ENalphaDial.value() / 10.0,
            # 'enrFitIntercept': self.ENfitInterceptCheck.isChecked(),
            'enrL1Ratio':                       self.ENl1RatioDial.value() / 10.0,
            'enrNormalize':                     self.ENnormalizeCheck.isChecked(),
            'enrPositive':                      self.ENpositiveCheck.isChecked(),
            'enrSelection':                     self.ENselectionCombo.currentText(),
            'enrTolerance':                     self.ENtolDial.value() / 100.0,
            'enrWarmStart':                     self.ENwarmStartCheck.isChecked(),

            'gprAlpha':                         self.GPalphaDial.value() / 100.0,
            # 'gprKernel': self.GPkernelCombo.currentText(),
            'gprNormalize':                     self.GPnormalizeCheck.isChecked(),
            # 'gprOptimizer': self.GPoptimizerCombo.currentText(),

            'knnrAlgorithm':                    self.KNNalgorithmCombo.currentText(),
            'knnrLeafSize':                     self.KNNleafSizeDial.value(),
            'knnrMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
            'knnrNumberOfNeighbors':            self.KNNneighborsDial.value(),
            'knnrWeightsFunction':              self.KNNweightsCombo.currentText(),

            'krrAlpha':                         self.KRalphaDial.value() / 10.0,
            'krrCoefficient0':                  self.KRcoef0Dial.value() / 10.0,
            'krrGamma':                         self.KRgammaDial.value() / 10.0,
            'krrKernel':                        self.KRkernelCombo.currentText(),
            'krrPolynomialDegree':              self.KRdegreeCombo.currentText(),

            'mlprActivationFunction':           self.MLPactivationCombo.currentText(),
            # 'mlprBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
            'mlprEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
            'mlprFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
            'mlprHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
            'mlprInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
            'mlprLearningRate':                 self.MLPlearningRateCombo.currentText(),
            'mlprMaximumIterations':            self.MLPmaxIterDial.value(),
            'mlprMomentum':                     self.MLPmomentumDial.value() / 10.0,
            'mlprNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
            'mlprNumericalStability':           self.MLPepsilonDial.value() / 100.0,
            'mlprPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
            'mlprPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
            'mlprRandomState':                  self.MLPrandomStateEntry.text(),
            'mlprShuffle':                      self.MLPshuffleCheck.isChecked(),
            'mlprSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
            'mlprTolerance':                    self.MLPtolDial.value() / 100.0,
            'mlprValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
            'mlprWarmStart':                    self.MLPwarmStartCheck.isChecked(),
            'mlprWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

            'rfrBootstrap':                     self.RFbootstrapCheck.isChecked(),
            'rfrCriterion':                     self.RFcriterionCombo.currentText(),
            'rfrMaximumDepth':                  self.RFmaxDepthDial.value(),
            'rfrMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
            'rfrMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
            'rfrMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
            'rfrMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
            'rfrMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
            'rfrMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
            'rfrNumberOfTrees':                 self.RFestimatorsDial.value(),
            'rfrOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
            'rfrRandomState':                   self.RFrandomStateEntry.text(),
            'rfrWarmStart':                     self.RFwarmStartCheck.isChecked(),

            'sgdrAlpha':                        self.SGDalphaDial.value() / 100000,
            'sgdrAverage':                      self.SGDaverageCheck.isChecked(),
            'sgdrEta0':                         self.SGDeta0Dial.value() / 10.0,
            'sgdrFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
            'sgdrLearningRate':                 self.SGDlearningRateCombo.currentText(),
            'sgdrLoss':                         self.SGDlossCombo.currentText(),
            'sgdrL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
            'sgdrMaxIterations':                self.SGDmaxIterationsDial.value(),
            'sgdrPenalty':                      self.SGDpenaltyCombo.currentText(),
            'sgdrPowerT':                       self.SGDpowerTDial.value() / 10.0,
            'sgdrShuffle':                      self.SGDshuffleCheck.isChecked(),
            'sgdrTolerance':                    self.SGDtolDial.value() / 100.0,
            'sgdrWarmStart':                    self.SGDwarmStartCheck.isChecked(),

            'svmrC':                            dh.nonize(self.SVMCDial.value()),
            # 'svmrCacheSize': self.SVMcacheSizeDial.value(),
            'svmrCoefficient0':                 self.SVMcoef0Dial.value() / 10.0,
            'svmrEpsilon':                      self.SVMepsilonDial.value() / 10.0,
            'svmrGamma':                        self.SVMgammaDial.value(),
            'svmrKernel':                       self.SVMkernelCombo.currentText(),
            'svmrMaximumIterations':            self.SVMmaxIterDial.value(),
            'svmrPolynomialDegree':             self.SVMdegreeCombo.currentText(),
            'svmrShrinking':                    self.SVMshrinkingCheck.isChecked(),
            'svmrTolerance':                    self.SVMtolDial.value() / 100.0,
        }

        return options

    def set_parameters_tab(self):
        self.parametersSelection = make_scroll_area(self.regressionLayouts['Adaptive Boost'], width=275)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_parameters_layout(self):
        self.parametersGrid.removeWidget(self.parametersSelection)
        self.parametersSelection = make_scroll_area(
            self.regressionLayouts[self.modelParameterSelection.currentItem().text()], width=275
        )
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_regressors(self):
        self.set_ab_regressor()
        self.set_dt_regressor()
        self.set_en_regressor()
        self.set_gp_regressor()
        self.set_knn_regressor()
        self.set_kr_regressor()
        self.set_mlp_regressor()
        self.set_rf_regressor()
        self.set_sgd_regressor()
        self.set_svm_regressor()

    def set_ab_regressor(self):
        layout = self.regressionLayouts['Adaptive Boost']
        _, self.ABestimatorsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
            layout=layout, row=1, column=0, description=''
        )

        _, self.ABlearningRateDial = make_pair(
            pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
            layout=layout, row=2, column=0, description=''
        )

        _, self.ABlossCombo = make_pair(
            pair='combo', comboItems=('linear', 'square', 'exponential'), text='Loss:',
            layout=layout, row=3, column=0, pairWidth=100, description=''
        )

        _, self.ABrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=4, column=0,
            labelWidth=125, pairWidth=50, description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

    def set_dt_regressor(self):
        layout = self.regressionLayouts['Decision Tree']
        _, self.DTcriterionCombo = make_pair(
            pair='combo', comboItems=('mse', 'friedman_mse', 'mae'), text='Criterion:',
            layout=layout, row=1, column=0, labelWidth=200, pairWidth=100,
            description=CRITERION_DESCRIPTION
        )

        _, self.DTmaxDepthDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=2, column=0, labelWidth=125,
            description=MAX_DEPTH_DESCRIPTION
        )

        _, self.DTmaxFeaturesCombo = make_pair(
            pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=3, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        # self.DTminImpurityDecreaseLabel = make_label(self, text='Minimum Impurity Decrease:', layout=self.dtTab,
        #                                             row=30, column=0, width=200,
        #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)
        # self.DTminImpurityDecreaseDial = make_dial(self, layout=self.dtTab,
        #                                             row=30, column=1, width=50,
        #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)

        _, self.DTminSamplesLeafDial = make_pair(
            pair='dial', dialSettings=(1, 4, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=6, column=0,
            labelWidth=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        _, self.DTminSamplesSplitDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=7, column=0,
            labelWidth=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        _, self.DTminWeightFractionLeafDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=8,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        _, self.DTpresortCheck = make_pair(
            pair='check', text='Presort Data:', layout=layout, row=9, column=0,
            labelWidth=200, description=PRESORT_DESCRIPTION
        )

        _, self.DTrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=10, column=0,
            labelWidth=125, pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )

        _, self.DTsplitterCombo = make_pair(
            pair='combo', comboItems=('best', 'random'), text='Splitter:',
            layout=layout, row=11, column=0, pairWidth=75,
            description=SPLITTER_DESCRIPTION
        )

    def set_en_regressor(self):
        layout = self.regressionLayouts['Elastic Net']
        _, self.ENalphaDial = make_pair(
            pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=''
        )

        # self.ENfitInterceptLabel = make_label(self, text='Fit Intercept:', layout=self.layouts['Elastic Net'],
        #                                      row=1, column=0,
        #                                      description='')
        # self.ENfitInterceptCheck = make_button(self, type='check', layout=self.layouts['Elastic Net'],
        #                                       row=1, column=1,
        #                                       description='')

        _, self.ENl1RatioDial = make_pair(
            pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
            row=2, column=0, description=''
        )

        _, self.ENnormalizeCheck = make_pair(
            pair='check', text='Normalize:', layout=layout, row=3, column=0,
            description=''
        )

        _, self.ENpositiveCheck = make_pair(
            pair='check', text='Positive:', layout=layout, row=4, column=0,
            description=''
        )

        _, self.ENselectionCombo = make_pair(
            pair='combo', comboItems=('cyclic', 'random'), text='Selection:',
            layout=layout, row=5, column=0, description=''
        )

        _, self.ENtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=6, column=0, description=''
        )

        _, self.ENwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=7, column=0,
            description=''
        )

    def set_gp_regressor(self):
        layout = self.regressionLayouts['Gaussian Process']
        _, self.GPalphaDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=''
        )

        _, self.GPnormalizeCheck = make_pair(
            pair='check', text='Normalize:', layout=layout, row=2, column=0,
            description=''
        )

        _, self.ABrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=3, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

    def set_knn_regressor(self):
        layout = self.regressionLayouts['Nearest Neighbors']
        _, self.KNNalgorithmCombo = make_pair(
            pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
            text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
            description=ALGORITHM_DESCRIPTION
        )

        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

        _, self.KNNleafSizeDial = make_pair(
            pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:', layout=layout,
            row=2, column=0, description=LEAF_SIZE_DESCRIPTION
        )

        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

        _, self.KNNminkowskiPowerDial = make_pair(
            pair='dial', dialSettings=(1, 100, 2, 1), text='Minkowski Power:',
            layout=layout, row=3, column=0, description=P_DESCRIPTION
        )

        _, self.KNNneighborsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 5, 1), text='Number of Neighbors:',
            layout=layout, row=4, column=0, labelWidth=200,
            description=N_NEIGHBORS_DESCRIPTION
        )

        _, self.KNNweightsCombo = make_pair(
            pair='combo', comboItems=('uniform', 'distance'), text='Weights Function:',
            layout=layout, row=5, column=0, labelWidth=200, pairWidth=100,
            description=WEIGHTS_DESCRIPTION
        )

    def set_kr_regressor(self):
        layout = self.regressionLayouts['Kernel Ridge']
        _, self.KRalphaDial = make_pair(
            pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=ALPHA_DESCRIPTION
        )
        _, self.KRcoef0Dial = make_pair(
            pair='dial', dialSettings=(0, 10, 10, 1), text='Coefficient 0:', layout=layout,
            row=2, column=0, description=COEF0_DESCRIPTION
        )

        _, self.KRdegreeCombo = make_pair(
            pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:', layout=layout,
            row=3, column=0, description=DEGREE_DESCRIPTION
        )

        _, self.KRgammaDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout, row=4,
            column=0, description=GAMMA_DESCRIPTION
        )

        _, self.KRkernelCombo = make_pair(
            pair='combo', comboItems=('linear', 'poly', 'rbf'), text='Kernel:',
            layout=layout, row=5, column=0, description=KERNEL_DESCRIPTION
        )

    def set_mlp_regressor(self):
        layout = self.regressionLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )

        _, self.MLPalphaDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha (Penalty Parameter):',
            layout=layout, row=2, column=0, labelWidth=200,
            description=MLP_ALPHA_DESCRIPTION
        )

        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)

        _, self.MLPbeta1Dial = make_pair(
            pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )

        _, self.MLPbeta2Dial = make_pair(
            pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )

        _, self.MLPearlyStoppingCheck = make_pair(
            pair='check', text='Early Stopping:', layout=layout, row=5, column=0,
            labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )

        _, self.MLPepsilonDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )

        _, self.MLPhiddenLayerSizesEntry = make_pair(
            pair='entry', text='Hidden Layer Sizes:', layout=layout, row=7,
            column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

        _, self.MLPinitLearningRateDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )

        _, self.MLPlearningRateCombo = make_pair(
            pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )

        _, self.MLPmaxIterDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
            layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )

        _, self.MLPmomentumDial = make_pair(
            pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:', layout=layout,
            row=11, column=0, description=MOMENTUM_DESCRIPTION
        )

        _, self.MLPnesterovsMomentumCheck = make_pair(
            pair='check', text='Nesterov\'s Momentum:', layout=layout, row=12,
            column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )

        _, self.MLPpowerTDial = make_pair(
            pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )

        _, self.MLPrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=14, column=0,
            pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )

        _, self.MLPshuffleCheck = make_pair(
            pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )

        _, self.MLPsolverCombo = make_pair(
            pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )

        _, self.MLPtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=17, column=0, description=MLP_TOL_DESCRIPTION
        )

        _, self.MLPvalidationFractionDial = make_pair(
            pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )

        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

        _, self.MLPwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def set_rf_regressor(self):
        layout = self.regressionLayouts['Random Forest']
        _, self.RFbootstrapCheck = make_pair(
            pair='check', text='Bootstrap:', layout=layout, row=1, column=0,
            description=BOOTSTRAP_DESCRIPTION
        )

        _, self.RFcriterionCombo = make_pair(
            pair='combo', comboItems=('mse', 'mae'), text='Criterion:', layout=layout,
            row=2, column=0, pairWidth=50, description=CRITERION_DESCRIPTION
        )

        _, self.RFmaxDepthDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=3, column=0, description=MAX_DEPTH_DESCRIPTION
        )

        _, self.RFmaxFeaturesCombo = make_pair(
            pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=4, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.RFmaxLeafNodesDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Leaf Nodes:',
            layout=layout, row=5, column=0, labelWidth=220,
            description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.RFminImpurityDecreaseDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Impurity Decrease:', layout=layout, row=6, column=0,
            labelWidth=220, description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )

        _, self.RFminSamplesLeafDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=7, column=0,
            labelWidth=220, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        _, self.RFminSamplesSplitDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=8, column=0,
            labelWidth=175, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        _, self.RFminWeightFractionLeafDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=9,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        _, self.RFestimatorsDial = make_pair(
            pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
            layout=layout, row=10, column=0, labelWidth=200,
            description=N_ESTIMATORS_DESCRIPTION
        )

        _, self.RFoobScoreCheck = make_pair(
            pair='check', text='Out-of-Bag Samples:', layout=layout, row=11, column=0,
            labelWidth=200, description=OOB_SCORE_DESCRIPTION
        )

        # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
        # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)

        # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
        # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
        _, self.RFrandomStateEntry = make_pair(
            pair='entry', text='Random State:', layout=layout, row=12, column=0,
            pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )

        _, self.RFwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=13, column=0,
            labelWidth=200, description=WARM_START_DESCRIPTION
        )

    def set_sgd_regressor(self):
        layout = self.regressionLayouts['Stochastic Gradient Descent']
        _, self.SGDalphaDial = make_pair(
            pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout, row=1,
            column=0, description=''
        )

        _, self.SGDaverageCheck = make_pair(
            pair='check', text='Average:', layout=layout, row=2, column=0,
            description=''
        )

        _, self.SGDeta0Dial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout, row=3,
            column=0, description=''
        )

        _, self.SGDfitInterceptCheck = make_pair(
            pair='check', text='Fit Intercept:', layout=layout, row=4, column=0,
            description=''
        )

        _, self.SGDlearningRateCombo = make_pair(
            pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
            text='Learning Rate:', layout=layout, row=5, column=0, pairWidth=100,
            description=''
        )

        _, self.SGDlossCombo = make_pair(
            pair='combo', comboItems=(
                'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
            layout=layout,
            row=6, column=0, pairWidth=100, description=''
        )

        _, self.SGDl1RatioDial = make_pair(
            pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:', layout=layout,
            row=7, column=0, description=''
        )

        _, self.SGDmaxIterationsDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=8, column=0,
            description=''
        )

        _, self.SGDpenaltyCombo = make_pair(
            pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
            text='Penalty:', layout=layout, row=9, column=0, pairWidth=100,
            description=''
        )

        _, self.SGDpowerTDial = make_pair(
            pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
            row=10, column=0, description=''
        )

        _, self.SGDshuffleCheck = make_pair(
            pair='check', text='Shuffle:', layout=layout, row=11, column=0,
            description=''
        )

        _, self.SGDtolDial = make_pair(
            pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:', layout=layout,
            row=12, column=0, description=''
        )

        _, self.SGDwarmStartCheck = make_pair(
            pair='check', text='Warm Start:', layout=layout, row=13, column=0,
            description=''
        )

    def set_svm_regressor(self):
        layout = self.regressionLayouts['Support Vector Machine']
        _, self.SVMCDial = make_pair(
            pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
            column=0, description=C_DESCRIPTION
        )

        # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=0,
        #                                    description=CACHE_SIZE_DESCRIPTION)
        # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=1, width=50,
        #                                    description=CACHE_SIZE_DESCRIPTION)

        _, self.SVMcoef0Dial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:', layout=layout,
            row=2, column=0, description=COEF0_DESCRIPTION
        )

        _, self.SVMdegreeCombo = make_pair(
            pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:', layout=layout,
            row=3, column=0, pairWidth=100, description=DEGREE_DESCRIPTION
        )

        _, self.SVMepsilonDial = make_pair(
            pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:', layout=layout,
            row=4, column=0, description=EPSILON_DESCRIPTION
        )

        _, self.SVMgammaDial = make_pair(
            pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout, row=5,
            column=0, description=GAMMA_DESCRIPTION
        )

        _, self.SVMkernelCombo = make_pair(
            pair='combo', comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
            text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
            description=KERNEL_DESCRIPTION
        )

        _, self.SVMmaxIterDial = make_pair(
            pair='dial', dialSettings=(1, 1000, 100, 1), text='Maximum Iterations:',
            layout=layout, row=7, column=0, labelWidth=200,
            description=MAX_ITER_DESCRIPTION
        )

        _, self.SVMshrinkingCheck = make_pair(
            pair='check', text='Shrinking:', layout=layout, row=8, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMtolDial = make_pair(
            pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=9, column=0, description=TOL_DESCRIPTION
        )

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            items=[''] + self.headers, command=self.update_columns, layout=self.indexGrid,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            items=self.headers, command=self.graph_raw, layout=self.columnGrid, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            items=options, layout=self.columnGrid, command=self.graph_raw, row=0, column=0,
            width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        mode = self.mode.selectedItems()[0].text().lower()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        data, xKeys, yKeys = dh.process_regression_data(dir, index, column, mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            REGRESSION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
        )
        self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)

    def run(self):
        try:
            mode = self.mode.selectedItems()[0].text().lower()
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            models = self.get_models()
            xLabel = index if mode == 'series' else 'Time Step'
            if self.validate(models, mode):
                x, y, xKeys, yKeys = Regressors.train_nn(dir, index, column, models, mode)
                Regressors.plot_regression(x, y, xLabel=xLabel, yLabel=column, xKeys=xKeys, yKeys=yKeys)
                self.siteContainer = load_browser(
                    self.siteContainer,
                    REGRESSION_GRAPH
                )  # TODO self.results = (dh.denumerify(x, y, xKeys, yKeys), index, column)
        except Exception as e:
            print(e)

    def get_models(self):
        checks = [x.text() for x in self.modelSelection.selectedItems()]
        if self.autoCheck.isChecked():
            models = Regressors.cross_validation_regression_models(checks)
        else:
            options = self.get_options()
            models = Regressors.regression_models(checks, options)
        return models

    def validate(self, models, mode):
        error = False
        if len(models) > 0:
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    # TODO must assemble dataframe to prepare export
    def export_results(self):
        dh.export_data(self.results, 'test', self.csvCheck.isChecked())


class ReportMenu(SubMenu):
    def update_preferences(self):
        if self.title == "report_generator0 Settings":
            with open(self.parent.util.MASTERPATH + self.parent.util.r_s_p, "w") as report_settings:
                for i in range(self.settings.__len__()):
                    report_settings.write(str(self.settings[i]) + "\n")

        with open(self.parent.util.MASTERPATH + self.parent.util.temp_r_s_p, "w") as report_settings:
            for i in range(self.settings.__len__()):
                report_settings.write(str(self.settings[i]) + "\n")

    def browse(self):
        path = tkf.askdirectory(parent=self.top, initialdir="/", title='Select Folder')
        self.parent.util.entries[0].delete(0, END)
        self.parent.util.entries[0].insert(
            0,
            path
        )  # path = tkf.asksaveasfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))  # self.parent.util.entries[0].delete(0, END)  # self.parent.util.entries[0].insert(0, path)

    def run(self):
        """self.progress_bar = ttk.Progressbar(self.top, mode='indeterminate', orient=HORIZONTAL)
        self.progress_bar.grid(row=6, column=1, columnspan=3, sticky=W+E)
        self.progress_bar.start(5)"""

        if self.parent.tests.verify_filepath_entry(
            self.parent.util.entries[0].get()
        ) and self.parent.tests.verify_settings_checks(self.settings):
            self.parent.set_filepath(self.parent.util.entries[0].get())  # entries[0] = filepath
            self.update_preferences()
            self.parent.search_resume(self.settings)

    def apply(self):
        self.update_preferences()
        for i in range(4):
            if self.settings[i]:
                self.deselect_check_button(i)
        self.settings[:] = []
        self.top.destroy()

    def populate(self):
        self.settings = [True, False, False, True]
        """Load report preferences"""
        with open(self.util.MASTERPATH + self.util.r_s_p, "r") as report_settings:
            for i, line in enumerate(report_settings):
                self.settings[i] = True if line.strip() == 'True' else False

        if self.title == "search":
            # Entries
            self.util.entry(container=self.top, width=[20], row=[3], column=[2], columnspan=[2], sticky='e')
            self.btxt, self.bcmds, self.brow, self.bcol, self.bstk = ["Select Folder", "Run", "Cancel"], [self.browse,
                                                                                                          self.run,
                                                                                                          self.cancel], [
                3, 5, 5], [4, 4, 1], ['w', 'w', 'e']
            self.ltxt, self.lrow, self.lcol, self.lcolspn, self.lstk = ["CSV:", "Excel:", "Union:", "Intersection:",
                                                                        "Folder path:"], [1, 1, 2, 2, 3], [1, 3, 1, 3,
                                                                                                           1], [3, 3, 1,
                                                                                                                1, 1], [
                                                                                                                           'w'] * 5

        elif self.title == "report_generator0 Settings":
            self.btxt, self.bcmds, self.brow, self.bcol, self.bstk = ["Apply", "Cancel"], [self.apply, self.cancel], [5,
                                                                                                                      5], [
                4, 1], ['w', 'e']
            self.ltxt, self.lrow, self.lcol, self.lcolspn, self.lstk = ["CSV:", "Excel:", "Union:", "Intersection:"], [
                1, 1, 2, 2], [1, 3, 1, 3], [3, 3, 1, 1], ['w'] * 4

        # label
        self.util.name(
            self.top, text=self.ltxt, row=self.lrow, column=self.lcol, columnspan=self.lcolspn,
            sticky=self.lstk
        )
        # Separators
        self.util.separator(container=self.top, orient='h', row=4, column=1, columnspan=4, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=self.btxt, commands=self.bcmds, cursor='hand2', row=self.brow,
            column=self.bcol, sticky=self.bstk
        )
        # Check Buttons
        self.util.check_button(
            container=self.top,
            commands=[(lambda: self.toggle_check_button(0)), (lambda: self.toggle_check_button(1)),
                      (lambda: self.toggle_check_button(2)), (lambda: self.toggle_check_button(3))],
            cursor='left_ptr', row=[1, 1, 2, 2], column=[2, 4, 2, 4], sticky=['e', 'e', 'e', 'e']
        )
        # TODO UNION AND INTERSECTION BUTTONS SHOULD BE RADIO BUTTONS NOT CHECK BUTTONS
        for i in range(4):
            if self.settings[i]:
                self.select_check_button(i)

    def run(self):
        self.parent.set_filepath(self.parent.util.entries[0].get())
        self.update_preferences()
        self.parent.search_resume(self.settings)

    def populate(self):
        self.settings = [True, False, self.util.get_var(self.top, 'bool', None)]
        self.load_preferences()
        if self.title == "search":
            self.util.entry(container=self.top, width=[15], coords=((3, 2),), columnspan=[2], sticky='e')
            btxt, bcmds, bcoords, bstk = SR_BT, [lambda: self.util.select_folder(self), self.run, self.cancel], (
                (3, 4), (5, 4), (5, 1)), ('w', 'w', 'e')
            ltxt, lcoords, lcolspn, lstk = SR_ML, ((1, 1), (1, 3), (3, 1)), (3, 3, 1), ['w'] * 5
        else:
            btxt, bcmds, bcoords, bstk = RP_BT, [self.apply, self.cancel], ((5, 4), (5, 1)), ('w', 'e')
            ltxt, lcoords, lcolspn, lstk = RP_ML, ((1, 1), (1, 3)), (3, 3), ['w'] * 2

        self.util.name(self.top, text=ltxt, coords=lcoords, columnspan=lcolspn, sticky=lstk)
        self.util.separator(container=self.top, orient='h', coords=(4, 1), columnspan=4, sticky='we')
        self.util.button(container=self.top, text=btxt, commands=bcmds, cursor=HAND, coords=bcoords, sticky=bstk)
        self.util.check_button(
            container=self.top,
            commands=[(lambda: self.toggle_check(0)), (lambda: self.toggle_check(1))], cursor=PTR,
            coords=((1, 2), (1, 4)), sticky=['e', 'e']
        )
        self.util.radio_button(
            container=self.top, text=SR_RT, variables=[self.settings[2]] * 2, values=[False, True],
            commands=[(lambda: self.toggle_radio(2, False)), (lambda: self.toggle_radio(2, True))],
            cursor=PTR, coords=((2, 1), (2, 3)), sticky=['w', 'e']
        )

        for i in range(2):
            if self.settings[i]:
                self.select_check(i)
        self.select_radio(self.settings[2].get())

    def apply(self):
        self.update_preferences()
        self.top.destroy()

    def load_preferences(self):
        with open(RSP, "r") as reportSettings:
            for i, line in enumerate(reportSettings):
                if type(self.settings[i]) == bool:
                    self.settings[i] = True if line.strip() == 'True' else False
                else:
                    self.settings[2].set(True if line.strip() == 'True' else False)

    def update_preferences(self):
        if self.title == "report_generator0 Settings":
            with open(RSP, "w") as reportSettings:
                for i in range(self.settings.__len__()):
                    writer(reportSettings, self.settings, i)

        with open(temp_RSP, "w") as reportSettings:
            for i in range(self.settings.__len__()):
                writer(reportSettings, self.settings, i)

    def update_preferences(self):
        if self.title == "report_generator0 Settings":
            with open(MASTER + RSP, "w") as reportSettings:
                for i in range(self.settings.__len__()):
                    reportSettings.write(str(self.settings[i]) + "\n")

        with open(MASTER + temp_RSP, "w") as reportSettings:
            for i in range(self.settings.__len__()):
                reportSettings.write(str(self.settings[i]) + "\n")

    def apply(self):
        self.update_preferences()
        self.top.destroy()

    def populate(self):
        self.settings = [True, False, BooleanVar()]
        self.settings[2].set(False)
        """Load report preferences"""
        with open(MASTER + RSP, "r") as reportSettings:
            for i, line in enumerate(reportSettings):
                if type(self.settings[i]) == bool:
                    self.settings[i] = True if line.strip() == 'True' else False

        if self.title == "search":
            # Entries
            self.util.entry(container=self.top, width=[20], row=[3], column=[2], columnspan=[2], sticky='e')
            self.btxt, self.bcmds, self.brow, self.bcol, self.bstk = ["Select Folder", "Run", "Cancel"], [self.browse,
                                                                                                          self.run,
                                                                                                          self.cancel], [
                3, 5, 5], [4, 4, 1], ['w', 'w', 'e']
            self.ltxt, self.lrow, self.lcol, self.lcolspn, self.lstk = ["CSV:", "Excel:", "Folder path:"], [1, 1, 3], [
                1, 3, 1], [3, 3, 1], ['w'] * 5

        elif self.title == "report_generator0 Settings":
            self.btxt, self.bcmds, self.brow, self.bcol, self.bstk = ["Apply", "Cancel"], [self.apply, self.cancel], [5,
                                                                                                                      5], [
                4, 1], ['w', 'e']
            self.ltxt, self.lrow, self.lcol, self.lcolspn, self.lstk = ["CSV:", "Excel:"], [1, 1], [1, 3], [3, 3], [
                                                                                                                       'w'] * 2

        # label
        self.util.name(
            self.top, text=self.ltxt, row=self.lrow, column=self.lcol, columnspan=self.lcolspn,
            sticky=self.lstk
        )
        # Separators
        self.util.separator(container=self.top, orient='h', row=4, column=1, columnspan=4, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=self.btxt, commands=self.bcmds, cursor='hand2', row=self.brow,
            column=self.bcol, sticky=self.bstk
        )
        # Check Buttons
        self.util.check_button(
            container=self.top,
            commands=[(lambda: self.toggle_check(0)), (lambda: self.toggle_check(1))],
            cursor='left_ptr', row=[1, 1], column=[2, 4], sticky=['e', 'e']
        )

        # Radio Button
        self.util.radio_button(
            container=self.top, text=['Union', 'Intersection'], variables=[self.settings[2]] * 2,
            values=[False, True],
            commands=[(lambda: self.toggle_radio(2, False)), (lambda: self.toggle_radio(2, True))],
            cursor='left_ptr', row=[2, 2], column=[1, 3], sticky=['e', 'e']
        )

        for i in range(2):
            if self.settings[i]:
                self.select_check(i)

    # TODO progress bar decorator
    def run(self):
        # self.progress_bar = ttk.Progressbar(self.top, mode='indeterminate', orient=HORIZONTAL)
        # self.progress_bar.grid(row=6, column=1, columnspan=3, sticky=W+E)
        # self.progress_bar.start(5)
        self.parent.set_filepath(self.parent.util.entries[0].get())
        self.update_preferences()
        self.parent.search_resume(self.settings)

    def populate(self):
        self.settings = [True, False, BooleanVar()]
        # Load report preferences
        with open(RSP, "r") as reportSettings:
            for i, line in enumerate(reportSettings):
                if type(self.settings[i]) == bool:
                    self.settings[i] = True if line.strip() == 'True' else False
                else:
                    self.settings[2].set(True if line.strip() == 'True' else False)

        if self.title == "search":
            # Entries
            self.util.entry(container=self.top, width=[15], row=[3], column=[2], columnspan=[2], sticky='e')
            btxt, bcmds, brow, bcol, bstk = SR_BT, [lambda: select_folder(self), self.run, self.cancel], [3, 5, 5], [4,
                                                                                                                     4,
                                                                                                                     1], [
                'w', 'w', 'e']
            ltxt, lrow, lcol, lcolspn, lstk = SR_ML, [1, 1, 3], [1, 3, 1], [3, 3, 1], ['w'] * 5

        if self.title == "report_generator0 Settings":
            btxt, bcmds, brow, bcol, bstk = RP_BT, [self.apply, self.cancel], [5, 5], [4, 1], ['w', 'e']
            ltxt, lrow, lcol, lcolspn, lstk = RP_ML, [1, 1], [1, 3], [3, 3], ['w'] * 2

        # label
        self.util.name(self.top, text=ltxt, row=lrow, column=lcol, columnspan=lcolspn, sticky=lstk)
        # Separators
        self.util.separator(container=self.top, orient='h', row=4, column=1, columnspan=4, sticky='we')
        # Buttons
        self.util.button(container=self.top, text=btxt, commands=bcmds, cursor=HAND, row=brow, column=bcol, sticky=bstk)
        # Check Buttons
        self.util.check_button(
            container=self.top,
            commands=[(lambda: self.toggle_check(0)), (lambda: self.toggle_check(1))], cursor=PTR,
            row=[1, 1], column=[2, 4], sticky=['e', 'e']
        )

        # Radio Button
        self.util.radio_button(
            container=self.top, text=SR_RT, variables=[self.settings[2]] * 2, values=[False, True],
            commands=[(lambda: self.toggle_radio(2, False)), (lambda: self.toggle_radio(2, True))],
            cursor=PTR, row=[2, 2], column=[1, 3], sticky=['w', 'e']
        )

        for i in range(2):
            if self.settings[i]:
                self.select_check(i)
        self.select_radio(self.settings[2].get())

    def apply(self):
        self.update_preferences()
        self.top.destroy()

    def update_preferences(self):
        if self.title == "report_generator0 Settings":
            with open(RSP, "w") as reportSettings:
                for i in range(self.settings.__len__()):
                    ReportMenu.writer(reportSettings, self.settings, i)

        with open(temp_RSP, "w") as reportSettings:
            for i in range(self.settings.__len__()):
                ReportMenu.writer(reportSettings, self.settings, i)

    @staticmethod
    def writer(file, info, i):
        try:
            file.write(str(info[i].get()) + "\n")
        except:
            file.write(str(info[i]) + "\n")

    def update_preferences(self):
        if self.title == "report_generator0 Settings":
            with open(self.parent.util.MASTERPATH + self.parent.util.r_s_p, "w") as report_settings:
                for i in range(self.settings.__len__()):
                    report_settings.write(str(self.settings[i]) + "\n")

        with open(self.parent.util.MASTERPATH + self.parent.util.temp_r_s_p, "w") as report_settings:
            for i in range(self.settings.__len__()):
                report_settings.write(str(self.settings[i]) + "\n")

    def browse(self):
        path = tkf.asksaveasfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        self.parent.util.entries[0].delete(0, END)
        self.parent.util.entries[0].insert(0, path)

    def run(self):
        """self.progress_bar = ttk.Progressbar(self.top, mode='indeterminate', orient=HORIZONTAL)
        self.progress_bar.grid(row=6, column=1, columnspan=3, sticky=W+E)
        self.progress_bar.start(5)"""

        self.parent.set_filepath(self.parent.util.entries[0].get())  # entries[0] = filepath
        self.update_preferences()
        self.settings[:] = []
        self.parent.search_resume()

    def populate(self):
        self.settings = [True, False, False, True]
        """Load report preferences"""
        with open(self.util.MASTERPATH + self.util.r_s_p, "r") as report_settings:
            for i, line in enumerate(report_settings):
                self.settings[i] = True if line.strip() == 'True' else False

        if self.title == "search":
            # Entries
            self.util.entry(container=self.top, width=[20], row=[3], column=[2], columnspan=[2], sticky='e')
            self.bt, self.bcmds, self.br, self.bc, self.bs = ["Browse", "Run", "Cancel"], [self.browse, self.run,
                                                                                           self.cancel], [3, 5, 5], [4,
                                                                                                                     4,
                                                                                                                     1], [
                'w', 'w', 'e']
            self.lt, self.lr, self.lc, self.lcs, self.ls = ["CSV:", "Dictionary:", "Single file:", "Multiple files:",
                                                            "File path:"], [1, 1, 2, 2, 3], [1, 3, 1, 3, 1], [3, 3, 1,
                                                                                                              1, 1], [
                                                                                                                         'w'] * 5

        elif self.title == "report_generator0 Settings":
            self.bt, self.bcmds, self.br, self.bc, self.bs = ["Apply", "Cancel"], [self.apply, self.cancel], [5, 5], [4,
                                                                                                                      1], [
                'w', 'e']
            self.lt, self.lr, self.lc, self.lcs, self.ls = ["CSV:", "Dictionary:", "Single file:", "Multiple files:"], [
                1, 1, 2, 2], [1, 3, 1, 3], [3, 3, 1, 1], ['w'] * 4

        # label
        self.util.name(self.top, text=self.lt, row=self.lr, column=self.lc, columnspan=self.lcs, sticky=self.ls)
        # Separators
        self.util.separator(container=self.top, orient='h', row=4, column=1, columnspan=4, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=self.bt, commands=self.bcmds, cursor='hand2', row=self.br,
            column=self.bc, sticky=self.bs
        )
        # Check Buttons
        self.util.check_button(
            container=self.top,
            commands=[(lambda: self.toggle_check_button(0)), (lambda: self.toggle_check_button(1)),
                      (lambda: self.toggle_check_button(2)), (lambda: self.toggle_check_button(3))],
            cursor='left_ptr', row=[1, 1, 2, 2], column=[2, 4, 2, 4], sticky=['e', 'e', 'e', 'e']
        )

        for i in range(4):
            if self.settings[i]:
                self.select_check_button(i)

    def update_preferences(self):
        if self.title == "report_generator0 Settings":
            with open(self.parent.util.MASTERPATH + self.parent.util.rSP, "w") as reportSettings:
                for i in range(self.settings.__len__()):
                    reportSettings.write(str(self.settings[i]) + "\n")

        with open(self.parent.util.MASTERPATH + self.parent.util.temp_rSP, "w") as reportSettings:
            for i in range(self.settings.__len__()):
                reportSettings.write(str(self.settings[i]) + "\n")

    def browse(self):
        path = tkf.askdirectory(parent=self.top, initialdir="", title='Select Folder')
        self.parent.util.entries[0].delete(0, END)
        self.parent.util.entries[0].insert(
            0,
            path
        )  # path = tkf.asksaveasfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))  # self.parent.util.entries[0].delete(0, END)  # self.parent.util.entries[0].insert(0, path)

    def run(self):
        # self.progress_bar = ttk.Progressbar(self.top, mode='indeterminate', orient=HORIZONTAL)
        # self.progress_bar.grid(row=6, column=1, columnspan=3, sticky=W+E)
        # self.progress_bar.start(5)
        if self.test.test_entry(self.parent.util.entries[0].get()) and self.test.test_checks(self.settings):
            self.parent.set_filepath(self.parent.util.entries[0].get())  # entries[0] = filepath
            self.update_preferences()
            self.parent.search_resume(self.settings)
        else:
            print("GOOF!")

    def apply(self):
        self.update_preferences()
        for i in range(4):
            if self.settings[i]:
                self.deselect_check_button(i)
        self.top.destroy()

    def populate(self):
        self.settings = [True, False, False, True]
        """Load report preferences"""
        with open(self.util.MASTERPATH + self.util.rSP, "r") as reportSettings:
            for i, line in enumerate(reportSettings):
                self.settings[i] = True if line.strip() == 'True' else False

        if self.title == "search":
            # Entries
            self.util.entry(container=self.top, width=[20], row=[3], column=[2], columnspan=[2], sticky='e')
            self.btxt, self.bcmds, self.brow, self.bcol, self.bstk = ["Select Folder", "Run", "Cancel"], [self.browse,
                                                                                                          self.run,
                                                                                                          self.cancel], [
                3, 5, 5], [4, 4, 1], ['w', 'w', 'e']
            self.ltxt, self.lrow, self.lcol, self.lcolspn, self.lstk = ["CSV:", "Excel:", "Union:", "Intersection:",
                                                                        "Folder path:"], [1, 1, 2, 2, 3], [1, 3, 1, 3,
                                                                                                           1], [3, 3, 1,
                                                                                                                1, 1], [
                                                                                                                           'w'] * 5

        elif self.title == "report_generator0 Settings":
            self.btxt, self.bcmds, self.brow, self.bcol, self.bstk = ["Apply", "Cancel"], [self.apply, self.cancel], [5,
                                                                                                                      5], [
                4, 1], ['w', 'e']
            self.ltxt, self.lrow, self.lcol, self.lcolspn, self.lstk = ["CSV:", "Excel:", "Union:", "Intersection:"], [
                1, 1, 2, 2], [1, 3, 1, 3], [3, 3, 1, 1], ['w'] * 4

        # label
        self.util.name(
            self.top, text=self.ltxt, row=self.lrow, column=self.lcol, columnspan=self.lcolspn,
            sticky=self.lstk
        )
        # Separators
        self.util.separator(container=self.top, orient='h', row=4, column=1, columnspan=4, sticky='we')
        # Buttons
        self.util.button(
            container=self.top, text=self.btxt, commands=self.bcmds, cursor='hand2', row=self.brow,
            column=self.bcol, sticky=self.bstk
        )
        # Check Buttons
        self.util.check_button(
            container=self.top,
            commands=[(lambda: self.toggle_check_button(0)), (lambda: self.toggle_check_button(1)),
                      (lambda: self.toggle_check_button(2)), (lambda: self.toggle_check_button(3))],
            cursor='left_ptr', row=[1, 1, 2, 2], column=[2, 4, 2, 4], sticky=['e', 'e', 'e', 'e']
        )
        # TODO UNION AND INTERSECTION BUTTONS SHOULD BE RADIO BUTTONS NOT CHECK BUTTONS
        for i in range(4):
            if self.settings[i]:
                self.select_check_button(i)


class ReportSettings:
    def update_preferences(self):
        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Report_Preferences.txt",
            "w"
        ) as report_preferences:
            for index in range(self.populator.settings.__len__()):
                report_preferences.write(str(self.populator.settings[index]) + "\n")

        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Temporary_Report_Preferences.txt",
            "w"
        ) as report_preferences:
            for index in range(self.populator.settings.__len__()):
                report_preferences.write(str(self.populator.settings[index]) + "\n")

    def apply(self):
        self.update_preferences()
        self.populator.csv_button.deselect()
        self.populator.machine_button.deselect()
        self.populator.single_file_button.deselect()
        self.populator.multiple_file_button.deselect()
        self.populator.settings[:] = []
        self.populator.top.destroy()

    def cancel(self):
        self.populator.csv_button.deselect()
        self.populator.machine_button.deselect()
        self.populator.single_file_button.deselect()
        self.populator.multiple_file_button.deselect()
        self.populator.settings[:] = []
        self.populator.top.destroy()

    def __init__(self, parent):
        self.parent = parent
        self.top = Toplevel(self.parent.master)
        self.top.title("report_generator0 Preferences")
        self.settings = [True, False, False, True]

        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Report_Preferences.txt",
            "r"
        ) as report_preferences:
            for index, line in enumerate(report_preferences):
                if line.strip() == 'True':
                    self.settings[index] = True
                elif line.strip() == 'False':
                    self.settings[index] = False

        # CSV EXPORT
        label1 = Label(self.top, text="Export as comma separated value (csv) file:")
        label1.grid(row=1, column=1, columnspan=3, sticky=W)

        self.csv_button = Checkbutton(self.top, command=self.toggle_csv, cursor='left_ptr')
        self.csv_button.grid(row=1, column=4, sticky=E)

        # MACHINE LEARNING EXPORT
        label2 = Label(self.top, text="Export as machine learning input file:")
        label2.grid(row=2, column=1, columnspan=3, sticky=W)

        self.machine_button = Checkbutton(self.top, command=self.toggle_machine, cursor='left_ptr')
        self.machine_button.grid(row=2, column=4, sticky=E)

        # SINGLE VS MULTIPLE FILE OUTPUT
        label3 = Label(self.top, text="Single file:")
        label3.grid(row=3, column=1, sticky=W)

        self.single_file_button = Checkbutton(self.top, command=self.toggle_single, cursor='left_ptr')
        self.single_file_button.grid(row=3, column=2, sticky=E)

        label3 = Label(self.top, text="Multiple Files:")
        label3.grid(row=3, column=3, sticky=W)

        self.multiple_file_button = Checkbutton(self.top, command=self.toggle_multiple, cursor='left_ptr')
        self.multiple_file_button.grid(row=3, column=4, sticky=E)

        # SEPARATOR
        separator = ttk.Separator(self.top, orient=HORIZONTAL)
        separator.grid(row=5, column=1, columnspan=5, sticky=W + E)

        apply_button = Button(self.top, text="Apply", command=self.apply, cursor='hand2')
        apply_button.grid(row=6, column=3, sticky=E)

        cancel_button = Button(self.top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=6, column=4, sticky=E)

        if self.settings[0]:
            self.csv_button.select()

        if self.settings[1]:
            self.machine_button.select()

        if self.settings[2]:
            self.single_file_button.select()

        if self.settings[3]:
            self.multiple_file_button.select()

        self.top.grab_set()

    def toggle_csv(self):
        if self.settings[0]:
            self.settings[0] = False
        else:
            self.settings[0] = True

    def toggle_machine(self):
        if self.settings[1]:
            self.settings[1] = False
        else:
            self.settings[1] = True

    def toggle_single(self):
        if self.settings[2]:
            self.settings[2] = False
        else:
            self.settings[2] = True

    def toggle_multiple(self):
        if self.settings[3]:
            self.settings[3] = False
        else:
            self.settings[3] = True

    def update_preferences(self):
        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Report_Preferences.txt",
            "w"
        ) as report_preferences:
            for index in range(self.settings.__len__()):
                report_preferences.write(str(self.settings[index]) + "\n")

        with open(
            self.parent.util.MASTERPATH + "\BridgeDataQuery\\Utilities14\Preferences\Temporary_Report_Preferences.txt",
            "w"
        ) as report_preferences:
            for index in range(self.settings.__len__()):
                report_preferences.write(str(self.settings[index]) + "\n")

    def apply(self):
        self.update_preferences()
        self.csv_button.deselect()
        self.machine_button.deselect()
        self.single_file_button.deselect()
        self.multiple_file_button.deselect()
        self.settings[:] = []
        self.top.destroy()

    def cancel(self):
        self.csv_button.deselect()
        self.machine_button.deselect()
        self.single_file_button.deselect()
        self.multiple_file_button.deselect()
        self.settings[:] = []
        self.top.destroy()


class Results_Menu():
    def __init__(self, ai_model, menuname="Results"):
        app = ResultsMenu(ai_model, menuname)
        app.geometry("%dx%d" % (WIDTH / 2, 3 * HEIGHT / 4))
        ani = animation.FuncAnimation(f, animate, interval=1000)
        app.mainloop()


class Results(tk.Frame):
    def __init__(self, parent, controller, menuname):
        tk.Frame.__init__(self, parent)
        label = tk.Label(self, text=menuname, font=LARGE_FONT)
        label.pack(pady=10, padx=10)
        canvas = FigureCanvasTkAgg(f, self)
        canvas.show()
        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        toolbar = NavigationToolbar2TkAgg(canvas, self)
        toolbar.update()
        canvas._tkcanvas.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        canvas._tkcanvas.pack()


class ResultsMenu(tk.Tk):
    def __init__(self):
        # self.AI_Model = AI_Model
        tk.Tk.__init__(self)

        tk.Tk.iconbitmap(self, default="i.ico")
        tk.Tk.wm_title(self, "Results")
        tk.Tk.minsize(self, width=int(WIDTH / 2), height=int(HEIGHT / 2))
        print(HEIGHT / 2)

        container = tk.Frame(self)
        container.pack(side="top", fill="both", expand=True)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)

        menubar = tk.Menu(container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_command(label="Save")  # , command=lambda:popupmsg("Not supported"))
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)

        # Transition Matrix Probabilities
        menubar.add_command(
            label="Transition Matrix Probabilities",
            command=lambda: self.show_frame(TransitionProbabilitiesPage)
        )

        # DETERIORATION MENU
        deterioration_menu = tk.Menu(menubar, tearoff=1)
        deterioration_menu.add_command(
            label="Raw Data Deterioration Curve",
            command=lambda: self.show_frame(DeteriorationPage)
        )
        deterioration_menu.add_command(
            label="Simulation Deterioration Curve",
            command=lambda: self.show_frame(DeteriorationPage)
        )
        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

        # FREQUENCY MENU
        frequency_menu = tk.Menu(menubar, tearoff=1)
        frequency_menu.add_command(label="Raw Data Histograms", command=lambda: self.show_frame(FrequencyPage))
        frequency_menu.add_command(label="Simulation Histograms", command=lambda: self.show_frame(FrequencyPage))
        frequency_menu.add_command(label="3D Histogram", command=lambda: self.show_frame(FrequencyPage))
        menubar.add_cascade(label="Frequency", menu=frequency_menu)

        tk.Tk.config(self, menu=menubar)

        self.frames = {}

        for F in (StartPage, FrequencyPage, DeteriorationPage, TransitionProbabilitiesPage):
            frame = F(container, self)
            self.frames[F] = frame
            frame.grid(row=0, column=0, sticky="nsew")

        self.show_frame(StartPage)

    def show_frame(self, cont):
        frame = self.frames[cont]
        frame.tkraise()

    def __init__(self, ai_model, menuname):
        self.ai_model = ai_model
        tk.Tk.__init__(self)

        # tk.Tk.iconbitmap(self, default=("\C:\\Users\\frano\PycharmProjects\BridgeDataQuery\interface7\InterfaceUtilities0\icon2\i.ico"))
        tk.Tk.wm_title(self, menuname)
        tk.Tk.minsize(self, width=int(WIDTH / 2), height=int(HEIGHT / 2))

        container = tk.Frame(self)
        container.pack(side="top", fill="both", expand=True)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)

        menubar = tk.Menu(container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_command(label="Save", command=lambda: popup_message("Not supported"))
        filemenu.add_separator()

        #############################################################################

        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)

        # TRANSITION PROBABILITIES MENU
        menubar.add_command(
            label=titles[0],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.model.results, 25, xlim=(1, 25),
                title=titles[0], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # DETERIORATION MENU
        deterioration_menu = tk.Menu(menubar, tearoff=1)

        # Raw Deterioration
        deterioration_menu.add_command(
            label=titles[1],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_summary(), 25,
                ylabel="State", xlim=(1, 25), ylim=(0, 10),
                title=titles[1], color=1, zorder=True
            )
        )

        # Simulation2 Deterioration
        deterioration_menu.add_command(
            label=titles[2],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.model.sub_model.simulation,
                25, ylabel="State", xlim=(1, 25), ylim=(0, 10),
                title=titles[2], color=2, zorder=True
            )
        )

        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

        # FREQUENCY MENU
        frequency_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        frequency_menu.add_command(
            label=titles[3],
            command=lambda: self.show_frame(
                0, 10, self.ai_model.tm_object.get_f_s_1(normalize),
                self.ai_model.vs.__len__(), xlabel="State",
                ylabel="Frequency",
                xlim=(0, self.ai_model.vs.__len__()),
                ylim=(0, 1) if normalize == True else (0,
                                                       int(self.ai_model.tm_object.get_summary().__len__())),
                title=titles[3], color=1,
                legend=[year for year in range(1992, 2017)],
                fill=True
            )
        )

        # Simulation2 Per Year
        frequency_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ),
                self.ai_model.vs.__len__(),
                xlabel="State", ylabel="Frequency",
                xlim=(
                    0, self.ai_model.vs.__len__()),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Raw Per State
        frequency_menu.add_command(
            label=titles[5],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, ylabel="Frequency", xlim=(1, 25), \
                ylim=(0, 1) if normalize == True else ( \
                    0, int(len(self.ai_model.tm_object.get_summary()))),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # Simulation2 Per State
        frequency_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), 25,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # 3D Frequency
        frequency_menu.add_command(
            label=titles[7],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, type=1, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_summary()))),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        menubar.add_cascade(label="Frequency", menu=frequency_menu)

        # HISTOGRAM MENU
        histogram_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        histogram_menu.add_command(
            label=titles[3],
            command=lambda: self.show_frame(
                0, 10, self.ai_model.tm_object.get_f_s_1(normalize),
                self.ai_model.vs.__len__(), type=1, xlabel="State",
                ylabel="Frequency",
                xlim=(0, self.ai_model.vs.__len__()),
                ylim=(0, 1) if normalize == True else (0,
                                                       int(self.ai_model.tm_object.get_summary().__len__())),
                title=titles[3], color=1,
                legend=[year for year in range(1992, 2017)],
                fill=True
            )
        )

        # Simulation2 Per Year
        histogram_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ),
                self.ai_model.vs.__len__(), type=1,
                xlabel="State", ylabel="Frequency",
                xlim=(
                    0, self.ai_model.vs.__len__()),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Raw Per State
        histogram_menu.add_command(
            label=titles[5],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, type=1, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_summary()))),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # Simulation2 Per State
        histogram_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), 25, type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # 3D Histogram
        histogram_menu.add_command(
            label=titles[7],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, type=1, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_summary()))),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        menubar.add_cascade(label="Histogram", menu=histogram_menu)

        #############################################################################

        tk.Tk.config(self, menu=menubar)
        self.frame = Results(container, self, menuname)
        self.frame.grid(row=0, column=0, sticky="nsew")

    def show_frame(
        self, xi, xf, ydata, data_criteria, type=0, xlabel="Time (Years)", ylabel='Probability',
        xlim=(0, 25), ylim=(0, 1), title='', color=0, legend=None, fill=False, zorder=False
    ):
        self.plt = plt.subplot2grid((6, 4), (0, 0), rowspan=5, colspan=4)
        # self.simulation = plt.subplot2grid((6, 3), (5, 0), rowspan=2, colspan=3,sharex=self.raw_data)
        # raw_data_deterioration.clear()
        # simulation_deterioration.clear()
        # self.raw_data.clear()

        for index, curve in enumerate(ydata):
            # print(index)
            if curve.__len__() == data_criteria:
                if type == 0:
                    self.plt.plot(
                        [x for x in range(xi, xf)], curve, colors[color][index % len(colors[color])],
                        marker=mark[index % len(mark)], markersize=2, fillstyle=fill_style[index % len(mark)],
                        dashes=dash[index % len(dash)]
                    )
                    if fill:
                        self.plt.fill_between(
                            [x for x in range(xi, xf)], 0, curve,
                            facecolors=colors[color][index % colors[color].__len__()], alpha=0.5
                        )
                    if zorder:
                        pass  # self.plt.set_zorder(index)

                elif type == 1:
                    self.plt.hist(
                        curve, bins=int(self.ai_model.vs.__len__()),
                        histtype='bar'
                    )  # button1 = ttk.Button(self, text="Back to Home", command=lambda: controller.show_frame(StartPage))  # button1.pack()

        if legend is not None:
            self.plt.legend(legend, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.5)

        # self.simulation.plot0(y, [0, 1, 3, 6], 'teal', label="Simulation2")
        # self.raw_data.legend(bbox_to_anchor=(0, 6, 1, 0.102), loc=2, ncol=2, borderaxespad=0)

        self.plt.set_title(title)
        self.plt.set_xlabel(xlabel)
        self.plt.set_ylabel(ylabel)
        self.plt.set_xlim(xlim)
        self.plt.set_ylim(ylim)
        self.plt.axes.set_xticks([v for v in range(1, data_criteria + 1)])
        self.frame.tkraise()
        self.geometry("%dx%d" % (WIDTH / 2, 3 * HEIGHT / 4))
        animation.FuncAnimation(f, animate, interval=100)

    def __init__(self, ai_model, menuname):
        self.ai_model = ai_model
        tk.Tk.__init__(self)
        # tk.Tk.iconbitmap(self, default=("\C:\\Users\\frano\PycharmProjects\BridgeDataQuery\Interface\InterfaceUtilities\Icons\i.ico"))
        tk.Tk.wm_title(self, menuname)
        tk.Tk.minsize(self, width=int(WIDTH / 2), height=int(HEIGHT / 2))
        container = tk.Frame(self)
        container.pack(side="top", fill="both", expand=True)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)
        menubar = tk.Menu(container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_command(label="Save", command=lambda: popup_message("Not supported"))
        filemenu.add_separator()
        #############################################################################
        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)
        # TRANSITION PROBABILITIES MENU
        menubar.add_command(
            label=titles[0],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.model.results, 25, xlim=(1, 25),
                title=titles[0], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )
        deterioration_menu = tk.Menu(menubar, tearoff=1)
        # Raw Deterioration
        deterioration_menu.add_command(
            label=titles[1],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_summary(), 25,
                ylabel="State", xlim=(1, 25), ylim=(0, 10),
                title=titles[1], color=1, zorder=True
            )
        )
        # Simulation Deterioration
        deterioration_menu.add_command(
            label=titles[2],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.model.sub_model.simulation,
                25, ylabel="State", xlim=(1, 25), ylim=(0, 10),
                title=titles[2], color=2, zorder=True
            )
        )
        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)
        frequency_menu = tk.Menu(menubar, tearoff=1)
        # Raw Per Year
        frequency_menu.add_command(
            label=titles[3],
            command=lambda: self.show_frame(
                0, 10, self.ai_model.tm_object.get_f_s_1(normalize),
                len(self.ai_model.vs), xlabel="State",
                ylabel="Frequency", xlim=(0, len(self.ai_model.vs)),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_summary()))),
                title=titles[3], color=1,
                legend=[year for year in range(1992, 2017)],
                fill=True
            )
        )
        # Simulation Per Year
        frequency_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ),
                len(self.ai_model.vs),
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(
                    0, 1) if normalize == True else (0,
                                                     int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )
        # Raw Per State
        frequency_menu.add_command(
            label=titles[5],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (0, int(
                    len(
                        self.ai_model.tm_object.get_summary()
                    )
                )),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )
        # Simulation Per State
        frequency_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), 25,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(
                    0, 1) if normalize == True else (0,
                                                     int(self.ai_model.iterations.get())),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )
        # 3D Frequency
        frequency_menu.add_command(
            label=titles[7],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, type=1, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (0, int(
                    len(
                        self.ai_model.tm_object.get_summary()
                    )
                )),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )
        menubar.add_cascade(label="Frequency", menu=frequency_menu)
        histogram_menu = tk.Menu(menubar, tearoff=1)
        # Raw Per Year
        histogram_menu.add_command(
            label=titles[3],
            command=lambda: self.show_frame(
                0, 10, self.ai_model.tm_object.get_f_s_1(normalize),
                len(self.ai_model.vs), type=1, xlabel="State",
                ylabel="Frequency", xlim=(0, len(self.ai_model.vs)),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_h()))),
                title=titles[3], color=1,
                legend=[year for year in range(1992, 2017)],
                fill=True
            )
        )
        # Simulation Per Year
        histogram_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ),
                len(self.ai_model.vs), type=1,
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(
                    0, 1) if normalize == True else (0,
                                                     int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )
        # Raw Per State
        histogram_menu.add_command(
            label=titles[5],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, type=1, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (0, int(
                    len(
                        self.ai_model.tm_object.get_summary()
                    )
                )),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )
        # Simulation Per State
        histogram_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), 25, type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(
                    0, 1) if normalize == True else (0,
                                                     int(self.ai_model.iterations.get())),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )
        # 3D Histogram
        histogram_menu.add_command(
            label=titles[7],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, type=1, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (0, int(
                    len(
                        self.ai_model.tm_object.get_summary()
                    )
                )),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )
        menubar.add_cascade(label="Histogram", menu=histogram_menu)
        #############################################################################
        tk.Tk.config(self, menu=menubar)
        self.frame = Results(container, self, menuname)
        self.frame.grid(row=0, column=0, sticky="nsew")

    def __init__(self, ai_model, menuname="Results"):
        app = ResultsMenu(ai_model, menuname)
        app.geometry("%dx%d" % (WIDTH / 2, 3 * HEIGHT / 4))
        ani = animation.FuncAnimation(f, animate, interval=1000)
        app.mainloop()

    def __init__(self):
        # self.AI_Model = AI_Model
        tk.Tk.__init__(self)

        tk.Tk.iconbitmap(self, default="i.ico")
        tk.Tk.wm_title(self, "Results")
        tk.Tk.minsize(self, width=int(WIDTH / 2), height=int(HEIGHT / 2))
        print(HEIGHT / 2)

        container = tk.Frame(self)
        container.pack(side="top", fill="both", expand=True)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)

        menubar = tk.Menu(container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_command(label="Save")  # , command=lambda:popupmsg("Not supported"))
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)

        # Transition Matrix Probabilities
        menubar.add_command(
            label="Transition Matrix Probabilities",
            command=lambda: self.show_frame(TransitionProbabilitiesPage)
        )

        # DETERIORATION MENU
        deterioration_menu = tk.Menu(menubar, tearoff=1)
        deterioration_menu.add_command(
            label="Raw Data Deterioration Curve",
            command=lambda: self.show_frame(DeteriorationPage)
        )
        deterioration_menu.add_command(
            label="Simulation2 Deterioration Curve",
            command=lambda: self.show_frame(DeteriorationPage)
        )
        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

        # FREQUENCY MENU
        frequency_menu = tk.Menu(menubar, tearoff=1)
        frequency_menu.add_command(label="Raw Data Histograms", command=lambda: self.show_frame(FrequencyPage))
        frequency_menu.add_command(label="Simulation2 Histograms", command=lambda: self.show_frame(FrequencyPage))
        frequency_menu.add_command(label="3D Histogram", command=lambda: self.show_frame(FrequencyPage))
        menubar.add_cascade(label="Frequency", menu=frequency_menu)

        tk.Tk.config(self, menu=menubar)

        self.frames = {}

        for F in (StartPage, FrequencyPage, DeteriorationPage, TransitionProbabilitiesPage):
            frame = F(container, self)
            self.frames[F] = frame
            frame.grid(row=0, column=0, sticky="nsew")

        self.show_frame(StartPage)

    def show_frame(self, cont):
        frame = self.frames[cont]
        frame.tkraise()

    def __init__(self):
        # self.AI_Model = AI_Model
        tk.Tk.__init__(self)
        tk.Tk.iconbitmap(self, default="i.ico")
        tk.Tk.wm_title(self, "Results")
        tk.Tk.minsize(self, width=int(WIDTH / 2), height=int(HEIGHT / 2))
        print(HEIGHT / 2)
        container = tk.Frame(self)
        container.pack(side="top", fill="both", expand=True)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)
        menubar = tk.Menu(container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_command(label="Save")  # , command=lambda:popupmsg("Not supported"))
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)
        # Transition Matrix Probabilities
        menubar.add_command(
            label="Transition Matrix Probabilities",
            command=lambda: self.show_frame(TransitionProbabilitiesPage)
        )
        # DETERIORATION MENU
        deterioration_menu = tk.Menu(menubar, tearoff=1)
        deterioration_menu.add_command(
            label="Raw Data Deterioration Curve",
            command=lambda: self.show_frame(DeteriorationPage)
        )
        deterioration_menu.add_command(
            label="Simulation2 Deterioration Curve",
            command=lambda: self.show_frame(DeteriorationPage)
        )
        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)
        # FREQUENCY MENU
        frequency_menu = tk.Menu(menubar, tearoff=1)
        frequency_menu.add_command(label="Raw Data Histograms", command=lambda: self.show_frame(FrequencyPage))
        frequency_menu.add_command(label="Simulation2 Histograms", command=lambda: self.show_frame(FrequencyPage))
        frequency_menu.add_command(label="3D Histogram", command=lambda: self.show_frame(FrequencyPage))
        menubar.add_cascade(label="Frequency", menu=frequency_menu)
        tk.Tk.config(self, menu=menubar)
        self.frames = {}
        for F in (StartPage, FrequencyPage, DeteriorationPage, TransitionProbabilitiesPage):
            frame = F(container, self)
            self.frames[F] = frame
            frame.grid(row=0, column=0, sticky="nsew")
        self.show_frame(StartPage)

    def show_frame(self, cont):
        frame = self.frames[cont]
        frame.tkraise()

    def __init__(self, ai_model, menuname):
        self.ai_model = ai_model
        self.model = ai_model.model
        self.sampler = ai_model.model.sampler
        #############################################################################
        tk.Tk.__init__(self)
        # tk.Tk.iconbitmap(self, default=("\C:\\Users\\frano\PycharmProjects\BridgeDataQuery\interface7\InterfaceUtilities0\icon2\i.ico"))
        tk.Tk.wm_title(self, menuname)
        tk.Tk.minsize(self, width=int(WIDTH / 2), height=int(HEIGHT / 2))
        container = ttk.Frame(self)
        container.pack(side="top", fill="both", expand=True)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)
        menubar = tk.Menu(container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_command(label="Run", command=lambda: popup_message("What are you running from?"))
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)
        #############################################################################
        self.transition_probabilities_menu(menubar)
        self.deterioration_menu(menubar)
        self.frequency_menu(menubar)
        self.histogram_menu(menubar)
        tk.Tk.config(self, menu=menubar)
        self.frame = Results(container, self, menuname)
        self.frame.grid(row=0, column=0, sticky="nsew")
        self.cx = (1, len(self.ai_model.model.data.columns))
        self.cy = (0, len(self.ai_model.vs))

    def transition_probabilities_menu(self, menubar):
        menubar.add_command(
            label=titles[0], command=lambda: self.plotgif(
                ydata=self.model.pdf.as_matrix(), tc=0,
                legend=self.sampler.legendLabels, fill=True
            )
        )

    def deterioration_menu(self, menubar):
        deterioration_menu = tk.Menu(menubar, tearoff=1)

        # Raw Deterioration
        deterioration_menu.add_command(
            label=titles[1],
            command=lambda: self.plotgif(
                ydata=self.model.data.as_matrix(), tc=1,
                labels=("Time (Years)", "State"), yLim=self.cy
            )
        )

        # Simulation2 Deterioration
        deterioration_menu.add_command(
            label=titles[2],
            command=lambda: self.plotgif(
                ydata=self.sampler.simulation, tc=2,
                labels=("Time (Years)", "State"), yLim=self.cy
            )
        )

        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

    def frequency_menu(self, menubar):
        frequency_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        frequency_menu.add_command(
            label=titles[3], command=lambda: self.show_frame(
                xi=0, xf=len(self.ai_model.vs),
                ydata=self.ai_model.model.tm_object.get_f_s_1(
                    normalize
                ), xlabel="State",
                ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_summary()
                        )
                    )),
                title=titles[3], color=1,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Simulation2 Per Year
        frequency_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                xi=0, xf=len(self.ai_model.vs),
                ydata=self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ), xlabel="State",
                ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Raw Per State
        frequency_menu.add_command(
            label=titles[5], command=lambda: self.show_frame(
                xi=1, xf=26,
                ydata=self.ai_model.model.tm_object.get_f_s_2(
                    normalize
                ), ylabel="Frequency",
                xlim=(1, 25), ylim=(
                    0, 1) if normalize == True else (0, int(len(self.ai_model.model.tm_object.get_summary()))),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legendLabels,
                fill=True
            )
        )

        # Simulation2 Per State
        frequency_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                xi=1, xf=26,
                ydata=self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), ylabel="Frequency",
                xlim=(1, 25), ylim=(
                    0, 1) if normalize == True else (0, int(self.ai_model.iterations.get())), title=titles[6], color=0,
                legend=self.ai_model.model.sub_model.legendLlabels,
                fill=True
            )
        )

        # 3D Frequency
        frequency_menu.add_command(
            label=titles[7], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.tm_object.get_f_s_2(
                    normalize
                ), type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_summary()
                        )
                    )),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legendLabels,
                fill=True
            )
        )

        menubar.add_cascade(label="Frequency", menu=frequency_menu)

    def histogram_menu(self, menubar):
        histogram_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        histogram_menu.add_command(
            label=titles[3], command=lambda: self.show_frame(
                0, len(self.ai_model.vs),
                self.ai_model.model.tm_object.get_f_s_1(
                    normalize
                ), type=1,
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_h()
                        )
                    )),
                title=titles[3], color=1,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Simulation2 Per Year
        histogram_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                0, len(self.ai_model.vs),
                self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ), type=1,
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Raw Per State
        histogram_menu.add_command(
            label=titles[5], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.tm_object.get_f_s_2(
                    normalize
                ), type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_summary()
                        )
                    )),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legendLabels,
                fill=True
            )
        )

        # Simulation2 Per State
        histogram_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[6], color=0,
                legend=self.ai_model.model.sub_model.legendLabels,
                fill=True
            )
        )

        # 3D Histogram
        histogram_menu.add_command(
            label=titles[7], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.tm_object.get_f_s_2(
                    normalize
                ), type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_summary()
                        )
                    )),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legendLabels,
                fill=True
            )
        )

        menubar.add_cascade(label="Histogram", menu=histogram_menu)

    def show_frame(self):
        self.frame.tkraise()
        self.geometry("%dx%d" % (WIDTH / 2, 3 * HEIGHT / 4))
        animation.FuncAnimation(f, animate, interval=100)

    def plotgif(
        self, ydata, type=0, labels=('Time (Years)', 'Probability'), yLim=(0, 1), tc=0,
        # tc = title and color index
        legend=None, fill=False
    ):
        plot = plt.subplot2grid((6, 4), (0, 0), rowspan=5, colspan=4)

        for index, curve in enumerate(ydata):
            # Line Plot
            if type == 0:
                xLim = self.cx
                rx = (1, 26)
                PlotGenerator.plot_curve(plot, index, curve, tc, rx, fill)
                PlotGenerator.plot_configure(plot, legend, titles[tc], labels[0], labels[1], xLim, yLim, rx)
            # Histogram
            elif type == 1:
                PlotGenerator.plot_histogram(plot, curve, bins=int(len(self.ai_model.vs)))

        self.show_frame()

    def __init__(self, ai_model, menuname):
        self.ai_model = ai_model
        tk.Tk.__init__(self)

        # tk.Tk.iconbitmap(self, default=("\C:\\Users\\frano\PycharmProjects\BridgeDataQuery\interface7\InterfaceUtilities0\icon2\i.ico"))
        tk.Tk.wm_title(self, menuname)
        tk.Tk.minsize(self, width=int(WIDTH / 2), height=int(HEIGHT / 2))

        container = tk.Frame(self)
        container.pack(side="top", fill="both", expand=True)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)

        menubar = tk.Menu(container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_command(label="Save", command=lambda: popup_message("Not supported"))
        filemenu.add_separator()

        #############################################################################

        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)

        # TRANSITION PROBABILITIES MENU
        menubar.add_command(
            label=titles[0],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.model.results, 25, xlim=(1, 25),
                title=titles[0], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # DETERIORATION MENU
        deterioration_menu = tk.Menu(menubar, tearoff=1)

        # Raw Deterioration
        deterioration_menu.add_command(
            label=titles[1],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_summary(), 25,
                ylabel="State", xlim=(1, 25), ylim=(0, 10),
                title=titles[1], color=1, zorder=True
            )
        )

        # Simulation2 Deterioration
        deterioration_menu.add_command(
            label=titles[2],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.model.sub_model.simulation,
                25, ylabel="State", xlim=(1, 25), ylim=(0, 10),
                title=titles[2], color=2, zorder=True
            )
        )

        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

        # FREQUENCY MENU
        frequency_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        frequency_menu.add_command(
            label=titles[3],
            command=lambda: self.show_frame(
                0, 10, self.ai_model.tm_object.get_f_s_1(normalize),
                len(self.ai_model.vs), xlabel="State",
                ylabel="Frequency", xlim=(0, len(self.ai_model.vs)),
                ylim=(0, 1) if normalize == True else (0, int(
                    len(
                        self.ai_model.tm_object.get_summary()
                    )
                )),
                title=titles[3], color=1,
                legend=[year for year in range(1992, 2017)],
                fill=True
            )
        )

        # Simulation2 Per Year
        frequency_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ),
                len(self.ai_model.vs),
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Raw Per State
        frequency_menu.add_command(
            label=titles[5],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_summary()))),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # Simulation2 Per State
        frequency_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), 25,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # 3D Frequency
        frequency_menu.add_command(
            label=titles[7],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, type=1, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_summary()))),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        menubar.add_cascade(label="Frequency", menu=frequency_menu)

        # HISTOGRAM MENU
        histogram_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        histogram_menu.add_command(
            label=titles[3],
            command=lambda: self.show_frame(
                0, 10, self.ai_model.tm_object.get_f_s_1(normalize),
                len(self.ai_model.vs), type=1, xlabel="State",
                ylabel="Frequency", xlim=(0, len(self.ai_model.vs)),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_h()))),
                title=titles[3], color=1,
                legend=[year for year in range(1992, 2017)],
                fill=True
            )
        )

        # Simulation2 Per Year
        histogram_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ),
                len(self.ai_model.vs), type=1,
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Raw Per State
        histogram_menu.add_command(
            label=titles[5],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, type=1, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_summary()))),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # Simulation2 Per State
        histogram_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), 25, type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # 3D Histogram
        histogram_menu.add_command(
            label=titles[7],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.tm_object.get_f_s_2(normalize),
                25, type=1, ylabel="Frequency", xlim=(1, 25),
                ylim=(0, 1) if normalize == True else (
                    0, int(len(self.ai_model.tm_object.get_summary()))),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        menubar.add_cascade(label="Histogram", menu=histogram_menu)

        #############################################################################

        tk.Tk.config(self, menu=menubar)
        self.frame = Results(container, self, menuname)
        self.frame.grid(row=0, column=0, sticky="nsew")

    def __init__(self, ai_model, menuname):
        self.ai_model = ai_model
        tk.Tk.__init__(self)

        # tk.Tk.iconbitmap(self, default=("\C:\\Users\\frano\PycharmProjects\BridgeDataQuery\interface7\InterfaceUtilities0\icon2\i.ico"))
        tk.Tk.wm_title(self, menuname)
        tk.Tk.minsize(self, width=int(WIDTH / 2), height=int(HEIGHT / 2))

        container = ttk.Frame(self)
        container.pack(side="top", fill="both", expand=True)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)

        menubar = tk.Menu(container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_command(label="Save", command=lambda: popup_message("Not supported"))
        filemenu.add_separator()

        #############################################################################

        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)

        # TRANSITION PROBABILITIES MENU
        menubar.add_command(
            label=titles[0],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.model.results, 25, xlim=(1, 25),
                title=titles[0], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # DETERIORATION MENU
        deterioration_menu = tk.Menu(menubar, tearoff=1)

        # Raw Deterioration
        deterioration_menu.add_command(
            label=titles[1], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.tm_object.get_summary(),
                25, ylabel="State",
                xlim=(1, 25), ylim=(0, 10),
                title=titles[1], color=1,
                zorder=True
            )
        )

        # Simulation2 Deterioration
        deterioration_menu.add_command(
            label=titles[2],
            command=lambda: self.show_frame(
                1, 26, self.ai_model.model.sub_model.simulation,
                25, ylabel="State", xlim=(1, 25), ylim=(0, 10),
                title=titles[2], color=2, zorder=True
            )
        )

        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

        # FREQUENCY MENU
        frequency_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        frequency_menu.add_command(
            label=titles[3], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.tm_object.get_f_s_1(
                    normalize
                ),
                len(self.ai_model.vs),
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_summary()
                        )
                    )),
                title=titles[3], color=1,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Simulation2 Per Year
        frequency_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ),
                len(self.ai_model.vs),
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Raw Per State
        frequency_menu.add_command(
            label=titles[5], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.tm_object.get_f_s_2(
                    normalize
                ), 25,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_summary()
                        )
                    )),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # Simulation2 Per State
        frequency_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), 25,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[6], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # 3D Frequency
        frequency_menu.add_command(
            label=titles[7], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.tm_object.get_f_s_2(
                    normalize
                ), 25, type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_summary()
                        )
                    )),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        menubar.add_cascade(label="Frequency", menu=frequency_menu)

        # HISTOGRAM MENU
        histogram_menu = tk.Menu(menubar, tearoff=1)

        # Raw Per Year
        histogram_menu.add_command(
            label=titles[3], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.tm_object.get_f_s_1(
                    normalize
                ),
                len(self.ai_model.vs), type=1,
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_h()
                        )
                    )),
                title=titles[3], color=1,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Simulation2 Per Year
        histogram_menu.add_command(
            label=titles[4], command=lambda: self.show_frame(
                0, 10,
                self.ai_model.model.sub_model.get_f_s_1(
                    normalize
                ),
                len(self.ai_model.vs), type=1,
                xlabel="State", ylabel="Frequency",
                xlim=(0, len(self.ai_model.vs)),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[4], color=2,
                legend=[year for year in
                        range(1992, 2017)],
                fill=True
            )
        )

        # Raw Per State
        histogram_menu.add_command(
            label=titles[5], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.tm_object.get_f_s_2(
                    normalize
                ), 25, type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_summary()
                        )
                    )),
                title=titles[5], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # Simulation2 Per State
        histogram_menu.add_command(
            label=titles[6], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.sub_model.get_f_s_2(
                    normalize
                ), 25, type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0,
                    int(self.ai_model.iterations.get())),
                title=titles[6], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        # 3D Histogram
        histogram_menu.add_command(
            label=titles[7], command=lambda: self.show_frame(
                1, 26,
                self.ai_model.model.tm_object.get_f_s_2(
                    normalize
                ), 25, type=1,
                ylabel="Frequency", xlim=(1, 25),
                ylim=(0,
                      1) if normalize == True else (
                    0, int(
                        len(
                            self.ai_model.model.tm_object.get_summary()
                        )
                    )),
                title=titles[7], color=0,
                legend=self.ai_model.model.sub_model.legend_labels,
                fill=True
            )
        )

        menubar.add_cascade(label="Histogram", menu=histogram_menu)

        #############################################################################

        tk.Tk.config(self, menu=menubar)
        self.frame = Results(container, self, menuname)
        self.frame.grid(row=0, column=0, sticky="nsew")

    def show_frame(
        self, xi, xf, ydata, data_criteria, type=0, xlabel="Time (Years)", ylabel='Probability',
        xlim=(0, 25), ylim=(0, 1), title='', color=0, legend=None, fill=False, zorder=False
    ):
        self.plt = plt.subplot2grid((6, 4), (0, 0), rowspan=5, colspan=4)
        for index, curve in enumerate(ydata):
            # print(index)
            if len(curve) == data_criteria:
                # Line Plot
                if type == 0:
                    self.plt.plot(
                        [x for x in range(xi, xf)], curve, colors[color][index % len(colors[color])],
                        marker=mark[index % len(mark)], markersize=2, fillstyle=fill_style[index % len(mark)],
                        dashes=dash[index % len(dash)]
                    )
                    if fill:
                        self.plt.fill_between(
                            [x for x in range(xi, xf)], 0, curve,
                            facecolors=colors[color][index % len(colors[color])], alpha=0.5
                        )
                    if zorder:
                        self.plt.set_zorder(index)
                # Histogram
                elif type == 1:
                    self.plt.hist(curve, bins=int(len(self.ai_model.vs)), histtype='bar')
        if legend is not None:
            self.plt.legend(legend, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.5)
        self.plt.set_title(title)
        self.plt.set_xlabel(xlabel)
        self.plt.set_ylabel(ylabel)
        self.plt.set_xlim(xlim)
        self.plt.set_ylim(ylim)
        self.plt.axes.set_xticks([v for v in range(1, data_criteria + 1)])
        self.frame.tkraise()
        self.geometry("%dx%d" % (WIDTH / 2, 3 * HEIGHT / 4))
        animation.FuncAnimation(f, animate, interval=100)

    def __init__(self):
        # self.AI_Model = AI_Model
        tk.Tk.__init__(self)

        tk.Tk.iconbitmap(self, default="i.ico")
        tk.Tk.wm_title(self, "Results")
        tk.Tk.minsize(self, width=int(WIDTH / 2), height=int(HEIGHT / 2))
        print(HEIGHT / 2)

        container = tk.Frame(self)
        container.pack(side="top", fill="both", expand=True)
        container.grid_rowconfigure(0, weight=1)
        container.grid_columnconfigure(0, weight=1)

        menubar = tk.Menu(container)
        filemenu = tk.Menu(menubar, tearoff=0)
        filemenu.add_command(label="Save")  # , command=lambda:popupmsg("Not supported"))
        filemenu.add_separator()
        filemenu.add_command(label="Exit", command=quit)
        menubar.add_cascade(label="File", menu=filemenu)

        # Transition Matrix Probabilities
        menubar.add_command(
            label="Transition Matrix Probabilities",
            command=lambda: self.show_frame(TransitionProbabilitiesPage)
        )

        # DETERIORATION MENU
        deterioration_menu = tk.Menu(menubar, tearoff=1)
        deterioration_menu.add_command(
            label="Raw Data Deterioration Curve",
            command=lambda: self.show_frame(DeteriorationPage)
        )
        deterioration_menu.add_command(
            label="Simulation2 Deterioration Curve",
            command=lambda: self.show_frame(DeteriorationPage)
        )
        menubar.add_cascade(label="Deterioration", menu=deterioration_menu)

        # FREQUENCY MENU
        frequency_menu = tk.Menu(menubar, tearoff=1)
        frequency_menu.add_command(label="Raw Data Histograms", command=lambda: self.show_frame(FrequencyPage))
        frequency_menu.add_command(label="Simulation2 Histograms", command=lambda: self.show_frame(FrequencyPage))
        frequency_menu.add_command(label="3D Histogram", command=lambda: self.show_frame(FrequencyPage))
        menubar.add_cascade(label="Frequency", menu=frequency_menu)

        tk.Tk.config(self, menu=menubar)

        self.frames = {}

        for F in (StartPage, FrequencyPage, DeteriorationPage, TransitionProbabilitiesPage):
            frame = F(container, self)
            self.frames[F] = frame
            frame.grid(row=0, column=0, sticky="nsew")

        self.show_frame(StartPage)

    def show_frame(self, cont):
        frame = self.frames[cont]
        frame.tkraise()


class SearchMenu(Window):
    def c_lo_run(self):
        self.files, self.filename = 'single', 'report'
        self.populator = PopulateSearchMenu.PopulateSearchMenu(self)

    @staticmethod
    def help():
        popup = tk.Tk()
        popup.wm_title("!")
        label = ttk.Label(popup, text="PASS Lab\nChristian Lozoya\n2017")
        label.pack(side="top", fill="x", pady=10)
        B1 = ttk.Button(popup, text="Okay", command=popup.destroy)
        B1.pack()
        B1.mainloop()

    def save(self):
        path = tkf.asksaveasfilename(filetypes=(("Bridge Data Query files", "*.bdq"), ("All files", "*.*")))
        try:
            path = path + ".bdq"
            with open(path, "w") as saveFile:
                for i in range(self.util.number_of_items):
                    saveFile.write(self.populator.entryList[self.populator.parameterNames[i]].get() + "\n")
        except:
            return

    def load(self):
        try:
            path = tkf.askopenfilename(filetypes=(("Bridge Data Query files", "*.bdq"), ("All files", "*.*")))
            with open(path, "r") as loadFile:
                for i in range(len(self.populator.entryList)):
                    self.populator.entryList[self.populator.parameterNames[i]].delete(0, END)
                for i, line in enumerate(loadFile):
                    if line.strip():
                        self.populator.entryList[self.populator.parameterNames[i]].insert(i, line.strip())
        except:
            return

    def search(self):
        ReportMenu.ReportMenu(self, "search").populate()

    def clear(self):
        for i in range(len(self.populator.entryList)):
            self.populator.entryList[self.populator.parameterNames[i + 0]].delete(0, END)

    def report_settings(self):
        ReportMenu.ReportMenu(self, "report_generator0 Settings").populate()

    def markov_chain_menu(self):
        MarkovChainMenu.MarkovChainMenu(self, "Markov Chain Monte Carlo").populate()

    def search_resume(self, settings):
        with open(self.util.MASTERPATH + "\\BridgeDataQuery\Database\\temp.txt", "w") as saveFile:
            for i in range(len(self.populator.entryList)):
                saveFile.write(self.populator.entryList[self.populator.parameterNames[i]].get() + "\n")

        Search.Search(self, settings)

    def set_filepath(self, filepath):
        self.filepath = filepath


class StartPage(tk.Frame):
    def __init__(self, parent, controller):
        tk.Frame.__init__(self, parent)

        label = tk.Label(self, text="Results", font=LARGE_FONT)
        label.pack(pady=10, padx=10)

        # button1 = ttk.Button(self, text="Deterioration", command=lambda: controller.show_frame(DeteriorationPage))  # button1.pack()

        # button2 = ttk.Button(self, text="Frequency", command=lambda: controller.show_frame(FrequencyPage))  # button2.pack()

        # button3 = ttk.Button(self, text="Transition Probabilities", command=lambda: controller.show_frame(TransitionProbabilitiesPage))  # button3.pack()

    def __init__(self, parent, controller):
        tk.Frame.__init__(self, parent)
        label = tk.Label(self, text="Results", font=LARGE_FONT)
        label.pack(
            pady=10,
            padx=10
        )  # button1 = ttk.Button(self, text="Deterioration", command=lambda: controller.show_frame(DeteriorationPage))  # button1.pack()  # button2 = ttk.Button(self, text="Frequency", command=lambda: controller.show_frame(FrequencyPage))  # button2.pack()  # button3 = ttk.Button(self, text="Transition Probabilities", command=lambda: controller.show_frame(TransitionProbabilitiesPage))  # button3.pack()

    def __init__(self, parent, controller):
        tk.Frame.__init__(self, parent)

        label = tk.Label(self, text="Results", font=LARGE_FONT)
        label.pack(pady=10, padx=10)

        # button1 = ttk.Button(self, text="Deterioration", command=lambda: controller.show_frame(DeteriorationPage))  # button1.pack()

        # button2 = ttk.Button(self, text="Frequency", command=lambda: controller.show_frame(FrequencyPage))  # button2.pack()

        # button3 = ttk.Button(self, text="Transition Probabilities", command=lambda: controller.show_frame(TransitionProbabilitiesPage))  # button3.pack()

    def __init__(self, parent, controller):
        tk.Frame.__init__(self, parent)

        label = tk.Label(self, text="Results", font=LARGE_FONT)
        label.pack(pady=10, padx=10)

        # button1 = ttk.Button(self, text="Deterioration", command=lambda: controller.show_frame(DeteriorationPage))  # button1.pack()

        # button2 = ttk.Button(self, text="Frequency", command=lambda: controller.show_frame(FrequencyPage))  # button2.pack()

        # button3 = ttk.Button(self, text="Transition Probabilities", command=lambda: controller.show_frame(TransitionProbabilitiesPage))  # button3.pack()


class SettingsMenu(SubMenu):
    def __init__(self, parent, title, icon, algorithms):
        SubMenu.__init__(self, parent, title, icon)
        self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)

        self.optionLayouts = {name: make_grid() for name in algorithms}

        self.modelParameterSelection = self.set_models(
            algorithms, self.hbox, command=self.set_parameters_layout,
            multiSelect=False
        )

        self.autoTuneGrid = make_group_box(
            self.hbox, layout=make_grid(), text='Tune', row=0, column=3, width=45,
            height=45
        )
        self.autoCheck = make_button(
            buttonType='check', layout=self.autoTuneGrid,
            description=AUTOMATIC_TUNING_DESCRIPTION
        )

        self.set_parameters_tab()

    def set_parameters_tab(self):
        self.parametersGrid = make_group_box(
            self.hbox, layout=make_grid(), text='Settings', row=0, column=1,
            width=1000, height=225
        )

        default = None
        self.parametersSelection = make_scroll_area(default, width=1000)
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)

    def set_parameters_layout(self):
        self.parametersGrid.removeWidget(self.parametersSelection)
        self.parametersSelection = make_scroll_area(
            self.optionLayouts[self.modelParameterSelection.currentItem().text()], width=1000
        )
        self.parametersGrid.addWidget(self.parametersSelection, 0, 0)


class TransceiverSettings:
    def __init__(self, app, parent, layout):
        try:
            self.app = app
            self.parent = parent
            self.layout = layout
            b = self.app.transceiver.bands[self.app.transceiverConfig.bandIndex]
            _, self.encryptionCombo = self.app.assembler.pair(
                self.parent, pair='combo',
                comboItems=self.app.encryptor.encryptions, default=self.app.encryptionConfig.encryptionIndex,
                command=lambda: self.update_encryption(), layout=layout.layout(), gbHeight=40,
                **widgetkwargs.settings.encryptionCombo, )
            _, self.baudRateCombo = self.app.assembler.pair(
                self.parent, pair='combo',
                comboItems=self.app.transceiver.baudRates, default=self.app.transceiverConfig.baudRateIndex,
                command=lambda: self.update_baud_rate(), layout=layout.layout(), gbHeight=40,
                **widgetkwargs.settings.baudRateCombo, )
            _, self.bandCombo = self.app.assembler.pair(
                self.parent, pair='combo',
                comboItems=self.app.transceiver.bandNames, default=self.app.transceiverConfig.bandIndex,
                layout=layout.layout(), command=lambda: self.update_band(), gbHeight=40,
                **widgetkwargs.settings.bandCombo, )
            self.rfGroupBox, self.rfSlider = self.app.assembler.pair(
                self.parent, pair='slider',
                text='Radio Frequency ({})'.format(b.units),
                inputSettings=(b.minimum * 100, b.maximum * 100,  # TODO use band conversion
                               self.app.transceiverConfig.transmissionFrequency * 100, 0.01,),
                command=lambda: self.update_frequency_slider(), layout=layout.layout(), gbHeight=40,
                **widgetkwargs.settings.rfSlider, )
            self.rfSpinBox = self.app.assembler.make_numerical_input(
                self.parent,
                inputSettings=(b.minimum, b.maximum, self.app.transceiverConfig.transmissionFrequency, 0.01,),
                command=lambda: self.update_frequency_entry(), layout=self.rfGroupBox.layout(),
                **widgetkwargs.settings.rfSpinBox, )
            self.portGroupBox, self.portEntry = self.app.assembler.pair(
                self.parent, pair='numerical',
                inputSettings=(0, 9999, self.app.transceiverConfig.port, 1), pairText=self.app.dataConfig.head,
                layout=layout.layout(), command=lambda: self.set_port(), gbHeight=40,
                **widgetkwargs.settings.portEntry, )
            self.portLkBtn = self.app.assembler.make_button(
                self.parent, command=lambda: self.toggle_connection(),
                icon=paths.connected if self.app.transceiverConfig.portConnected else paths.disconnected,
                layout=self.portGroupBox.layout(), **widgetkwargs.settings.portLkBtn, )
        except Exception as e:
            print(e)

    def update_baud_rate(self):
        index = self.baudRateCombo.currentIndex()
        self.app.transceiverConfig.update('baudRate', int(self.app.transceiver.baudRates[index]))
        self.app.transceiverConfig.update('baudRateIndex', index)

    def update_frequency_slider(self):
        try:
            v = self.rfSlider.value() / 100  # TODO use band conversion
            self.rfSpinBox.setValue(v)
            self.app.transceiverConfig.transmissionFrequency = v
            self.frequency_change_status()
        except Exception as e:
            print('Update frequency error slider: ' + str(e))

    def update_frequency_entry(self):
        try:
            v = self.rfSpinBox.value()
            self.rfSlider.setValue(v * 100)  # TODO use band conversion
            self.app.transceiverConfig.transmissionFrequency = v
            self.frequency_change_status()
        except Exception as e:
            print('Update frequency error entry: ' + str(e))

    def frequency_change_status(self):
        frequency = self.rfSpinBox.value()
        units = self.app.transceiver.bands[self.app.transceiverConfig.bandIndex].units
        self.parent.update_status('Radio Frequency: {} {}.'.format(frequency, units), 'success')

    def update_encryption(self):
        try:
            index = self.encryptionCombo.currentIndex()
            self.app.encryptionConfig.update('encryptionIndex', index)
            self.app.encryptionConfig.update('encryption', self.app.encryptor.encryptions[index])
        except Exception as e:
            self.parent.update_status(*status.updateEncryptionError, e)

    def toggle_connection(self):
        try:
            connected = not self.app.transceiverConfig.portConnected
            if connected:
                self.connect_port()
            else:
                self.disconnect_port()
            self.app.transceiverConfig.update('portConnected', connected)
            self.app.transceiverMenu.set_stylesheets()
            self.app.logMenu.set_stylesheets()
        except Exception as e:
            self.parent.update_status(*status.connectionError, e)

    def set_port(self):
        try:
            self.app.transceiverConfig.update('port', self.portEntry.value())
        except Exception as e:
            self.parent.update_status(*status.setPortError, e)

    def connect_port(self):
        try:
            # TODO connect to port
            serverConnected = self.app.server.connect()
            clientConnected = self.app.client.connect()
            if clientConnected and serverConnected:
                self.portLkBtn.set_connected()
                self.parent.update_status(*status.connectedPort, self.app.transceiverConfig.port)
        except Exception as e:
            self.parent.update_status(*status.connectPortError, e)

    def disconnect_port(self):
        # TODO confirm disconnected
        # QtWidgets.QMessageBox.question(self,
        # 'PyQt5 message', "Do you like PyQt5?", QMessageBox.Yes | QMessageBox.No,
        #                      QMessageBox.No)
        self.app.server.disconnect()
        self.app.client.disconnect()
        self.app.transceiverConfig.update('transceiverActive', False)
        self.portLkBtn.set_glowing()
        self.parent.update_status(*status.disconnectedPort, self.app.transceiverConfig.port)

    def __init__(self, app, parent, layout):
        try:
            self.app = app
            self.parent = parent
            self.layout = layout
            b = self.app.transceiver.bands[self.app.transceiverConfig.bandIndex]
            _, self.encryptionCombo = self.app.assembler.pair(
                self.parent, pair='combo',
                comboItems=self.app.encryptor.encryptions, default=self.app.encryptionConfig.encryptionIndex,
                command=lambda: self.update_encryption(), layout=layout.layout(), gbHeight=40,
                **widgetkwargs.settings.encryptionCombo, )
            _, self.baudRateCombo = self.app.assembler.pair(
                self.parent, pair='combo',
                comboItems=self.app.transceiver.baudRates, default=self.app.transceiverConfig.baudRateIndex,
                command=lambda: self.update_baud_rate(), layout=layout.layout(), gbHeight=40,
                **widgetkwargs.settings.baudRateCombo, )
            _, self.bandCombo = self.app.assembler.pair(
                self.parent, pair='combo',
                comboItems=self.app.transceiver.bandNames, default=self.app.transceiverConfig.bandIndex,
                layout=layout.layout(), command=lambda: self.update_band(), gbHeight=40,
                **widgetkwargs.settings.bandCombo, )
            self.rfGroupBox, self.rfSlider = self.app.assembler.pair(
                self.parent, pair='slider',
                text='Radio Frequency ({})'.format(b.units),
                settings=(b.minimum * 100, b.maximum * 100,  # TODO use band conversion
                          self.app.transceiverConfig.transmissionFrequency * 100, 0.01,),
                command=lambda: self.update_frequency_slider(), layout=layout.layout(), gbHeight=40,
                **widgetkwargs.settings.rfSlider, )
            self.rfSpinBox = self.app.assembler.make_numerical_input(
                self.parent,
                settings=(b.minimum, b.maximum, self.app.transceiverConfig.transmissionFrequency, 0.01,),
                command=lambda: self.update_frequency_entry(), layout=self.rfGroupBox.layout(),
                **widgetkwargs.settings.rfSpinBox, )
            # self.portGroupBox, self.portEntry = self.app.assembler.pair(
            #     self.parent,
            #     pair='numerical',
            #     settings=(0, 9999, self.app.transceiverConfig.port, 1),
            #     pairText=self.app.dataConfig.head,
            #     layout=layout.layout(),
            #     command=lambda: self.set_port(),
            #     gbHeight=40,
            #     **widgetkwargs.settings.portEntry,
            # )
            self.portGroupBox, self.portCombo = self.app.assembler.pair(
                self.parent, pair='combo',
                comboItems=self.app.comPort.serial_ports(), default=self.app.transceiverConfig.portIndex,
                layout=layout.layout(), command=lambda: self.set_port(), gbHeight=40,
                **widgetkwargs.settings.portEntry, )
            # self.portGroupBox = self.app.assembler.make_group_box(
            #     layout.layout(),
            # )
            # self.portCombo = combo.Combo(
            #     self.app,
            #     self.parent,
            #     options=self.app.comPort.serial_ports(),
            #     default=self.app.transceiverConfig.portIndex,
            #     command=lambda: self.set_port(),
            # )
            # self.portGroupBox.layout().addWidget(self.portCombo)
            self.portLkBtn = lockbutton.LockButton(
                app=self.app, parent=self.parent, name='portLock',
                config=self.app.transceiverConfig, pair=self.portCombo, callback=self.toggle_transceiver_active,
                layout=self.portGroupBox.layout(), pos=(0, 1), tooltip='Lock Port'
            )
        except Exception as e:
            print(e)

    def toggle_transceiver_active(self, disable=True):
        if self.app.dataConfig.delimiterValid:
            self.app.transceiverMenu.set_stylesheets()
        if disable:
            self.app.transceiverConfig.update('_transceiverActive', False)
        self.app.deviceMenu.reset_menu()

    def update_baud_rate(self, *args, **kwargs):
        index = self.baudRateCombo.currentIndex()
        self.app.transceiverConfig.update('baudRate', int(self.app.transceiver.baudRates[index]))
        self.app.transceiverConfig.update('baudRateIndex', index)

    def update_band(self, *args, **kwargs):
        index = self.bandCombo.currentIndex()
        self.app.transceiverConfig.band = self.app.transceiver.bandNames[index]
        self.app.transceiverConfig.bandIndex = index
        b = self.app.transceiver.bands[index]
        _f = self.app.transceiverConfig.transmissionFrequency
        if _f >= b.minimum and _f <= b.maximum:
            f = _f
        else:
            f = b.minimum
        self.app.transceiverConfig.transmissionFrequency = f
        try:
            self.rfGroupBox.setTitle('Radio Frequency ({})'.format(b.units))
            self.rfSlider.setRange(b.minimum * 100, b.maximum * 100)  # TODO use band conversion
            self.rfSlider.setValue(f)
            self.rfSpinBox.setRange(b.minimum, b.maximum)
            self.rfSpinBox.setValue(f)
            self.frequency_change_status()
        except Exception as e:
            print('Update band error: ' + str(e))

    def update_frequency_slider(self, *args, **kwargs):
        try:
            v = self.rfSlider.value() / 100  # TODO use band conversion
            self.rfSpinBox.setValue(v)
            self.app.transceiverConfig.transmissionFrequency = v
            self.frequency_change_status()
        except Exception as e:
            print('Update frequency error slider: ' + str(e))

    def update_frequency_entry(self, *args, **kwargs):
        try:
            v = self.rfSpinBox.value()
            self.rfSlider.setValue(v * 100)  # TODO use band conversion
            self.app.transceiverConfig.transmissionFrequency = v
            self.frequency_change_status()
        except Exception as e:
            print('Update frequency error entry: ' + str(e))

    def frequency_change_status(self, *args, **kwargs):
        frequency = self.rfSpinBox.value()
        units = self.app.transceiver.bands[self.app.transceiverConfig.bandIndex].units
        self.parent.update_status('Radio Frequency: {} {}.'.format(frequency, units), 'success')

    def update_encryption(self, *args, **kwargs):
        try:
            index = self.encryptionCombo.currentIndex()
            self.app.encryptionConfig.update('encryptionIndex', index)
            self.app.encryptionConfig.update('encryption', self.app.encryptor.encryptions[index])
        except Exception as e:
            self.parent.update_status(*status.updateEncryptionError, e)

    def set_port(self, *args, **kwargs):
        try:
            index = self.portCombo.currentIndex()
            self.app.transceiverConfig.update('portIndex', index)
            self.app.transceiverConfig.update('port', self.app.comPort.serial_ports()[index])
        except Exception as e:
            self.parent.update_status(*status.setPortError, e)

    def disconnect_port(self, *args, **kwargs):
        # TODO confirm disconnected
        # QtWidgets.QMessageBox.question(self,
        # 'PyQt5 message', "Do you like PyQt5?", QMessageBox.Yes | QMessageBox.No,
        #                      QMessageBox.No)
        self.app.comPort.disconnect()
        self.app.transceiverConfig.update('_transceiverActive', False)
        self.portLkBtn.set_glowing()
        self.parent.update_status(*status.disconnectedPort, self.app.transceiverConfig.port)


class TransitionProbabilitiesPage(tk.Frame):
    def __init__(self, parent, controller):
        tk.Frame.__init__(self, parent)
        label = tk.Label(self, text="Transition Probabilities", font=LARGE_FONT)
        label.pack(pady=10, padx=10)
        # utton1 = ttk.Button(self, text="Back to Home", command=lambda: controller.show_frame(StartPage))
        # button1.pack()
        # button2 = ttk.Button(self, text="Deterioration", command=lambda: controller.show_frame(DeteriorationPage))
        # button2.pack()
        canvas = FigureCanvasTkAgg(f, self)
        canvas.show()
        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        toolbar = NavigationToolbar2TkAgg(canvas, self)
        toolbar.update()
        canvas._tkcanvas.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
        canvas._tkcanvas.pack()
        global current_frame
        current_frame = "transition probabilities frame"


class Window(tk.Tk):
    def __init__(self, window_name):
        """Creates the window where the application will be displayed."""
        tk.Tk.__init__(self)
        # tk.Tk.iconbitmap(self, default="\C:\\Users\\frano\PycharmProjects\BridgeDataQuery\Interface\InterfaceUtilities\Icons\i.ico"))
        self.util = MenuGenerator.MenuBuilder()
        tk.Tk.wm_title(self, window_name)
        # tk.Tk.minsize(self, width=int(self.util.WIDTH / 2), height=int(3 * self.util.HEIGHT / 4))
        # geometry("%dx%d" % (WIDTH / 2, 3 * HEIGHT / 4))
        self.container = tk.Frame(self)
        self.container.pack(side="top", fill="both", expand=True)
        self.container.grid_rowconfigure(0, weight=1)
        self.container.grid_columnconfigure(0, weight=1)


class Slave(QtGui.QMainWindow):
    def __init__(self, app, title):
        super(Slave, self).__init__()
        self.setStyleSheet(configuration.WINDOW_STYLE)

        width = WIDTH / 2
        height = HEIGHT / 2
        xpos = (WIDTH - width) / 2
        ypos = (HEIGHT - height) / 2
        self.setGeometry(xpos, ypos, width, height)
        self.setWindowTitle(title)
        icon = QtGui.QIcon(configuration.WINDOW_ICON)
        self.setWindowIcon(icon)
        statusbar = self.statusBar()
        statusbar.setStyleSheet(configuration.STATUSBAR_STYLE)
        self.menu_bar()
        self.data_toolbar()
        self.plan_toolbar()
        self.assist_toolbar()
        self.show()
        sys.exit(app.exec_())

    def menu_bar(self):
        menubar = self.menuBar()
        menubar.setStyleSheet(configuration.MENUBAR_STYLE)
        self.file_dropdown(menubar)
        self.edit_dropdown(menubar)
        self.view_dropdown(menubar)

    def file_dropdown(self, menubar):
        fileMenu = menubar.addMenu('&File')

        openFolderAction = QtGui.QAction(QtGui.QIcon(configuration.OPEN_FOLDER_ICON), '&Open Folder', self)
        openFolderAction.setStatusTip(configuration.OPEN_FOLDER_DESCRIPTION)
        openFolderAction.triggered.connect(QtGui.qApp.quit)

        fileMenu.addAction(openFolderAction)

        saveFolderAction = QtGui.QAction(QtGui.QIcon(SAVE_FOLDER_ICON), '&Save Folder', self)
        saveFolderAction.setStatusTip(configuration.SAVE_FOLDER_DESCRIPTION)
        saveFolderAction.triggered.connect(QtGui.qApp.quit)

        fileMenu.addAction(saveFolderAction)

        fileMenu.addSeparator()

        openFileAction = QtGui.QAction(QtGui.QIcon(configuration.OPEN_FILE_ICON), '&Open File', self)
        openFileAction.setShortcut('Ctrl+O')
        openFileAction.setStatusTip(configuration.OPEN_FILE_DESCRIPTION)
        openFileAction.triggered.connect(self.open_file)

        fileMenu.addAction(openFileAction)

        saveFileAction = QtGui.QAction(QtGui.QIcon(configuration.SAVE_FILE_ICON), '&Save File', self)
        saveFileAction.setShortcut('Ctrl+S')
        saveFileAction.setStatusTip(configuration.SAVE_FILE_DESCRIPTION)
        saveFileAction.triggered.connect(QtGui.qApp.quit)

        fileMenu.addAction(saveFileAction)

        fileMenu.addSeparator()

        exitAction = QtGui.QAction(QtGui.QIcon(configuration.EXIT_ICON), '&Exit', self)
        exitAction.setShortcut('Ctrl+Q')
        exitAction.setStatusTip(configuration.EXIT_DESCRIPTION)
        exitAction.triggered.connect(QtGui.qApp.quit)

        fileMenu.addAction(exitAction)

    def edit_dropdown(self, menubar):
        editMenu = menubar.addMenu('&Edit')
        exitAction = QtGui.QAction(QtGui.QIcon(configuration.EXIT_ICON), '&Copy', self)
        exitAction.setShortcut('Ctrl+Q')
        exitAction.setStatusTip(configuration.EXIT_DESCRIPTION)
        exitAction.triggered.connect(QtGui.qApp.quit)

        editMenu.addAction(exitAction)

    def view_dropdown(self, menubar):
        viewMenu = menubar.addMenu('&View')
        exitAction = QtGui.QAction(QtGui.QIcon(configuration.EXIT_ICON), '&Reset View', self)
        exitAction.setShortcut('Ctrl+Q')
        exitAction.setStatusTip(configuration.EXIT_DESCRIPTION)
        exitAction.triggered.connect(QtGui.qApp.quit)

        viewMenu.addAction(exitAction)

    def data_toolbar(self):
        self.dataToolbar = QtGui.QToolBar(self)
        self.dataToolbar.setStyleSheet(configuration.TOOLBAR_STYLE)
        self.dataToolbar.setIconSize(QtCore.QSize(100, 100))
        self.dataToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        icon = QtGui.QIcon(configuration.DATABASE_ICON)
        databaseAction = QtGui.QAction(icon, configuration.DATABASE_DESCRIPTION, self)
        databaseAction.setShortcut('Ctrl+D')
        databaseAction.setStatusTip(configuration.DATABASE_DESCRIPTION)
        databaseAction.triggered.connect(self.database_menu)
        databaseAction.setIconText("Database")
        self.dataToolbar.addAction(databaseAction)

        icon = QtGui.QIcon(configuration.SEARCH_ICON)
        searchAction = QtGui.QAction(icon, configuration.SEARCH_DESCRIPTION, self)
        searchAction.setShortcut('Ctrl+R')
        searchAction.setStatusTip(configuration.SEARCH_DESCRIPTION)
        searchAction.triggered.connect(self.search_menu)
        searchAction.setIconText("search Engine")
        self.dataToolbar.addAction(searchAction)

        icon = QtGui.QIcon(configuration.GEO_SEARCH_ICON)
        geoSearchAction = QtGui.QAction(icon, configuration.GEO_SEARCH_DESCRIPTION, self)
        geoSearchAction.setShortcut('Ctrl+G')
        geoSearchAction.setStatusTip(configuration.GEO_SEARCH_DESCRIPTION)
        geoSearchAction.triggered.connect(self.geo_search_menu)
        geoSearchAction.setIconText("Geographic search")
        self.dataToolbar.addAction(geoSearchAction)

        icon = QtGui.QIcon(configuration.MACHINE_LEARNING_ICON)
        machineLearningAction = QtGui.QAction(icon, configuration.MACHINE_LEARNING_DESCRIPTION, self)
        machineLearningAction.setShortcut('Ctrl+M')
        machineLearningAction.setStatusTip(configuration.MACHINE_LEARNING_DESCRIPTION)
        machineLearningAction.triggered.connect(self.machine_learning_menu)
        machineLearningAction.setIconText("Machine Learning")
        self.dataToolbar.addAction(machineLearningAction)

        icon = QtGui.QIcon(configuration.SENTIMENT_ICON)
        sentimentAction = QtGui.QAction(icon, configuration.SENTIMENT_DESCRIPTION, self)
        sentimentAction.setStatusTip(SENTIMENT_DESCRIPTION)
        sentimentAction.triggered.connect(self.sentiment_menu)
        sentimentAction.setIconText("Sentiment Analysis")
        self.dataToolbar.addAction(sentimentAction)

        self.addToolBar(self.dataToolbar)

    def plan_toolbar(self):
        self.planToolbar = QtGui.QToolBar(self)
        self.planToolbar.setStyleSheet(TOOLBAR_STYLE)
        self.planToolbar.setIconSize(QtCore.QSize(100, 100))
        self.planToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        icon = QtGui.QIcon(PLANNER_ICON)
        plannerAction = QtGui.QAction(icon, PLANNER_DESCRIPTION, self)
        plannerAction.setStatusTip(PLANNER_DESCRIPTION)
        plannerAction.triggered.connect(self.planner_menu)
        plannerAction.setIconText("Planner")
        self.planToolbar.addAction(plannerAction)

        icon = QtGui.QIcon(SCHEDULE_ICON)
        scheduleAction = QtGui.QAction(icon, SCHEDULE_DESCRIPTION, self)
        scheduleAction.setShortcut('Ctrl+P')
        scheduleAction.setStatusTip(SCHEDULE_DESCRIPTION)
        scheduleAction.triggered.connect(self.schedule_menu)
        scheduleAction.setIconText("Schedule")
        self.planToolbar.addAction(scheduleAction)

        icon = QtGui.QIcon(TASKS_ICON)
        tasksAction = QtGui.QAction(icon, TASKS_DESCRIPTION, self)
        tasksAction.setShortcut('Ctrl+T')
        tasksAction.setStatusTip(TASKS_DESCRIPTION)
        tasksAction.triggered.connect(self.tasks_menu)
        tasksAction.setIconText("Tasks")
        self.planToolbar.addAction(tasksAction)

        icon = QtGui.QIcon(RESOURCES_ICON)
        resourcesAction = QtGui.QAction(icon, RESOURCES_DESCRIPTION, self)
        resourcesAction.setShortcut('Ctrl+P')
        resourcesAction.setStatusTip(RESOURCES_DESCRIPTION)
        resourcesAction.triggered.connect(self.resources_menu)
        resourcesAction.setIconText("Resources")
        self.planToolbar.addAction(resourcesAction)

        self.addToolBar(QtCore.Qt.LeftToolBarArea, self.planToolbar)

    def assist_toolbar(self):
        self.assistToolbar = QtGui.QToolBar(self)
        self.assistToolbar.setStyleSheet(configuration.TOOLBAR_STYLE)
        self.assistToolbar.setIconSize(QtCore.QSize(100, 100))
        self.assistToolbar.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)

        icon = QtGui.QIcon(configuration.UPDATES_ICON)
        updatesAction = QtGui.QAction(icon, configuration.UPDATES_DESCRIPTION, self)
        updatesAction.setShortcut('Ctrl+U')
        updatesAction.setStatusTip(configuration.UPDATES_DESCRIPTION)
        updatesAction.triggered.connect(self.updates_menu)
        updatesAction.setIconText("Updates")
        self.assistToolbar.addAction(updatesAction)

        icon = QtGui.QIcon(configuration.HELP_ICON)
        helpAction = QtGui.QAction(icon, configuration.HELP_DESCRIPTION, self)
        helpAction.setShortcut('Ctrl+H')
        helpAction.setStatusTip(configuration.HELP_DESCRIPTION)
        helpAction.triggered.connect(self.help_menu)
        helpAction.setIconText("Help2")
        self.assistToolbar.addAction(helpAction)

        self.addToolBar(self.assistToolbar)

    def database_menu(self):
        self.database_menu = DatabaseMenu(self, 'Database', configuration.DATABASE_ICON)
        self.database_menu.show()

    def search_menu(self):
        self.searchMenu = SearchMenu(self, 'search', configuration.SEARCH_ICON)
        self.searchMenu.show()

    def geo_search_menu(self):
        self.geoSearchMenu = GeoSearchMenu(self, 'Geographic search', GEO_SEARCH_ICON)
        self.geoSearchMenu.show()

    def machine_learning_menu(self):
        self.machine_learning_menu = MachineLearningMenu(self, 'Machine Learning', MACHINE_LEARNING_ICON)
        self.machine_learning_menu.show()

    def sentiment_menu(self):
        self.sentiment_menu = SentimentMenu(self, 'Sentiment Analysis', SENTIMENT_ICON)
        self.sentiment_menu.show()

    def updates_menu(self):
        self.updates_menu = UpdatesMenu(self, 'Updates', UPDATES_ICON)
        self.updates_menu.show()

    def help_menu(self):
        self.help_menu = HelpMenu(self, 'Help2', HELP_ICON)
        self.help_menu.show()

    def planner_menu(self):
        self.planner_menu = PlannerMenu(self, 'Planner', PLANNER_ICON)
        self.planner_menu.show()

    def schedule_menu(self):
        self.schedule_menu = ScheduleMenu(self, 'Schedule', SCHEDULE_ICON)
        self.schedule_menu.show()

    def tasks_menu(self):
        self.tasks_menu = TasksMenu(self, 'Tasks', TASKS_ICON)
        self.tasks_menu.show()

    def resources_menu(self):
        self.resources_menu = ResourcesMenu(self, 'Resources', RESOURCES_ICON)
        self.resources_menu.show()

    def open_file(self):
        path = QtGui.QFileDialog.getOpenFileName(self, 'Open file', os.getcwd())
        print(path)

import random
import sys
import tkinter as tk
import tkinter.ttk as ttk

from PyQt5 import Qt, QtWidgets

QtWidgets.QApplication.processEvents()
app = Qt.QApplication(sys.argv)
main = Main()
main.show()
app.exec_()
# ML = MENU LABELS
# BT = BUTTON TEXT
# RT = RADIO TEXT
# RV = RADIO VALUES
# DM = DROP DOWN MENU
# DL = DROP DOWN MENU LABELS
# MAIN MENU
MM_DM = ["File", "search", "Machine Learning", "Geographic search", "Help2"]
MM_DL = [["Settings", "separator()", "Exit"], ["search"],
         ["Markov Chain Monte Carlo"], ["Geographic search"], ["Help2"]]
# MACHINE LEARNING MENU
ML_BT = ["Run", "Cancel", "Select Folder"]
ML_ML = ["Input Paths:", "Item:", "Initial State:", "Iterations:"]
ML_RT = ['Full', 'Clean']
# GEOGRAPHIC SEARCH MENU
GS_BT = ["Select Folder", "Cancel", "Run", "Save"]
GS_ML = ["Directory:", "Units:", "Radius:", "Latitude:", "Longitude:", "Save:"]
# REPORTS
RP_BT = ["Apply", "Cancel"]
RP_ML = ["CSV:", "Excel:"]
# SEARCH REPORTS
SR_BT = ["Select Folder", "Run", "Cancel"]
SR_ML = ["CSV:", "Excel:", "Folder path:"]
SR_RT = ['Union', 'Intersection']
# SEARCH MENU
SM_BT = ["search", "Clear"]
SM_DM = ["File"]
SM_DL = [["Open search", "Save search As", "Exit"]]

# TODO get_options(), set_nb_classifier()
class ClassificationAdvancedOptionsMenu(SubMenu):
    def rewindow(self):
        self.classificationTab = make_tab(self, text='Classification', master=self.tabs)
        self.set_classification_tab()
        self.setLayout(self.hbox)

    def set_classification_tab(self):
        self.modelSelection = make_list(
            items=CLASSIFIERS_NAMES, command=self.set_classification_layout,
            layout=self.classificationTab, row=0, column=0, width=200
        )
        self.scrollArea = make_scroll_area(self.classificationLayouts['Adaptive Boost'], width=275)
        self.classificationTab.addWidget(self.scrollArea, 0, 1)

    def set_classification_layout(self):
        self.classificationTab.removeWidget(self.scrollArea)
        self.scrollArea = make_scroll_area(
            self.classificationLayouts[self.modelSelection.currentItem().text()],
            width=275
        )
        self.classificationTab.addWidget(self.scrollArea, 0, 1)

    def set_ab_classifier(self):
        layout = self.classificationLayouts['Adaptive Boost']
        _, self.ABalgorithmCombo = make_pair(
            self, pair='combo', comboItems=('SAMME', 'SAMME.R'), text='Algorithm:',
            layout=layout, row=1, column=0, pairWidth=100, description=''
        )
        _, self.ABestimatorsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
            layout=layout, row=2, column=0, description=''
        )
        _, self.ABlearningRateDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
            layout=layout, row=3, column=0, description=''
        )
        _, self.ABrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=4, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

    def set_dt_classifier(self):
        layout = self.classificationLayouts['Decision Tree']
        _, self.DTcriterionCombo = make_pair(
            self, pair='combo', comboItems=('mse', 'friedman_mse', 'mae'),
            text='Criterion:', layout=layout, row=1, column=0, labelWidth=200,
            pairWidth=100, description=CRITERION_DESCRIPTION
        )
        _, self.DTmaxDepthDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=2, column=0, labelWidth=125,
            description=MAX_DEPTH_DESCRIPTION
        )
        _, self.DTmaxFeaturesCombo = make_pair(
            self, pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=3, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )
        _, self.DTmaxLeafNodesDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Maximum Leaf Nodes:', layout=layout, row=4, column=0,
            labelWidth=200, description=MAX_LEAF_NODES_DESCRIPTION
        )
        _, self.DTmaxLeafNodesDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Maximum Leaf Nodes:', layout=layout, row=4, column=0,
            labelWidth=200, description=MAX_LEAF_NODES_DESCRIPTION
        )
        _, self.DTminImpurityDecreaseDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Min Impurity Decrease:', layout=layout, row=5, column=0,
            labelWidth=200, description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )
        _, self.DTminSamplesLeafDial = make_pair(
            self, pair='dial', dialSettings=(1, 4, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=6, column=0,
            labelWidth=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )
        _, self.DTminSamplesSplitDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=7, column=0,
            labelWidth=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )
        _, self.DTminWeightFractionLeafDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=8,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )
        _, self.DTpresortCheck = make_pair(
            self, pair='check', text='Presort Data:', layout=layout, row=9, column=0,
            labelWidth=200, description=PRESORT_DESCRIPTION
        )
        _, self.DTrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=10,
            column=0, labelWidth=125, pairWidth=50,
            description=RANDOM_STATE_DESCRIPTION
        )
        _, self.DTsplitterCombo = make_pair(
            self, pair='combo', comboItems=('best', 'random'), text='Splitter:',
            layout=layout, row=11, column=0, pairWidth=75,
            description=SPLITTER_DESCRIPTION
        )

    def set_gp_classifier(self):
        layout = self.classificationLayouts['Gaussian Process']
        _, self.GPrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=1, column=0,
            labelWidth=125, pairWidth=50, description=''
        )
        _, self.GPwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=2, column=0,
            description=''
        )

    def set_knn_classifier(self):
        layout = self.classificationLayouts['Nearest Neighbors']
        _, self.KNNalgorithmCombo = make_pair(
            self, pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
            text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
            description=ALGORITHM_DESCRIPTION
        )
        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)
        _, self.KNNleafSizeDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:',
            layout=layout, row=2, column=0, description=LEAF_SIZE_DESCRIPTION
        )
        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)
        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)
        _, self.KNNminkowskiPowerDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 2, 1),
            text='Minkowski Power:', layout=layout, row=3, column=0,
            description=P_DESCRIPTION
        )
        _, self.KNNneighborsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 5, 1),
            text='Number of Neighbors:', layout=layout, row=4, column=0,
            labelWidth=200, description=N_NEIGHBORS_DESCRIPTION
        )
        _, self.KNNweightsCombo = make_pair(
            self, pair='combo', comboItems=('uniform', 'distance'),
            text='Weights Function:', layout=layout, row=5, column=0, labelWidth=200,
            pairWidth=100, description=WEIGHTS_DESCRIPTION
        )

    def set_mlp_classifier(self):
        layout = self.classificationLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            self, pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )
        _, self.MLPalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Alpha (Penalty Parameter):', layout=layout, row=2, column=0,
            labelWidth=200, description=MLP_ALPHA_DESCRIPTION
        )
        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        _, self.MLPbeta1Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )
        _, self.MLPbeta2Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )
        _, self.MLPearlyStoppingCheck = make_pair(
            self, pair='check', text='Early Stopping:', layout=layout, row=5,
            column=0, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )
        _, self.MLPepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )
        _, self.MLPhiddenLayerSizesEntry = make_pair(
            self, pair='entry', text='Hidden Layer Sizes:', layout=layout,
            row=7, column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )
        _, self.MLPinitLearningRateDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )
        _, self.MLPlearningRateCombo = make_pair(
            self, pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )
        _, self.MLPmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )
        _, self.MLPmomentumDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
            layout=layout, row=11, column=0, description=MOMENTUM_DESCRIPTION
        )
        _, self.MLPnesterovsMomentumCheck = make_pair(
            self, pair='check', text='Nesterov\'s Momentum:', layout=layout,
            row=12, column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )
        _, self.MLPpowerTDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )
        _, self.MLPrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=14,
            column=0, pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )
        _, self.MLPshuffleCheck = make_pair(
            self, pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )
        _, self.MLPsolverCombo = make_pair(
            self, pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )
        _, self.MLPtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=17, column=0, description=MLP_TOL_DESCRIPTION
        )
        _, self.MLPvalidationFractionDial = make_pair(
            self, pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )
        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)
        _, self.MLPwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def set_nb_classifier(self):
        pass

    def set_qda_classifier(self):
        layout = self.classificationLayouts['Quadratic Discriminant']
        _, self.QDAregParamDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Regularization Parameter:', layout=layout, row=1, column=0,
            description=''
        )
        _, self.QDAstoreCovarianceCheck = make_pair(
            self, pair='check', text='Store Covariance:', layout=layout, row=2,
            column=0, description=''
        )
        _, self.QDAtolDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1), text='Tolerance:', layout=layout,
            row=3, column=0, description=''
        )

    def set_rf_classifier(self):
        layout = self.classificationLayouts['Random Forest']
        _, self.RFbootstrapCheck = make_pair(
            self, pair='check', text='Bootstrap:', layout=layout, row=1, column=0,
            description=BOOTSTRAP_DESCRIPTION
        )
        _, self.RFcriterionCombo = make_pair(
            self, pair='combo', comboItems=('mse', 'mae'), text='Criterion:',
            layout=layout, row=2, column=0, pairWidth=50,
            description=CRITERION_DESCRIPTION
        )
        _, self.RFmaxDepthDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=3, column=0, description=MAX_DEPTH_DESCRIPTION
        )
        _, self.RFmaxFeaturesCombo = make_pair(
            self, pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=4, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )
        _, self.RFmaxLeafNodesDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Maximum Leaf Nodes:', layout=layout, row=5, column=0,
            labelWidth=220, description=MAX_LEAF_NODES_DESCRIPTION
        )
        _, self.RFminImpurityDecreaseDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Impurity Decrease:', layout=layout, row=6, column=0,
            labelWidth=220, description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )
        _, self.RFminSamplesLeafDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=7, column=0,
            labelWidth=220, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )
        _, self.RFminSamplesSplitDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=8, column=0,
            labelWidth=175, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )
        _, self.RFminWeightFractionLeafDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=9,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )
        _, self.RFestimatorsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
            layout=layout, row=10, column=0, labelWidth=200,
            description=N_ESTIMATORS_DESCRIPTION
        )
        _, self.RFoobScoreCheck = make_pair(
            self, pair='check', text='Out-of-Bag Samples:', layout=layout, row=11,
            column=0, labelWidth=200, description=OOB_SCORE_DESCRIPTION
        )
        # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
        # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)
        # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
        # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
        _, self.RFrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=12,
            column=0, pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )
        _, self.RFwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=13, column=0,
            labelWidth=200, description=WARM_START_DESCRIPTION
        )

    def set_sgd_classifier(self):
        pass
        layout = self.classificationLayouts['Stochastic Gradient Descent']
        _, self.SGDalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout,
            row=1, column=0, description=''
        )
        _, self.SGDaverageCheck = make_pair(
            self, pair='check', text='Average:', layout=layout, row=2, column=0,
            description=''
        )
        _, self.SGDeta0Dial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout,
            row=3, column=0, description=''
        )
        _, self.SGDepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:',
            layout=layout, row=4, column=0, description=''
        )
        _, self.SGDfitInterceptCheck = make_pair(
            self, pair='check', text='Fit Intercept:', layout=layout, row=5,
            column=0, description=''
        )
        _, self.SGDlearningRateCombo = make_pair(
            self, pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
            text='Learning Rate:', layout=layout, row=6, column=0, pairWidth=100,
            description=''
        )
        _, self.SGDlossCombo = make_pair(
            self, pair='combo', comboItems=(
                'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
            layout=layout,
            row=7, column=0, pairWidth=100, description=''
        )
        _, self.SGDl1RatioDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:',
            layout=layout, row=8, column=0, description=''
        )
        _, self.SGDmaxIterationsDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=9, column=0,
            description=''
        )
        _, self.SGDpenaltyCombo = make_pair(
            self, pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
            text='Penalty:', layout=layout, row=10, column=0, pairWidth=100,
            description=''
        )
        _, self.SGDpowerTDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
            row=11, column=0, description=''
        )
        _, self.SGDrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=12,
            column=0, labelWidth=125, pairWidth=50, description=''
        )
        _, self.SGDshuffleCheck = make_pair(
            self, pair='check', text='Shuffle:', layout=layout, row=13, column=0,
            description=''
        )
        _, self.SGDtolDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:',
            layout=layout, row=14, column=0, description=''
        )
        _, self.SGDwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=15, column=0,
            description=''
        )

    def set_svm_classifier(self):
        pass
        layout = self.classificationLayouts['Support Vector Machine']
        _, self.SVMCDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
            column=0, description=C_DESCRIPTION
        )

        # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=0,
        #                                    description=CACHE_SIZE_DESCRIPTION)
        # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=1, width=50,
        #                                    description=CACHE_SIZE_DESCRIPTION)

        _, self.SVMcoef0Dial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
            layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
        )
        # DecisionFunctionShape
        _, self.SVMdegreeCombo = make_pair(
            self, pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
            layout=layout, row=3, column=0, pairWidth=100,
            description=DEGREE_DESCRIPTION
        )

        _, self.SVMprobabilityCheck = make_pair(
            self, pair='check', text='Probability:', layout=layout, row=4, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMgammaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
            row=5, column=0, description=GAMMA_DESCRIPTION
        )

        _, self.SVMkernelCombo = make_pair(
            self, pair='combo',
            comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
            text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
            description=KERNEL_DESCRIPTION
        )

        _, self.SVMmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=7, column=0, labelWidth=200,
            description=MAX_ITER_DESCRIPTION
        )

        _, self.SVMrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=8,
            column=0, labelWidth=125, pairWidth=50, description=''
        )

        _, self.SVMshrinkingCheck = make_pair(
            self, pair='check', text='Shrinking:', layout=layout, row=9, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=10, column=0, description=TOL_DESCRIPTION
        )

    def defaults(self):
        pass

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.setFixedSize(500, 300)
        self.classificationLayouts = {
            'Adaptive Boost':              make_grid(self), 'Decision Tree': make_grid(self),
            'Elastic Net':                 make_grid(self), 'Gaussian Process': make_grid(self),
            'Nearest Neighbors':           make_grid(self), 'Multilayer Perceptron': make_grid(self),
            'Quadratic Discriminant':      make_grid(self), 'Random Forest': make_grid(self),
            'Stochastic Gradient Descent': make_grid(self),
            'Support Vector Machine':      make_grid(self)
        }
        self.set_ab_classifier()
        self.set_dt_classifier()
        self.set_en_classifier()
        self.set_gp_classifier()
        self.set_knn_classifier()
        self.set_mlp_classifier()
        self.set_qda_classifier()
        self.set_rf_classifier()
        self.set_sgd_classifier()
        self.set_svm_classifier()
        self.rewindow()

    def get_options(self):
        options = {
            'abcEstimators':                    self.ABestimatorsDial.value(),
            'abcLearningRate':                  self.ABlearningRateDial.value() / 10.0,
            'abcLoss':                          self.ABlossCombo.currentText(),

            'dtcCriterion':                     self.DTcriterionCombo.currentText(),
            'dtcMaximumDepth':                  self.DTmaxDepthDial.value(),
            'dtcMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
            'dtcMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
            'dtcMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
            'dtcMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
            'dtcMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
            'dtcPresort':                       self.DTpresortCheck.isChecked(),
            'dtcRandomState':                   self.DTrandomStateEntry.text(),
            'dtcSplitter':                      self.DTsplitterCombo.currentText(),

            'enrAlpha':                         self.ENalphaDial.value() / 10.0,
            # 'enrFitIntercept': self.ENfitInterceptCheck.isChecked(),
            'enrL1Ratio':                       self.ENl1RatioDial.value() / 10.0,
            'enrNormalize':                     self.ENnormalizeCheck.isChecked(),
            'enrPositive':                      self.ENpositiveCheck.isChecked(),
            'enrSelection':                     self.ENselectionCombo.currentText(),
            'enrTolerance':                     self.ENtolDial.value() / 100.0,
            'enrWarmStart':                     self.ENwarmStartCheck.isChecked(),

            'gpcAlpha':                         self.GPalphaDial.value() / 100.0,
            # 'gpcKernel': self.GPkernelCombo.currentText(),
            'gpcNormalize':                     self.GPnormalizeCheck.isChecked(),
            # 'gpcOptimizer': self.GPoptimizerCombo.currentText(),

            'knncAlgorithm':                    self.KNNalgorithmCombo.currentText(),
            'knncLeafSize':                     self.KNNleafSizeDial.value(),
            'knncMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
            'knncNumberOfNeighbors':            self.KNNneighborsDial.value(),
            'knncWeightsFunction':              self.KNNweightsCombo.currentText(),

            'mlpcActivationFunction':           self.MLPactivationCombo.currentText(),
            # 'mlpcBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
            'mlpcEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
            'mlpcFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
            'mlpcHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
            'mlpcInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
            'mlpcLearningRate':                 self.MLPlearningRateCombo.currentText(),
            'mlpcMaximumIterations':            self.MLPmaxIterDial.value(),
            'mlpcMomentum':                     self.MLPmomentumDial.value() / 10.0,
            'mlpcNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
            'mlpcNumericalStability':           self.MLPepsilonDial.value() / 100.0,
            'mlpcPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
            'mlpcPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
            'mlpcRandomState':                  self.MLPrandomStateEntry.text(),
            'mlpcShuffle':                      self.MLPshuffleCheck.isChecked(),
            'mlpcSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
            'mlpcTolerance':                    self.MLPtolDial.value() / 100.0,
            'mlpcValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
            'mlpcWarmStart':                    self.MLPwarmStartCheck.isChecked(),
            'mlpcWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

            'qda':                              None,

            'rfcBootstrap':                     self.RFbootstrapCheck.isChecked(),
            'rfcCriterion':                     self.RFcriterionCombo.currentText(),
            'rfcMaximumDepth':                  self.RFmaxDepthDial.value(),
            'rfcMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
            'rfcMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
            'rfcMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
            'rfcMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
            'rfcMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
            'rfcMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
            'rfcNumberOfTrees':                 self.RFestimatorsDial.value(),
            'rfcOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
            'rfcRandomState':                   self.RFrandomStateEntry.text(),
            'rfcWarmStart':                     self.RFwarmStartCheck.isChecked(),

            'sgdcAlpha':                        self.SGDalphaDial.value() / 100000,
            'sgdcAverage':                      self.SGDaverageCheck.isChecked(),
            'sgdcEta0':                         self.SGDeta0Dial.value() / 10.0,
            'sgdcFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
            'sgdcLearningRate':                 self.SGDlearningRateCombo.currentText(),
            'sgdcLoss':                         self.SGDlossCombo.currentText(),
            'sgdcL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
            'sgdcMaxIterations':                self.SGDmaxIterationsDial.value(),
            'sgdcPenalty':                      self.SGDpenaltyCombo.currentText(),
            'sgdcPowerT':                       self.SGDpowerTDial.value() / 10.0,
            'sgdcShuffle':                      self.SGDshuffleCheck.isChecked(),
            'sgdcTolerance':                    self.SGDtolDial.value() / 100.0,
            'sgdcWarmStart':                    self.SGDwarmStartCheck.isChecked(),

            'svmcC':                            dh.nonize(self.SVMCDial.value()),
            # 'svmcCacheSize': self.SVMcacheSizeDial.value(),
            'svmcCoefficient0':                 self.SVMcoef0Dial.value() / 10.0,
            'svmcEpsilon':                      self.SVMepsilonDial.value() / 10.0,
            'svmcGamma':                        self.SVMgammaDial.value(),
            'svmcKernel':                       self.SVMkernelCombo.currentText(),
            'svmcMaximumIterations':            self.SVMmaxIterDial.value(),
            'svmcPolynomialDegree':             self.SVMdegreeCombo.currentText(),
            'svmcShrinking':                    self.SVMshrinkingCheck.isChecked(),
            'svmcTolerance':                    self.SVMtolDial.value() / 100.0,
        }
        return options

    def set_en_classifier(self):
        pass

    def set_gp_classifier(self):
        layout = self.classificationLayouts['Gaussian Process']
        _, self.GPrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=1, column=0,
            labelWidth=125, pairWidth=50, description=''
        )
        _, self.GPwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=2, column=0,
            description=''
        )

    def set_knn_classifier(self):
        layout = self.classificationLayouts['Nearest Neighbors']
        _, self.KNNalgorithmCombo = make_pair(
            self, pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
            text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
            description=ALGORITHM_DESCRIPTION
        )
        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)
        _, self.KNNleafSizeDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:',
            layout=layout, row=2, column=0, description=LEAF_SIZE_DESCRIPTION
        )
        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)
        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)
        _, self.KNNminkowskiPowerDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 2, 1),
            text='Minkowski Power:', layout=layout, row=3, column=0,
            description=P_DESCRIPTION
        )
        _, self.KNNneighborsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 5, 1),
            text='Number of Neighbors:', layout=layout, row=4, column=0,
            labelWidth=200, description=N_NEIGHBORS_DESCRIPTION
        )
        _, self.KNNweightsCombo = make_pair(
            self, pair='combo', comboItems=('uniform', 'distance'),
            text='Weights Function:', layout=layout, row=5, column=0, labelWidth=200,
            pairWidth=100, description=WEIGHTS_DESCRIPTION
        )

    def set_mlp_classifier(self):
        layout = self.classificationLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            self, pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )
        _, self.MLPalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Alpha (Penalty Parameter):', layout=layout, row=2, column=0,
            labelWidth=200, description=MLP_ALPHA_DESCRIPTION
        )
        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        _, self.MLPbeta1Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )
        _, self.MLPbeta2Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )
        _, self.MLPearlyStoppingCheck = make_pair(
            self, pair='check', text='Early Stopping:', layout=layout, row=5,
            column=0, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )
        _, self.MLPepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )
        _, self.MLPhiddenLayerSizesEntry = make_pair(
            self, pair='entry', text='Hidden Layer Sizes:', layout=layout,
            row=7, column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )
        _, self.MLPinitLearningRateDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )
        _, self.MLPlearningRateCombo = make_pair(
            self, pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )
        _, self.MLPmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )
        _, self.MLPmomentumDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
            layout=layout, row=11, column=0, description=MOMENTUM_DESCRIPTION
        )
        _, self.MLPnesterovsMomentumCheck = make_pair(
            self, pair='check', text='Nesterov\'s Momentum:', layout=layout,
            row=12, column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )
        _, self.MLPpowerTDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )
        _, self.MLPrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=14,
            column=0, pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )
        _, self.MLPshuffleCheck = make_pair(
            self, pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )
        _, self.MLPsolverCombo = make_pair(
            self, pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )
        _, self.MLPtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=17, column=0, description=MLP_TOL_DESCRIPTION
        )
        _, self.MLPvalidationFractionDial = make_pair(
            self, pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )
        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)
        _, self.MLPwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.setFixedSize(500, 300)
        self.classificationLayouts = {
            'Adaptive Boost':              make_grid(self), 'Decision Tree': make_grid(self),
            'Gaussian Process':            make_grid(self), 'Nearest Neighbors': make_grid(self),
            'Multilayer Perceptron':       make_grid(self), 'Naive Bayes': make_grid(self),
            'Quadratic Discriminant':      make_grid(self), 'Random Forest': make_grid(self),
            'Stochastic Gradient Descent': make_grid(self),
            'Support Vector Machine':      make_grid(self)
        }
        self.set_ab_classifier()
        self.set_dt_classifier()
        self.set_gp_classifier()
        self.set_knn_classifier()
        self.set_mlp_classifier()
        self.set_nb_classifier()
        self.set_qda_classifier()
        self.set_rf_classifier()
        self.set_sgd_classifier()
        self.set_svm_classifier()
        self.rewindow()

    def get_options(self):
        options = {
            'abcEstimators':                    self.ABestimatorsDial.value(),
            'abcLearningRate':                  self.ABlearningRateDial.value() / 10.0,
            'abcLoss':                          self.ABlossCombo.currentText(),

            'dtcCriterion':                     self.DTcriterionCombo.currentText(),
            'dtcMaximumDepth':                  self.DTmaxDepthDial.value(),
            'dtcMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
            'dtcMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
            'dtcMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
            'dtcMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
            'dtcMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
            'dtcPresort':                       self.DTpresortCheck.isChecked(),
            'dtcRandomState':                   self.DTrandomStateEntry.text(),
            'dtcSplitter':                      self.DTsplitterCombo.currentText(),

            'gpcAlpha':                         self.GPalphaDial.value() / 100.0,
            # 'gpcKernel': self.GPkernelCombo.currentText(),
            'gpcNormalize':                     self.GPnormalizeCheck.isChecked(),
            # 'gpcOptimizer': self.GPoptimizerCombo.currentText(),

            'knncAlgorithm':                    self.KNNalgorithmCombo.currentText(),
            'knncLeafSize':                     self.KNNleafSizeDial.value(),
            'knncMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
            'knncNumberOfNeighbors':            self.KNNneighborsDial.value(),
            'knncWeightsFunction':              self.KNNweightsCombo.currentText(),

            'mlpcActivationFunction':           self.MLPactivationCombo.currentText(),
            # 'mlpcBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
            'mlpcEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
            'mlpcFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
            'mlpcHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
            'mlpcInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
            'mlpcLearningRate':                 self.MLPlearningRateCombo.currentText(),
            'mlpcMaximumIterations':            self.MLPmaxIterDial.value(),
            'mlpcMomentum':                     self.MLPmomentumDial.value() / 10.0,
            'mlpcNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
            'mlpcNumericalStability':           self.MLPepsilonDial.value() / 100.0,
            'mlpcPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
            'mlpcPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
            'mlpcRandomState':                  self.MLPrandomStateEntry.text(),
            'mlpcShuffle':                      self.MLPshuffleCheck.isChecked(),
            'mlpcSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
            'mlpcTolerance':                    self.MLPtolDial.value() / 100.0,
            'mlpcValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
            'mlpcWarmStart':                    self.MLPwarmStartCheck.isChecked(),
            'mlpcWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

            'nb':                               None,

            'qda':                              None,

            'rfcBootstrap':                     self.RFbootstrapCheck.isChecked(),
            'rfcCriterion':                     self.RFcriterionCombo.currentText(),
            'rfcMaximumDepth':                  self.RFmaxDepthDial.value(),
            'rfcMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
            'rfcMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
            'rfcMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
            'rfcMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
            'rfcMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
            'rfcMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
            'rfcNumberOfTrees':                 self.RFestimatorsDial.value(),
            'rfcOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
            'rfcRandomState':                   self.RFrandomStateEntry.text(),
            'rfcWarmStart':                     self.RFwarmStartCheck.isChecked(),

            'sgdcAlpha':                        self.SGDalphaDial.value() / 100000,
            'sgdcAverage':                      self.SGDaverageCheck.isChecked(),
            'sgdcEta0':                         self.SGDeta0Dial.value() / 10.0,
            'sgdcFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
            'sgdcLearningRate':                 self.SGDlearningRateCombo.currentText(),
            'sgdcLoss':                         self.SGDlossCombo.currentText(),
            'sgdcL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
            'sgdcMaxIterations':                self.SGDmaxIterationsDial.value(),
            'sgdcPenalty':                      self.SGDpenaltyCombo.currentText(),
            'sgdcPowerT':                       self.SGDpowerTDial.value() / 10.0,
            'sgdcShuffle':                      self.SGDshuffleCheck.isChecked(),
            'sgdcTolerance':                    self.SGDtolDial.value() / 100.0,
            'sgdcWarmStart':                    self.SGDwarmStartCheck.isChecked(),

            'svmcC':                            dh.nonize(self.SVMCDial.value()),
            # 'svmcCacheSize': self.SVMcacheSizeDial.value(),
            'svmcCoefficient0':                 self.SVMcoef0Dial.value() / 10.0,
            'svmcEpsilon':                      self.SVMepsilonDial.value() / 10.0,
            'svmcGamma':                        self.SVMgammaDial.value(),
            'svmcKernel':                       self.SVMkernelCombo.currentText(),
            'svmcMaximumIterations':            self.SVMmaxIterDial.value(),
            'svmcPolynomialDegree':             self.SVMdegreeCombo.currentText(),
            'svmcShrinking':                    self.SVMshrinkingCheck.isChecked(),
            'svmcTolerance':                    self.SVMtolDial.value() / 100.0,
        }
        return options

    def set_mlp_classifier(self):
        layout = self.classificationLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            self, pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )

        _, self.MLPalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Alpha (Penalty Parameter):', layout=layout, row=2, column=0,
            labelWidth=200, description=MLP_ALPHA_DESCRIPTION
        )

        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)

        _, self.MLPbeta1Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )

        _, self.MLPbeta2Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 2 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )

        _, self.MLPearlyStoppingCheck = make_pair(
            self, pair='check', text='Early Stopping:', layout=layout, row=5,
            column=0, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )

        _, self.MLPepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )

        _, self.MLPhiddenLayerSizesEntry = make_pair(
            self, pair='entry', text='Hidden Layer Sizes:', layout=layout,
            row=7, column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

        _, self.MLPinitLearningRateDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )

        _, self.MLPlearningRateCombo = make_pair(
            self, pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )

        _, self.MLPmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )

        _, self.MLPmomentumDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
            layout=layout, row=11, column=0, description=MOMENTUM_DESCRIPTION
        )

        _, self.MLPnesterovsMomentumCheck = make_pair(
            self, pair='check', text='Nesterov\'s Momentum:', layout=layout,
            row=12, column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )

        _, self.MLPpowerTDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )

        _, self.MLPrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=14,
            column=0, pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )

        _, self.MLPshuffleCheck = make_pair(
            self, pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )

        _, self.MLPsolverCombo = make_pair(
            self, pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )

        _, self.MLPtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=17, column=0, description=MLP_TOL_DESCRIPTION
        )

        _, self.MLPvalidationFractionDial = make_pair(
            self, pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )

        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

        _, self.MLPwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def set_svm_classifier(self):
        pass
        layout = self.classificationLayouts['Support Vector Machine']
        _, self.SVMCDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
            column=0, description=C_DESCRIPTION
        )

        # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
        #                                    row=9, column=0,
        #                                    description=CACHE_SIZE_DESCRIPTION)
        # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
        #                                    row=9, column=1, width=50,
        #                                    description=CACHE_SIZE_DESCRIPTION)

        _, self.SVMcoef0Dial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
            layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
        )
        # DecisionFunctionShape
        _, self.SVMdegreeCombo = make_pair(
            self, pair='combo', comboItems=('2', '3', '4', '5'), text='Degree:',
            layout=layout, row=3, column=0, pairWidth=100,
            description=DEGREE_DESCRIPTION
        )

        _, self.SVMprobabilityCheck = make_pair(
            self, pair='check', text='Probability:', layout=layout, row=4, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMgammaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
            row=5, column=0, description=GAMMA_DESCRIPTION
        )

        _, self.SVMkernelCombo = make_pair(
            self, pair='combo',
            comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
            text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
            description=KERNEL_DESCRIPTION
        )

        _, self.SVMmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=7, column=0, labelWidth=200,
            description=MAX_ITER_DESCRIPTION
        )

        _, self.SVMrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=8,
            column=0, labelWidth=125, pairWidth=50, description=''
        )

        _, self.SVMshrinkingCheck = make_pair(
            self, pair='check', text='Shrinking:', layout=layout, row=9, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=10, column=0, description=TOL_DESCRIPTION
        )

    def defaults(self):
        pass


class ClassificationMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.advancedOptionsMenu = ClassificationAdvancedOptionsMenu(
            self, 'Classification Advanced Options',
            CLASSIFICATION_ICON
        )

        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)

        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=7, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=7,
            column=2, description=PARALLEL_DESCRIPTION
        )

        modeGroup.addButton(self.seriesRadio)
        modeGroup.addButton(self.parallelRadio)
        self.seriesRadio.setChecked(True)
        self.parallelRadio.setChecked(False)
        self.mode = 'series'

        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=8, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=8, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=9,
            column=0, description=RUN_CLASSIFICATION_DESCRIPTION
        )

        self.advancedOptionsButton = make_button(
            self, command=lambda: self.advancedOptionsMenu.show(),
            text='Advanced Options', layout=self.topRightLayout, row=9, column=1,
            width=150
        )

        self.set_classifiers()
        self.siteContainer = make_browser(layout=self.bottomLayout, file=CLASSIFICATION_GRAPH)
        try:
            self.combos()
        except:
            pass

    def set_classifiers(self):
        layout = self.topRightLayout
        # Left Column
        _, self.aBCheck = make_pair(
            self, pair='check', text='Adaptive Boost:', layout=layout, row=1, column=0,
            description=AB_DESCRIPTION
        )

        _, self.dTreeCheck = make_pair(
            self, pair='check', text='Decision Tree:', layout=layout, row=2, column=0,
            description=D_TREE_DESCRIPTION
        )

        _, self.eNCheck = make_pair(
            self, pair='check', text='Elastic Net:', layout=layout, row=3, column=0,
            description=E_NET_DESCRIPTION
        )

        _, self.gProcessCheck = make_pair(
            self, pair='check', text='Gaussian Process:', layout=layout, row=4, column=0,
            description=''
        )

        _, self.kNNCheck = make_pair(
            self, pair='check', text='Nearest Neighbors:', layout=layout, row=5, column=0,
            description=K_NEIGHBORS_DESCRIPTION
        )

        # Right Column
        _, self.mlpCheck = make_pair(
            self, pair='check', text='Multilayer Perceptron:', layout=layout, row=1, column=2,
            description=MLP_DESCRIPTION
        )

        _, self.qdaCheck = make_pair(
            self, pair='check', text='Quadratic Discriminant:', layout=layout, row=2, column=2,
            description=QDA_DESCRIPTION
        )

        _, self.rForestCheck = make_pair(
            self, pair='check', text='Random Forest:', layout=layout, row=3, column=2,
            description=R_FOREST_DESCRIPTION
        )

        _, self.sGDradientCheck = make_pair(
            self, pair='check', text='Stochastic Gradient Descent:', layout=layout,
            row=4, column=2, description=SGD_DESCRIPTION
        )

        _, self.svmCheck = make_pair(
            self, pair='check', text='Support Vector Machine:', layout=layout, row=5, column=2,
            description=SVM_DESCRIPTION
        )

        _, self.automaticCheck = make_pair(
            self, pair='check', text='Auto-Tune:', layout=layout, row=6, column=0,
            description=AUTOMATIC_TUNING_DESCRIPTION
        )
        self.classifierChecks = [self.aBCheck, self.dTreeCheck, self.eNCheck, self.gProcessCheck, self.kNNCheck,
                                 self.mlpCheck, self.qdaCheck, self.rForestCheck, self.sGDradientCheck, self.svmCheck]

    def graph_raw(self):
        self.get_mode()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        data, xKeys, yKeys = dh.process_data(dir, index, column, self.mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
        )
        self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)

    def run(self):
        self.get_mode()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        if self.validate():
            models = self.get_models()
            data, xKeys, yKeys = dh.process_data(dir, index, column, self.mode)
            results = Classifiers.classification(models, x=data.index, y=data)
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.index, data.index),)
            y = ((results, data),)
            make_plot(
                CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Classification',),
                xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                lineWidths=((1, 1),), legends=((True, True),), types=(('line', 'scatter'),), xKeys=(xKeys,),
                yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)

    def get_checks(self):
        checks = {
            'Adaptive Boost':              self.aBCheck.isChecked(), 'Decision Tree': self.dTreeCheck.isChecked(),
            'Elastic Net':                 self.eNCheck.isChecked(), 'Gaussian Process': self.gProcessCheck.isChecked(),
            'Nearest Neighbors':           self.kNNCheck.isChecked(),
            'Multilayer Perceptron':       self.mlpCheck.isChecked(),
            'Quadratic Discriminant':      self.qdaCheck.isChecked(), 'Random Forest': self.rForestCheck.isChecked(),
            'Stochastic Gradient Descent': self.sGDradientCheck.isChecked(),
            'Support Vector Machine':      self.svmCheck.isChecked(),
        }
        return checks

    def validate(self):
        error = False
        if any(check.isChecked() for check in self.classifierChecks):
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if self.mode == 'parallel':
            if dh.filecount(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.advancedOptionsMenu = ClassificationAdvancedOptionsMenu(
            self, 'Classification Advanced Options',
            CLASSIFICATION_ICON
        )

        """TOP RIGHT"""

        self.classLabel = make_label(
            self, text='Class:', layout=self.topRightLayout, row=9, column=0,
            description=CLASS_COMBO_DESCRIPTION
        )

        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=8, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=8, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=10, column=0,
            description=RUN_CLASSIFICATION_DESCRIPTION
        )

        self.advancedOptionsButton = make_button(
            self, command=self.advancedOptionsMenu.show, text='Advanced Options',
            layout=self.topRightLayout, row=10, column=1, width=150
        )

        self.set_classifiers()
        self.siteContainer = make_browser(layout=self.bottomLayout, file=CLASSIFICATION_GRAPH)
        try:
            self.combos()
        except:
            pass

    def set_classifiers(self):
        layout = self.topRightLayout
        # Left Column
        _, self.aBCheck = make_pair(
            self, pair='check', text='Adaptive Boost:', layout=layout, row=1, column=0,
            description=AB_DESCRIPTION
        )
        _, self.dTreeCheck = make_pair(
            self, pair='check', text='Decision Tree:', layout=layout, row=2, column=0,
            description=D_TREE_DESCRIPTION
        )
        _, self.gProcessCheck = make_pair(
            self, pair='check', text='Gaussian Process:', layout=layout, row=3, column=0,
            description=''
        )
        _, self.kNNCheck = make_pair(
            self, pair='check', text='Nearest Neighbors:', layout=layout, row=4, column=0,
            description=K_NEIGHBORS_DESCRIPTION
        )
        _, self.mlpCheck = make_pair(
            self, pair='check', text='Multilayer Perceptron:', layout=layout, row=5, column=0,
            description=MLP_DESCRIPTION
        )
        # Right Column
        _, self.nBCheck = make_pair(
            self, pair='check', text='Naive Bayes:', layout=layout, row=1, column=2,
            description=NAIVE_BAYES_DESCRIPTION
        )
        _, self.qdaCheck = make_pair(
            self, pair='check', text='Quadratic Discriminant:', layout=layout, row=2, column=2,
            description=QDA_DESCRIPTION
        )
        _, self.rForestCheck = make_pair(
            self, pair='check', text='Random Forest:', layout=layout, row=3, column=2,
            description=R_FOREST_DESCRIPTION
        )
        _, self.sGDradientCheck = make_pair(
            self, pair='check', text='Stochastic Gradient Descent:', layout=layout,
            row=4, column=2, description=SGD_DESCRIPTION
        )
        _, self.svmCheck = make_pair(
            self, pair='check', text='Support Vector Machine:', layout=layout, row=5, column=2,
            description=SVM_DESCRIPTION
        )
        _, self.automaticCheck = make_pair(
            self, pair='check', text='Auto-Tune:', layout=layout, row=6, column=0,
            description=AUTOMATIC_TUNING_DESCRIPTION
        )
        self.classifierChecks = [self.aBCheck, self.dTreeCheck, self.gProcessCheck, self.kNNCheck, self.mlpCheck,
                                 self.nBCheck, self.qdaCheck, self.rForestCheck, self.sGDradientCheck, self.svmCheck]

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)
        self.classCombo = make_combo(
            self, [''] + self.headers, command=None, layout=self.topRightLayout, row=9,
            column=1, width=200, description=INDEX_COMBO_DESCRIPTION
        )
        self.indexCombo = make_combo(
            self, [''] + self.headers, command=self.update_columns, layout=self.topRightLayout,
            row=8, column=1, width=200, description=INDEX_COMBO_DESCRIPTION
        )
        self.columnCombo = make_combo(
            self, self.headers, command=self.graph_raw, layout=self.topRightLayout, row=8,
            column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def graph_raw(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        classification = self.classCombo.currentText()
        dir = self.readLabel.text()
        data, classLabels, xKeys, yKeys, labelKeys = dh.process_classification_data(
            dir, index, column,
            classification, )
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Raw Data',), xLabels=(index,), yLabels=(column,),
            lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,),
            classLabels=(classLabels,)
        )
        self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)

    def run(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        classification = self.classCombo.currentText()
        dir = self.readLabel.text()
        if self.validate():
            try:
                models = self.get_models()
                data, classLabels, xKeys, yKeys, labelKeys = dh.process_classification_data(
                    dir, index, column,
                    classification, )
                results = Classifiers.classification(models, x=data, y=classLabels)
                data = pd.DataFrame(data, columns=(column,), index=data.index)
                x = ((data.index, data.index),)
                y = ((results, data),)
                make_plot(
                    CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Classification',), xLabels=(index,),
                    yLabels=(column,), lineWidths=((1, 1),), legends=((True, True),),
                    types=(('line', 'scatter'),), xKeys=(xKeys,), yKeys=(yKeys,), classLabels=(classLabels,)
                )
                self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)
            except Exception as e:
                print(e)

    def validate(self):
        error = False
        if any(check.isChecked() for check in self.classifierChecks):
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.advancedOptionsMenu = ClassificationAdvancedOptionsMenu(
            self, 'Classification Advanced Options',
            CLASSIFICATION_ICON
        )

        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)

        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=7, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=7,
            column=2, description=PARALLEL_DESCRIPTION
        )

        modeGroup.addButton(self.seriesRadio)
        modeGroup.addButton(self.parallelRadio)
        self.seriesRadio.setChecked(True)
        self.parallelRadio.setChecked(False)
        self.mode = 'series'

        self.classLabel = make_label(
            self, text='Class:', layout=self.topRightLayout, row=9, column=0,
            description=CLASS_COMBO_DESCRIPTION
        )

        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=8, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=8, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=10, column=0,
            description=RUN_CLASSIFICATION_DESCRIPTION
        )

        self.advancedOptionsButton = make_button(
            self, command=self.advancedOptionsMenu.show, text='Advanced Options',
            layout=self.topRightLayout, row=10, column=1, width=150
        )

        self.set_classifiers()
        self.siteContainer = make_browser(layout=self.bottomLayout, file=CLASSIFICATION_GRAPH)
        try:
            self.combos()
        except:
            pass

    def set_classifiers(self):
        layout = self.topRightLayout
        # Left Column
        _, self.aBCheck = make_pair(
            self, pair='check', text='Adaptive Boost:', layout=layout, row=1, column=0,
            description=AB_DESCRIPTION
        )

        _, self.dTreeCheck = make_pair(
            self, pair='check', text='Decision Tree:', layout=layout, row=2, column=0,
            description=D_TREE_DESCRIPTION
        )

        _, self.gProcessCheck = make_pair(
            self, pair='check', text='Gaussian Process:', layout=layout, row=3, column=0,
            description=''
        )

        _, self.kNNCheck = make_pair(
            self, pair='check', text='Nearest Neighbors:', layout=layout, row=4, column=0,
            description=K_NEIGHBORS_DESCRIPTION
        )

        _, self.mlpCheck = make_pair(
            self, pair='check', text='Multilayer Perceptron:', layout=layout, row=5, column=0,
            description=MLP_DESCRIPTION
        )

        # Right Column
        _, self.nBCheck = make_pair(
            self, pair='check', text='Naive Bayes:', layout=layout, row=1, column=2,
            description=NAIVE_BAYES_DESCRIPTION
        )

        _, self.qdaCheck = make_pair(
            self, pair='check', text='Quadratic Discriminant:', layout=layout, row=2, column=2,
            description=QDA_DESCRIPTION
        )

        _, self.rForestCheck = make_pair(
            self, pair='check', text='Random Forest:', layout=layout, row=3, column=2,
            description=R_FOREST_DESCRIPTION
        )

        _, self.sGDradientCheck = make_pair(
            self, pair='check', text='Stochastic Gradient Descent:', layout=layout,
            row=4, column=2, description=SGD_DESCRIPTION
        )

        _, self.svmCheck = make_pair(
            self, pair='check', text='Support Vector Machine:', layout=layout, row=5, column=2,
            description=SVM_DESCRIPTION
        )

        _, self.automaticCheck = make_pair(
            self, pair='check', text='Auto-Tune:', layout=layout, row=6, column=0,
            description=AUTOMATIC_TUNING_DESCRIPTION
        )

        self.classifierChecks = [self.aBCheck, self.dTreeCheck, self.gProcessCheck, self.kNNCheck, self.mlpCheck,
                                 self.nBCheck, self.qdaCheck, self.rForestCheck, self.sGDradientCheck, self.svmCheck]

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.classCombo = make_combo(
            self, [''] + self.headers, command=None, layout=self.topRightLayout, row=9,
            column=1, width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            self, self.headers, command=self.graph_raw, layout=self.topRightLayout, row=8,
            column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        self.indexCombo = make_combo(
            self, [''] + self.headers, command=self.update_columns, layout=self.topRightLayout,
            row=8, column=1, width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            self, options, layout=self.topRightLayout, command=self.graph_raw, row=8,
            column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.graph_raw()

    def graph_raw(self):
        self.get_mode()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        classification = self.classCombo.currentText()
        dir = self.readLabel.text()
        data, xKeys, yKeys, classLabels = dh.process_classification_data(dir, index, column, classification, self.mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,), classLabels=(classLabels,)
        )
        self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)

    def run(self):
        self.get_mode()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        classification = self.classCombo.currentText()
        dir = self.readLabel.text()
        if self.validate():
            models = self.get_models()
            data, xKeys, yKeys, classLabels = dh.process_classification_data(
                dir, index, column, classification,
                self.mode
            )
            results = Classifiers.classification(models, x=data.index, y=data)
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.index, data.index),)
            y = ((results, data),)
            make_plot(
                CLASSIFICATION_GRAPH, X=x, Y=y, titles=('Classification',),
                xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                lineWidths=((1, 1),), legends=((True, True),), types=(('line', 'scatter'),), xKeys=(xKeys,),
                yKeys=(yKeys,), classLabels=(classLabels,)
            )
            self.siteContainer = load_browser(self.siteContainer, CLASSIFICATION_GRAPH)

    def get_checks(self):
        checks = {
            'Adaptive Boost':              self.aBCheck.isChecked(), 'Decision Tree': self.dTreeCheck.isChecked(),
            'Gaussian Process':            self.gProcessCheck.isChecked(),
            'Nearest Neighbors':           self.kNNCheck.isChecked(),
            'Multilayer Perceptron':       self.mlpCheck.isChecked(), 'Naive Bayes': self.nBCheck.isChecked(),
            'Quadratic Discriminant':      self.qdaCheck.isChecked(), 'Random Forest': self.rForestCheck.isChecked(),
            'Stochastic Gradient Descent': self.sGDradientCheck.isChecked(),
            'Support Vector Machine':      self.svmCheck.isChecked(),
        }
        return checks

    def get_mode(self):
        if self.seriesRadio.isChecked():
            self.mode = 'series'
        elif self.parallelRadio.isChecked():
            self.mode = 'parallel'

    def get_models(self):
        checks = self.get_checks()
        if self.automaticCheck.isChecked():
            models = Classifiers.cross_validation_classification_models(checks)
        else:
            options = self.advancedOptionsMenu.get_options()
            models = Classifiers.classification_models(checks, options)
        return models

    def validate(self):
        error = False
        if any(check.isChecked() for check in self.classifierChecks):
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if self.mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False


class DatabaseMenu(SubMenu):
    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=TXT_FILES, layout=self.topRightLayout)
        self.bajaLabel = make_label(self, text='BAJA:', layout=self.topRightLayout, row=1, column=0)
        self.bajaCheck = make_button(self, buttonType='check', layout=self.topRightLayout, row=1, column=1)

        self.encodingLabel = make_label(
            self, text='Encoding: ', layout=self.bottomLayout, row=1, column=0,
            description=ENCODING_DESCRIPTION
        )
        self.encodingEntry = make_entry(
            self, layout=self.bottomLayout, row=1, column=1,
            description=ENCODING_DESCRIPTION
        )
        self.IDLabel = make_label(
            self, text='ID Column: ', layout=self.bottomLayout, row=2, column=0,
            description=INDEX_COLUMN_DESCRIPTION
        )
        self.latLabel = make_label(
            self, text='Latitude Column: ', layout=self.bottomLayout, row=3, column=0,
            description=LATITUDE_COLUMN_DESCRIPTION
        )
        self.lonLabel = make_label(
            self, text='Longitude Column: ', layout=self.bottomLayout, row=4, column=0,
            description=LONGITUDE_COLUMN_DESCRIPTION
        )
        self.ID = make_entry(self, layout=self.bottomLayout, row=2, column=1, description=INDEX_COLUMN_DESCRIPTION)
        self.lat = make_entry(self, layout=self.bottomLayout, row=3, column=1, description=LATITUDE_COLUMN_DESCRIPTION)
        self.lon = make_entry(self, layout=self.bottomLayout, row=4, column=1, description=LONGITUDE_COLUMN_DESCRIPTION)

        with open(DATABASE_VARIABLES) as file:
            self.encodingEntry.setText(next(file).strip())
            self.ID.setText(next(file).strip())
            self.lat.setText(next(file).strip())
            self.lon.setText(next(file).strip())
            self.dataSource = next(file).strip()
            self.readLabel.setText(self.dataSource)

            # RUN BUTTON
        self.runButton = make_button(
            self, command=lambda: self.apply(self.readLabel.text()), text='Apply',
            layout=self.topRightLayout, row=4, column=0
        )

    def apply(self, dir):
        self.vars = [self.encodingEntry.text(), self.ID.text(), self.lat.text(), self.lon.text()]
        self.args = []
        for var in self.vars:
            if var == '':
                self.args.append('None')
            else:
                self.args.append("'" + str(var) + "'")
        database_setup(dir, self.args[0], self.args[1], self.args[2], self.args[3])
        self.parent.searchMenu.readLabel.setText(self.readLabel.text())
        self.parent.searchMenu.rewindow()
        # self.parent.geoSearchMenu.readLabel.setText(self.readLabel.text())
        self.parent.classificationMenu.readLabel.setText(self.readLabel.text())
        self.parent.regressionMenu.readLabel.setText(self.readLabel.text())
        self.parent.simulationMenu.readLabel.setText(self.readLabel.text())

        self.parent.regressionMenu.combos()
        self.parent.simulationMenu.combos()
        Search.dh.imp.reload(Search.dh.vars)  # geo.dh.imp.reload(geo.dh.vars)

    def apply(self, dir):
        self.vars = [self.encodingEntry.text(), self.ID.text(), self.lat.text(), self.lon.text()]
        self.args = []
        for var in self.vars:
            if var == '':
                self.args.append('None')
            else:
                self.args.append("'" + str(var) + "'")
        database_setup(dir, self.args[0], self.args[1], self.args[2], self.args[3])
        self.parent.searchMenu.readLabel.setText(self.readLabel.text())
        self.parent.searchMenu.rewindow()
        self.parent.geoSearchMenu.readLabel.setText(self.readLabel.text())
        self.parent.regressionMenu.readLabel.setText(self.readLabel.text())
        self.parent.mcmcMenu.readLabel.setText(self.readLabel.text())

        self.parent.regressionMenu.combos()
        self.parent.mcmcMenu.combos()
        Search.dh.imp.reload(Search.dh.vars)
        geo.dh.imp.reload(geo.dh.vars)

    def apply(self, dir):
        self.vars = [self.encodingEntry.text(), self.ID.text(), self.lat.text(), self.lon.text()]
        self.args = []
        for var in self.vars:
            if var == '':
                self.args.append('None')
            else:
                self.args.append("'" + str(var) + "'")
        database_setup(dir, self.args[0], self.args[1], self.args[2], self.args[3])
        self.parent.searchMenu.rewindow()
        self.parent.searchMenu.readLabel.setText(self.readLabel.text())
        self.parent.geoSearchMenu.readLabel.setText(self.readLabel.text())
        self.parent.machineLearningMenu.readLabel.setText(self.readLabel.text())
        self.parent.mcmcMenu.readLabel.setText(self.readLabel.text())

        self.parent.machineLearningMenu.combos()
        self.parent.mcmcMenu.combos()
        Search.dh.imp.reload(Search.dh.vars)
        geo.dh.imp.reload(geo.dh.vars)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        """TOP LEFT"""
        # FILES TO READ
        self.readLabel = QtWidgets.QLabel('')
        openFolderIcon = QtGui.QIcon(OPEN_FOLDER_ICON)
        self.readButton = QtWidgets.QPushButton(openFolderIcon, '', self)
        self.readButton.setStyleSheet(BUTTON_STYLE)
        self.readButton.setIconSize(QtCore.QSize(20, 20))
        menu.set_widget_size(self.readButton, 5, 20)
        self.readButton.clicked.connect(lambda: menu.open_folder(self, label=self.readLabel))
        self.topLeftLayout.addWidget(self.readButton, 0, 0)
        self.topLeftLayout.addWidget(self.readLabel, 0, 1)

        """TOP RIGHT"""
        # APPLY BUTTON
        self.runButton = make_button(self, lambda: menu.save_file(self), 'Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=TXT_FILES)
        self.bajaLabel = make_label(self, text='BAJA:', layout=self.topRightLayout, row=1, column=0)
        self.bajaCheck = make_button(self, buttonType='check', layout=self.topRightLayout, row=1, column=1)
        self.encodingLabel = make_label(
            self, text='Encoding: ', layout=self.bottomLayout, row=1, column=0,
            description=ENCODING_DESCRIPTION
        )
        self.encodingEntry = make_entry(
            self, layout=self.bottomLayout, row=1, column=1,
            description=ENCODING_DESCRIPTION
        )
        self.IDLabel = make_label(
            self, text='ID Column: ', layout=self.bottomLayout, row=2, column=0,
            description=INDEX_COLUMN_DESCRIPTION
        )
        self.latLabel = make_label(
            self, text='Latitude Column: ', layout=self.bottomLayout, row=3, column=0,
            description=LATITUDE_COLUMN_DESCRIPTION
        )
        self.lonLabel = make_label(
            self, text='Longitude Column: ', layout=self.bottomLayout, row=4, column=0,
            description=LONGITUDE_COLUMN_DESCRIPTION
        )
        self.ID = make_entry(self, layout=self.bottomLayout, row=2, column=1, description=INDEX_COLUMN_DESCRIPTION)
        self.lat = make_entry(self, layout=self.bottomLayout, row=3, column=1, description=LATITUDE_COLUMN_DESCRIPTION)
        self.lon = make_entry(self, layout=self.bottomLayout, row=4, column=1, description=LONGITUDE_COLUMN_DESCRIPTION)
        with open(DATABASE_VARIABLES) as file:
            self.encodingEntry.setText(next(file).strip())
            self.ID.setText(next(file).strip())
            self.lat.setText(next(file).strip())
            self.lon.setText(next(file).strip())
            self.dataSource = next(file).strip()
            self.readLabel.setText(self.dataSource)  # RUN BUTTON
        self.runButton = make_button(
            self, command=lambda: self.apply(self.readLabel.text()), text='Apply',
            layout=self.topRightLayout, row=4, column=0
        )

    def apply(self, dir):
        self.vars = [self.encodingEntry.text(), self.ID.text(), self.lat.text(), self.lon.text()]
        self.args = []
        for var in self.vars:
            if var == '':
                self.args.append('None')
            else:
                self.args.append("'" + str(var) + "'")
        database_setup(dir, self.args[0], self.args[1], self.args[2], self.args[3])
        self.parent.searchMenu.readLabel.setText(self.readLabel.text())
        self.parent.searchMenu.rewindow()
        # self.parent.geoSearchMenu.readLabel.setText(self.readLabel.text())
        self.parent.regressionMenu.readLabel.setText(self.readLabel.text())
        self.parent.simulationMenu.readLabel.setText(self.readLabel.text())

        self.parent.regressionMenu.combos()
        self.parent.simulationMenu.combos()
        Search.dh.imp.reload(Search.dh.vars)  # geo.dh.imp.reload(geo.dh.vars)

    def apply(self, dir):
        self.vars = [self.encodingEntry.text(), self.ID.text(), self.lat.text(), self.lon.text()]
        self.args = []
        for var in self.vars:
            if var == '':
                self.args.append('None')
            else:
                self.args.append("'" + str(var) + "'")
        database_setup(dir, self.args[0], self.args[1], self.args[2], self.args[3])
        self.parent.searchMenu.rewindow()
        self.parent.searchMenu.readLabel.setText(self.readLabel.text())
        self.parent.geoSearchMenu.readLabel.setText(self.readLabel.text())
        search.dh.imp.reload(search.dh.vars)
        geo.dh.imp.reload(geo.dh.vars)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file)
        self.runButton = make_button(self, command=lambda: save_file(self), text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

    def apply(self, dir):
        self.vars = [self.encodingEntry.text(), self.ID.text(), self.lat.text(), self.lon.text()]
        self.args = []
        for var in self.vars:
            if var == '':
                self.args.append('None')
            else:
                self.args.append("'" + str(var) + "'")
        database_setup(dir, self.args[0], self.args[1], self.args[2], self.args[3])
        self.parent.searchMenu.readLabel.setText(self.readLabel.text())
        self.parent.searchMenu.rewindow()
        self.parent.geoSearchMenu.readLabel.setText(self.readLabel.text())
        self.parent.machineLearningMenu.readLabel.setText(self.readLabel.text())
        self.parent.mcmcMenu.readLabel.setText(self.readLabel.text())

        self.parent.machineLearningMenu.combos()
        self.parent.mcmcMenu.combos()
        Search.dh.imp.reload(Search.dh.vars)
        geo.dh.imp.reload(geo.dh.vars)


class DocumentationMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.documentationTab = make_tab(self, text='1', master=self.tabs)
        self.documentationContainer = make_browser(layout=self.documentationTab, file=DOCUMENTATION)
        self.tutorialsTab = make_tab(self, text='Tutorials', master=self.tabs)
        self.tutorialsContainer = make_browser(layout=self.tutorialsTab, file=None)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.documentationTab = make_tab(self, text='Documentation', master=self.tabs)
        self.documentationContainer = make_browser(layout=self.documentationTab, file=DOCUMENTATION)
        self.tutorialsTab = make_tab(self, text='Tutorials', master=self.tabs)
        self.tutorialsContainer = make_browser(layout=self.tutorialsTab, file=None)

    def __init__(self, parent, title, icon):
        submenu.SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.documentationTab = menu.make_tab(self, text='1', master=self.tabs)
        self.documentationContainer = menu.make_browser(layout=self.documentationTab, file=path.DOCUMENTATION)
        self.tutorialsTab = menu.make_tab(self, text='Tutorials', master=self.tabs)
        self.tutorialsContainer = menu.make_browser(layout=self.tutorialsTab, file=None)


class GeoSearchMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=KML_FILES)

        """TOP RIGHT"""
        # UNITS SELECTION
        self.units = UNITS[0]

        self.unitsLabel = make_label(self, 'Units:')
        self.topRightLayout.addWidget(self.unitsLabel, 0, 0)

        self.unitsCombo = make_combo(self, UNITS, self.change_units)
        self.topRightLayout.addWidget(self.unitsCombo, 0, 1)

        # RADIUS, LATITUDE, LONGITUDE ENTRY
        self.radiusLabel = make_label(self, 'Radius:')
        self.topRightLayout.addWidget(self.radiusLabel, 1, 0)

        self.rad = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.rad, 1, 1)

        self.lonLabel = make_label(self, 'Longitude:')
        self.topRightLayout.addWidget(self.lonLabel, 2, 0)

        self.lon = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.lon, 2, 1)

        self.latLabel = make_label(self, 'Latitude:')
        self.topRightLayout.addWidget(self.latLabel, 3, 0)

        self.lat = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.lat, 3, 1)

        self.runButton = make_button(self, command=lambda: self.run_geo_search(), text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        # BOTTOM
        self.mapa = folium.Map(tiles='Stamen Terrain', zoom_start=13)
        self.mapa.save(BASE_MAP)

        self.mapContainer = QtWebEngineWidgets.QWebEngineView()
        self.mapContainer.load(QtCore.QUrl.fromLocalFile(BASE_MAP))
        self.bottomLayout.addWidget(self.mapContainer)

    def change_units(self, units):
        self.units = units

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=KML_FILES)

        """TOP RIGHT"""
        # UNITS SELECTION
        self.units = UNITS[0]

        self.unitsLabel = make_label(self, 'Units:')
        self.topRightLayout.addWidget(self.unitsLabel, 0, 0)

        self.unitsCombo = make_combo(self, UNITS, self.change_units)
        self.topRightLayout.addWidget(self.unitsCombo, 0, 1)

        # RADIUS, LATITUDE, LONGITUDE ENTRY
        self.radiusLabel = make_label(self, 'Radius:')
        self.topRightLayout.addWidget(self.radiusLabel, 1, 0)

        self.rad = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.rad, 1, 1)

        self.lonLabel = make_label(self, 'Longitude:')
        self.topRightLayout.addWidget(self.lonLabel, 2, 0)

        self.lon = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.lon, 2, 1)

        self.latLabel = make_label(self, 'Latitude:')
        self.topRightLayout.addWidget(self.latLabel, 3, 0)

        self.lat = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.lat, 3, 1)

        self.runButton = make_button(self, command=lambda: self.run_geo_search(), text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        # BOTTOM
        self.mapa = folium.Map(tiles='Stamen Terrain')
        self.mapa.save(BASE_MAP)

        self.mapContainer = QtWebEngineWidgets.QWebEngineView()
        self.mapContainer.load(QtCore.QUrl.fromLocalFile(BASE_MAP))
        self.bottomLayout.addWidget(self.mapContainer)

    def change_units(self, units):
        self.units = units

    def run_geo_search(self):
        self.mapa = folium.Map(tiles='Stamen Terrain')
        indices, coordinates = gather_coordinates(self.readLabel.text())
        indices, coordinates = interpret_query(
            centroid=(int(self.lat.text()), int(self.lon.text())), indices=indices,
            coordinates=coordinates, radius=int(self.rad.text()), units=self.units
        )
        create_kml(indices, coordinates, self.saveLabel.text())
        for point in range(len(coordinates)):
            folium.Marker(coordinates[point], popup=indices[point]).add_to(self.mapa)
        self.mapa.save(BASE_MAP)
        self.mapContainer.load(QtCore.QUrl.fromLocalFile(BASE_MAP))

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=KML_FILES)

        """TOP RIGHT"""
        # UNITS SELECTION
        self.units = UNITS[0]
        self.unitsLabel = make_label(self, text='Units:', layout=self.topRightLayout, row=0, column=0)
        self.unitsCombo = make_combo(self, UNITS, self.change_units, layout=self.topRightLayout, row=0, column=1)

        # LATITUDE, LONGITUDE, RADIUS
        self.latLabel = make_label(self, text='Latitude:', layout=self.topRightLayout, row=1, column=0)
        self.lonLabel = make_label(self, text='Longitude:', layout=self.topRightLayout, row=2, column=0)
        self.radiusLabel = make_label(self, text='Radius:', layout=self.topRightLayout, row=3, column=0)

        self.lat = make_entry(self, width=40, layout=self.topRightLayout, row=1, column=1)
        self.lon = make_entry(self, width=40, layout=self.topRightLayout, row=2, column=1)
        self.rad = make_entry(self, width=40, layout=self.topRightLayout, row=3, column=1)

        self.runButton = make_button(
            self, command=lambda: self.run_geo_search(), text='Run',
            layout=self.topRightLayout, row=4, column=0
        )

        # BOTTOM
        self.mapa = folium.Map(tiles='OpenStreetMap', location=[61.217381, -149.863129], zoom_start=13)
        self.mapa.save(BASE_MAP)
        self.mapContainer = make_browser(layout=self.bottomLayout, file=BASE_MAP)
        self.bottomLayout.addWidget(self.mapContainer)
        self.saveLabel.setText(os.path.join(self.saveLabel.text(), 'geoSearch.kml'))
        self.lat.setText('30')
        self.lon.setText('-81')
        self.rad.setText('100')

    def change_units(self, units):
        self.units = units

    def run_geo_search(self):
        self.mapa = folium.Map(
            tiles='OpenStreetMap', location=[float(self.lat.text()), float(self.lon.text())],
            zoom_start=7
        )
        indices, coordinates = gather_coordinates(self.readLabel.text())
        indices, coordinates = interpret_query(
            centroid=(float(self.lat.text()), float(self.lon.text())),
            indices=indices, coordinates=coordinates, radius=float(self.rad.text()),
            units=self.units
        )
        popups = []
        for index in indices:
            popup = ""
            for i in index:
                popup += (str(i) + ": " + str(index[i]) + "\n")
            popups.append(popup)

        create_kml(popups, coordinates, self.saveLabel.text())

        for index, coordinate, popup in zip(indices, coordinates, popups):
            print(coordinate)
            folium.Marker(coordinate, popup=popup).add_to(self.mapa)
        self.mapa.save(BASE_MAP)
        self.mapContainer.load(QtCore.QUrl.fromLocalFile(BASE_MAP))

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=KML_FILES)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.saveLabel.setText(os.path.join(self.saveLabel.text(), 'geoSearch.kml'))
        """TOP RIGHT"""
        # UNITS SELECTION
        self.unitsLabel = make_label(
            self, text='Units:', layout=self.topRightLayout, row=0, column=0,
            description=UNITS_DESCRIPTION
        )
        self.unitsCombo = make_combo(
            self, UNITS, layout=self.topRightLayout, row=0, column=1,
            description=UNITS_DESCRIPTION
        )

        # LATITUDE, LONGITUDE, RADIUS
        self.latLabel = make_label(
            self, text='Latitude:', layout=self.topRightLayout, row=1, column=0,
            description=LATITUDE_DESCRIPTION
        )
        self.lonLabel = make_label(
            self, text='Longitude:', layout=self.topRightLayout, row=2, column=0,
            description=LONGITUDE_DESCRIPTION
        )
        self.radiusLabel = make_label(
            self, text='Radius:', layout=self.topRightLayout, row=3, column=0,
            description=RADIUS_DESCRIPTION
        )
        self.lat = make_entry(
            self, width=40, layout=self.topRightLayout, row=1, column=1,
            description=LATITUDE_DESCRIPTION
        )
        self.lon = make_entry(
            self, width=40, layout=self.topRightLayout, row=2, column=1,
            description=LONGITUDE_DESCRIPTION
        )
        self.rad = make_entry(
            self, width=40, layout=self.topRightLayout, row=3, column=1,
            description=RADIUS_DESCRIPTION
        )
        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=4, column=0,
            description=RUN_GEOSEARCH_DESCRIPTION
        )

        # BOTTOM
        self.mapContainer = make_browser(layout=self.bottomLayout, file=BASE_MAP)
        self.tile = 'OpenStreetMap'
        self.mapa = geo.create_map(
            BASE_MAP, self.tile, self.mapContainer,
            [61.217381, -149.863129]
        )  # self.mapa = MapFunctions.do_this(self.mapa)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=KML_FILES)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.saveLabel.setText(os.path.join(self.saveLabel.text(), 'geoSearch.kml'))
        """TOP RIGHT"""
        # UNITS SELECTION
        self.unitsLabel = make_label(
            self, text='Units:', layout=self.topRightLayout, row=0, column=0,
            description=UNITS_DESCRIPTION
        )
        self.unitsCombo = make_combo(
            self, UNITS, layout=self.topRightLayout, row=0, column=1,
            description=UNITS_DESCRIPTION
        )

        # LATITUDE, LONGITUDE, RADIUS
        self.latLabel = make_label(
            self, text='Latitude:', layout=self.topRightLayout, row=1, column=0,
            description=LATITUDE_DESCRIPTION
        )
        self.lonLabel = make_label(
            self, text='Longitude:', layout=self.topRightLayout, row=2, column=0,
            description=LONGITUDE_DESCRIPTION
        )
        self.radiusLabel = make_label(
            self, text='Radius:', layout=self.topRightLayout, row=3, column=0,
            description=RADIUS_DESCRIPTION
        )
        self.lat = make_entry(
            self, width=40, layout=self.topRightLayout, row=1, column=1,
            description=LATITUDE_DESCRIPTION
        )
        self.lon = make_entry(
            self, width=40, layout=self.topRightLayout, row=2, column=1,
            description=LONGITUDE_DESCRIPTION
        )
        self.rad = make_entry(
            self, width=40, layout=self.topRightLayout, row=3, column=1,
            description=RADIUS_DESCRIPTION
        )
        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=4,
            column=0, description=RUN_GEOSEARCH_DESCRIPTION
        )

        # BOTTOM
        self.mapContainer = make_browser(layout=self.bottomLayout, file=BASE_MAP)
        self.tile = 'OpenStreetMap'
        self.mapa = geo.create_map(BASE_MAP, self.tile, self.mapContainer, [61.217381, -149.863129])
        self.mapa = MapFunctions.do_this(self.mapa)

    def run(self):
        centroid = (float(self.lat.text()), float(self.lon.text()))
        self.mapa = folium.Map(tiles=self.tile, location=centroid, zoom_start=7)
        info, coords = geo.gather_coordinates(self.readLabel.text())
        info, coords = geo.check_distance(
            centroid=centroid, info=info, coords=coords, radius=float(self.rad.text()),
            units=self.unitsCombo.currentText()
        )
        popups = geo.get_popups(info)
        geo.plot_points(info, coords, popups, self.mapa)
        geo.create_kml(popups, coords, self.saveLabel.text())
        geo.load_map(self.mapa, BASE_MAP, self.mapContainer)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        """TOP LEFT"""
        # FILES TO READ
        self.readLabel = make_label(self, '')
        self.readButton = make_button(self, lambda: menu.open_folder(self, label=self.readLabel), '', OPEN_FOLDER_ICON)
        self.topLeftLayout.addWidget(self.readButton, 0, 0)
        self.topLeftLayout.addWidget(self.readLabel, 0, 1)

        # FILE TO SAVE
        self.saveLabel = make_label(self, '')
        self.saveButton = make_button(self, lambda: menu.save_file(self, label=self.saveLabel), '', SAVE_FILE_ICON)
        self.topLeftLayout.addWidget(self.saveButton, 1, 0)
        self.topLeftLayout.addWidget(self.saveLabel, 1, 1)

        """TOP RIGHT"""
        # UNITS SELECTION
        self.unitsLabel = make_label(self, 'Units:')
        self.unitsCombo = QtWidgets.QComboBox(self)
        menu.set_widget_size(self.unitsCombo, 40, 20)
        self.unitsCombo.setStyleSheet(COMBO_STYLE)
        for unit in UNITS:
            self.unitsCombo.addItem(unit)
        self.units = UNITS[0]
        self.topRightLayout.addWidget(self.unitsLabel, 0, 0)
        self.topRightLayout.addWidget(self.unitsCombo, 0, 1)
        self.unitsCombo.activated[str].connect(self.change_units)

        # RADIUS, LATITUDE, LONGITUDE ENTRY
        self.radiusLabel = make_label(self, 'Radius:')
        self.rad = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.radiusLabel, 1, 0)
        self.topRightLayout.addWidget(self.rad, 1, 1)

        self.lonLabel = make_label(self, 'Longitude:')
        self.lon = make_entry(self, width=40)

        self.topRightLayout.addWidget(self.lonLabel, 2, 0)
        self.topRightLayout.addWidget(self.lon, 2, 1)

        self.latLabel = make_label(self, 'Latitude:')
        self.lat = make_entry(self, width=40)

        self.topRightLayout.addWidget(self.latLabel, 3, 0)
        self.topRightLayout.addWidget(self.lat, 3, 1)
        self.runButton = make_button(self, lambda: self.run_geo_search(), 'Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        # BOTTOM
        self.mapa = folium.Map()
        self.mapa.save("baseMap.html")
        self.mapContainer = QtWebEngineWidgets.QWebEngineView()
        self.mapContainer.load(QtCore.QUrl.fromLocalFile("graph2/sunburst.html"))
        self.bottomLayout.addWidget(self.mapContainer)

    def change_units(self, units):
        self.units = units

    def run_geo_search(self):
        self.mapa = folium.Map()
        indices, coordinates = gather_coordinates(self.readLabel.text())
        indices, coordinates = interpret_query(
            centroid=(int(self.lat.text()), int(self.lon.text())), indices=indices,
            coordinates=coordinates, radius=int(self.rad.text()), units=self.units
        )
        create_kml(indices, coordinates, self.saveLabel.text())
        for point in range(len(coordinates)):
            folium.Marker(coordinates[point], popup=indices[point]).add_to(self.mapa)
        self.mapa.save("baseMap.html")  # self.mapContainer.load(QtCore.QUrl("baseMap.html"))

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=KML_FILES)

        """TOP RIGHT"""
        # UNITS SELECTION
        self.units = UNITS[0]

        self.unitsLabel = make_label(self, 'Units:')
        self.topRightLayout.addWidget(self.unitsLabel, 0, 0)

        self.unitsCombo = make_combo(self, UNITS, self.change_units)
        self.topRightLayout.addWidget(self.unitsCombo, 0, 1)

        # RADIUS, LATITUDE, LONGITUDE ENTRY
        self.radiusLabel = make_label(self, 'Radius:')
        self.topRightLayout.addWidget(self.radiusLabel, 1, 0)

        self.rad = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.rad, 1, 1)

        self.lonLabel = make_label(self, 'Longitude:')
        self.topRightLayout.addWidget(self.lonLabel, 2, 0)

        self.lon = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.lon, 2, 1)

        self.latLabel = make_label(self, 'Latitude:')
        self.topRightLayout.addWidget(self.latLabel, 3, 0)

        self.lat = make_entry(self, width=40)
        self.topRightLayout.addWidget(self.lat, 3, 1)

        self.runButton = make_button(self, command=lambda: self.run_geo_search(), text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        # BOTTOM
        self.mapa = folium.Map()
        self.mapa.save(BASE_MAP)

        self.mapContainer = QtWebEngineWidgets.QWebEngineView()
        self.mapContainer.load(QtCore.QUrl.fromLocalFile(BASE_MAP))
        self.bottomLayout.addWidget(self.mapContainer)

    def change_units(self, units):
        self.units = units

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=KML_FILES)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.saveLabel.setText(os.path.join(self.saveLabel.text(), 'geoSearch.kml'))
        """TOP RIGHT"""
        # UNITS SELECTION
        self.units = UNITS[0]
        self.unitsLabel = make_label(
            self, text='Units:', layout=self.topRightLayout, row=0, column=0,
            description=UNITS_DESCRIPTION
        )
        self.unitsCombo = make_combo(
            self, UNITS, self.change_units, layout=self.topRightLayout, row=0, column=1,
            description=UNITS_DESCRIPTION
        )
        # LATITUDE, LONGITUDE, RADIUS
        self.latLabel = make_label(
            self, text='Latitude:', layout=self.topRightLayout, row=1, column=0,
            description=LATITUDE_DESCRIPTION
        )
        self.lonLabel = make_label(
            self, text='Longitude:', layout=self.topRightLayout, row=2, column=0,
            description=LONGITUDE_DESCRIPTION
        )
        self.radiusLabel = make_label(
            self, text='Radius:', layout=self.topRightLayout, row=3, column=0,
            description=RADIUS_DESCRIPTION
        )
        self.lat = make_entry(
            self, width=40, layout=self.topRightLayout, row=1, column=1,
            description=LATITUDE_DESCRIPTION
        )
        self.lon = make_entry(
            self, width=40, layout=self.topRightLayout, row=2, column=1,
            description=LONGITUDE_DESCRIPTION
        )
        self.rad = make_entry(
            self, width=40, layout=self.topRightLayout, row=3, column=1,
            description=RADIUS_DESCRIPTION
        )
        self.runButton = make_button(
            self, command=lambda: self.run_geo_search(), text='Run',
            layout=self.topRightLayout, row=4, column=0, description=RUN_GEOSEARCH_DESCRIPTION
        )
        # BOTTOM
        self.mapContainer = make_browser(layout=self.bottomLayout, file=BASE_MAP)
        self.tile = 'OpenStreetMap'
        self.mapa = geo.create_map(BASE_MAP, self.tile, self.mapContainer, [61.217381, -149.863129])
        self.mapa = MapFunctions.do_this(self.mapa)
        self.bottomLayout.addWidget(self.mapContainer)

    def change_units(self, units):
        self.units = units

    def run_geo_search(self):
        centroid = (float(self.lat.text()), float(self.lon.text()))
        self.mapa = folium.Map(tiles=self.tile, location=centroid, zoom_start=7)
        info, coords = geo.gather_coordinates(self.readLabel.text())
        info, coords = geo.check_distance(
            centroid=centroid, info=info, coords=coords, radius=float(self.rad.text()),
            units=self.units
        )
        popups = geo.get_popups(info)
        geo.plot_points(info, coords, popups, self.mapa)
        geo.create_kml(popups, coords, self.saveLabel.text())
        geo.load_map(self.mapa, BASE_MAP, self.mapContainer)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=KML_FILES)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.saveLabel.setText(os.path.join(self.saveLabel.text(), 'geoSearch.kml'))
        """TOP RIGHT"""
        # UNITS SELECTION
        self.unitsLabel = make_label(
            self, text='Units:', layout=self.topRightLayout, row=0, column=0,
            description=UNITS_DESCRIPTION
        )
        self.unitsCombo = make_combo(
            self, UNITS, layout=self.topRightLayout, row=0, column=1,
            description=UNITS_DESCRIPTION
        )

        # LATITUDE, LONGITUDE, RADIUS
        self.latLabel = make_label(
            self, text='Latitude:', layout=self.topRightLayout, row=1, column=0,
            description=LATITUDE_DESCRIPTION
        )
        self.lonLabel = make_label(
            self, text='Longitude:', layout=self.topRightLayout, row=2, column=0,
            description=LONGITUDE_DESCRIPTION
        )
        self.radiusLabel = make_label(
            self, text='Radius:', layout=self.topRightLayout, row=3, column=0,
            description=RADIUS_DESCRIPTION
        )
        self.lat = make_entry(
            self, width=40, layout=self.topRightLayout, row=1, column=1,
            description=LATITUDE_DESCRIPTION
        )
        self.lon = make_entry(
            self, width=40, layout=self.topRightLayout, row=2, column=1,
            description=LONGITUDE_DESCRIPTION
        )
        self.rad = make_entry(
            self, width=40, layout=self.topRightLayout, row=3, column=1,
            description=RADIUS_DESCRIPTION
        )
        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=4,
            column=0, description=RUN_GEOSEARCH_DESCRIPTION
        )

        # BOTTOM
        self.mapContainer = make_browser(layout=self.bottomLayout, file=BASE_MAP)
        self.tile = 'OpenStreetMap'
        self.mapa = geo.create_map(
            BASE_MAP, self.tile, self.mapContainer,
            [61.217381, -149.863129]
        )  # self.mapa = MapFunctions.do_this(self.mapa)

    def __init__(self, parent, title, icon2):
        SubMenu.__init__(self, parent, title, icon2)
        top_left_splitter(self, open=open_folder, save=save_file, fileExt=KML_FILES)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.saveLabel.setText(os.path.join(self.saveLabel.text(), 'geoSearch.kml'))
        """TOP RIGHT"""
        # UNITS SELECTION
        self.unitsLabel = make_label(
            self, text='Units:', layout=self.topRightLayout,
            row=0, column=0,
            description=UNITS_DESCRIPTION
        )
        self.unitsCombo = make_combo(
            self, UNITS, layout=self.topRightLayout,
            row=0, column=1,
            description=UNITS_DESCRIPTION
        )

        # LATITUDE, LONGITUDE, RADIUS
        self.latLabel = make_label(
            self, text='Latitude:', layout=self.topRightLayout,
            row=1, column=0,
            description=LATITUDE_DESCRIPTION
        )
        self.lonLabel = make_label(
            self, text='Longitude:', layout=self.topRightLayout,
            row=1, column=0,
            description=LONGITUDE_DESCRIPTION
        )
        self.radiusLabel = make_label(
            self, text='Radius:', layout=self.topRightLayout,
            row=2, column=0,
            description=RADIUS_DESCRIPTION
        )
        self.lat = make_entry(
            self, width=40, layout=self.topRightLayout,
            row=1, column=1,
            description=LATITUDE_DESCRIPTION
        )
        self.lon = make_entry(
            self, width=40, layout=self.topRightLayout,
            row=1, column=1,
            description=LONGITUDE_DESCRIPTION
        )
        self.rad = make_entry(
            self, width=40, layout=self.topRightLayout,
            row=2, column=1,
            description=RADIUS_DESCRIPTION
        )
        self.runButton = make_button(
            self, command=self.run, text='Run',
            layout=self.topRightLayout,
            row=3, column=0, description=RUN_GEOSEARCH_DESCRIPTION
        )

        # BOTTOM
        self.mapContainer = make_browser(layout=self.bottomLayout, file=BASE_MAP)
        self.tile = 'OpenStreetMap'
        self.mapa = geo.create_map(BASE_MAP, self.tile, self.mapContainer, [61.217381, -149.863129])
        # self.mapa = MapFunctions.do_this(self.mapa)

    def run(self):
        centroid = (float(self.lat.text()), float(self.lon.text()))
        self.mapa = folium.Map(tiles=self.tile, location=centroid, zoom_start=3)
        info, coords = geo.gather_coordinates(self.readLabel.text())
        info, coords = geo.check_distance(
            centroid=centroid, info=info, coords=coords,
            radius=float(self.rad.text()),
            units=self.unitsCombo.currentText()
        )
        popups = geo.get_popups(info)
        geo.plot_points(info, coords, popups, self.mapa)
        geo.create_kml(popups, coords, self.saveLabel.text())
        geo.load_map(self.mapa, BASE_MAP, self.mapContainer)


class HelpMenu(SubMenu):
    def populate(self):
        self.top.wm_title("!")
        self.util.name(
            container=self.top, text=("PASS Lab\nChristian Lozoya\n2017",), coords=((1, 1),),
            columnspan=(1,), sticky=('w',)
        )
        self.util.button(
            container=self.top, text=("Okay",), commands=(self.top.destroy,), cursor=HAND,
            coords=((2, 1),), sticky=('e',)
        )

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        """TOP LEFT"""
        # FILES TO READ
        self.readLabel = QtWidgets.QLabel('')
        openFolderIcon = QtGui.QIcon(OPEN_FOLDER_ICON)
        self.readButton = QtWidgets.QPushButton(openFolderIcon, '', self)
        self.readButton.setStyleSheet(BUTTON_STYLE)
        self.readButton.setIconSize(QtCore.QSize(20, 20))
        menu.set_widget_size(self.readButton, 5, 20)
        self.readButton.clicked.connect(lambda: menu.open_files(self, multiple=True, label=self.readLabel))
        self.topLeftLayout.addWidget(self.readButton, 0, 0)
        self.topLeftLayout.addWidget(self.readLabel, 0, 1)

        # FILE TO SAVE
        self.saveLabel = QtWidgets.QLabel('')
        self.saveButton = make_button(self, lambda: menu.save_file(self, label=self.saveLabel), '', SAVE_FILE_ICON)
        self.topLeftLayout.addWidget(self.saveButton, 1, 0)
        self.topLeftLayout.addWidget(self.saveLabel, 1, 1)

        """TOP RIGHT"""
        # RUN BUTTON
        self.runButton = make_button(self, lambda: menu.save_file(self), 'Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)


# TODO create a tabbed menu for class,clust,regress,dim red
class MachineLearningMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.advancedOptionsMenu = MachineLearningAdvancedOptionsMenu(
            self, 'Machine Learning Advanced Options',
            MACHINE_LEARNING_ICON
        )

        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)

        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=7, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=7,
            column=2, description=PARALLEL_DESCRIPTION
        )

        self.seriesRadio.setChecked(True)
        modeGroup.addButton(self.seriesRadio)
        modeGroup.addButton(self.parallelRadio)

        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=8, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=8, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=9,
            column=0, description=RUN_MACHINE_LEARNING_DESCRIPTION
        )

        self.advancedOptionsButton = make_button(
            self, command=lambda: self.advancedOptionsMenu.show(),
            text='Advanced Options', layout=self.topRightLayout, row=9, column=1,
            width=150
        )

        _, self.taskOptionCombo = make_pair(
            self, pair='combo', comboItems=(
                'Regression6', 'Classification', 'Clustering', 'Dimensionality Reduction'), text='Task:',
            layout=self.topRightLayout, row=9, column=2, pairWidth=150, description=''
        )

        self.siteContainer = make_browser(layout=self.bottomLayout, file=REGRESSOR_GRAPH)
        self.combos()
        self.set_regressors()

    def set_regressors(self):
        layout = self.topRightLayout
        # Left Column
        _, self.aBCheck = make_pair(
            self, pair='check', text='Adaptive Boost:', layout=layout, row=1, column=0,
            description=AB_DESCRIPTION
        )

        _, self.dTreeCheck = make_pair(
            self, pair='check', text='Decision Tree:', layout=layout, row=2, column=0,
            description=D_TREE_DESCRIPTION
        )

        _, self.eNCheck = make_pair(
            self, pair='check', text='Elastic Net:', layout=layout, row=3, column=0,
            description=E_NET_DESCRIPTION
        )

        _, self.gProcessCheck = make_pair(
            self, pair='check', text='Gaussian Process:', layout=layout, row=4, column=0,
            description=''
        )

        _, self.kNNCheck = make_pair(
            self, pair='check', text='Nearest Neighbors:', layout=layout, row=5, column=0,
            description=K_NEIGHBORS_DESCRIPTION
        )

        # Right Column
        _, self.kRidgeCheck = make_pair(
            self, pair='check', text='Kernel Ridge:', layout=layout, row=1, column=2,
            description=K_RIDGE_DESCRIPTION
        )

        _, self.mlpCheck = make_pair(
            self, pair='check', text='Multilayer Perceptron:', layout=layout, row=2, column=2,
            description=MLP_DESCRIPTION
        )

        _, self.rForestCheck = make_pair(
            self, pair='check', text='Random Forest:', layout=layout, row=3, column=2,
            description=R_FOREST_DESCRIPTION
        )

        _, self.sGDradientCheck = make_pair(
            self, pair='check', text='Stochastic Gradient Descent:', layout=layout,
            row=4, column=2, description=SGD_DESCRIPTION
        )

        _, self.svmCheck = make_pair(
            self, pair='check', text='Support Vector Machine:', layout=layout, row=5, column=2,
            description=SVM_DESCRIPTION
        )

        _, self.automaticCheck = make_pair(
            self, pair='check', text='Auto-Tune:', layout=layout, row=6, column=0,
            description=AUTOMATIC_TUNING_DESCRIPTION
        )

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            self, [''] + self.headers, lambda: self.update_columns(),
            layout=self.topRightLayout, row=8, column=1, width=200,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            self, self.headers, command=self.graph_raw, layout=self.topRightLayout, row=8,
            column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            if self.validate():
                data, xKeys, yKeys = dh.process_data(dir, index, column, self.mode)
                data = pd.DataFrame(data, columns=(column,), index=data.index)
                x = ((data.index,),)
                y = ((data,),)
                make_tabbed_plot(
                    REGRESSOR_GRAPH, X=x, Y=y, titles=('Raw Data',),
                    xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                    lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,),
                    yKeys=(yKeys,)
                )
                self.siteContainer = load_browser(self.siteContainer, REGRESSOR_GRAPH)
        except Exception as e:
            print(e)

    def run(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        if self.validate():
            task = self.taskOptionCombo.currentText()
            models = self.get_models(task)
            data, xKeys, yKeys = dh.process_data(dir, index, column, self.mode)
            if self.taskOptionCombo.currentText() == 'Regression6':
                results = Regressors.regression(models, x=data.index, y=data)
            elif self.taskOptionCombo.currentText() == 'Classification':
                results = Classifiers.classification(models, x=data.index, y=data)
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.index, data.index),)
            y = ((results, data),)
            make_tabbed_plot(
                REGRESSOR_GRAPH, X=x, Y=y, titles=('Regression6',),
                xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                lineWidths=((1, 1),), legends=((True, True),), types=(('line', 'scatter'),),
                xKeys=(xKeys,), yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, REGRESSOR_GRAPH)

    def get_checks(self, task):
        if task == 'Classification':
            checks = {
                'abc':  self.aBCheck.isChecked(), 'dtc': self.dTreeCheck.isChecked(),
                'nbc':  self.eNCheck.isChecked(), 'gpc': self.gProcessCheck.isChecked(),
                'knnc': self.kNNCheck.isChecked(), 'qdac': self.kRidgeCheck.isChecked(),
                'mlpc': self.mlpCheck.isChecked(), 'rfc': self.rForestCheck.isChecked(),
                'sgdc': self.sGDradientCheck.isChecked(), 'svc': self.svmCheck.isChecked(),
            }
        elif task == 'Regression6':
            checks = {
                'Adaptive Boost':              self.aBCheck.isChecked(), 'Decision Tree': self.dTreeCheck.isChecked(),
                'Elastic Net':                 self.eNCheck.isChecked(),
                'Gaussian Process':            self.gProcessCheck.isChecked(),
                'Nearest Neighbors':           self.kNNCheck.isChecked(), 'Kernel Ridge': self.kRidgeCheck.isChecked(),
                'Multilayer Perceptron':       self.mlpCheck.isChecked(),
                'Random Forest':               self.rForestCheck.isChecked(),
                'Stochastic Gradient Descent': self.sGDradientCheck.isChecked(),
                'Support Vector Machine':      self.svmCheck.isChecked(),
            }

        return checks

    def get_models(self, task):
        checks = self.get_checks(task)
        if self.automaticCheck.isChecked():
            if task == 'Classification':
                models = Classifiers.cross_validation_classification_models(checks)
            elif task == 'Regression6':
                models = Regressors.cross_validation_regression_models(checks)
        else:
            if task == 'Classification':
                options = self.advancedOptionsMenu.get_options(task)
                models = Classifiers.classification_models(checks, options)
            elif task == 'Regression6':
                options = self.advancedOptionsMenu.get_options(task)
                models = Regressors.regression_models(checks, options)
        return models

    def validate(self):
        error = False
        if self.seriesRadio.isChecked():
            self.mode = 'series'
        elif self.parallelRadio.isChecked():
            self.mode = 'parallel'
        else:
            QMessageBox.critical(self, "No Mode", "Select a mode.", QMessageBox.Ok)
            self.mode = None
            error = True
        return not error

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            if self.validate():
                data, xKeys, yKeys = self.process_data(dir, index, column)
                data = pd.DataFrame(data, columns=(column,), index=data.index)
                x = ((data.index,),)
                y = ((data,),)
                make_tabbed_plot(
                    REGRESSOR_GRAPH, X=x, Y=y, titles=('Raw Data',),
                    xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                    lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,),
                    yKeys=(yKeys,)
                )
                self.siteContainer = load_browser(self.siteContainer, REGRESSOR_GRAPH)
        except Exception as e:
            print(e)

    def run(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        if self.validate():
            task = self.taskOptionCombo.currentText()
            models = self.get_models(task)
            data, xKeys, yKeys = self.process_data(dir, index, column)
            if self.taskOptionCombo.currentText() == 'Regression6':
                results = Regressors.regression(models, x=data.index, y=data)
            elif self.taskOptionCombo.currentText() == 'Classification':
                results = Classifiers.classification(models, x=data.index, y=data)
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.index, data.index),)
            y = ((results, data),)
            make_tabbed_plot(
                REGRESSOR_GRAPH, X=x, Y=y, titles=('Regression6',),
                xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                lineWidths=((1, 1),), legends=((True, True),), types=(('line', 'scatter'),),
                xKeys=(xKeys,), yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, REGRESSOR_GRAPH)

    def process_data(self, dir, index, column):
        data = dh.read_data_list(dir, index, column)
        print(data)
        data = dh.merge_data_list(data)
        print(data)
        # data = data.dropna()
        print(data)
        data, yKeys = dh.numerify_values(data)
        data = dh.data_field(data, self.mode)
        data, xKeys = dh.numerify_index(data, series=True)
        print(data)
        # if xKeys != None: xKeys = {k: xKeys[k] for k in xKeys if type(xKeys[k]) != type(np.nan)}
        # if yKeys != None: yKeys = {k: yKeys[k] for k in yKeys if type(yKeys[k]) != type(np.nan)}
        print(xKeys)
        print(yKeys)
        return data, xKeys, yKeys

    def process_data(self, dir, index, column):
        data = dh.read_data_list(dir, index, column)
        data = dh.merge_data_list(data)
        data = dh.vectorize_data(data, self.mode)
        data, xKeys = dh.numerify_index(data, series=True)
        data, yKeys = dh.numerify_values(data)
        data = data.dropna().astype(float)
        return data, xKeys, yKeys

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file)

        """TOP RIGHT"""
        # TODO EXPORT AS TEXT, EXCEL, PDF
        self.svmLabel = make_label(self, 'SVM:')
        self.svmCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.svmLabel, 1, 0)
        self.topRightLayout.addWidget(self.svmCheck, 1, 1)

        self.kMeansLabel = make_label(self, 'K-Means:')
        self.kMeansCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.kMeansLabel, 1, 2)
        self.topRightLayout.addWidget(self.kMeansCheck, 1, 3)

        self.mCMCLabel = make_label(self, 'MCMC:')
        self.mCMCCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.mCMCLabel, 2, 0)
        self.topRightLayout.addWidget(self.mCMCCheck, 2, 1)

        self.nNLabel = make_label(self, 'Neural Network:')
        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.nNLabel, 2, 2)
        self.topRightLayout.addWidget(self.excelCheck, 2, 3)

        # UNION OR INTERSECTION SEARCH
        self.fullLabel = make_label(self, 'Full:')
        self.fullRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.fullLabel, 3, 0)
        self.topRightLayout.addWidget(self.fullRadio, 3, 1)

        self.cleanLabel = make_label(self, 'Clean:')
        self.cleanRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.cleanLabel, 3, 2)
        self.topRightLayout.addWidget(self.cleanRadio, 3, 3)
        self.runButton = make_button(self, command=lambda: save_file(self), text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        self.graphContainer = QtWebEngineWidgets.QWebEngineView()
        self.graphContainer.load(QtCore.QUrl.fromLocalFile(BASE_GRAPH))
        self.bottomLayout.addWidget(self.graphContainer)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file)

        """TOP RIGHT"""
        # TODO EXPORT AS TEXT, EXCEL, PDF
        self.svmLabel = make_label(self, 'SVM:')
        self.svmCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.svmLabel, 1, 0)
        self.topRightLayout.addWidget(self.svmCheck, 1, 1)

        self.kMeansLabel = make_label(self, 'K-Means:')
        self.kMeansCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.kMeansLabel, 1, 2)
        self.topRightLayout.addWidget(self.kMeansCheck, 1, 3)

        self.mCMCLabel = make_label(self, 'MCMC:')
        self.mCMCCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.mCMCLabel, 2, 0)
        self.topRightLayout.addWidget(self.mCMCCheck, 2, 1)

        self.nNLabel = make_label(self, 'Neural Network:')
        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.nNLabel, 2, 2)
        self.topRightLayout.addWidget(self.excelCheck, 2, 3)

        # UNION OR INTERSECTION SEARCH
        self.fullLabel = make_label(self, 'Full:')
        self.fullRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.fullLabel, 3, 0)
        self.topRightLayout.addWidget(self.fullRadio, 3, 1)

        self.cleanLabel = make_label(self, 'Clean:')
        self.cleanRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.cleanLabel, 3, 2)
        self.topRightLayout.addWidget(self.cleanRadio, 3, 3)
        self.runButton = make_button(self, command=lambda: save_file(self), text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        self.graphContainer = QtWebEngineWidgets.QWebEngineView()
        self.graphContainer.load(QtCore.QUrl.fromLocalFile(BASE_GRAPH))
        self.bottomLayout.addWidget(self.graphContainer)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file)

        """TOP RIGHT"""
        # TODO EXPORT AS TEXT, EXCEL, PDF
        self.svmLabel = make_label(self, 'SVM:')
        self.svmCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.svmLabel, 1, 0)
        self.topRightLayout.addWidget(self.svmCheck, 1, 1)

        self.kMeansLabel = make_label(self, 'K-Means:')
        self.kMeansCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.kMeansLabel, 1, 2)
        self.topRightLayout.addWidget(self.kMeansCheck, 1, 3)

        self.mCMCLabel = make_label(self, 'MCMC:')
        self.mCMCCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.mCMCLabel, 2, 0)
        self.topRightLayout.addWidget(self.mCMCCheck, 2, 1)

        self.nNLabel = make_label(self, 'Neural Network:')
        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.nNLabel, 2, 2)
        self.topRightLayout.addWidget(self.excelCheck, 2, 3)

        # UNION OR INTERSECTION SEARCH
        self.fullLabel = make_label(self, 'Full:')
        self.fullRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.fullLabel, 3, 0)
        self.topRightLayout.addWidget(self.fullRadio, 3, 1)

        self.cleanLabel = make_label(self, 'Clean:')
        self.cleanRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.cleanLabel, 3, 2)
        self.topRightLayout.addWidget(self.cleanRadio, 3, 3)
        self.runButton = make_button(self, command=lambda: save_file(self), text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        self.graphContainer = QtWebEngineWidgets.QWebEngineView()
        self.graphContainer.load(QtCore.QUrl.fromLocalFile(BASE_GRAPH))
        self.bottomLayout.addWidget(self.graphContainer)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file)

        """TOP RIGHT"""
        self.svmLabel = make_label(self, 'SVM:')
        self.svmCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.svmLabel, 1, 0)
        self.topRightLayout.addWidget(self.svmCheck, 1, 1)

        self.kMeansLabel = make_label(self, 'K-Means:')
        self.kMeansCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.kMeansLabel, 1, 2)
        self.topRightLayout.addWidget(self.kMeansCheck, 1, 3)

        self.mCMCLabel = make_label(self, 'MCMC:')
        self.mCMCCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.mCMCLabel, 2, 0)
        self.topRightLayout.addWidget(self.mCMCCheck, 2, 1)

        self.nNLabel = make_label(self, 'Neural Network:')
        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.nNLabel, 2, 2)
        self.topRightLayout.addWidget(self.excelCheck, 2, 3)

        # UNION OR INTERSECTION SEARCH
        self.fullLabel = make_label(self, 'Full:')
        self.fullRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.fullLabel, 3, 0)
        self.topRightLayout.addWidget(self.fullRadio, 3, 1)

        self.cleanLabel = make_label(self, 'Clean:')
        self.cleanRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.cleanLabel, 3, 2)
        self.topRightLayout.addWidget(self.cleanRadio, 3, 3)
        self.runButton = make_button(self, command=lambda: save_file(self), text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        self.graphContainer = QtWebEngineWidgets.QWebEngineView()
        self.graphContainer.load(QtCore.QUrl.fromLocalFile(BASE_GRAPH))
        self.bottomLayout.addWidget(self.graphContainer)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 6)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 6)
        top_left_splitter(self, open=open_folder, save=save_file)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.headers = dh.line_reader(HEADERS)
        self.advancedOptionsMenu = MachineLearningAdvancedOptionsMenu(
            self, 'Machine Learning Advanced Options',
            MACHINE_LEARNING_ICON
        )
        """TOP RIGHT"""
        self.svmLabel = make_label(
            self, text='SVM:', layout=self.topRightLayout, row=1, column=0,
            description=SVM_DESCRIPTION
        )
        self.svmCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=1,
            description=SVM_DESCRIPTION
        )
        self.kMeansLabel = make_label(
            self, text='K-Means:', layout=self.topRightLayout, row=1, column=2,
            description=K_NEIGHBORS_DESCRIPTION
        )
        self.kMeansCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=3,
            description=K_NEIGHBORS_DESCRIPTION
        )
        self.rForestLabel = make_label(
            self, text='Random Forest:', layout=self.topRightLayout, row=2, column=0,
            description=R_FOREST_DESCRIPTION
        )
        self.rForestCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=2, column=1,
            description=R_FOREST_DESCRIPTION
        )
        self.nNLabel = make_label(
            self, text='Neural Network:', layout=self.topRightLayout, row=2, column=2,
            description=NN_DESCRIPTION
        )
        self.nNCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=2, column=3,
            description=NN_DESCRIPTION
        )
        self.lsvmLabel = make_label(
            self, text='LSVM:', layout=self.topRightLayout, row=3, column=0,
            description=LSVM_DESCRIPTION
        )
        self.lsvmCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=3, column=1,
            description=LSVM_DESCRIPTION
        )
        self.kRidgeLabel = make_label(
            self, text='K-Ridge:', layout=self.topRightLayout, row=3, column=2,
            description=K_RIDGE_DESCRIPTION
        )
        self.kRidgeCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=3, column=3,
            description=K_RIDGE_DESCRIPTION
        )
        self.svsLabel = make_label(
            self, text='SVS:', layout=self.topRightLayout, row=4, column=0,
            description=SVS_DESCRIPTION
        )
        self.svsCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=4, column=1,
            description=SVS_DESCRIPTION
        )
        self.dTreeLabel = make_label(
            self, text='Decision Tree:', layout=self.topRightLayout, row=4, column=2,
            description=D_TREE_DESCRIPTION
        )
        self.dTreeCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=4, column=3,
            description=D_TREE_DESCRIPTION
        )
        # UNION OR INTERSECTION SEARCH
        # self.fullLabel = make_label(self, text='Full:', layout=self.topRightLayout, row=5, column=0)
        # self.fullRadio = make_button(self, type='radio', layout=self.topRightLayout, row=5, column=1)
        # self.cleanLabel = make_label(self, text='Clean:', layout=self.topRightLayout, row=5, column=1)
        # self.cleanRadio = make_button(self, type='radio', layout=self.topRightLayout, row=5, column=2)
        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=6, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )
        self.indexCombo = make_combo(
            self, [''] + self.headers, None, layout=self.topRightLayout, row=6, column=1,
            width=200, description=INDEX_COMBO_DESCRIPTION
        )
        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=6, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.columnCombo = make_combo(
            self, self.headers, layout=self.topRightLayout, row=6, column=3, width=200,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=7,
            column=0, description=RUN_MACHINE_LEARNING_DESCRIPTION
        )
        self.advancedOptionsButton = make_button(
            self, command=lambda: self.advancedOptionsMenu.show(),
            text='Advanced Options', layout=self.topRightLayout, row=7, column=2
        )
        self.siteContainer = make_browser(layout=self.bottomLayout, file=REGRESSOR_GRAPH)
        self.bottomLayout.addWidget(self.siteContainer)

    def run(self):
        index = 'col1'  # self.indexEntry.text()
        column = 'col2'  # self.columnEntry.text()
        dir = r'C:\Users\frano\PycharmProjects\Big\Database\Children Of The Sky'  # self.readLabel.text()
        try:
            checks = self.get_checks()
            # dataFrameList = Regressors.dh.read_data_list(dir, index=index, column=column)
            # data = Regressors.dh.clean_data(MarkovChain2.dh.merge_data_list(dataFrameList))
            models = CrossValidation.regression(checks)
            results = Regressors.regression(models, index, column)
            make_line_plot(results, REGRESSOR_GRAPH, index, column)
            self.siteContainer = load_browser(self.siteContainer, REGRESSOR_GRAPH)

        except Exception as e:
            print(e)

    def get_checks(self):
        regression = True
        if regression:
            checks = {
                'lsvr': self.lsvmCheck.isChecked(), 'svs': self.svsCheck.isChecked(),
                'svr':  self.svmCheck.isChecked(), 'kr': self.kRidgeCheck.isChecked(),
                'dtr':  self.dTreeCheck.isChecked(), 'nnr': self.nNCheck.isChecked(),
                'knn':  self.kMeansCheck.isChecked(), 'rfr': self.rForestCheck.isChecked()
            }

            return checks

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        """TOP LEFT"""
        # FILES TO READ
        self.readLabel = make_label(self, '')
        self.readButton = make_button(
            self, lambda: menu.open_files(self, multiple=True, label=self.readLabel), '',
            OPEN_FOLDER_ICON
        )
        self.topLeftLayout.addWidget(self.readButton, 0, 0)
        self.topLeftLayout.addWidget(self.readLabel, 0, 1)

        # FILE TO SAVE
        self.saveLabel = make_label(self, '')
        self.saveButton = make_button(self, lambda: menu.save_file(self, label=self.saveLabel), '', SAVE_FILE_ICON)
        self.topLeftLayout.addWidget(self.saveButton, 1, 0)
        self.topLeftLayout.addWidget(self.saveLabel, 1, 1)

        """TOP RIGHT"""
        # TODO EXPORT AS TEXT, EXCEL, PDF
        self.svmLabel = make_label(self, 'SVM:')
        self.svmCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.svmLabel, 1, 0)
        self.topRightLayout.addWidget(self.svmCheck, 1, 1)

        self.kMeansLabel = make_label(self, 'K-Means:')
        self.kMeansCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.kMeansLabel, 1, 2)
        self.topRightLayout.addWidget(self.kMeansCheck, 1, 3)

        self.mCMCLabel = make_label(self, 'MCMC:')
        self.mCMCCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.mCMCLabel, 2, 0)
        self.topRightLayout.addWidget(self.mCMCCheck, 2, 1)

        self.nNLabel = make_label(self, 'Neural Network:')
        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.nNLabel, 2, 2)
        self.topRightLayout.addWidget(self.excelCheck, 2, 3)

        # UNION OR INTERSECTION SEARCH
        self.fullLabel = make_label(self, 'Full:')
        self.fullRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.fullLabel, 3, 0)
        self.topRightLayout.addWidget(self.fullRadio, 3, 1)

        self.cleanLabel = make_label(self, 'Clean:')
        self.cleanRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.cleanLabel, 3, 2)
        self.topRightLayout.addWidget(self.cleanRadio, 3, 3)
        self.runButton = make_button(self, lambda: menu.save_file(self), 'Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        self.graphContainer = QtWebEngineWidgets.QWebEngineView()
        self.graphContainer.load(QtCore.QUrl('graph2/Tooltip.html'))  # self.bottomLayout.addWidget(self.graphContainer)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file)

        """TOP RIGHT"""
        # TODO EXPORT AS TEXT, EXCEL, PDF
        self.svmLabel = make_label(self, 'SVM:')
        self.svmCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.svmLabel, 1, 0)
        self.topRightLayout.addWidget(self.svmCheck, 1, 1)

        self.kMeansLabel = make_label(self, 'K-Means:')
        self.kMeansCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.kMeansLabel, 1, 2)
        self.topRightLayout.addWidget(self.kMeansCheck, 1, 3)

        self.mCMCLabel = make_label(self, 'MCMC:')
        self.mCMCCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.mCMCLabel, 2, 0)
        self.topRightLayout.addWidget(self.mCMCCheck, 2, 1)

        self.nNLabel = make_label(self, 'Neural Network:')
        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.nNLabel, 2, 2)
        self.topRightLayout.addWidget(self.excelCheck, 2, 3)

        # UNION OR INTERSECTION SEARCH
        self.fullLabel = make_label(self, 'Full:')
        self.fullRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.fullLabel, 3, 0)
        self.topRightLayout.addWidget(self.fullRadio, 3, 1)

        self.cleanLabel = make_label(self, 'Clean:')
        self.cleanRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.cleanLabel, 3, 2)
        self.topRightLayout.addWidget(self.cleanRadio, 3, 3)
        self.runButton = make_button(self, command=lambda: save_file(self), text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        self.graphContainer = QtWebEngineWidgets.QWebEngineView()
        self.graphContainer.load(QtCore.QUrl.fromLocalFile(BASE_GRAPH))
        self.bottomLayout.addWidget(self.graphContainer)


# TODO write descriptions for ab, en, gp, sgd options
class MachineLearningAdvancedOptionsMenu(SubMenu):
    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.setFixedSize(500, 300)
        self.regressionLayouts = {
            'Adaptive Boost':              make_grid(self), 'Decision Tree': make_grid(self),
            'Elastic Net':                 make_grid(self), 'Gaussian Process': make_grid(self),
            'Nearest Neighbors':           make_grid(self), 'Kernel Ridge': make_grid(self),
            'Multilayer Perceptron':       make_grid(self), 'Random Forest': make_grid(self),
            'Stochastic Gradient Descent': make_grid(self),
            'Support Vector Machine':      make_grid(self)
        }
        self.set_ab()
        self.set_dt()
        self.set_en()
        self.set_gp()
        self.set_knn()
        self.set_kr()
        self.set_mlp()
        self.set_rf()
        self.set_sgd()
        self.set_svm()
        self.rewindow()

    def get_options(self, task):
        if task == 'Classification':
            options = {
                'abcEstimators':                    self.ABestimatorsDial.value(),
                'abcLearningRate':                  self.ABlearningRateDial.value() / 10.0,
                'abcLoss':                          self.ABlossCombo.currentText(),

                'dtcCriterion':                     self.DTcriterionCombo.currentText(),
                'dtcMaximumDepth':                  self.DTmaxDepthDial.value(),
                'dtcMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
                'dtcMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
                'dtcMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
                'dtcMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
                'dtcMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
                'dtcPresort':                       self.DTpresortCheck.isChecked(),
                'dtcRandomState':                   self.DTrandomStateEntry.text(),
                'dtcSplitter':                      self.DTsplitterCombo.currentText(),

                'enrAlpha':                         self.ENalphaDial.value() / 10.0,
                # 'enrFitIntercept': self.ENfitInterceptCheck.isChecked(),
                'enrL1Ratio':                       self.ENl1RatioDial.value() / 10.0,
                'enrNormalize':                     self.ENnormalizeCheck.isChecked(),
                'enrPositive':                      self.ENpositiveCheck.isChecked(),
                'enrSelection':                     self.ENselectionCombo.currentText(),
                'enrTolerance':                     self.ENtolDial.value() / 100.0,
                'enrWarmStart':                     self.ENwarmStartCheck.isChecked(),

                'gpcAlpha':                         self.GPalphaDial.value() / 100.0,
                # 'gpcKernel': self.GPkernelCombo.currentText(),
                'gpcNormalize':                     self.GPnormalizeCheck.isChecked(),
                # 'gpcOptimizer': self.GPoptimizerCombo.currentText(),

                'knncAlgorithm':                    self.KNNalgorithmCombo.currentText(),
                'knncLeafSize':                     self.KNNleafSizeDial.value(),
                'knncMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
                'knncNumberOfNeighbors':            self.KNNneighborsDial.value(),
                'knncWeightsFunction':              self.KNNweightsCombo.currentText(),

                'krrAlpha':                         self.KRalphaDial.value() / 10.0,
                'krrCoefficient0':                  self.KRcoef0Dial.value() / 10.0,
                'krrGamma':                         self.KRgammaDial.value() / 10.0,
                'krrKernel':                        self.KRkernelCombo.currentText(),
                'krrPolynomialDegree':              self.KRdegreeCombo.currentText(),

                'mlpcActivationFunction':           self.MLPactivationCombo.currentText(),
                # 'mlpcBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
                'mlpcEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
                'mlpcFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
                'mlpcHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
                'mlpcInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
                'mlpcLearningRate':                 self.MLPlearningRateCombo.currentText(),
                'mlpcMaximumIterations':            self.MLPmaxIterDial.value(),
                'mlpcMomentum':                     self.MLPmomentumDial.value() / 10.0,
                'mlpcNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
                'mlpcNumericalStability':           self.MLPepsilonDial.value() / 100.0,
                'mlpcPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
                'mlpcPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
                'mlpcRandomState':                  self.MLPrandomStateEntry.text(),
                'mlpcShuffle':                      self.MLPshuffleCheck.isChecked(),
                'mlpcSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
                'mlpcTolerance':                    self.MLPtolDial.value() / 100.0,
                'mlpcValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
                'mlpcWarmStart':                    self.MLPwarmStartCheck.isChecked(),
                'mlpcWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

                'rfcBootstrap':                     self.RFbootstrapCheck.isChecked(),
                'rfcCriterion':                     self.RFcriterionCombo.currentText(),
                'rfcMaximumDepth':                  self.RFmaxDepthDial.value(),
                'rfcMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
                'rfcMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
                'rfcMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
                'rfcMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
                'rfcMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
                'rfcMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
                'rfcNumberOfTrees':                 self.RFestimatorsDial.value(),
                'rfcOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
                'rfcRandomState':                   self.RFrandomStateEntry.text(),
                'rfcWarmStart':                     self.RFwarmStartCheck.isChecked(),

                'sgdcAlpha':                        self.SGDalphaDial.value() / 100000,
                'sgdcAverage':                      self.SGDaverageCheck.isChecked(),
                'sgdcEta0':                         self.SGDeta0Dial.value() / 10.0,
                'sgdcFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
                'sgdcLearningRate':                 self.SGDlearningRateCombo.currentText(),
                'sgdcLoss':                         self.SGDlossCombo.currentText(),
                'sgdcL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
                'sgdcMaxIterations':                self.SGDmaxIterationsDial.value(),
                'sgdcPenalty':                      self.SGDpenaltyCombo.currentText(),
                'sgdcPowerT':                       self.SGDpowerTDial.value() / 10.0,
                'sgdcShuffle':                      self.SGDshuffleCheck.isChecked(),
                'sgdcTolerance':                    self.SGDtolDial.value() / 100.0,
                'sgdcWarmStart':                    self.SGDwarmStartCheck.isChecked(),

                'svcC':                             dh.nonize(self.SVMCDial.value()),
                # 'svcCacheSize': self.SVMcacheSizeDial.value(),
                'svcCoefficient0':                  self.SVMcoef0Dial.value() / 10.0,
                'svcEpsilon':                       self.SVMepsilonDial.value() / 10.0,
                'svcGamma':                         self.SVMgammaDial.value(),
                'svcKernel':                        self.SVMkernelCombo.currentText(),
                'svcMaximumIterations':             self.SVMmaxIterDial.value(),
                'svcPolynomialDegree':              self.SVMdegreeCombo.currentText(),
                'svcShrinking':                     self.SVMshrinkingCheck.isChecked(),
                'svcTolerance':                     self.SVMtolDial.value() / 100.0,
            }
        elif task == 'Regression6':
            options = {
                'abrEstimators':                    self.ABestimatorsDial.value(),
                'abrLearningRate':                  self.ABlearningRateDial.value() / 10.0,
                'abrLoss':                          self.ABlossCombo.currentText(),

                'dtrCriterion':                     self.DTcriterionCombo.currentText(),
                'dtrMaximumDepth':                  self.DTmaxDepthDial.value(),
                'dtrMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
                'dtrMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
                'dtrMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
                'dtrMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
                'dtrMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
                'dtrPresort':                       self.DTpresortCheck.isChecked(),
                'dtrRandomState':                   self.DTrandomStateEntry.text(),
                'dtrSplitter':                      self.DTsplitterCombo.currentText(),

                'enrAlpha':                         self.ENalphaDial.value() / 10.0,
                # 'enrFitIntercept': self.ENfitInterceptCheck.isChecked(),
                'enrL1Ratio':                       self.ENl1RatioDial.value() / 10.0,
                'enrNormalize':                     self.ENnormalizeCheck.isChecked(),
                'enrPositive':                      self.ENpositiveCheck.isChecked(),
                'enrSelection':                     self.ENselectionCombo.currentText(),
                'enrTolerance':                     self.ENtolDial.value() / 100.0,
                'enrWarmStart':                     self.ENwarmStartCheck.isChecked(),

                'gprAlpha':                         self.GPalphaDial.value() / 100.0,
                # 'gprKernel': self.GPkernelCombo.currentText(),
                'gprNormalize':                     self.GPnormalizeCheck.isChecked(),
                # 'gprOptimizer': self.GPoptimizerCombo.currentText(),

                'knnrAlgorithm':                    self.KNNalgorithmCombo.currentText(),
                'knnrLeafSize':                     self.KNNleafSizeDial.value(),
                'knnrMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
                'knnrNumberOfNeighbors':            self.KNNneighborsDial.value(),
                'knnrWeightsFunction':              self.KNNweightsCombo.currentText(),

                'krrAlpha':                         self.KRalphaDial.value() / 10.0,
                'krrCoefficient0':                  self.KRcoef0Dial.value() / 10.0,
                'krrGamma':                         self.KRgammaDial.value() / 10.0,
                'krrKernel':                        self.KRkernelCombo.currentText(),
                'krrPolynomialDegree':              self.KRdegreeCombo.currentText(),

                'mlprActivationFunction':           self.MLPactivationCombo.currentText(),
                # 'mlprBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
                'mlprEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
                'mlprFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
                'mlprHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
                'mlprInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
                'mlprLearningRate':                 self.MLPlearningRateCombo.currentText(),
                'mlprMaximumIterations':            self.MLPmaxIterDial.value(),
                'mlprMomentum':                     self.MLPmomentumDial.value() / 10.0,
                'mlprNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
                'mlprNumericalStability':           self.MLPepsilonDial.value() / 100.0,
                'mlprPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
                'mlprPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
                'mlprRandomState':                  self.MLPrandomStateEntry.text(),
                'mlprShuffle':                      self.MLPshuffleCheck.isChecked(),
                'mlprSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
                'mlprTolerance':                    self.MLPtolDial.value() / 100.0,
                'mlprValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
                'mlprWarmStart':                    self.MLPwarmStartCheck.isChecked(),
                'mlprWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

                'rfrBootstrap':                     self.RFbootstrapCheck.isChecked(),
                'rfrCriterion':                     self.RFcriterionCombo.currentText(),
                'rfrMaximumDepth':                  self.RFmaxDepthDial.value(),
                'rfrMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
                'rfrMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
                'rfrMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
                'rfrMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
                'rfrMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
                'rfrMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
                'rfrNumberOfTrees':                 self.RFestimatorsDial.value(),
                'rfrOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
                'rfrRandomState':                   self.RFrandomStateEntry.text(),
                'rfrWarmStart':                     self.RFwarmStartCheck.isChecked(),

                'sgdrAlpha':                        self.SGDalphaDial.value() / 100000,
                'sgdrAverage':                      self.SGDaverageCheck.isChecked(),
                'sgdrEta0':                         self.SGDeta0Dial.value() / 10.0,
                'sgdrFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
                'sgdrLearningRate':                 self.SGDlearningRateCombo.currentText(),
                'sgdrLoss':                         self.SGDlossCombo.currentText(),
                'sgdrL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
                'sgdrMaxIterations':                self.SGDmaxIterationsDial.value(),
                'sgdrPenalty':                      self.SGDpenaltyCombo.currentText(),
                'sgdrPowerT':                       self.SGDpowerTDial.value() / 10.0,
                'sgdrShuffle':                      self.SGDshuffleCheck.isChecked(),
                'sgdrTolerance':                    self.SGDtolDial.value() / 100.0,
                'sgdrWarmStart':                    self.SGDwarmStartCheck.isChecked(),

                'svrC':                             dh.nonize(self.SVMCDial.value()),
                # 'svrCacheSize': self.SVMcacheSizeDial.value(),
                'svrCoefficient0':                  self.SVMcoef0Dial.value() / 10.0,
                'svrEpsilon':                       self.SVMepsilonDial.value() / 10.0,
                'svrGamma':                         self.SVMgammaDial.value(),
                'svrKernel':                        self.SVMkernelCombo.currentText(),
                'svrMaximumIterations':             self.SVMmaxIterDial.value(),
                'svrPolynomialDegree':              self.SVMdegreeCombo.currentText(),
                'svrShrinking':                     self.SVMshrinkingCheck.isChecked(),
                'svrTolerance':                     self.SVMtolDial.value() / 100.0,
            }

        return options

    def refresh(self):
        # self.set_classification_tab()
        # self.set_clustering_tab()
        # self.set_dimensionality_reduction_tab()
        self.set_regression_tab()

    def rewindow(self):
        self.classificationTab = make_tab(self, text='Classification', master=self.tabs)
        self.clusteringTab = make_tab(self, text='Clustering', master=self.tabs)
        self.dimensionalityReductionTab = make_tab(self, text='Dimensionality Reduction', master=self.tabs)
        self.regressionTab = make_tab(self, text='Regression6', master=self.tabs)
        self.refresh()
        self.setLayout(self.hbox)

    def set_regression_tab(self):
        self.modelSelection = make_list(
            items=REGRESSORS_NAMES, command=self.set_layout, layout=self.regressionTab,
            row=0, column=0, width=200
        )

        self.scrollArea = make_scroll_area(self.regressionLayouts['Adaptive Boost'], width=275)
        self.regressionTab.addWidget(self.scrollArea, 0, 1)

    def set_layout(self):
        self.regressionTab.removeWidget(self.scrollArea)
        self.scrollArea = make_scroll_area(self.regressionLayouts[self.modelSelection.currentItem().text()], width=275)
        self.regressionTab.addWidget(self.scrollArea, 0, 1)

    def set_ab(self):
        layout = self.regressionLayouts['Adaptive Boost']
        _, self.ABestimatorsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
            layout=layout, row=1, column=0, description=''
        )

        _, self.ABlearningRateDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
            layout=layout, row=2, column=0, description=''
        )

        _, self.ABlossCombo = make_pair(
            self, pair='combo', comboItems=('linear', 'square', 'exponential'),
            text='Loss:', layout=layout, row=3, column=0, pairWidth=100, description=''
        )

    def set_dt(self):
        layout = self.regressionLayouts['Decision Tree']
        _, self.DTcriterionCombo = make_pair(
            self, pair='combo', comboItems=('mse', 'friedman_mse', 'mae'),
            text='Criterion:', layout=layout, row=1, column=0, labelWidth=200,
            pairWidth=100, description=CRITERION_DESCRIPTION
        )

        _, self.DTmaxDepthDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=2, column=0, labelWidth=125,
            description=MAX_DEPTH_DESCRIPTION
        )

        _, self.DTmaxFeaturesCombo = make_pair(
            self, pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=3, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Maximum Leaf Nodes:', layout=layout, row=4, column=0,
            labelWidth=200, description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Maximum Leaf Nodes:', layout=layout, row=4, column=0,
            labelWidth=200, description=MAX_LEAF_NODES_DESCRIPTION
        )
        # self.DTminImpurityDecreaseLabel = make_label(self, text='Minimum Impurity Decrease:', layout=self.dtTab,
        #                                             row=30, column=0, width=200,
        #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)
        # self.DTminImpurityDecreaseDial = make_dial(self, layout=self.dtTab,
        #                                             row=30, column=1, width=50,
        #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)
        _, self.DTminSamplesLeafDial = make_pair(
            self, pair='dial', dialSettings=(1, 4, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=6, column=0,
            labelWidth=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )
        _, self.DTminSamplesSplitDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=7, column=0,
            labelWidth=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )
        _, self.DTminWeightFractionLeafDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=8,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )
        _, self.DTpresortCheck = make_pair(
            self, pair='check', text='Presort Data:', layout=layout, row=9, column=0,
            labelWidth=200, description=PRESORT_DESCRIPTION
        )
        _, self.DTrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=10,
            column=0, labelWidth=125, pairWidth=50,
            description=RANDOM_STATE_DESCRIPTION
        )
        _, self.DTsplitterCombo = make_pair(
            self, pair='combo', comboItems=('best', 'random'), text='Splitter:',
            layout=layout, row=11, column=0, pairWidth=75,
            description=SPLITTER_DESCRIPTION
        )

    def set_en(self):
        layout = self.regressionLayouts['Elastic Net']
        _, self.ENalphaDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
            row=1, column=0, description=''
        )
        # self.ENfitInterceptLabel = make_label(self, text='Fit Intercept:', layout=self.layouts['Elastic Net'],
        #                                      row=1, column=0,
        #                                      description='')
        # self.ENfitInterceptCheck = make_button(self, type='check', layout=self.layouts['Elastic Net'],
        #                                       row=1, column=1,
        #                                       description='')
        _, self.ENl1RatioDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:',
            layout=layout, row=2, column=0, description=''
        )
        _, self.ENnormalizeCheck = make_pair(
            self, pair='check', text='Normalize:', layout=layout, row=3, column=0,
            description=''
        )
        _, self.ENpositiveCheck = make_pair(
            self, pair='check', text='Positive:', layout=layout, row=4, column=0,
            description=''
        )
        _, self.ENselectionCombo = make_pair(
            self, pair='combo', comboItems=('cyclic', 'random'), text='Selection:',
            layout=layout, row=5, column=0, description=''
        )
        _, self.ENtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=6, column=0, description=''
        )
        _, self.ENwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=7, column=0,
            description=''
        )

    def set_gp(self):
        layout = self.regressionLayouts['Gaussian Process']
        _, self.GPalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Alpha:', layout=layout,
            row=1, column=0, description=''
        )
        _, self.GPnormalizeCheck = make_pair(
            self, pair='check', text='Normalize:', layout=layout, row=2, column=0,
            description=''
        )

    def set_knn(self):
        layout = self.regressionLayouts['Nearest Neighbors']
        _, self.KNNalgorithmCombo = make_pair(
            self, pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
            text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
            description=ALGORITHM_DESCRIPTION
        )
        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)
        _, self.KNNleafSizeDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:',
            layout=layout, row=2, column=0, description=LEAF_SIZE_DESCRIPTION
        )
        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)
        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)
        _, self.KNNminkowskiPowerDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 2, 1),
            text='Minkowski Power:', layout=layout, row=3, column=0,
            description=P_DESCRIPTION
        )
        _, self.KNNneighborsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 5, 1),
            text='Number of Neighbors:', layout=layout, row=4, column=0,
            labelWidth=200, description=N_NEIGHBORS_DESCRIPTION
        )
        _, self.KNNweightsCombo = make_pair(
            self, pair='combo', comboItems=('uniform', 'distance'),
            text='Weights Function:', layout=layout, row=5, column=0, labelWidth=200,
            pairWidth=100, description=WEIGHTS_DESCRIPTION
        )

    def set_kr(self):
        layout = self.regressionLayouts['Kernel Ridge']
        _, self.KRalphaDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
            row=1, column=0, description=ALPHA_DESCRIPTION
        )
        _, self.KRcoef0Dial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 10, 1), text='Coefficient 0:',
            layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
        )
        _, self.KRdegreeCombo = make_pair(
            self, pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
            layout=layout, row=3, column=0, description=DEGREE_DESCRIPTION
        )
        _, self.KRgammaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
            row=4, column=0, description=GAMMA_DESCRIPTION
        )
        _, self.KRkernelCombo = make_pair(
            self, pair='combo', comboItems=('linear', 'poly', 'rbf'), text='Kernel:',
            layout=layout, row=5, column=0, description=KERNEL_DESCRIPTION
        )

    def set_mlp(self):
        layout = self.regressionLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            self, pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )
        _, self.MLPalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Alpha (Penalty Parameter):', layout=layout, row=2, column=0,
            labelWidth=200, description=MLP_ALPHA_DESCRIPTION
        )
        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)

        _, self.MLPbeta1Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )
        _, self.MLPbeta2Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )
        _, self.MLPearlyStoppingCheck = make_pair(
            self, pair='check', text='Early Stopping:', layout=layout, row=5,
            column=0, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )
        _, self.MLPepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )
        _, self.MLPhiddenLayerSizesEntry = make_pair(
            self, pair='entry', text='Hidden Layer Sizes:', layout=layout,
            row=7, column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )
        _, self.MLPinitLearningRateDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )
        _, self.MLPlearningRateCombo = make_pair(
            self, pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )
        _, self.MLPmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )
        _, self.MLPmomentumDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
            layout=layout, row=11, column=0, description=MOMENTUM_DESCRIPTION
        )
        _, self.MLPnesterovsMomentumCheck = make_pair(
            self, pair='check', text='Nesterov\'s Momentum:', layout=layout,
            row=12, column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )
        _, self.MLPpowerTDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )
        _, self.MLPrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=14,
            column=0, pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )
        _, self.MLPshuffleCheck = make_pair(
            self, pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )
        _, self.MLPsolverCombo = make_pair(
            self, pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )
        _, self.MLPtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=17, column=0, description=MLP_TOL_DESCRIPTION
        )
        _, self.MLPvalidationFractionDial = make_pair(
            self, pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )
        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)
        _, self.MLPwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def set_svm(self):
        layout = self.regressionLayouts['Support Vector Machine']
        _, self.SVMCDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
            column=0, description=C_DESCRIPTION
        )

        # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=0,
        #                                    description=CACHE_SIZE_DESCRIPTION)
        # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=1, width=50,
        #                                    description=CACHE_SIZE_DESCRIPTION)

        _, self.SVMcoef0Dial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
            layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
        )

        _, self.SVMdegreeCombo = make_pair(
            self, pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
            layout=layout, row=3, column=0, pairWidth=100,
            description=DEGREE_DESCRIPTION
        )

        _, self.SVMepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:',
            layout=layout, row=4, column=0, description=EPSILON_DESCRIPTION
        )

        _, self.SVMgammaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
            row=5, column=0, description=GAMMA_DESCRIPTION
        )

        _, self.SVMkernelCombo = make_pair(
            self, pair='combo',
            comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
            text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
            description=KERNEL_DESCRIPTION
        )

        _, self.SVMmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=7, column=0, labelWidth=200,
            description=MAX_ITER_DESCRIPTION
        )

        _, self.SVMshrinkingCheck = make_pair(
            self, pair='check', text='Shrinking:', layout=layout, row=8, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=9, column=0, description=TOL_DESCRIPTION
        )

    def defaults(self):
        pass

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, standard=False)
        """BOTTOM"""
        self.rewindow()  # self.readLabel.textChanged.connect(self.parent.databaseMenu.apply(self.readLabel.text()))

    def refresh(self):
        # SUPPORT VECTOR MACHINE
        label1 = make_label(self, text='SUPPORT VECTOR MACHINE', layout=self.bottom, row=0, column=0, width=200)

        self.CLabel = make_label(self, text='C:', layout=self.bottom, row=1, column=0)
        self.CEntry = make_entry(self, layout=self.bottom, row=1, column=1, width=50)

        self.epsilonLabel = make_label(self, text='Epsilon:', layout=self.bottom, row=2, column=0)
        self.epsilonEntry = make_entry(self, layout=self.bottom, row=2, column=1, width=50)

        self.kernelLabel = make_label(self, text='Kernel:', layout=self.bottom, row=3, column=0)
        self.kernelCombo = make_combo(
            self, ('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'), layout=self.bottom,
            row=3, column=1, width=100
        )

        self.degreeLabel = make_label(self, text='Degree:', layout=self.bottom, row=4, column=0)
        self.degreeEntry = make_combo(
            self, ('0', '1', '1', '2', '3', '5', '6'), layout=self.bottom, row=4, column=1,
            width=100
        )

        self.gammaLabel = make_label(self, text='Gamma:', layout=self.bottom, row=5, column=0)
        self.gammaEntry = make_entry(self, layout=self.bottom, row=5, column=1, width=50)

        self.coef0Label = make_label(self, text='Coefficient0:', layout=self.bottom, row=6, column=0)
        self.coef0Entry = make_entry(self, layout=self.bottom, row=6, column=1, width=50)

        self.shrinkingLabel = make_label(self, text='Shrinking:', layout=self.bottom, row=7, column=0)
        self.shrinkingCheck = make_button(self, type='check', layout=self.bottom, row=7, column=1)

        self.tolLabel = make_label(self, text='Tolerance:', layout=self.bottom, row=8, column=0)
        self.tolEntry = make_entry(self, layout=self.bottom, row=8, column=1, width=50)

        self.cacheSizeLabel = make_label(self, text='Cache Size:', layout=self.bottom, row=9, column=0)
        self.cacheSizeEntry = make_entry(self, layout=self.bottom, row=9, column=1, width=50)

        self.maxIterLabel = make_label(self, text='Maximum Iterations', layout=self.bottom, row=10, column=0)
        self.maxIterEntry = make_entry(self, layout=self.bottom, row=10, column=1, width=50)
        # K NEIGHBORS
        label2 = make_label(self, text='K NEAREST NEIGHBORS', layout=self.bottom, row=11, column=0, width=200)

        self.nNeighborsLabel = make_label(
            self, text='Number of Neighbors:', layout=self.bottom, row=12, column=0,
            width=200
        )
        self.nNeighborsEntry = make_entry(self, layout=self.bottom, row=12, column=1, width=50)

        self.weightsLabel = make_label(self, text='Weights Function:', layout=self.bottom, row=13, column=0, width=200)
        self.weightsCombo = make_combo(self, ('uniform', 'distance'), layout=self.bottom, row=13, column=1, width=100)

        self.algorithmLabel = make_label(self, text='Algorithm:', layout=self.bottom, row=14, column=0)
        self.algorithmCombo = make_combo(
            self, ('auto', 'ball_tree', 'kd_tree', 'brute'), layout=self.bottom, row=14,
            column=1, width=100
        )

        self.leafSizeLabel = make_label(self, text='Leaf Size:', layout=self.bottom, row=15, column=0)
        self.leafSizeEntry = make_entry(self, layout=self.bottom, row=15, column=1, width=50)

        self.pLabel = make_label(self, text='Minkowski Power:', layout=self.bottom, row=16, column=0, width=200)
        self.pEntry = make_entry(self, layout=self.bottom, row=16, column=1, width=50)

        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

        # DECISION TREE
        label3 = make_label(self, text='DECISION TREE', layout=self.bottom, row=20, column=0, width=250)
        self.criterionLabel = make_label(self, text='Criterion:', layout=self.bottom, row=21, column=0, width=200)
        self.criterionCombo = make_combo(
            self, ('mse', 'friedman_mse', 'mae'), layout=self.bottom, row=21, column=1,
            width=100
        )

        self.splitterLabel = make_label(self, text='Splitter:', layout=self.bottom, row=22, column=0)
        self.splitterCombo = make_combo(self, ('best', 'random'), layout=self.bottom, row=22, column=1, width=75)

        self.maxDepthLabel = make_label(self, text='Maximum Depth:', layout=self.bottom, row=23, column=0, width=125)
        self.maxDepthEntry = make_entry(self, layout=self.bottom, row=23, column=1, width=50)

        self.minSamplesSplitLabel = make_label(
            self, text='Minimum Samples:', layout=self.bottom, row=24, column=0,
            width=125
        )
        self.minSamplesSplitEntry = make_entry(self, layout=self.bottom, row=24, column=1, width=50)


class MCMCMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 7)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 7)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)

        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)
        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=1, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=1,
            column=2, description=PARALLEL_DESCRIPTION
        )

        modeGroup.addButton(self.parallelRadio)
        modeGroup.addButton(self.seriesRadio)
        self.seriesRadio.setChecked(True)
        self.parallelRadio.setChecked(False)
        self.mode = 'series'

        samplerGroup = QtWidgets.QButtonGroup(self.topRightLayout)

        _, self.mcRadio = make_pair(
            self, pair='radio', text='Monte Carlo:', layout=self.topRightLayout, row=2,
            column=0, description=''
        )
        _, self.lhsRadio = make_pair(
            self, pair='radio', text='Latin Hypercube:', layout=self.topRightLayout, row=2,
            column=2, description=LATIN_HYPERCUBES_DESCRIPTION
        )

        samplerGroup.addButton(self.lhsRadio)
        samplerGroup.addButton(self.mcRadio)
        self.mcRadio.setChecked(True)

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=6, column=0,
            description=RUN_MARKOV_CHAIN_DESCRIPTION
        )

        self.siteContainer = make_browser(layout=self.bottomLayout, file=MARKOV_CHAIN_GRAPH)
        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=3, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )
        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=3, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        _, self.iterationsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 1, 1), text='Iterations:',
            layout=self.topRightLayout, row=4, column=0,
            description=ITERATIONS_DESCRIPTION
        )

        self.initialStateLabel = make_label(
            self, text='Initial State:', layout=self.topRightLayout, row=4, column=2,
            description=INITIAL_STATE_DESCRIPTION
        )

        _, self.conditionCombo = make_pair(
            self, pair='combo', comboItems=('', '>', '>=', '<', '<='), text='Condition:',
            layout=self.topRightLayout, row=5, column=0, description=''
        )

        try:
            self.combos()
        except:
            pass

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            self, [''] + self.headers, command=self.update_columns, layout=self.topRightLayout,
            row=3, column=1, width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            self, self.headers, command=self.update_states, layout=self.topRightLayout, row=3,
            column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(
                        self.readLabel.text(), index=self.indexCombo.currentText(),
                        column=(self.columnCombo.currentText())
                    )
                )
            ), layout=self.topRightLayout, row=4, column=3,
            width=50, description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()

        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            self, options, command=self.update_states, layout=self.topRightLayout, row=3,
            column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.update_states()

    def update_states(self):
        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(self.readLabel.text(), index=None, column=self.columnCombo.currentText(), )
                )
            ),
            layout=self.topRightLayout, row=4, column=3, width=50,
            description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def run(self):
        initialState = self.initialStateCombo.currentText()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        iterations = self.iterationsDial.value()
        condition = dh.get_operator(self.conditionCombo.currentText())

        if self.validate(dir, index, column):
            dataMatrix, data, xKeys, yKeys = dh.process_regression_data(dir, index, column, self.mode, matrix=True)
            if yKeys:
                inverseKeys = {yKeys[k]: k for k in yKeys}
                initialState = inverseKeys[initialState]
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            timeSteps, dindex = MonteCarlo.mh.time_steps(dataMatrix, self.mode)
            stateVector = MarkovChain.mh.state_vector(initialState, data)
            transitionProbabilityMatrix = MarkovChain.transition_probability_matrix(dataMatrix, self.mode, condition)
            markovChain = MarkovChain.markov_chain(stateVector, transitionProbabilityMatrix, iterations)
            monteCarlo = MonteCarlo.monte_carlo(stateVector, transitionProbabilityMatrix, iterations, timeSteps)
            monteCarloBounds = MonteCarlo.mh.min_max_mean(monteCarlo, mode=self.mode)
            x = ((dindex, dindex, data.index), (markovChain.T.index,))
            y = ((monteCarloBounds, monteCarlo, data), (markovChain.T,))
            make_plot(
                MARKOV_CHAIN_GRAPH, X=x, Y=y, titles=('Monte Carlo', 'Markov Chain'),
                xLabels=(index if self.mode == 'series' else 'Time Step', 'Iteration'),
                yLabels=(column, 'Transition Probability'), lineWidths=((3, 0.1, 1), (3,)),
                legends=((True, False, True), (True,)), types=(('line', 'line', 'scatter'), ('line',)),
                xKeys=(xKeys, None), yKeys=(yKeys, None)
            )
            self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)
            MarkovChain.create_transition_matrix_html(transitionProbabilityMatrix)

    def get_mode(self):
        if self.seriesRadio.isChecked():
            self.mode = 'series'
        elif self.parallelRadio.isChecked():
            self.mode = 'parallel'

    def graph_raw(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        if self.validate(dir, index, column):
            data, xKeys, yKeys = dh.process_regression_data(dir, index, column, self.mode)
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.index,),)
            y = ((data,),)
            make_plot(
                MARKOV_CHAIN_GRAPH, X=x, Y=y, titles=('Raw Data',),
                xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
                legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)

    def validate(self, dir, index, column):
        error = False
        self.get_mode()
        if self.mcRadio.isChecked():
            self.sampler = 'mc'
        elif self.lhsRadio.isChecked():
            self.sampler = 'lhs'

        if dir == '':
            QMessageBox.critical(self, "No Directory", "Specify a directory.", QMessageBox.Ok)
            error = True

        if self.mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 8)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 8)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)

        self.headers = dh.line_reader(HEADERS)

        """TOP RIGHT"""
        # UNION OR INTERSECTION SEARCH
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)
        self.seriesLabel = make_label(
            self, text='Series:', layout=self.topRightLayout, row=1, column=0,
            description=SERIES_DESCRIPTION
        )
        self.seriesRadio = make_button(
            self, type='radio', layout=self.topRightLayout, row=1, column=1,
            description=SERIES_DESCRIPTION
        )
        modeGroup.addButton(self.seriesRadio)

        self.parallelLabel = make_label(
            self, text='Parallel:', layout=self.topRightLayout, row=1, column=2,
            description=PARALLEL_DESCRIPTION
        )
        self.parallelRadio = make_button(
            self, type='radio', layout=self.topRightLayout, row=1, column=3,
            description=PARALLEL_DESCRIPTION
        )
        modeGroup.addButton(self.parallelRadio)

        samplerGroup = QtWidgets.QButtonGroup(self.topRightLayout)
        self.lhsLabel = make_label(
            self, text='Latin Hypercubes:', layout=self.topRightLayout, row=2, column=0,
            description=LATIN_HYPERCUBES_DESCRIPTION
        )
        self.lhsRadio = make_button(
            self, type='radio', layout=self.topRightLayout, row=2, column=1,
            description=LATIN_HYPERCUBES_DESCRIPTION
        )
        samplerGroup.addButton(self.lhsRadio)

        self.ccLabel = make_label(
            self, text='Central Composite:', layout=self.topRightLayout, row=2, column=2,
            description=CENTRAL_COMPOSITE_DESCRIPTION
        )
        self.ccRadio = make_button(
            self, type='radio', layout=self.topRightLayout, row=2, column=3,
            description=CENTRAL_COMPOSITE_DESCRIPTION
        )
        samplerGroup.addButton(self.ccRadio)

        self.readLabel.setText(r'C:\Users\frano\PycharmProjects\Big\Database\Children Of The Sky')

        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=3, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )
        self.indexCombo = make_combo(
            self, [''] + self.headers, lambda: self.update_columns(),
            layout=self.topRightLayout, row=3, column=1, width=200,
            description=INDEX_COMBO_DESCRIPTION
        )
        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=3, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.columnCombo = make_combo(
            self, self.headers, lambda: self.update_states(), layout=self.topRightLayout,
            row=3, column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        self.iterationsLabel = make_label(
            self, text='Iterations:', layout=self.topRightLayout, row=4, column=0,
            description=ITERATIONS_DESCRIPTION
        )
        self.iterationsEntry = make_entry(
            self, layout=self.topRightLayout, row=4, column=1, width=50,
            description=ITERATIONS_DESCRIPTION
        )
        self.initialStateLabel = make_label(
            self, text='Initial State:', layout=self.topRightLayout, row=4, column=2,
            description=INITIAL_STATE_DESCRIPTION
        )
        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(self.readLabel.text(), index='col2', column=(self.columnCombo.currentText()))
                )
            ),
            layout=self.topRightLayout, row=4, column=3, width=50,
            description=INITIAL_STATE_DESCRIPTION
        )

        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run',
            description=RUN_MARKOV_CHAIN_DESCRIPTION
        )
        self.topRightLayout.addWidget(self.runButton, 6, 0)

        self.siteContainer = make_browser(layout=self.bottomLayout, file=MARKOV_CHAIN_GRAPH)
        self.bottomLayout.addWidget(self.siteContainer)

    def update_columns(self):
        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            self, options, command=lambda: self.update_states(), layout=self.topRightLayout,
            row=3, column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )
        self.update_states()

    def update_states(self):
        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(self.readLabel.text(), index=None, column=self.columnCombo.currentText(), )
                )
            ),
            layout=self.topRightLayout, row=4, column=3, width=50,
            description=INITIAL_STATE_DESCRIPTION
        )

    def run(self):
        initialState = self.initialStateCombo.currentText()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = r'C:\Users\frano\PycharmProjects\Big\Database\Children Of The Sky'  # self.readLabel.text()
        iterations = '25'  # self.iterationsEntry.text()

        if not self.validate(dir, index, column, iterations):
            iterations = int(iterations)
            try:
                dataFrameList = MarkovChain.dh.read_data_list(dir, index=index, column=column)
                data = MarkovChain.dh.clean_data(MarkovChain.dh.merge_data_list(dataFrameList))
                stateVector = MarkovChain.vs.state_vector(initialState, dataFrameList)
                transitionProbabilityMatrix = MarkovChain.transition_probability_matrix(dataFrameList, mode=self.mode)
                markovChain = MarkovChain.markov_chain(stateVector, transitionProbabilityMatrix, iterations=iterations)
                make_line_plot(markovChain.T, MARKOV_CHAIN_GRAPH, index, column)
                self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)
                print(
                    transitionProbabilityMatrix
                )  # monteCarlo = MonteCarlo2.monte_carlo(stateVector, transitionProbabilityMatrix, iterations=iterations)  # make_line_plot(monteCarlo.T, MONTE_CARLO_GRAPH)  # self.siteContainer = load_browser(self.siteContainer, MONTE_CARLO_GRAPH)

            except Exception as e:
                print(e)

    def validate(self, dir, index, column, iters):
        error = False

        if self.seriesRadio.isChecked():
            self.mode = 'series'
        elif self.parallelRadio.isChecked():
            self.mode = 'parallel'
        else:
            QMessageBox.critical(self, "No Mode", "Select a mode.", QMessageBox.Ok)
            self.mode = None
            error = True

        if self.lhsRadio.isChecked():
            self.sampler = 'lhs'
        elif self.ccRadio.isChecked():
            self.sampler = 'cc'
        else:
            QMessageBox.critical(self, "No Sampler", "Select a sampler.", QMessageBox.Ok)
            self.sampler = None
            error = True
        if index == '':
            QMessageBox.warning(self, "No Index", "Select index.", QMessageBox.Ok)
            error = False
        if column == '':
            QMessageBox.critical(self, "No Column", "Select column.", QMessageBox.Ok)
            error = True
        if iters == '':
            QMessageBox.critical(self, "No Iterations", "Specify number of iterations.", QMessageBox.Ok)
            error = True
        else:
            try:
                assert (float(iters) == int(iters))
                self.iterations = int(iters)
            except Exception as e:
                QMessageBox.critical(self, "Iterations", "Iterations must be an integer.\n" + str(e), QMessageBox.Ok)
                self.iterations = None
        if dir == '':
            QMessageBox.critical(self, "No Directory", "Specify a directory.", QMessageBox.Ok)
            error = True
        return error

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 7)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 7)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)
        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=1, column=0,
            description=SERIES_DESCRIPTION
        )
        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=1,
            column=2, description=PARALLEL_DESCRIPTION
        )
        modeGroup.addButton(self.parallelRadio)
        modeGroup.addButton(self.seriesRadio)
        self.seriesRadio.setChecked(True)
        self.parallelRadio.setChecked(False)
        self.mode = 'series'
        samplerGroup = QtWidgets.QButtonGroup(self.topRightLayout)
        _, self.mcRadio = make_pair(
            self, pair='radio', text='Monte Carlo:', layout=self.topRightLayout, row=2,
            column=0, description=''
        )
        _, self.lhsRadio = make_pair(
            self, pair='radio', text='Latin Hypercube:', layout=self.topRightLayout, row=2,
            column=2, description=LATIN_HYPERCUBES_DESCRIPTION
        )
        samplerGroup.addButton(self.lhsRadio)
        samplerGroup.addButton(self.mcRadio)
        self.mcRadio.setChecked(True)
        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=6,
            column=0, description=RUN_MARKOV_CHAIN_DESCRIPTION
        )
        self.siteContainer = make_browser(layout=self.bottomLayout, file=MARKOV_CHAIN_GRAPH)
        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=3, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )
        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=3, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )
        _, self.iterationsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 1, 1), text='Iterations:',
            layout=self.topRightLayout, row=4, column=0,
            description=ITERATIONS_DESCRIPTION
        )
        self.initialStateLabel = make_label(
            self, text='Initial State:', layout=self.topRightLayout, row=4, column=2,
            description=INITIAL_STATE_DESCRIPTION
        )
        _, self.conditionCombo = make_pair(
            self, pair='combo', comboItems=('', '>', '>=', '<', '<='), text='Condition:',
            layout=self.topRightLayout, row=5, column=0, description=''
        )
        try:
            self.combos()
        except:
            pass

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)
        self.indexCombo = make_combo(
            self, [''] + self.headers, lambda: self.update_columns(),
            layout=self.topRightLayout, row=3, column=1, width=200,
            description=INDEX_COMBO_DESCRIPTION
        )
        self.columnCombo = make_combo(
            self, self.headers, lambda: self.update_states(), layout=self.topRightLayout,
            row=3, column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )
        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(
                        self.readLabel.text(), index=self.indexCombo.currentText(),
                        column=(self.columnCombo.currentText())
                    )
                )
            ), layout=self.topRightLayout, row=4, column=3,
            width=50, description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            self, options, command=lambda: self.update_states(), layout=self.topRightLayout,
            row=3, column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )
        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)
        self.update_states()

    def update_states(self):
        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(self.readLabel.text(), index=None, column=self.columnCombo.currentText(), )
                )
            ),
            layout=self.topRightLayout, row=4, column=3, width=50,
            description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def run(self):
        initialState = self.initialStateCombo.currentText()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        iterations = self.iterationsDial.value()
        condition = dh.get_operator(self.conditionCombo.currentText())

        if self.validate(dir, index, column):
            dataMatrix, data, xKeys, yKeys = dh.process_data(dir, index, column, self.mode, matrix=True)
            if yKeys:
                inverseKeys = {yKeys[k]: k for k in yKeys}
                initialState = inverseKeys[initialState]
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            timeSteps, dindex = MonteCarlo.mh.time_steps(dataMatrix, self.mode)
            stateVector = MarkovChain.mh.state_vector(initialState, data)
            transitionProbabilityMatrix = MarkovChain.transition_probability_matrix(dataMatrix, self.mode, condition)
            markovChain = MarkovChain.markov_chain(stateVector, transitionProbabilityMatrix, iterations)
            monteCarlo = MonteCarlo.monte_carlo(stateVector, transitionProbabilityMatrix, iterations, timeSteps)
            monteCarloBounds = MonteCarlo.mh.min_max_mean(monteCarlo, mode=self.mode)
            x = ((dindex, dindex, data.index), (markovChain.T.index,))
            y = ((monteCarloBounds, monteCarlo, data), (markovChain.T,))
            make_plot(
                MARKOV_CHAIN_GRAPH, X=x, Y=y, titles=('Monte Carlo', 'Markov Chain'),
                xLabels=(index if self.mode == 'series' else 'Time Step', 'Iteration'),
                yLabels=(column, 'Transition Probability'), lineWidths=((3, 0.1, 1), (3,)),
                legends=((True, False, True), (True,)), types=(('line', 'line', 'scatter'), ('line',)),
                xKeys=(xKeys, None), yKeys=(yKeys, None)
            )
            self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)
            MarkovChain.create_transition_matrix_html(transitionProbabilityMatrix)

    def get_mode(self):
        if self.seriesRadio.isChecked():
            self.mode = 'series'
        elif self.parallelRadio.isChecked():
            self.mode = 'parallel'

    def graph_raw(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        if self.validate(dir, index, column):
            data, xKeys, yKeys = dh.process_data(dir, index, column, self.mode)
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.index,),)
            y = ((data,),)
            make_plot(
                MARKOV_CHAIN_GRAPH, X=x, Y=y, titles=('Raw Data',),
                xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
                legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)

    def validate(self, dir, index, column):
        error = False
        self.get_mode()
        if self.mcRadio.isChecked():
            self.sampler = 'mc'
        elif self.lhsRadio.isChecked():
            self.sampler = 'lhs'
        if dir == '':
            QMessageBox.critical(self, "No Directory", "Specify a directory.", QMessageBox.Ok)
            error = True
        if self.mode == 'parallel':
            if dh.filecount(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 7)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 7)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)
        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=1, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=1,
            column=2, description=PARALLEL_DESCRIPTION
        )
        modeGroup.addButton(self.parallelRadio)
        modeGroup.addButton(self.seriesRadio)
        self.seriesRadio.setChecked(True)
        samplerGroup = QtWidgets.QButtonGroup(self.topRightLayout)
        _, self.mcRadio = make_pair(
            self, pair='radio', text='Monte Carlo:', layout=self.topRightLayout, row=2,
            column=0, description=''
        )
        _, self.lhsRadio = make_pair(
            self, pair='radio', text='Latin Hypercube:', layout=self.topRightLayout, row=2,
            column=2, description=LATIN_HYPERCUBES_DESCRIPTION
        )
        samplerGroup.addButton(self.lhsRadio)
        samplerGroup.addButton(self.mcRadio)
        self.mcRadio.setChecked(True)
        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run',
            description=RUN_MARKOV_CHAIN_DESCRIPTION
        )
        self.topRightLayout.addWidget(self.runButton, 6, 0)

        self.siteContainer = make_browser(layout=self.bottomLayout, file=MARKOV_CHAIN_GRAPH)
        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=3, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )
        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=3, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )
        self.iterationsLabel = make_label(
            self, text='Iterations:', layout=self.topRightLayout, row=4, column=0,
            description=ITERATIONS_DESCRIPTION
        )
        self.iterationsDial = make_dial(
            self, min=1, max=100, value=1, layout=self.topRightLayout, row=4, column=1,
            description=ITERATIONS_DESCRIPTION
        )
        self.initialStateLabel = make_label(
            self, text='Initial State:', layout=self.topRightLayout, row=4, column=2,
            description=INITIAL_STATE_DESCRIPTION
        )
        self.conditionLabel = make_label(
            self, 'Condition:', layout=self.topRightLayout, row=5, column=0,
            description=''
        )
        self.conditionCombo = make_combo(
            self, ('', '>', '>=', '<', '<='), layout=self.topRightLayout, row=5, column=1,
            description=''
        )
        try:
            self.combos()
        except:
            pass

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            self, [''] + self.headers, lambda: self.update_columns(),
            layout=self.topRightLayout, row=3, column=1, width=200,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            self, self.headers, lambda: self.update_states(), layout=self.topRightLayout,
            row=3, column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(
                        self.readLabel.text(), index=self.indexCombo.currentText(),
                        column=(self.columnCombo.currentText())
                    )
                )
            ), layout=self.topRightLayout, row=4, column=3,
            width=50, description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()
        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            self, options, command=lambda: self.update_states(), layout=self.topRightLayout,
            row=3, column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )
        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.update_states()

    def update_states(self):
        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(self.readLabel.text(), index=None, column=self.columnCombo.currentText(), )
                )
            ),
            layout=self.topRightLayout, row=4, column=3, width=50,
            description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def run(self):
        initialState = self.initialStateCombo.currentText()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        iterations = self.iterationsDial.value()
        condition = dh.get_operator(self.conditionCombo.currentText())

        if self.validate(dir, index, column):
            data = dh.merge_data_list(dh.read_data_list(dir, index=index, column=column))
            data, xKeys = dh.numerify_index(data)
            pData = dh.data_field(data, self.mode)
            pData = pd.DataFrame(pData, columns=(column,), index=pData.index)
            timeSteps = MonteCarlo.mh.time_steps(data, self.mode)
            stateVector = MarkovChain.mh.state_vector(initialState, data)
            transitionProbabilityMatrix = MarkovChain.transition_probability_matrix(data, self.mode, condition)
            markovChain = MarkovChain.markov_chain(stateVector, transitionProbabilityMatrix, iterations)
            monteCarlo = MonteCarlo.monte_carlo(stateVector, transitionProbabilityMatrix, iterations, timeSteps)
            monteCarloBounds = MonteCarlo.mh.min_max_mean(monteCarlo, mode=self.mode)
            monteCarloFrequency = markovChain.T  # MonteCarlo2.mh.frequency(monteCarlo)
            dindex = data.index if self.mode == 'series' else data.T.index
            x = ((markovChain.T.index,), (dindex, dindex, pData.index), (monteCarloFrequency.index,))
            y = ((markovChain.T,), (monteCarloBounds, monteCarlo, pData), (monteCarloFrequency,))
            make_tabbed_plot(
                MARKOV_CHAIN_GRAPH, X=x, Y=y,
                titles=('Markov Chain', 'Monte Carlo', 'Monte Carlo Frequency'),
                xLabels=('Iteration', index if self.mode == 'series' else 'Time Step', 'Iteration'),
                yLabels=('Transition Probability', column, 'Transition Probability'),
                lineWidths=((3,), (3, 0.1, 1), (1,)), legends=((True,), (True, False, True), (True,)),
                types=(('line',), ('line', 'line', 'scatter'), ('scatter',)), xKeys=(None, xKeys, None),
                yKeys=(None, None, None)
            )
            self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            if self.validate(dir, index, column):
                data = dh.data_field(dh.merge_data_list(dh.read_data_list(dir, index, column)), self.mode)
                data, xKeys = dh.numerify_index(data, series=True)
                data = pd.DataFrame(data, columns=(column,), index=data.index)
                x = ((data.index,),)
                y = ((data,),)
                make_tabbed_plot(
                    REGRESSOR_GRAPH, X=x, Y=y, titles=('Raw Data',),
                    xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                    lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,)
                )
                self.siteContainer = load_browser(self.siteContainer, REGRESSOR_GRAPH)
        except Exception as e:
            print(e)

    def process_data(self, dir, index, column):
        data = dh.read_data_list(dir, index, column)
        data = dh.merge_data_list(data)
        pData = dh.vectorize_data(data, self.mode)
        pData, xKeys = dh.numerify_index(pData, series=True)
        pData, yKeys = dh.numerify_values(pData)
        pData = pData.dropna().astype(float)
        print(data)
        data = dh.clean_data(data)
        data, _ = dh.numerify_values(data)
        print(data)
        data, _ = dh.numerify_index(data)
        return pData, data, xKeys, yKeys

    def run(self):
        initialState = self.initialStateCombo.currentText()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        iterations = self.iterationsDial.value()
        condition = dh.get_operator(self.conditionCombo.currentText())

        if self.validate(dir, index, column):
            pData, data, xKeys, yKeys = self.process_data(dir, index, column)
            if yKeys:
                inverseKeys = {yKeys[k]: k for k in yKeys}
                initialState = inverseKeys[initialState]
            pData = pd.DataFrame(pData, columns=(column,), index=pData.index)
            timeSteps = MonteCarlo.mh.time_steps(data, self.mode)
            stateVector = MarkovChain.mh.state_vector(initialState, data)
            transitionProbabilityMatrix = MarkovChain.transition_probability_matrix(data, self.mode, condition)
            markovChain = MarkovChain.markov_chain(stateVector, transitionProbabilityMatrix, iterations)
            monteCarlo = MonteCarlo.monte_carlo(stateVector, transitionProbabilityMatrix, iterations, timeSteps)
            monteCarloBounds = MonteCarlo.mh.min_max_mean(monteCarlo, mode=self.mode)
            dindex = data.index if self.mode == 'series' else data.T.index
            x = ((dindex, dindex, pData.index), (markovChain.T.index,))
            y = ((monteCarloBounds, monteCarlo, pData), (markovChain.T,))
            make_tabbed_plot(
                MARKOV_CHAIN_GRAPH, X=x, Y=y, titles=('Monte Carlo', 'Markov Chain'),
                xLabels=(index if self.mode == 'series' else 'Time Step', 'Iteration'),
                yLabels=(column, 'Transition Probability'), lineWidths=((3, 0.1, 1), (3,)),
                legends=((True, False, True), (True,)), types=(('line', 'line', 'scatter'), ('line',)),
                xKeys=(xKeys, None), yKeys=(yKeys, None)
            )
            self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            if self.validate(dir, index, column):
                pData, _, xKeys, yKeys = self.process_data(dir, index, column)
                pData = pd.DataFrame(pData, columns=(column,), index=pData.index)
                x = ((pData.index,),)
                y = ((pData,),)
                make_tabbed_plot(
                    REGRESSOR_GRAPH, X=x, Y=y, titles=('Raw Data',),
                    xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                    lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,),
                    yKeys=(yKeys,)
                )
                self.siteContainer = load_browser(self.siteContainer, REGRESSOR_GRAPH)
        except Exception as e:
            print(e)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 7)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 7)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)

        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)
        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=1, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=1,
            column=2, description=PARALLEL_DESCRIPTION
        )

        modeGroup.addButton(self.parallelRadio)
        modeGroup.addButton(self.seriesRadio)
        self.seriesRadio.setChecked(True)

        samplerGroup = QtWidgets.QButtonGroup(self.topRightLayout)

        _, self.mcRadio = make_pair(
            self, pair='radio', text='Monte Carlo:', layout=self.topRightLayout, row=2,
            column=0, description=''
        )
        _, self.lhsRadio = make_pair(
            self, pair='radio', text='Latin Hypercube:', layout=self.topRightLayout, row=2,
            column=2, description=LATIN_HYPERCUBES_DESCRIPTION
        )

        samplerGroup.addButton(self.lhsRadio)
        samplerGroup.addButton(self.mcRadio)
        self.mcRadio.setChecked(True)

        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=6,
            column=0, description=RUN_MARKOV_CHAIN_DESCRIPTION
        )

        self.siteContainer = make_browser(layout=self.bottomLayout, file=MARKOV_CHAIN_GRAPH)
        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=3, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )
        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=3, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        _, self.iterationsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 1, 1), text='Iterations:',
            layout=self.topRightLayout, row=4, column=0,
            description=ITERATIONS_DESCRIPTION
        )

        self.initialStateLabel = make_label(
            self, text='Initial State:', layout=self.topRightLayout, row=4, column=2,
            description=INITIAL_STATE_DESCRIPTION
        )

        _, self.conditionCombo = make_pair(
            self, pair='combo', comboItems=('', '>', '>=', '<', '<='), text='Condition:',
            layout=self.topRightLayout, row=5, column=0, description=''
        )

        try:
            self.combos()
        except:
            pass

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            self, [''] + self.headers, lambda: self.update_columns(),
            layout=self.topRightLayout, row=3, column=1, width=200,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            self, self.headers, lambda: self.update_states(), layout=self.topRightLayout,
            row=3, column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(
                        self.readLabel.text(), index=self.indexCombo.currentText(),
                        column=(self.columnCombo.currentText())
                    )
                )
            ), layout=self.topRightLayout, row=4, column=3,
            width=50, description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def update_columns(self):
        place = self.columnCombo.currentText()

        if self.indexCombo.currentText() != '':
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        else:
            options = [h for h in self.headers if h != self.indexCombo.currentText()]
        self.columnCombo = make_combo(
            self, options, command=lambda: self.update_states(), layout=self.topRightLayout,
            row=3, column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if place != self.indexCombo.currentText():
            self.columnCombo.setCurrentText(place)

        self.update_states()

    def update_states(self):
        self.initialStateCombo = make_combo(
            self, dh.get_uniques(
                dh.merge_data_list(
                    dh.read_data_list(self.readLabel.text(), index=None, column=self.columnCombo.currentText(), )
                )
            ),
            layout=self.topRightLayout, row=4, column=3, width=50,
            description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def run(self):
        initialState = self.initialStateCombo.currentText()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        iterations = self.iterationsDial.value()
        condition = dh.get_operator(self.conditionCombo.currentText())

        if self.validate(dir, index, column):
            dataMatrix, data, xKeys, yKeys = dh.process_data(dir, index, column, self.mode, matrix=True)
            if yKeys:
                inverseKeys = {yKeys[k]: k for k in yKeys}
                initialState = inverseKeys[initialState]
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            print('matrix')
            print(dataMatrix)

            # print('data')
            # print(data)

            timeSteps, dindex = MonteCarlo.mh.time_steps(data, self.mode)
            # print('timesteps')
            # print(timeSteps)

            stateVector = MarkovChain.mh.state_vector(initialState, data)

            transitionProbabilityMatrix = MarkovChain.transition_probability_matrix(dataMatrix, self.mode, condition)
            print('transition')
            print(transitionProbabilityMatrix)

            markovChain = MarkovChain.markov_chain(stateVector, transitionProbabilityMatrix, iterations)

            monteCarlo = MonteCarlo.monte_carlo(stateVector, transitionProbabilityMatrix, iterations, timeSteps)
            # print('monte')
            # print(monteCarlo)

            monteCarloBounds = MonteCarlo.mh.min_max_mean(monteCarlo, mode=self.mode)

            x = ((dindex, dindex, data.index), (markovChain.T.index,))
            y = ((monteCarloBounds, monteCarlo, data), (markovChain.T,))
            make_tabbed_plot(
                MARKOV_CHAIN_GRAPH, X=x, Y=y, titles=('Monte Carlo', 'Markov Chain'),
                xLabels=(index if self.mode == 'series' else 'Time Step', 'Iteration'),
                yLabels=(column, 'Transition Probability'), lineWidths=((3, 0.1, 1), (3,)),
                legends=((True, False, True), (True,)), types=(('line', 'line', 'scatter'), ('line',)),
                xKeys=(xKeys, None), yKeys=(yKeys, None)
            )
            self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)

    def graph_raw(self):
        try:
            index = self.indexCombo.currentText()
            column = self.columnCombo.currentText()
            dir = self.readLabel.text()
            if self.validate(dir, index, column):
                data, xKeys, yKeys = dh.process_data(dir, index, column, self.mode)
                data = pd.DataFrame(data, columns=(column,), index=data.index)
                x = ((data.index,),)
                y = ((data,),)
                make_tabbed_plot(
                    REGRESSOR_GRAPH, X=x, Y=y, titles=('Raw Data',),
                    xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                    lineWidths=((1,),), legends=((True,),), types=(('scatter',),), xKeys=(xKeys,),
                    yKeys=(yKeys,)
                )
                self.siteContainer = load_browser(self.siteContainer, REGRESSOR_GRAPH)
        except Exception as e:
            print(e)

    def validate(self, dir, index, column):
        error = False
        if self.seriesRadio.isChecked():
            self.mode = 'series'
        elif self.parallelRadio.isChecked():
            self.mode = 'parallel'

        if self.mcRadio.isChecked():
            self.sampler = 'mc'
        elif self.lhsRadio.isChecked():
            self.sampler = 'lhs'

        if dir == '':
            QMessageBox.critical(self, "No Directory", "Specify a directory.", QMessageBox.Ok)
            error = True
        return not error


class MarkovChainMenu:
    def __init__(self, GUI, parent, MASTERPATH):
        top = self.top = Toplevel(parent)
        self.parent = parent
        self.top.title("Markov Chain Monte Carlo")
        self.settings = [True, False]
        self.MASTERPATH = MASTERPATH
        self.figure = 1
        self.GUI = GUI
        self.paths = 1

        self.GUI.listGenerator.setNonNoneValueList()

        # Create a Tkinter variable
        self.item_of_interest = StringVar(self.top)
        self.initial_state = StringVar(self.top)

        # Dictionary with options
        self.valid_item_of_iterest_names = self.GUI.listGenerator.getNonNoneName()
        self.valid_item_of_iterest_numbers = self.GUI.listGenerator.getNonNoneNumber()
        self.item_of_interest.set('5A')  # set the default option
        self.initial_state.set('None')

        # Loading user preferences
        if True:
            with open(MASTERPATH + "\BridgeDataQuery\\Utilities14\Report_Preferences.txt", "r") as report_preferences:
                index = 0
                for line in report_preferences:
                    if line.strip() == 'True':
                        self.settings[index] = True
                    elif line.strip() == 'False':
                        self.settings[index] = False
                    index = 1

        # FILE PATHS
        label1 = Label(top, text="Input File Paths:")
        label1.grid(row=1, column=1, sticky=W)

        self.input_file_paths = Entry(top, width=30)
        self.input_file_paths.grid(row=1, column=3, columnspan=2)

        # PATH SELECTION BUTTON
        self.path_selection = Button(top, compound=LEFT, text="Open", command=self.load, cursor='hand2')
        self.path_selection.grid(row=1, column=5, columnspan=2)

        # ITEM OF INTEREST
        label2 = Label(top, text="Item of Interest:")
        label2.grid(row=self.paths + 1, column=1, sticky=W)

        popupMenu1 = OptionMenu(
            self.top, self.item_of_interest, *self.valid_item_of_iterest_numbers,
            command=self.itemSelection
        )
        popupMenu1.grid(row=self.paths + 1, column=2, columnspan=3, sticky=W + E)

        # INITIAL STATE
        label3 = Label(top, text="Initial State:")
        label3.grid(row=self.paths + 2, column=1, sticky=W)
        self.itemSelection('5A')

        # ITERATIONS
        label3 = Label(top, text="Iterations:")
        label3.grid(row=self.paths + 3, column=1, sticky=W)

        self.iterations = Entry(top, width=30)
        self.iterations.grid(row=self.paths + 3, column=3, columnspan=2)

        # SEPARATOR
        separator = ttk.Separator(top, orient=HORIZONTAL)
        separator.grid(row=self.paths + 5, column=1, columnspan=4, sticky=W + E)

        run_button = Button(top, text="Run", command=self.run, cursor='hand2')
        run_button.grid(row=self.paths + 6, column=4, sticky=E)

        cancel_button = Button(top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=self.paths + 6, column=5, sticky=E)

        self.top.grab_set()


class MasterPath:
    def __init__(self):
        self.MASTERPATH = str("C:\\Users\\clozo_000\PycharmProjects")

    def getMasterPath(self):
        return self.MASTERPATH


# TODO create a tabbed menu for class,clust,regress,dim red
class RegressionMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.advancedOptionsMenu = RegressionAdvancedOptionsMenu(self, 'Regression0 Advanced Options', REGRESSION_ICON)

        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)

        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=7, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=7,
            column=2, description=PARALLEL_DESCRIPTION
        )

        modeGroup.addButton(self.seriesRadio)
        modeGroup.addButton(self.parallelRadio)
        self.seriesRadio.setChecked(True)
        self.parallelRadio.setChecked(False)
        self.mode = 'series'

        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=8, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=8, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=9, column=0,
            description=RUN_REGRESSION_DESCRIPTION
        )

        self.advancedOptionsButton = make_button(
            self, command=self.advancedOptionsMenu.show, text='Advanced Options',
            layout=self.topRightLayout, row=9, column=1, width=150
        )

        self.set_regressors()
        self.siteContainer = make_browser(layout=self.bottomLayout, file=REGRESSION_GRAPH)
        try:
            self.combos()
        except:
            pass

    def run(self):
        self.get_mode()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        if self.validate():
            models = self.get_models()
            data, xKeys, yKeys = dh.process_regression_data(dir, index, column, self.mode)
            results = Regressors.regression(models, x=data.index, y=data)
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.index, data.index),)
            y = ((results, data),)
            make_plot(
                REGRESSION_GRAPH, X=x, Y=y, titles=('Regression0',),
                xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                lineWidths=((1, 1),), legends=((True, True),), types=(('line', 'scatter'),), xKeys=(xKeys,),
                yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)

    def get_checks(self):
        checks = {
            'Adaptive Boost':              self.aBCheck.isChecked(), 'Decision Tree': self.dTreeCheck.isChecked(),
            'Elastic Net':                 self.eNCheck.isChecked(), 'Gaussian Process': self.gProcessCheck.isChecked(),
            'Nearest Neighbors':           self.kNNCheck.isChecked(), 'Kernel Ridge': self.kRidgeCheck.isChecked(),
            'Multilayer Perceptron':       self.mlpCheck.isChecked(), 'Random Forest': self.rForestCheck.isChecked(),
            'Stochastic Gradient Descent': self.sGDradientCheck.isChecked(),
            'Support Vector Machine':      self.svmCheck.isChecked(),
        }
        return checks

    def get_mode(self):
        if self.seriesRadio.isChecked():
            self.mode = 'series'
        elif self.parallelRadio.isChecked():
            self.mode = 'parallel'

    def get_models(self):
        checks = self.get_checks()
        if self.automaticCheck.isChecked():
            models = Regressors.cross_validation_regression_models(checks)
        else:
            options = self.advancedOptionsMenu.get_options()
            models = Regressors.regression_models(checks, options)
        return models

    def validate(self):
        error = False
        if any(check.isChecked() for check in self.regressorChecks):
            pass
        else:
            QMessageBox.critical(self, 'No Model', 'Select a model.', QMessageBox.Ok)
            error = True

        if self.mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
                error = True

        if error == False:
            return True
        else:
            return False

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        """TOP LEFT"""
        # FILES TO READ
        self.readLabel = QtWidgets.QLabel('')
        openFolderIcon = QtGui.QIcon(OPEN_FOLDER_ICON)
        self.readButton = QtWidgets.QPushButton(openFolderIcon, '', self)
        self.readButton.setStyleSheet(BUTTON_STYLE)
        self.readButton.setIconSize(QtCore.QSize(20, 20))
        menu.set_widget_size(self.readButton, 5, 20)
        self.readButton.clicked.connect(lambda: menu.open_files(self, multiple=True, label=self.readLabel))
        self.topLeftLayout.addWidget(self.readButton, 0, 0)
        self.topLeftLayout.addWidget(self.readLabel, 0, 1)

        # FILE TO SAVE
        self.saveLabel = QtWidgets.QLabel('')
        saveFileIcon = QtGui.QIcon(SAVE_FILE_ICON)
        self.saveButton = QtWidgets.QPushButton(saveFileIcon, '', self)
        self.saveButton.setStyleSheet(BUTTON_STYLE)
        self.saveButton.setIconSize(QtCore.QSize(20, 20))
        menu.set_widget_size(self.saveButton, 5, 20)
        self.saveButton.clicked.connect(lambda: menu.save_file(self, label=self.saveLabel))
        self.topLeftLayout.addWidget(self.saveButton, 1, 0)
        self.topLeftLayout.addWidget(self.saveLabel, 1, 1)

        """TOP RIGHT"""
        # RUN BUTTON
        self.runButton = make_button(self, lambda: menu.save_file(self), 'Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.advancedOptionsMenu = RegressionAdvancedOptionsMenu(self, 'Regression6 Advanced Options', REGRESSION_ICON)

        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)

        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=7, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=7,
            column=2, description=PARALLEL_DESCRIPTION
        )

        modeGroup.addButton(self.seriesRadio)
        modeGroup.addButton(self.parallelRadio)
        self.seriesRadio.setChecked(True)
        self.parallelRadio.setChecked(False)
        self.mode = 'series'

        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=8, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=8, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=9,
            column=0, description=RUN_REGRESSION_DESCRIPTION
        )

        self.advancedOptionsButton = make_button(
            self, command=lambda: self.advancedOptionsMenu.show(),
            text='Advanced Options', layout=self.topRightLayout, row=9, column=1,
            width=150
        )

        self.set_regressors()
        self.siteContainer = make_browser(layout=self.bottomLayout, file=REGRESSION_GRAPH)
        try:
            self.combos()
        except:
            pass

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.advancedOptionsMenu = RegressionAdvancedOptionsMenu(self, 'Regression6 Advanced Options', REGRESSION_ICON)

        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)

        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=7, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=7,
            column=2, description=PARALLEL_DESCRIPTION
        )

        modeGroup.addButton(self.seriesRadio)
        modeGroup.addButton(self.parallelRadio)
        self.seriesRadio.setChecked(True)
        self.parallelRadio.setChecked(False)
        self.mode = 'series'

        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=8, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=8, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=9, column=0,
            description=RUN_REGRESSION_DESCRIPTION
        )

        self.advancedOptionsButton = make_button(
            self, command=self.advancedOptionsMenu.show, text='Advanced Options',
            layout=self.topRightLayout, row=9, column=1, width=150
        )

        self.set_regressors()
        self.siteContainer = make_browser(layout=self.bottomLayout, file=REGRESSION_GRAPH)
        try:
            self.combos()
        except:
            pass

    def set_regressors(self):
        layout = self.topRightLayout
        # Left Column
        _, self.aBCheck = make_pair(
            self, pair='check', text='Adaptive Boost:', layout=layout, row=1, column=0,
            description=AB_DESCRIPTION
        )
        _, self.dTreeCheck = make_pair(
            self, pair='check', text='Decision Tree:', layout=layout, row=2, column=0,
            description=D_TREE_DESCRIPTION
        )
        _, self.eNCheck = make_pair(
            self, pair='check', text='Elastic Net:', layout=layout, row=3, column=0,
            description=E_NET_DESCRIPTION
        )
        _, self.gProcessCheck = make_pair(
            self, pair='check', text='Gaussian Process:', layout=layout, row=4, column=0,
            description=''
        )
        _, self.kNNCheck = make_pair(
            self, pair='check', text='Nearest Neighbors:', layout=layout, row=5, column=0,
            description=K_NEIGHBORS_DESCRIPTION
        )
        # Right Column
        _, self.kRidgeCheck = make_pair(
            self, pair='check', text='Kernel Ridge:', layout=layout, row=1, column=2,
            description=K_RIDGE_DESCRIPTION
        )
        _, self.mlpCheck = make_pair(
            self, pair='check', text='Multilayer Perceptron:', layout=layout, row=2, column=2,
            description=MLP_DESCRIPTION
        )
        _, self.rForestCheck = make_pair(
            self, pair='check', text='Random Forest:', layout=layout, row=3, column=2,
            description=R_FOREST_DESCRIPTION
        )
        _, self.sGDradientCheck = make_pair(
            self, pair='check', text='Stochastic Gradient Descent:', layout=layout,
            row=4, column=2, description=SGD_DESCRIPTION
        )
        _, self.svmCheck = make_pair(
            self, pair='check', text='Support Vector Machine:', layout=layout, row=5, column=2,
            description=SVM_DESCRIPTION
        )
        _, self.automaticCheck = make_pair(
            self, pair='check', text='Auto-Tune:', layout=layout, row=6, column=0,
            description=AUTOMATIC_TUNING_DESCRIPTION
        )
        self.regressorChecks = [self.aBCheck, self.dTreeCheck, self.eNCheck, self.gProcessCheck, self.kNNCheck,
                                self.kRidgeCheck, self.mlpCheck, self.rForestCheck, self.sGDradientCheck, self.svmCheck]

    def combos(self):
        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        self.indexCombo = make_combo(
            self, [''] + self.headers, command=self.update_columns, layout=self.topRightLayout,
            row=8, column=1, width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            self, self.headers, command=self.graph_raw, layout=self.topRightLayout, row=8,
            column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )
        self.graph_raw()

    def graph_raw(self):
        self.get_mode()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        data, xKeys, yKeys = dh.process_regression_data(dir, index, column, self.mode)
        data = pd.DataFrame(data, columns=(column,), index=data.index)
        x = ((data.index,),)
        y = ((data,),)
        make_plot(
            REGRESSION_GRAPH, X=x, Y=y, titles=('Raw Data',),
            xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
            legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
        )
        self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)

    def run(self):
        self.get_mode()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        if self.validate():
            models = self.get_models()
            data, xKeys, yKeys = dh.process_regression_data(dir, index, column, self.mode)
            results = Regressors.regression(models, x=data.index, y=data)
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            x = ((data.index, data.index),)
            y = ((results, data),)
            make_plot(
                REGRESSION_GRAPH, X=x, Y=y, titles=('Regression6',),
                xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,),
                lineWidths=((1, 1),), legends=((True, True),), types=(('line', 'scatter'),), xKeys=(xKeys,),
                yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, REGRESSION_GRAPH)


# TODO write descriptions for ab, en, gp, sgd options
class RegressionAdvancedOptionsMenu(SubMenu):
    def rewindow(self):
        self.regressionTab = make_tab(self, text='Regression6', master=self.tabs)
        self.set_regression_tab()
        self.setLayout(self.hbox)

    def set_regression_tab(self):
        self.modelSelection = make_list(
            items=REGRESSORS_NAMES, command=self.set_regression_layout,
            layout=self.regressionTab, row=0, column=0, width=200
        )

        self.scrollArea = make_scroll_area(self.regressionLayouts['Adaptive Boost'], width=275)
        self.regressionTab.addWidget(self.scrollArea, 0, 1)

    def set_regression_layout(self):
        self.regressionTab.removeWidget(self.scrollArea)
        self.scrollArea = make_scroll_area(self.regressionLayouts[self.modelSelection.currentItem().text()], width=275)
        self.regressionTab.addWidget(self.scrollArea, 0, 1)

    def set_ab_regressor(self):
        layout = self.regressionLayouts['Adaptive Boost']
        _, self.ABestimatorsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Estimators:',
            layout=layout, row=1, column=0, description=''
        )

        _, self.ABlearningRateDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 10, 1), text='Learning Rate:',
            layout=layout, row=2, column=0, description=''
        )

        _, self.ABlossCombo = make_pair(
            self, pair='combo', comboItems=('linear', 'square', 'exponential'),
            text='Loss:', layout=layout, row=3, column=0, pairWidth=100, description=''
        )

        _, self.ABrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=4, column=0,
            labelWidth=125, pairWidth=50, description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

    def set_dt_regressor(self):
        layout = self.regressionLayouts['Decision Tree']
        _, self.DTcriterionCombo = make_pair(
            self, pair='combo', comboItems=('mse', 'friedman_mse', 'mae'),
            text='Criterion:', layout=layout, row=1, column=0, labelWidth=200,
            pairWidth=100, description=CRITERION_DESCRIPTION
        )

        _, self.DTmaxDepthDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=2, column=0, labelWidth=125,
            description=MAX_DEPTH_DESCRIPTION
        )

        _, self.DTmaxFeaturesCombo = make_pair(
            self, pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=3, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Maximum Leaf Nodes:', layout=layout, row=4, column=0,
            labelWidth=200, description=MAX_LEAF_NODES_DESCRIPTION
        )

        _, self.DTmaxLeafNodesDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Maximum Leaf Nodes:', layout=layout, row=4, column=0,
            labelWidth=200, description=MAX_LEAF_NODES_DESCRIPTION
        )

        # self.DTminImpurityDecreaseLabel = make_label(self, text='Minimum Impurity Decrease:', layout=self.dtTab,
        #                                             row=30, column=0, width=200,
        #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)
        # self.DTminImpurityDecreaseDial = make_dial(self, layout=self.dtTab,
        #                                             row=30, column=1, width=50,
        #                                             description=MIN_IMPURITY_DECREASE_DESCRIPTION)

        _, self.DTminSamplesLeafDial = make_pair(
            self, pair='dial', dialSettings=(1, 4, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=6, column=0,
            labelWidth=200, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )

        _, self.DTminSamplesSplitDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=7, column=0,
            labelWidth=150, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )

        _, self.DTminWeightFractionLeafDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=8,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )

        _, self.DTpresortCheck = make_pair(
            self, pair='check', text='Presort Data:', layout=layout, row=9, column=0,
            labelWidth=200, description=PRESORT_DESCRIPTION
        )

        _, self.DTrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=10,
            column=0, labelWidth=125, pairWidth=50,
            description=RANDOM_STATE_DESCRIPTION
        )

        _, self.DTsplitterCombo = make_pair(
            self, pair='combo', comboItems=('best', 'random'), text='Splitter:',
            layout=layout, row=11, column=0, pairWidth=75,
            description=SPLITTER_DESCRIPTION
        )

    def set_en_regressor(self):
        layout = self.regressionLayouts['Elastic Net']
        _, self.ENalphaDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
            row=1, column=0, description=''
        )

        # self.ENfitInterceptLabel = make_label(self, text='Fit Intercept:', layout=self.layouts['Elastic Net'],
        #                                      row=1, column=0,
        #                                      description='')
        # self.ENfitInterceptCheck = make_button(self, type='check', layout=self.layouts['Elastic Net'],
        #                                       row=1, column=1,
        #                                       description='')

        _, self.ENl1RatioDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:',
            layout=layout, row=2, column=0, description=''
        )

        _, self.ENnormalizeCheck = make_pair(
            self, pair='check', text='Normalize:', layout=layout, row=3, column=0,
            description=''
        )

        _, self.ENpositiveCheck = make_pair(
            self, pair='check', text='Positive:', layout=layout, row=4, column=0,
            description=''
        )

        _, self.ENselectionCombo = make_pair(
            self, pair='combo', comboItems=('cyclic', 'random'), text='Selection:',
            layout=layout, row=5, column=0, description=''
        )

        _, self.ENtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:', layout=layout,
            row=6, column=0, description=''
        )

        _, self.ENwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=7, column=0,
            description=''
        )

    def set_gp_regressor(self):
        layout = self.regressionLayouts['Gaussian Process']
        _, self.GPalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Alpha:', layout=layout,
            row=1, column=0, description=''
        )

        _, self.GPnormalizeCheck = make_pair(
            self, pair='check', text='Normalize:', layout=layout, row=2, column=0,
            description=''
        )

        _, self.ABrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=3, column=0,
            labelWidth=125, pairWidth=50, description=''
        )

    def set_knn_regressor(self):
        layout = self.regressionLayouts['Nearest Neighbors']
        _, self.KNNalgorithmCombo = make_pair(
            self, pair='combo', comboItems=('auto', 'ball_tree', 'kd_tree', 'brute'),
            text='Algorithm:', layout=layout, row=1, column=0, pairWidth=100,
            description=ALGORITHM_DESCRIPTION
        )

        # self.nJobsLabel = make_label(self, text='CPU Cores:', layout=self.bottomLayout, row=19, column=0, width=200)
        # self.nJobsCombo = make_combo(self, range(1,12), layout=self.bottomLayout, row=19, column=1, width=50)

        _, self.KNNleafSizeDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 30, 1), text='Leaf Size:',
            layout=layout, row=2, column=0, description=LEAF_SIZE_DESCRIPTION
        )

        # self.metricLabel = make_label(self, text='Distance Metric:', layout=self.bottomLayout, row=17, column=0, width=200)
        # self.metricCombo = make_combo(self,(), layout=self.bottomLayout, row=17, column=1, width=100)

        # self.metricParamsLabel = make_label(self, text='Metric:', layout=self.bottomLayout, row=18, column=0)
        # self.metricParamsCombo = make_combo(self, (), layout=self.bottomLayout, row=18, column=1, width=100)

        _, self.KNNminkowskiPowerDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 2, 1),
            text='Minkowski Power:', layout=layout, row=3, column=0,
            description=P_DESCRIPTION
        )

        _, self.KNNneighborsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 5, 1),
            text='Number of Neighbors:', layout=layout, row=4, column=0,
            labelWidth=200, description=N_NEIGHBORS_DESCRIPTION
        )

        _, self.KNNweightsCombo = make_pair(
            self, pair='combo', comboItems=('uniform', 'distance'),
            text='Weights Function:', layout=layout, row=5, column=0, labelWidth=200,
            pairWidth=100, description=WEIGHTS_DESCRIPTION
        )

    def set_kr_regressor(self):
        layout = self.regressionLayouts['Kernel Ridge']
        _, self.KRalphaDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
            row=1, column=0, description=ALPHA_DESCRIPTION
        )
        _, self.KRcoef0Dial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 10, 1), text='Coefficient 0:',
            layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
        )

        _, self.KRdegreeCombo = make_pair(
            self, pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
            layout=layout, row=3, column=0, description=DEGREE_DESCRIPTION
        )

        _, self.KRgammaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
            row=4, column=0, description=GAMMA_DESCRIPTION
        )

        _, self.KRkernelCombo = make_pair(
            self, pair='combo', comboItems=('linear', 'poly', 'rbf'), text='Kernel:',
            layout=layout, row=5, column=0, description=KERNEL_DESCRIPTION
        )

    def set_mlp_regressor(self):
        layout = self.regressionLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            self, pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )

        _, self.MLPalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Alpha (Penalty Parameter):', layout=layout, row=2, column=0,
            labelWidth=200, description=MLP_ALPHA_DESCRIPTION
        )

        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)

        _, self.MLPbeta1Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )

        _, self.MLPbeta2Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )
        _, self.MLPearlyStoppingCheck = make_pair(
            self, pair='check', text='Early Stopping:', layout=layout, row=5,
            column=0, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )
        _, self.MLPepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )
        _, self.MLPhiddenLayerSizesEntry = make_pair(
            self, pair='entry', text='Hidden Layer Sizes:', layout=layout,
            row=7, column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )
        _, self.MLPinitLearningRateDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )
        _, self.MLPlearningRateCombo = make_pair(
            self, pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )
        _, self.MLPmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )
        _, self.MLPmomentumDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
            layout=layout, row=11, column=0, description=MOMENTUM_DESCRIPTION
        )
        _, self.MLPnesterovsMomentumCheck = make_pair(
            self, pair='check', text='Nesterov\'s Momentum:', layout=layout,
            row=12, column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )
        _, self.MLPpowerTDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )
        _, self.MLPrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=14,
            column=0, pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )
        _, self.MLPshuffleCheck = make_pair(
            self, pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )
        _, self.MLPsolverCombo = make_pair(
            self, pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )
        _, self.MLPtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=17, column=0, description=MLP_TOL_DESCRIPTION
        )
        _, self.MLPvalidationFractionDial = make_pair(
            self, pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )
        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)
        _, self.MLPwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def set_rf_regressor(self):
        layout = self.regressionLayouts['Random Forest']
        _, self.RFbootstrapCheck = make_pair(
            self, pair='check', text='Bootstrap:', layout=layout, row=1, column=0,
            description=BOOTSTRAP_DESCRIPTION
        )
        _, self.RFcriterionCombo = make_pair(
            self, pair='combo', comboItems=('mse', 'mae'), text='Criterion:',
            layout=layout, row=2, column=0, pairWidth=50,
            description=CRITERION_DESCRIPTION
        )
        _, self.RFmaxDepthDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1), text='Maximum Depth:',
            layout=layout, row=3, column=0, description=MAX_DEPTH_DESCRIPTION
        )
        _, self.RFmaxFeaturesCombo = make_pair(
            self, pair='combo', comboItems=('auto', 'sqrt', 'log2'),
            text='Maximum Features:', layout=layout, row=4, column=0, labelWidth=200,
            pairWidth=50, description=MAX_FEATURES_DESCRIPTION
        )
        _, self.RFmaxLeafNodesDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Maximum Leaf Nodes:', layout=layout, row=5, column=0,
            labelWidth=220, description=MAX_LEAF_NODES_DESCRIPTION
        )
        _, self.RFminImpurityDecreaseDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Impurity Decrease:', layout=layout, row=6, column=0,
            labelWidth=220, description=MIN_IMPURITY_DECREASE_DESCRIPTION
        )
        _, self.RFminSamplesLeafDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples at Leaf:', layout=layout, row=7, column=0,
            labelWidth=220, description=MIN_SAMPLES_LEAF_DESCRIPTION
        )
        _, self.RFminSamplesSplitDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Minimum Samples Split:', layout=layout, row=8, column=0,
            labelWidth=175, description=MIN_SAMPLES_SPLIT_DESCRIPTION
        )
        _, self.RFminWeightFractionLeafDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1),
            text='Minimum Sum Weighted Fraction:', layout=layout, row=9,
            column=0, labelWidth=220,
            description=MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION
        )
        _, self.RFestimatorsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 10, 1), text='Number of Trees:',
            layout=layout, row=10, column=0, labelWidth=200,
            description=N_ESTIMATORS_DESCRIPTION
        )
        _, self.RFoobScoreCheck = make_pair(
            self, pair='check', text='Out-of-Bag Samples:', layout=layout, row=11,
            column=0, labelWidth=200, description=OOB_SCORE_DESCRIPTION
        )
        # self.RFnJobsLabel = make_label(self, text='CPU Cores:', layout=self.layouts['Random Forest'], row=44, column=0, width=200)
        # self.RFnJobsDial = make_dial(self, layout=self.layouts['Random Forest'], row=44, column=1, width=50)
        # self.RFverboseLabel = make_label(self, text='Verbosity of Tree:', layout=self.layouts['Random Forest'], row=46, column=0, width=200)
        # self.RFverboseDial = make_dial(self, layout=self.layouts['Random Forest'], row=46, column=1, width=50)
        _, self.RFrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=12,
            column=0, pairWidth=50, description=RANDOM_STATE_DESCRIPTION
        )
        _, self.RFwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=13, column=0,
            labelWidth=200, description=WARM_START_DESCRIPTION
        )

    def set_sgd_regressor(self):
        layout = self.regressionLayouts['Stochastic Gradient Descent']
        _, self.SGDalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1), text='Alpha:', layout=layout,
            row=1, column=0, description=''
        )
        _, self.SGDaverageCheck = make_pair(
            self, pair='check', text='Average:', layout=layout, row=2, column=0,
            description=''
        )
        _, self.SGDeta0Dial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1), text='Eta 0:', layout=layout,
            row=3, column=0, description=''
        )
        _, self.SGDfitInterceptCheck = make_pair(
            self, pair='check', text='Fit Intercept:', layout=layout, row=4,
            column=0, description=''
        )
        _, self.SGDlearningRateCombo = make_pair(
            self, pair='combo', comboItems=('constant', 'optimal', 'invscaling'),
            text='Learning Rate:', layout=layout, row=5, column=0, pairWidth=100,
            description=''
        )
        _, self.SGDlossCombo = make_pair(
            self, pair='combo', comboItems=(
                'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'), text='Loss:',
            layout=layout,
            row=6, column=0, pairWidth=100, description=''
        )
        _, self.SGDl1RatioDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 5, 1), text='L1 Ratio:',
            layout=layout, row=7, column=0, description=''
        )
        _, self.SGDmaxIterationsDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=8, column=0,
            description=''
        )
        _, self.SGDpenaltyCombo = make_pair(
            self, pair='combo', comboItems=('none', 'l1', 'l2', 'elasticnet'),
            text='Penalty:', layout=layout, row=9, column=0, pairWidth=100,
            description=''
        )
        _, self.SGDpowerTDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 2, 1), text='Power T:', layout=layout,
            row=10, column=0, description=''
        )
        _, self.SGDshuffleCheck = make_pair(
            self, pair='check', text='Shuffle:', layout=layout, row=11, column=0,
            description=''
        )
        _, self.SGDtolDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 50, 1), text='Tolerance:',
            layout=layout, row=12, column=0, description=''
        )
        _, self.SGDwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=13, column=0,
            description=''
        )

    def set_svm_regressor(self):
        layout = self.regressionLayouts['Support Vector Machine']
        _, self.SVMCDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
            column=0, description=C_DESCRIPTION
        )

        # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=0,
        #                                    description=CACHE_SIZE_DESCRIPTION)
        # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
        #                                    row=5, column=1, width=50,
        #                                    description=CACHE_SIZE_DESCRIPTION)

        _, self.SVMcoef0Dial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
            layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
        )

        _, self.SVMdegreeCombo = make_pair(
            self, pair='combo', comboItems=('1', '2', '3', '5'), text='Degree:',
            layout=layout, row=3, column=0, pairWidth=100,
            description=DEGREE_DESCRIPTION
        )

        _, self.SVMepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:',
            layout=layout, row=4, column=0, description=EPSILON_DESCRIPTION
        )

        _, self.SVMgammaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
            row=5, column=0, description=GAMMA_DESCRIPTION
        )

        _, self.SVMkernelCombo = make_pair(
            self, pair='combo',
            comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
            text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
            description=KERNEL_DESCRIPTION
        )

        _, self.SVMmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=7, column=0, labelWidth=200,
            description=MAX_ITER_DESCRIPTION
        )

        _, self.SVMshrinkingCheck = make_pair(
            self, pair='check', text='Shrinking:', layout=layout, row=8, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=9, column=0, description=TOL_DESCRIPTION
        )

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, opensave=False, tabbed=True)
        self.setFixedSize(500, 300)
        self.regressionLayouts = {
            'Adaptive Boost':              make_grid(self), 'Decision Tree': make_grid(self),
            'Elastic Net':                 make_grid(self), 'Gaussian Process': make_grid(self),
            'Nearest Neighbors':           make_grid(self), 'Kernel Ridge': make_grid(self),
            'Multilayer Perceptron':       make_grid(self), 'Random Forest': make_grid(self),
            'Stochastic Gradient Descent': make_grid(self),
            'Support Vector Machine':      make_grid(self)
        }
        self.set_ab_regressor()
        self.set_dt_regressor()
        self.set_en_regressor()
        self.set_gp_regressor()
        self.set_knn_regressor()
        self.set_kr_regressor()
        self.set_mlp_regressor()
        self.set_rf_regressor()
        self.set_sgd_regressor()
        self.set_svm_regressor()
        self.rewindow()

    def get_options(self):
        options = {
            'abrEstimators':                    self.ABestimatorsDial.value(),
            'abrLearningRate':                  self.ABlearningRateDial.value() / 10.0,
            'abrLoss':                          self.ABlossCombo.currentText(),

            'dtrCriterion':                     self.DTcriterionCombo.currentText(),
            'dtrMaximumDepth':                  self.DTmaxDepthDial.value(),
            'dtrMaximumLeafNodes':              self.DTmaxLeafNodesDial.value(),
            'dtrMaximumFeatures':               self.DTmaxFeaturesCombo.currentText(),
            'dtrMinimumSamplesLeaf':            self.DTminSamplesLeafDial.value() / 10.0,
            'dtrMinimumSamplesSplit':           self.DTminSamplesSplitDial.value() / 10.0,
            'dtrMinimumWeightFractionLeaf':     self.DTminWeightFractionLeafDial.value() / 10.0,
            'dtrPresort':                       self.DTpresortCheck.isChecked(),
            'dtrRandomState':                   self.DTrandomStateEntry.text(),
            'dtrSplitter':                      self.DTsplitterCombo.currentText(),

            'enrAlpha':                         self.ENalphaDial.value() / 10.0,
            # 'enrFitIntercept': self.ENfitInterceptCheck.isChecked(),
            'enrL1Ratio':                       self.ENl1RatioDial.value() / 10.0,
            'enrNormalize':                     self.ENnormalizeCheck.isChecked(),
            'enrPositive':                      self.ENpositiveCheck.isChecked(),
            'enrSelection':                     self.ENselectionCombo.currentText(),
            'enrTolerance':                     self.ENtolDial.value() / 100.0,
            'enrWarmStart':                     self.ENwarmStartCheck.isChecked(),

            'gprAlpha':                         self.GPalphaDial.value() / 100.0,
            # 'gprKernel': self.GPkernelCombo.currentText(),
            'gprNormalize':                     self.GPnormalizeCheck.isChecked(),
            # 'gprOptimizer': self.GPoptimizerCombo.currentText(),

            'knnrAlgorithm':                    self.KNNalgorithmCombo.currentText(),
            'knnrLeafSize':                     self.KNNleafSizeDial.value(),
            'knnrMinkowskiPower':               self.KNNminkowskiPowerDial.value(),
            'knnrNumberOfNeighbors':            self.KNNneighborsDial.value(),
            'knnrWeightsFunction':              self.KNNweightsCombo.currentText(),

            'krrAlpha':                         self.KRalphaDial.value() / 10.0,
            'krrCoefficient0':                  self.KRcoef0Dial.value() / 10.0,
            'krrGamma':                         self.KRgammaDial.value() / 10.0,
            'krrKernel':                        self.KRkernelCombo.currentText(),
            'krrPolynomialDegree':              self.KRdegreeCombo.currentText(),

            'mlprActivationFunction':           self.MLPactivationCombo.currentText(),
            # 'mlprBatchSize': dh.nonize(self.MLPbatchSizeDial.value()),
            'mlprEarlyStopping':                self.MLPearlyStoppingCheck.isChecked(),
            'mlprFirstMomentExponentialDecay':  self.MLPbeta1Dial.value() / 100.0,
            'mlprHiddenLayerSizes':             self.MLPhiddenLayerSizesEntry.text(),
            'mlprInitialLearningRate':          self.MLPinitLearningRateDial.value() / 10.0,
            'mlprLearningRate':                 self.MLPlearningRateCombo.currentText(),
            'mlprMaximumIterations':            self.MLPmaxIterDial.value(),
            'mlprMomentum':                     self.MLPmomentumDial.value() / 10.0,
            'mlprNesterovsMomentum':            self.MLPnesterovsMomentumCheck.isChecked(),
            'mlprNumericalStability':           self.MLPepsilonDial.value() / 100.0,
            'mlprPenaltyParameter':             self.MLPalphaDial.value() / 100000.0,
            'mlprPowerForInverseLearningRate':  self.MLPpowerTDial.value() / 10.0,
            'mlprRandomState':                  self.MLPrandomStateEntry.text(),
            'mlprShuffle':                      self.MLPshuffleCheck.isChecked(),
            'mlprSecondMomentExponentialDecay': self.MLPbeta2Dial.value() / 100.0,
            'mlprTolerance':                    self.MLPtolDial.value() / 100.0,
            'mlprValidationFraction':           self.MLPvalidationFractionDial.value() / 10.0,
            'mlprWarmStart':                    self.MLPwarmStartCheck.isChecked(),
            'mlprWeightOptimizationSolver':     self.MLPsolverCombo.currentText(),

            'rfrBootstrap':                     self.RFbootstrapCheck.isChecked(),
            'rfrCriterion':                     self.RFcriterionCombo.currentText(),
            'rfrMaximumDepth':                  self.RFmaxDepthDial.value(),
            'rfrMaximumFeatures':               self.RFmaxFeaturesCombo.currentText(),
            'rfrMaximumLeafNodes':              self.RFmaxLeafNodesDial.value(),
            'rfrMinimumImpurityDecrease':       self.RFminImpurityDecreaseDial.value() / 10.0,
            'rfrMinimumSamplesAtLeaf':          self.RFminSamplesLeafDial.value() / 10.0,
            'rfrMinimumSamplesSplit':           self.RFminSamplesSplitDial.value() / 10.0,
            'rfrMinimumSumWeightedFraction':    self.RFminWeightFractionLeafDial.value() / 10.0,
            'rfrNumberOfTrees':                 self.RFestimatorsDial.value(),
            'rfrOutOfBagSamples':               self.RFoobScoreCheck.isChecked(),
            'rfrRandomState':                   self.RFrandomStateEntry.text(),
            'rfrWarmStart':                     self.RFwarmStartCheck.isChecked(),

            'sgdrAlpha':                        self.SGDalphaDial.value() / 100000,
            'sgdrAverage':                      self.SGDaverageCheck.isChecked(),
            'sgdrEta0':                         self.SGDeta0Dial.value() / 10.0,
            'sgdrFitIntercept':                 self.SGDfitInterceptCheck.isChecked(),
            'sgdrLearningRate':                 self.SGDlearningRateCombo.currentText(),
            'sgdrLoss':                         self.SGDlossCombo.currentText(),
            'sgdrL1Ratio':                      self.SGDl1RatioDial.value() / 10.0,
            'sgdrMaxIterations':                self.SGDmaxIterationsDial.value(),
            'sgdrPenalty':                      self.SGDpenaltyCombo.currentText(),
            'sgdrPowerT':                       self.SGDpowerTDial.value() / 10.0,
            'sgdrShuffle':                      self.SGDshuffleCheck.isChecked(),
            'sgdrTolerance':                    self.SGDtolDial.value() / 100.0,
            'sgdrWarmStart':                    self.SGDwarmStartCheck.isChecked(),

            'svmrC':                            dh.nonize(self.SVMCDial.value()),
            # 'svmrCacheSize': self.SVMcacheSizeDial.value(),
            'svmrCoefficient0':                 self.SVMcoef0Dial.value() / 10.0,
            'svmrEpsilon':                      self.SVMepsilonDial.value() / 10.0,
            'svmrGamma':                        self.SVMgammaDial.value(),
            'svmrKernel':                       self.SVMkernelCombo.currentText(),
            'svmrMaximumIterations':            self.SVMmaxIterDial.value(),
            'svmrPolynomialDegree':             self.SVMdegreeCombo.currentText(),
            'svmrShrinking':                    self.SVMshrinkingCheck.isChecked(),
            'svmrTolerance':                    self.SVMtolDial.value() / 100.0,
        }

        return options

    def rewindow(self):
        self.regressionTab = make_tab(self, text='Regression0', master=self.tabs)
        self.set_regression_tab()
        self.setLayout(self.hbox)

    def set_kr_regressor(self):
        layout = self.regressionLayouts['Kernel Ridge']
        _, self.KRalphaDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 10, 1), text='Alpha:', layout=layout,
            row=1, column=0, description=ALPHA_DESCRIPTION
        )
        _, self.KRcoef0Dial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 10, 1), text='Coefficient 0:',
            layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
        )

        _, self.KRdegreeCombo = make_pair(
            self, pair='combo', comboItems=('2', '3', '4', '5'), text='Degree:',
            layout=layout, row=3, column=0, description=DEGREE_DESCRIPTION
        )

        _, self.KRgammaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
            row=4, column=0, description=GAMMA_DESCRIPTION
        )

        _, self.KRkernelCombo = make_pair(
            self, pair='combo', comboItems=('linear', 'poly', 'rbf'), text='Kernel:',
            layout=layout, row=5, column=0, description=KERNEL_DESCRIPTION
        )

    def set_mlp_regressor(self):
        layout = self.regressionLayouts['Multilayer Perceptron']
        _, self.MLPactivationCombo = make_pair(
            self, pair='combo', comboItems=('identity', 'logistic', 'tanh', 'relu'),
            text='Activation Function:', layout=layout, row=1, column=0,
            labelWidth=200, pairWidth=100, description=ACTIVATION_DESCRIPTION
        )

        _, self.MLPalphaDial = make_pair(
            self, pair='dial', dialSettings=(0, 100, 0, 1),
            text='Alpha (Penalty Parameter):', layout=layout, row=2, column=0,
            labelWidth=200, description=MLP_ALPHA_DESCRIPTION
        )

        # self.MLPbatchSizeLabel = make_label(self, text='Batch Size:', layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=0, width=200,
        #                                    description=BATCH_SIZE_DESCRIPTION)
        # self.MLPbatchSizeDial = make_dial(self, layout=self.layouts['Multilayer Perceptron'],
        #                                    row=5, column=1, width=50,
        #                                    description=BATCH_SIZE_DESCRIPTION)

        _, self.MLPbeta1Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 1 (First Moment Exponential Decay):', layout=layout, row=3,
            column=0, labelWidth=250, description=BETA_1_DESCRIPTION
        )

        _, self.MLPbeta2Dial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 99, 1),
            text='Beta 2 (Second Moment Exponential Decay):', layout=layout, row=4,
            column=0, labelWidth=250, description=BETA_2_DESCRIPTION
        )

        _, self.MLPearlyStoppingCheck = make_pair(
            self, pair='check', text='Early Stopping:', layout=layout, row=5,
            column=0, labelWidth=200, description=EARLY_STOPPING_DESCRIPTION
        )

        _, self.MLPepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Epsilon (Numerical Stability):', layout=layout, row=6, column=0,
            labelWidth=200, description=MLP_EPSILON_DESCRIPTION
        )

        _, self.MLPhiddenLayerSizesEntry = make_pair(
            self, pair='entry', text='Hidden Layer Sizes:', layout=layout,
            row=7, column=0, labelWidth=200, pairWidth=50,
            description=HIDDEN_LAYER_SIZES_DESCRIPTION
        )

        _, self.MLPinitLearningRateDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1),
            text='Initial Learning Rate:', layout=layout, row=8, column=0,
            labelWidth=200, description=LEARNING_RATE_INIT_DESCRIPTION
        )

        _, self.MLPlearningRateCombo = make_pair(
            self, pair='combo', comboItems=('constant', 'invscaling', 'adaptive'),
            text='Learning Rate:', layout=layout, row=9, column=0, labelWidth=200,
            pairWidth=100, description=LEARNING_RATE_DESCRIPTION
        )

        _, self.MLPmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=10, column=0, labelWidth=250,
            description=MLP_MAX_ITER_DESCRIPTION
        )

        _, self.MLPmomentumDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 9, 1), text='Momentum:',
            layout=layout, row=11, column=0, description=MOMENTUM_DESCRIPTION
        )

        _, self.MLPnesterovsMomentumCheck = make_pair(
            self, pair='check', text='Nesterov\'s Momentum:', layout=layout,
            row=12, column=0, labelWidth=200,
            description=NESTEROVS_MOMENTUM_DESCRIPTION
        )

        _, self.MLPpowerTDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 5, 1),
            text='Power for Inverse Learning Rate:', layout=layout, row=13, column=0,
            labelWidth=250, description=POWER_T_DESCRIPTION
        )

        _, self.MLPrandomStateEntry = make_pair(
            self, pair='entry', text='Random State:', layout=layout, row=14,
            column=0, pairWidth=50, description=MLP_RANDOM_STATE_DESCRIPTION
        )

        _, self.MLPshuffleCheck = make_pair(
            self, pair='check', text='Shuffle:', layout=layout, row=15, column=0,
            description=SHUFFLE_DESCRIPTION
        )

        _, self.MLPsolverCombo = make_pair(
            self, pair='combo', comboItems=('lbfgs', 'sgd', 'adam'),
            text='Solver (Weight Optimization):', layout=layout, row=16, column=0,
            labelWidth=200, pairWidth=100, description=SOLVER_DESCRIPTION
        )

        _, self.MLPtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=17, column=0, description=MLP_TOL_DESCRIPTION
        )

        _, self.MLPvalidationFractionDial = make_pair(
            self, pair='dial', dialSettings=(1, 9, 9, 1),
            text='Validation Fraction:', layout=layout, row=18, column=0,
            labelWidth=200, description=VALIDATION_FRACTION_DESCRIPTION
        )

        # self.MLPverboseLabel = make_label(self, text='Verbose:', layout=self.layouts['Multilayer Perceptron'], row=61, column=0)
        # self.MLPverboseCheck = make_button(self, type='check', layout=self.layouts['Multilayer Perceptron'], row=61, column=1)

        _, self.MLPwarmStartCheck = make_pair(
            self, pair='check', text='Warm Start:', layout=layout, row=19, column=0,
            labelWidth=200, description=MLP_WARM_START_DESCRIPTION
        )

    def set_svm_regressor(self):
        layout = self.regressionLayouts['Support Vector Machine']
        _, self.SVMCDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 1, 1), text='C:', layout=layout, row=1,
            column=0, description=C_DESCRIPTION
        )

        # self.SVMcacheSizeLabel = make_label(self, text='Cache Size:', layout=self.layouts['Support Vector Machine'],
        #                                    row=9, column=0,
        #                                    description=CACHE_SIZE_DESCRIPTION)
        # self.SVMcacheSizeDial = make_dial(self, layout=self.layouts['Support Vector Machine'],
        #                                    row=9, column=1, width=50,
        #                                    description=CACHE_SIZE_DESCRIPTION)

        _, self.SVMcoef0Dial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Coefficient 0:',
            layout=layout, row=2, column=0, description=COEF0_DESCRIPTION
        )

        _, self.SVMdegreeCombo = make_pair(
            self, pair='combo', comboItems=('2', '3', '4', '5'), text='Degree:',
            layout=layout, row=3, column=0, pairWidth=100,
            description=DEGREE_DESCRIPTION
        )

        _, self.SVMepsilonDial = make_pair(
            self, pair='dial', dialSettings=(1, 10, 1, 1), text='Epsilon:',
            layout=layout, row=4, column=0, description=EPSILON_DESCRIPTION
        )

        _, self.SVMgammaDial = make_pair(
            self, pair='dial', dialSettings=(0, 10, 0, 1), text='Gamma:', layout=layout,
            row=5, column=0, description=GAMMA_DESCRIPTION
        )

        _, self.SVMkernelCombo = make_pair(
            self, pair='combo',
            comboItems=('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'),
            text='Kernel:', layout=layout, row=6, column=0, pairWidth=100,
            description=KERNEL_DESCRIPTION
        )

        _, self.SVMmaxIterDial = make_pair(
            self, pair='dial', dialSettings=(1, 1000, 100, 1),
            text='Maximum Iterations:', layout=layout, row=7, column=0, labelWidth=200,
            description=MAX_ITER_DESCRIPTION
        )

        _, self.SVMshrinkingCheck = make_pair(
            self, pair='check', text='Shrinking:', layout=layout, row=8, column=0,
            description=SHRINKING_DESCRIPTION
        )

        _, self.SVMtolDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=layout, row=9, column=0, description=TOL_DESCRIPTION
        )


# TODO fix bug when using inequality/interval more than once in a single entry
# TODO results should save in the specified folder
# TODO table should update when database is changed
class SearchMenu(SubMenu):
    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, standard=False)
        top_left_splitter(
            self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON,
            updateFunction=self.rewindow
        )
        self.data = None
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        """TOP RIGHT"""
        _, self.txtCheck = make_pair(
            self, pair='check', text='txt:', layout=self.topRightLayout, row=1, column=0,
            description=TXT_EXPORT_DESCRIPTION
        )

        _, self.excelCheck = make_pair(
            self, pair='check', text='Excel:', layout=self.topRightLayout, row=1, column=2,
            description=EXCEL_EXPORT_DESCRIPTION
        )

        _, self.toleranceDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=self.topRightLayout, row=2, column=0, description=''
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=4, column=0,
            description=RUN_SEARCH_DESCRIPTION
        )

        """BOTTOM"""
        self.rewindow()

    def select_all(self):
        for entryCheck in self.entryChecks:
            self.entryChecks[entryCheck].setChecked(self.selectAllCheck.isChecked())

    def refresh(self):
        self.selectAllLabel, self.selectAllCheck = make_pair(
            self, pair='check', text='Select All:', layout=self.bottom,
            row=0, column=1, pairCommand=self.select_all
        )

        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        for i, header in enumerate(self.headers, start=1):
            self.labels[header.strip()] = make_label(
                self, text=header.strip() + ':', layout=self.bottom, row=i,
                column=0
            )
            self.entries[header.strip()] = make_entry(self, layout=self.bottom, row=i, column=1)
            self.entryChecks[header.strip()] = make_button(self, type='check', layout=self.bottom, row=i, column=2)

    def rewindow(self):
        try:
            self.bottom.deleteLater()
            self.bottomLayout.deleteLater()
            self.scrollArea.deleteLater()
            self.splitter2.deleteLater()
        except:
            pass
        self.bottom = make_grid(self)
        self.labels = {}
        self.entries = {}
        self.entryChecks = {}
        self.refresh()

        self.scrollArea = make_scroll_area(self.bottom)
        self.bottomLayout = make_grid(self.scrollArea)
        self.scrollArea.setMinimumSize(400, HEIGHT / 4)

        self.siteContainer = make_browser(layout=self.bottomLayout, file=SEARCH_RESULTS_TABLE)
        self.splitter3 = make_splitter(style='h', widgets=(self.scrollArea, self.siteContainer))
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.splitter3))
        # self.clearButton = make_button(self, command=lambda: clear(self.entries), text='Clear',
        #                               description=CLEAR_BUTTON_DESCRIPTION)
        # self.splitter2.addWidget(self.clearButton)
        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def run(self):
        columns = Search.get_columns(self.entries, self.entryChecks)
        entries = Search.get_entries(self.entries, self.entryChecks)
        tol = self.toleranceDial.value() / 100
        self.success_counter = []
        if not self.validate(columns):
            return
        results, files = Search.query_master_loop(
            self, self.readLabel.text(), self.saveLabel.text(), entries, columns,
            tol, self.txtCheck.isChecked(), self.excelCheck.isChecked()
        )
        if not (1 in self.success_counter):
            QMessageBox.critical(self, "No Results", "No matches were found.", QMessageBox.Ok)
        make_table(SEARCH_RESULTS_TABLE, results, files)
        self.siteContainer = load_browser(self.siteContainer, SEARCH_RESULTS_TABLE)

    def validate(self, columns):
        if not columns:
            QMessageBox.critical(self, "Empty search", "Enter interface7 criteria.", QMessageBox.Ok)
            return False
        return True

    def table_raw(self):
        pass  # make_table(SEARCH_RESULTS_TABLE, results, files)  # self.siteContainer = load_browser(self.siteContainer, SEARCH_RESULTS_TABLE)

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, standard=False)
        self.resultsSuffix = ' interface7 results'
        top_left_splitter(
            self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON,
            updateFunction=self.rewindow, layout=self.topRightLayout
        )
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.analysisTab, self.settingsTab, self.exportTab = set_tabs(
            self, ('Analysis', 'Settings', 'Export'),
            layout=self.topRightLayout
        )

        _, self.toleranceDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 100, 1), text='Accuracy:',
            layout=self.settingsTab, row=2, column=0, description=''
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=0, column=3,
            description=SEARCH_RUN_DESCRIPTION
        )
        set_export_options(self)

        """BOTTOM"""
        self.rewindow()

    def select_all(self):
        for entryCheck in self.entryChecks:
            self.entryChecks[entryCheck].setChecked(self.selectAllCheck.isChecked())

    def refresh(self):
        self.selectAllLabel, self.selectAllCheck = make_pair(
            self, pair='check', text='Select All:', layout=self.bottom,
            row=0, column=1, pairCommand=self.select_all
        )

        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        for i, header in enumerate(self.headers, start=1):
            _, self.entries[header.strip()] = make_pair(
                self, pair='entry', text=header.strip() + ':',
                layout=self.bottom, row=i, column=0
            )
            self.entryChecks[header.strip()] = make_button(
                self, buttonType='check', layout=self.bottom, row=i,
                column=1
            )

    def rewindow(self):
        try:
            self.bottom.deleteLater()
            self.bottomLayout.deleteLater()
            self.scrollArea.deleteLater()
            self.splitter2.deleteLater()
        except:
            pass
        self.bottom = make_grid(self)
        self.labels = {}
        self.entries = {}
        self.entryChecks = {}
        self.refresh()

        self.scrollArea = make_scroll_area(self.bottom)
        self.bottomLayout = make_grid(self.scrollArea)
        self.siteContainer = make_browser(layout=self.bottomLayout, file=SEARCH_RESULTS_TABLE)
        self.splitter3 = make_splitter(style='h', widgets=(self.scrollArea, self.siteContainer))
        self.splitter2 = make_splitter(style='v', widgets=(self.topright, self.splitter3))
        # self.clearButton = make_button(self, command=lambda: clear(self.entries), text='Clear',
        #                               description=CLEAR_BUTTON_DESCRIPTION)
        # self.splitter2.addWidget(self.clearButton)
        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def run(self):
        columns = Search.get_columns(self.entries, self.entryChecks)
        entries = Search.get_entries(self.entries, self.entryChecks)
        tol = self.toleranceDial.value() / 100
        formats = [x.text() for x in self.exportFormats.selectedItems()]
        self.success_counter = []
        if not self.validate(columns):
            return
        results, files = Search.query_master_loop(
            self, self.readLabel.text(), self.saveLabel.text(), entries, columns,
            tol, formats
        )
        if not (1 in self.success_counter):
            QMessageBox.critical(self, "No Results", "No matches were found.", QMessageBox.Ok)
            return
        make_table(SEARCH_RESULTS_TABLE, results.values(), files)
        self.siteContainer = load_browser(self.siteContainer, SEARCH_RESULTS_TABLE)
        self.results = results

    def validate(self, columns):
        if not columns:
            QMessageBox.critical(self, "Empty search", "Enter interface7 criteria.", QMessageBox.Ok)
            return False
        return True

    def table_raw(self):
        pass  # make_table(SEARCH_RESULTS_TABLE, results, files)  # self.siteContainer = load_browser(self.siteContainer, SEARCH_RESULTS_TABLE)

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, standard=False)
        self.resultsSuffix = ' interface7 results'
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 4)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 4)
        top_left_splitter(
            self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON,
            updateFunction=self.rewindow
        )
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.analysisTab, self.settingsTab, self.exportTab = set_tabs(
            self, ('Analysis', 'Settings', 'Export'),
            layout=self.topRightLayout
        )

        _, self.toleranceDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=self.settingsTab, row=2, column=0, description=''
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=4, column=0,
            description=SEARCH_RUN_DESCRIPTION
        )
        set_export_options(self)

        """BOTTOM"""
        self.rewindow()

    def select_all(self):
        for entryCheck in self.entryChecks:
            self.entryChecks[entryCheck].setChecked(self.selectAllCheck.isChecked())

    def refresh(self):
        self.selectAllLabel, self.selectAllCheck = make_pair(
            self, pair='check', text='Select All:', layout=self.bottom,
            row=0, column=1, pairCommand=self.select_all
        )

        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = dh.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        for i, header in enumerate(self.headers, start=1):
            self.labels[header.strip()] = make_label(
                self, text=header.strip() + ':', layout=self.bottom, row=i,
                column=0
            )
            self.entries[header.strip()] = make_entry(self, layout=self.bottom, row=i, column=1)
            self.entryChecks[header.strip()] = make_button(
                self, buttonType='check', layout=self.bottom, row=i,
                column=2
            )

    def rewindow(self):
        try:
            self.bottom.deleteLater()
            self.bottomLayout.deleteLater()
            self.scrollArea.deleteLater()
            self.splitter2.deleteLater()
        except:
            pass
        self.bottom = make_grid(self)
        self.labels = {}
        self.entries = {}
        self.entryChecks = {}
        self.refresh()

        self.scrollArea = make_scroll_area(self.bottom)
        self.bottomLayout = make_grid(self.scrollArea)

        self.siteContainer = make_browser(layout=self.bottomLayout, file=SEARCH_RESULTS_TABLE)
        self.splitter3 = make_splitter(style='h', widgets=(self.scrollArea, self.siteContainer))
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.splitter3))
        # self.clearButton = make_button(self, command=lambda: clear(self.entries), text='Clear',
        #                               description=CLEAR_BUTTON_DESCRIPTION)
        # self.splitter2.addWidget(self.clearButton)
        # set_widget_size(self.topright, WIDTH / 6, HEIGHT / 5)
        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def run(self):
        columns = Search.get_columns(self.entries, self.entryChecks)
        entries = Search.get_entries(self.entries, self.entryChecks)
        tol = self.toleranceDial.value() / 100
        formats = [x.text() for x in self.exportFormats.selectedItems()]
        self.success_counter = []
        if not self.validate(columns):
            return
        results, files = Search.query_master_loop(
            self, self.readLabel.text(), self.saveLabel.text(), entries, columns,
            tol, formats
        )
        if not (1 in self.success_counter):
            QMessageBox.critical(self, "No Results", "No matches were found.", QMessageBox.Ok)
            return
        make_table(SEARCH_RESULTS_TABLE, results, files)
        self.siteContainer = load_browser(self.siteContainer, SEARCH_RESULTS_TABLE)
        self.results = results

    def validate(self, columns):
        if not columns:
            QMessageBox.critical(self, "Empty search", "Enter interface7 criteria.", QMessageBox.Ok)
            return False
        return True

    def table_raw(self):
        pass  # make_table(SEARCH_RESULTS_TABLE, results, files)  # self.siteContainer = load_browser(self.siteContainer, SEARCH_RESULTS_TABLE)

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, standard=False)
        self.resultsSuffix = ' interface7 results'
        top_left_splitter(
            self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON,
            updateFunction=self.rewindow, layout=self.topRightLayout
        )
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        self.analysisTab, self.settingsTab, self.exportTab = set_tabs(
            self, ('Analysis', 'Settings', 'Export'),
            layout=self.topRightLayout
        )

        _, self.toleranceDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 100, 1), text='Accuracy:',
            layout=self.settingsTab, row=2, column=0, description=''
        )

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=0, column=3,
            description=SEARCH_RUN_DESCRIPTION
        )
        set_export_options(self)

        """BOTTOM"""
        self.rewindow()

    def select_all(self):
        for entryCheck in self.entryChecks:
            self.entryChecks[entryCheck].setChecked(self.selectAllCheck.isChecked())

    def refresh(self):
        self.selectAllLabel, self.selectAllCheck = make_pair(
            self, pair='check', text='Select All:', layout=self.bottom,
            row=0, column=1, pairCommand=self.select_all
        )

        if self.readLabel.text() == self.parent.databaseMenu.readLabel.text():
            self.headers = DataProcessor.line_reader(HEADERS)
        else:
            self.headers, _ = collect_headers(self.readLabel.text(), save=False)

        for i, header in enumerate(self.headers, start=1):
            _, self.entries[header.strip()] = make_pair(
                self, pair='entry', text=header.strip() + ':',
                layout=self.bottom, row=i, column=0
            )
            self.entryChecks[header.strip()] = make_button(
                self, buttonType='check', layout=self.bottom, row=i,
                column=1
            )

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, standard=False)
        top_left_splitter(self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON)

        """TOP RIGHT"""
        self.txtLabel = make_label(self, text='txt:', layout=self.topRightLayout, row=1, column=0)
        self.txtCheck = make_button(self, type='check', layout=self.topRightLayout, row=1, column=1)
        self.excelLabel = make_label(self, text='Excel:', layout=self.topRightLayout, row=1, column=2)
        self.excelCheck = make_button(self, type='check', layout=self.topRightLayout, row=1, column=3)
        # RUN BUTTON
        self.runButton = make_button(self, command=self.run, text='Run', layout=self.topRightLayout, row=4, column=0)

        """BOTTOM"""
        widget = QtWidgets.QWidget()
        widget.setStyleSheet(WIDGET_STYLE)
        self.bottom = make_grid(self)
        self.entries = {}

        for i, header in enumerate(HEADERS, start=1):
            self.entries[header] = make_entry(parent)
            label = make_label(self, header + ':')
            self.bottom.addWidget(label, i, 0)
            self.bottom.addWidget(self.entries[header], i, 1)

        widget.setLayout(self.bottom)
        scroll = make_scroll_area(widget)

        self.bottomLayout = make_grid(scroll)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, scroll))

        self.clearButton = make_button(self, command=lambda: clear(self.entries), text='Clear')
        self.splitter2.addWidget(self.clearButton)

        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        scroll.setMinimumSize(WIDTH / 4, HEIGHT / 4)

        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def run(self):
        columns = get_columns(self.entries)
        entries = get_entries(self.entries)
        self.success_counter = []
        if not validate(self, columns, (self.txtCheck.isChecked(), self.excelCheck.isChecked())):
            return
        self.p = make_progress_bar(self.bottomLayout)
        query_master_loop(
            self, self.readLabel.text(), entries, columns, self.txtCheck.isChecked(),
            self.excelCheck.isChecked()
        )
        self.p.deleteLater()
        if not (1 in self.success_counter):
            QMessageBox.critical(self, "No Results", "No matches were found.", QMessageBox.Ok)

    # TODO progress bar decorator
    def run(self):
        ReportMenu(self, self.top, "search").populate()

    def populate(self):
        self.frame = VerticalScrolledFrame(self.top)
        self.frame.grid(row=0, column=0, columnspan=3, sticky="nsew")
        self.entryList = setSearchEntryLists(self.frame.interior)
        self.populate_search_field()
        self.util.separator(container=self.top, orient='h', row=2, column=0, columnspan=3, sticky='we')
        self.util.button(
            container=self.top, text=SM_BT, commands=[self.run, self.clear], cursor=HAND, row=[3, 3],
            column=[2, 0], sticky=['se', 'sw']
        )
        self.util.drop_down_menu(
            parent=self.top, menus=SM_DM, tearoff=[0], labels=SM_DL,
            commands=[[self.load, self.save, self.top.destroy]]
        )

    def populate_search_field(self):
        for i, line in enumerate(self.entryList):
            ttk.Label(self.frame.interior, text=line).grid(row=i + 3, column=0, sticky='w', pady=5)
            self.entryList[FEATURES[i]].grid(row=i + 3, column=2, columnspan=1, sticky='e')
            self.entryList[FEATURES[i]].insert(0, '')

    def clear(self):
        for i in range(self.entryList.__len__()):
            self.entryList[FEATURES[i + 0]].delete(0, END)

    def set_filepath(self, filepath):
        self.filepath = filepath

    def search_resume(self, settings):
        entryList = self.entryList
        with open(MASTER + ROOT + "\Database\\temp.txt", "w") as saveFile:
            for i in range(entryList.__len__()):
                saveFile.write(entryList[FEATURES[i]].get() + "\n")
        search(
            entries=entryList, settings=settings, dtype={item: str for item in entryList if item != FOLDER},
            filepath=self.filepath, fileName=name_file(self.filepath),
            folderSuffix=set_folders([str(i) for i in range(1992, 2017)], entryList[FOLDER].get()),
            files=set_files(self.state_code_state(), entryList[FILE].get())
        )

    def state_code_state(self):
        self.states = {}
        with open(STATES, 'r') as states:
            with open(STATE_CODES, 'r') as state_codes:
                for state, state_code in zip(states, state_codes):
                    self.states[state_code.strip()] = state.strip()
        return self.states

    def save(self):
        path = tkf.asksaveasfilename(filetypes=(QRY_FILES, ALL_FILES))
        try:
            if path[-4:] != QRY_EXT:
                path = path + QRY_EXT
            with open(path, "w") as saveFile:
                for i in range(self.util.number_of_items):
                    saveFile.write(self.entryList[FEATURES[i]].get() + "\n")
        except:
            return

    def load(self):
        try:
            path = tkf.askopenfilename(filetypes=(QRY_FILES, ALL_FILES))
            with open(path, "r") as loadFile:
                for i in range(self.entryList.__len__()):
                    self.entryList[FEATURES[i]].delete(0, END)
                for i, line in enumerate(loadFile):
                    if line.strip():
                        self.entryList[FEATURES[i]].insert(i, line.strip())
        except:
            return

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, standard=False)
        top_left_splitter(self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON)

        """TOP RIGHT"""
        # TODO EXPORT AS TEXT, EXCEL, OR PDF checkbuttons
        self.txtLabel = make_label(self, 'txt:')
        self.topRightLayout.addWidget(self.txtLabel, 1, 0)

        self.txtCheck = make_button(self, type='check')
        self.topRightLayout.addWidget(self.txtCheck, 1, 1)

        self.excelLabel = make_label(self, 'Excel:')
        self.topRightLayout.addWidget(self.excelLabel, 1, 2)

        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.excelCheck, 1, 3)

        # RUN BUTTON
        self.runButton = make_button(self, command=self.run, text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        """BOTTOM"""
        widget = QtWidgets.QWidget()
        widget.setStyleSheet(WIDGET_STYLE)
        self.bottom = make_grid(self)
        self.entries = {}
        for i, header in enumerate(HEADERS, start=1):
            self.entries[header] = make_entry(parent)
            label = make_label(self, header + ':')
            self.bottom.addWidget(label, i, 0)
            self.bottom.addWidget(self.entries[header], i, 1)

        widget.setLayout(self.bottom)
        scroll = make_scroll_area(widget)

        self.bottomLayout = make_grid(scroll)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, scroll))

        self.clearButton = make_button(self, command=lambda: clear(self.entries), text='Clear')
        self.splitter2.addWidget(self.clearButton)

        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        scroll.setMinimumSize(WIDTH / 4, HEIGHT / 4)

        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def run(self):
        dtype = {entry: str for entry in self.entries if entry != FOLDER}
        columns = [entry for entry in self.entries if
                   entry not in (FILE, FOLDER) and self.entries[entry].text() is not '']

        if self.readLabel.text():
            dir = self.readLabel.text()
        else:
            dir = DATABASE

        folder = self.entries[FOLDER].text()
        filesList = set_files(state_code_state(), self.entries[FILE].text())

        with open(TEMP_SAVE, 'w') as saveFile:
            for i in range(self.entries.__len__()):
                saveFile.write(self.entries[FEATURES[i]].text() + "\n")

        for subdir, dirs, files in os.walk(dir):
            for file in files:
                for f in filesList:
                    if f in file and folder in subdir:
                        if os.stat(os.path.join(subdir, file)).st_size != 0:
                            search(entries=self.entries, file=file, dir=subdir[-2:], dtype=dtype, columns=columns)

    def save_query(self):
        path = save_file(self, fileExt=QRY_FILES)
        try:
            if path[-4:] != QRY_EXT:
                path = path + QRY_EXT
            with open(path, "w") as saveFile:
                for i in range(HEADERS.__len__()):
                    saveFile.write(self.entries[FEATURES[i]].get() + "\n")
        except:
            return

    def load_query(self):
        try:
            path = open_files(fileExt=QRY_FILES)
            with open(path, "r") as loadFile:
                for i in range(self.entries.__len__()):
                    self.entries[FEATURES[i]].delete(0, self.entries[FEATURES[i]].get().__len__())
                for i, line in enumerate(loadFile):
                    if line.strip():
                        self.entries[FEATURES[i]].insert(i, line.strip())
        except:
            return

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, standard=False)
        top_left_splitter(self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON)

        """TOP RIGHT"""
        # TODO EXPORT AS TEXT, EXCEL, OR PDF checkbuttons
        self.txtLabel = make_label(self, 'txt:')
        self.topRightLayout.addWidget(self.txtLabel, 1, 0)

        self.txtCheck = make_button(self, type='check')
        self.topRightLayout.addWidget(self.txtCheck, 1, 1)

        self.csvLabel = make_label(self, 'csv:')
        self.topRightLayout.addWidget(self.csvLabel, 1, 2)

        self.csvCheck = make_button(self, type='check')
        self.topRightLayout.addWidget(self.csvCheck, 1, 3)

        self.excelLabel = make_label(self, 'Excel:')
        self.topRightLayout.addWidget(self.excelLabel, 2, 0)

        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.excelCheck, 2, 1)

        self.pdfLabel = make_label(self, 'pdf:')
        self.topRightLayout.addWidget(self.pdfLabel, 2, 2)

        self.pdfCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.pdfCheck, 2, 3)

        # TODO UNION OR INTERSECTION SEARCH radiobutton
        self.unionLabel = make_label(self, 'Union:')
        self.topRightLayout.addWidget(self.unionLabel, 3, 0)

        self.unionRadio = make_button(self, type='radio')
        self.topRightLayout.addWidget(self.unionRadio, 3, 1)

        self.intersectionLabel = make_label(self, 'Intersection:')
        self.topRightLayout.addWidget(self.intersectionLabel, 3, 2)

        self.intersectionRadio = make_button(self, type='radio')
        self.topRightLayout.addWidget(self.intersectionRadio, 3, 3)

        # RUN BUTTON
        self.runButton = make_button(self, command=self.run, text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        """BOTTOM"""
        widget = QtWidgets.QWidget()
        widget.setStyleSheet(WIDGET_STYLE)
        self.bottom = make_grid(self)
        self.entries = {}
        for i, header in enumerate(HEADERS, start=1):
            self.entries[header] = make_entry(parent)
            label = make_label(self, header + ':')
            self.bottom.addWidget(label, i, 0)
            self.bottom.addWidget(self.entries[header], i, 1)

        widget.setLayout(self.bottom)
        scroll = make_scroll_area(widget)

        self.bottomLayout = make_grid(scroll)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, scroll))

        self.clearButton = make_button(self, command=lambda: clear(self.entries), text='Clear')
        self.splitter2.addWidget(self.clearButton)

        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        scroll.setMinimumSize(WIDTH / 4, HEIGHT / 4)

        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def run(self):
        dtype = {entry: str for entry in self.entries if entry != FOLDER}
        columns = [entry for entry in self.entries if entry != FOLDER and self.entries[entry].text() is not '']

        if self.readLabel.text():
            dir = self.readLabel.text()
        else:
            dir = DATABASE

        # filesList = set_files(state_code_state(), self.entries[FILE].text())

        with open(TEMP_SAVE, 'w') as saveFile:
            for i in range(self.entries.__len__()):
                saveFile.write(self.entries[FEATURES[i]].text() + "\n")

        for subdir, dirs, files in os.walk(dir):
            for file in files:
                if os.stat(os.path.join(subdir, file)).st_size != 0:
                    search(entries=self.entries, file=file, dir=subdir[-2:], dtype=dtype, columns=columns)

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, standard=False)
        top_left_splitter(
            self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON,
            updateFunction=self.rewindow
        )
        self.data = None
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        """TOP RIGHT"""
        self.txtLabel, self.txtCheck = make_pair(
            self, pair='check', text='txt:', layout=self.topRightLayout, row=1,
            column=0, description=TXT_EXPORT_DESCRIPTION
        )

        self.excelLabel, self.excelCheck = make_pair(
            self, pair='check', text='Excel:', layout=self.topRightLayout,
            row=1, column=2, description=EXCEL_EXPORT_DESCRIPTION
        )

        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=4,
            column=0, description=RUN_SEARCH_DESCRIPTION
        )

        """BOTTOM"""
        self.rewindow()

    def run(self):
        columns = Search.get_columns(self.entries, self.entryChecks)
        entries = Search.get_entries(self.entries, self.entryChecks)
        self.success_counter = []
        if not self.validate(columns):
            return
        results, files = Search.query_master_loop(
            self, self.readLabel.text(), entries, columns,
            self.txtCheck.isChecked(), self.excelCheck.isChecked()
        )
        if not (1 in self.success_counter):
            QMessageBox.critical(self, "No Results", "No matches were found.", QMessageBox.Ok)
        make_tabbed_table(SEARCH_RESULTS_TABLE, results, files)
        self.siteContainer = load_browser(self.siteContainer, SEARCH_RESULTS_TABLE)

    def validate(self, columns):
        if not columns:
            QMessageBox.critical(self, "Empty search", "Enter interface7 criteria.", QMessageBox.Ok)
            return False
        return True

    def table_raw(self):
        pass  # make_tabbed_table(SEARCH_RESULTS_TABLE, results, files)  # self.siteContainer = load_browser(self.siteContainer, SEARCH_RESULTS_TABLE)

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, standard=False)
        top_left_splitter(
            self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON,
            updateFunction=self.rewindow
        )
        self.data = None
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        """TOP RIGHT"""
        _, self.txtCheck = make_pair(
            self, pair='check', text='txt:', layout=self.topRightLayout, row=1, column=0,
            description=TXT_EXPORT_DESCRIPTION
        )
        _, self.excelCheck = make_pair(
            self, pair='check', text='Excel:', layout=self.topRightLayout, row=1, column=2,
            description=EXCEL_EXPORT_DESCRIPTION
        )
        _, self.toleranceDial = make_pair(
            self, pair='dial', dialSettings=(1, 100, 50, 1), text='Tolerance:',
            layout=self.topRightLayout, row=2, column=0, description=''
        )
        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=4,
            column=0, description=RUN_SEARCH_DESCRIPTION
        )

        """BOTTOM"""
        self.rewindow()

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, standard=False)
        self.topleft = make_frame(parent)
        self.topLeftLayout = make_grid(self.topleft)

        self.topright = make_frame(parent)
        self.topRightLayout = make_grid(self.topright)

        """BOTTOM"""
        widget = QtWidgets.QWidget()
        widget.setStyleSheet(WIDGET_STYLE)
        self.bottom = make_grid(self)
        self.entries = {}
        for i, header in enumerate(HEADERS, start=1):
            self.entries[header] = make_entry(parent)
            label = make_label(self, header + ':')
            self.bottom.addWidget(label, i, 0)
            self.bottom.addWidget(self.entries[header], i, 1)

        widget.setLayout(self.bottom)
        scroll = QtWidgets.QScrollArea()

        # scroll.setFrameShape(QtGui.QScrollArea.StyledPanel)
        scroll.setStyleSheet(FRAME_STYLE + SCROLL_STYLE)
        scroll.setWidget(widget)
        self.bottomLayout = make_grid(scroll)

        self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, scroll))

        """TOP LEFT"""
        # FILES TO READ
        self.readLabel = make_label(self, '')
        openFolderIcon = QtGui.QIcon(OPEN_FOLDER_ICON)
        self.readButton = make_button(
            self, lambda: menu.open_files(self, multiple=True, label=self.readLabel), '',
            OPEN_FOLDER_ICON
        )
        self.topLeftLayout.addWidget(self.readButton, 0, 0)
        self.topLeftLayout.addWidget(self.readLabel, 0, 1)

        # FILE TO SAVE
        self.saveLabel = make_label(self, '')
        self.saveButton = make_button(self, lambda: menu.save_file(self, label=self.saveLabel), '', SAVE_FILE_ICON)
        self.topLeftLayout.addWidget(self.saveButton, 1, 0)
        self.topLeftLayout.addWidget(self.saveLabel, 1, 1)

        """TOP RIGHT"""
        # TODO EXPORT AS TEXT, EXCEL, OR PDF checkbuttons
        self.csvLabel = make_label(self, 'csv:')
        self.csvCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.csvLabel, 1, 0)
        self.topRightLayout.addWidget(self.csvCheck, 1, 1)

        self.excelLabel = make_label(self, 'Excel:')
        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.excelLabel, 1, 2)
        self.topRightLayout.addWidget(self.excelCheck, 1, 3)

        self.pdfLabel = make_label(self, 'pdf:')
        self.pdfCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.pdfLabel, 2, 0)
        self.topRightLayout.addWidget(self.pdfCheck, 2, 1)

        # TODO UNION OR INTERSECTION SEARCH radiobutton
        self.unionLabel = make_label(self, 'Union:')
        self.unionRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.unionLabel, 3, 0)
        self.topRightLayout.addWidget(self.unionRadio, 3, 1)

        self.intersectionLabel = make_label(self, 'Intersection:')
        self.intersectionRadio = QtWidgets.QRadioButton(self)
        self.topRightLayout.addWidget(self.intersectionLabel, 3, 2)
        self.topRightLayout.addWidget(self.intersectionRadio, 3, 3)

        # RUN BUTTON
        self.runButton = make_button(self, lambda: menu.save_file(self), 'Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        self.clearButton = make_button(self, lambda: clear(self.entries), 'Clear')
        self.splitter2.addWidget(self.clearButton)

        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        menu.set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        scroll.setMinimumSize(WIDTH / 4, HEIGHT / 4)

        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def validate(self, columns):
        if not columns:
            QMessageBox.critical(self, "Empty other0", "Enter search criteria.", QMessageBox.Ok)
            return False
        return True

    def table_raw(self):
        pass  # make_table(SEARCH_RESULTS_TABLE, results, files)  # self.siteContainer = load_browser(self.siteContainer, SEARCH_RESULTS_TABLE)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon, standard=False)
        top_left_splitter(self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON)

        """TOP RIGHT"""
        # TODO EXPORT AS TEXT, EXCEL, OR PDF checkbuttons
        self.txtLabel = make_label(self, 'txt:')
        self.topRightLayout.addWidget(self.txtLabel, 1, 0)

        self.txtCheck = make_button(self, type='check')
        self.topRightLayout.addWidget(self.txtCheck, 1, 1)

        self.csvLabel = make_label(self, 'csv:')
        self.topRightLayout.addWidget(self.csvLabel, 1, 2)

        self.csvCheck = make_button(self, type='check')
        self.topRightLayout.addWidget(self.csvCheck, 1, 3)

        self.excelLabel = make_label(self, 'Excel:')
        self.topRightLayout.addWidget(self.excelLabel, 2, 0)

        self.excelCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.excelCheck, 2, 1)

        self.pdfLabel = make_label(self, 'pdf:')
        self.topRightLayout.addWidget(self.pdfLabel, 2, 2)

        self.pdfCheck = QtWidgets.QCheckBox(self)
        self.topRightLayout.addWidget(self.pdfCheck, 2, 3)

        # TODO UNION OR INTERSECTION SEARCH radiobutton
        self.unionLabel = make_label(self, 'Union:')
        self.topRightLayout.addWidget(self.unionLabel, 3, 0)

        self.unionRadio = make_button(self, type='radio')
        self.topRightLayout.addWidget(self.unionRadio, 3, 1)

        self.intersectionLabel = make_label(self, 'Intersection:')
        self.topRightLayout.addWidget(self.intersectionLabel, 3, 2)

        self.intersectionRadio = make_button(self, type='radio')
        self.topRightLayout.addWidget(self.intersectionRadio, 3, 3)

        # RUN BUTTON
        self.runButton = make_button(self, command=self.run_search, text='Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)

        """BOTTOM"""
        widget = QtWidgets.QWidget()
        widget.setStyleSheet(WIDGET_STYLE)
        self.bottom = make_grid(self)
        self.entries = {}
        for i, header in enumerate(HEADERS, start=1):
            self.entries[header] = make_entry(parent)
            label = make_label(self, header + ':')
            self.bottom.addWidget(label, i, 0)
            self.bottom.addWidget(self.entries[header], i, 1)

        widget.setLayout(self.bottom)
        scroll = make_scroll_area(widget)

        self.bottomLayout = make_grid(scroll)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, scroll))

        self.clearButton = make_button(self, command=lambda: clear(self.entries), text='Clear')
        self.splitter2.addWidget(self.clearButton)

        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        scroll.setMinimumSize(WIDTH / 4, HEIGHT / 4)

        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)

    def run_search(self):
        if self.saveLabel.text():
            dir = self.saveLabel.text()

        else:
            dir = DATABASE

        for subdir, dirs, files in os.walk(dir):
            for file in files:
                print(os.path.join(subdir, file))

    def save_query(self):
        path = save_file(fileExt=QRY_FILES)
        try:
            if path[-4:] != QRY_EXT:
                path = path + QRY_EXT
            with open(path, "w") as saveFile:
                for i in range(HEADERS.__len__()):
                    saveFile.write(self.entryList[FEATURES[i]].get() + "\n")
        except:
            return

    def load_query(self):
        try:
            path = open_files(fileExt=QRY_FILES)
            with open(path, "r") as loadFile:
                for i in range(self.entryList.__len__()):
                    self.entryList[FEATURES[i]].delete(0, self.entryList[FEATURES[i]].get().__len__())
                for i, line in enumerate(loadFile):
                    if line.strip():
                        self.entryList[FEATURES[i]].insert(i, line.strip())
        except:
            return

    def __init__(self, parent, title, icon):
        self.parent = parent
        SubMenu.__init__(self, parent, title, icon, standard=False)
        top_left_splitter(self, open=open_folder, save=open_folder, saveIcon=SAVE_FOLDER_ICON)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)
        """TOP RIGHT"""
        self.txtLabel = make_label(
            self, text='txt:', layout=self.topRightLayout, row=1, column=0,
            description=TXT_EXPORT_DESCRIPTION
        )
        self.txtCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=1,
            description=TXT_EXPORT_DESCRIPTION
        )
        self.excelLabel = make_label(
            self, text='Excel:', layout=self.topRightLayout, row=1, column=2,
            description=EXCEL_EXPORT_DESCRIPTION
        )
        self.excelCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=3,
            description=EXCEL_EXPORT_DESCRIPTION
        )
        # RUN BUTTON
        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=4,
            column=0, description=RUN_SEARCH_DESCRIPTION
        )

        """BOTTOM"""
        self.rewindow()  # self.readLabel.textChanged.connect(self.parent.databaseMenu.apply(self.readLabel.text()))

    def run(self):
        columns = search.get_columns(self.entries)
        entries = search.get_entries(self.entries)
        self.success_counter = []
        if not search.validate(self, columns, (self.txtCheck.isChecked(), self.excelCheck.isChecked())):
            return
        self.p = make_progress_bar(self.bottomLayout)
        search.query_master_loop(
            self, self.readLabel.text(), entries, columns, self.txtCheck.isChecked(),
            self.excelCheck.isChecked()
        )
        self.p.deleteLater()
        if not (1 in self.success_counter):
            QMessageBox.critical(self, "No Results", "No matches were found.", QMessageBox.Ok)

    def refresh(self):
        with open(HEADERS) as headers:
            for i, header in enumerate(headers, start=1):
                self.labels[header.strip()] = make_label(
                    self, text=header.strip() + ':', layout=self.bottom, row=i,
                    column=0
                )
                self.entries[header.strip()] = make_entry(self, layout=self.bottom, row=i, column=1)

    def rewindow(self):
        try:
            self.widget.deleteLater()
            self.bottom.deleteLater()
            self.bottomLayout.deleteLater()
            self.scrollArea.deleteLater()
            self.splitter2.deleteLater()
        except:
            pass
        self.widget = QtWidgets.QWidget()
        self.widget.setStyleSheet(WIDGET_STYLE)
        self.bottom = make_grid(self)
        self.labels = {}
        self.entries = {}
        self.refresh()
        self.widget.setLayout(self.bottom)
        self.scrollArea = make_scroll_area(self.widget)
        self.bottomLayout = make_grid(self.scrollArea)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.scrollArea))
        self.clearButton = make_button(
            self, command=lambda: clear(self.entries), text='Clear',
            description=CLEAR_BUTTON_DESCRIPTION
        )
        self.splitter2.addWidget(self.clearButton)
        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        self.scrollArea.setMinimumSize(WIDTH / 4, HEIGHT / 4)
        self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)


class SearchMenu(Window):
    @staticmethod
    def help():
        popup = tk.Tk()
        popup.wm_title("!")
        label = ttk.Label(popup, text="PASS Lab\nChristian Lozoya\n2017")
        label.pack(side="top", fill="x", pady=10)
        B1 = ttk.Button(popup, text="Okay", command=popup.destroy)
        B1.pack()
        B1.mainloop()

    def search(self):
        ReportMenu.ReportMenu(self, "search").populate()

    def report_settings(self):
        ReportMenu.ReportMenu(self, "report_generator0 Settings").populate()

    def markov_chain_menu(self):
        MarkovChainMenu.MarkovChainMenu(self, "Markov Chain Monte Carlo").populate()

    def set_filepath(self, filepath):
        self.filepath = filepath

    def c_lo_run(self):
        self.files, self.filename = 'single', 'report'
        self.populator = PopulateSearchMenu.PopulateSearchMenu(self)

    def save(self):
        path = tkf.asksaveasfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        try:
            if path[path.__len__() - 4] is not ".":
                path = path + ".txt"

            with open(path, "w") as saveFile:
                for i in range(self.util.number_of_items):
                    saveFile.write(self.populator.entryList[self.populator.parameterNames[i]].get() + "\n")
        except:
            return

    def load(self):
        path = tkf.askopenfilename(filetypes=(("Text files", "*.txt"), ("All files", "*.*")))
        try:
            with open(path, "r") as loadFile:
                for i in range(self.util.number_of_items):
                    self.populator.entryList[self.populator.parameterNames[i + 0]].delete(0, END)
                for i, line in enumerate(loadFile):
                    self.populator.entryList[self.populator.parameterNames[i]].insert(i, line.strip())

        except:
            return

    def help(self):
        popup = tk.Tk()
        popup.wm_title("!")
        label = ttk.Label(popup, text="PASS Lab\nChristian Lozoya\n2017")
        label.pack(side="top", fill="x", pady=10)
        B1 = ttk.Button(popup, text="Okay", command=popup.destroy)
        B1.pack()
        B1.mainloop()

    def search(self):
        self.name_report()

    def search_resume(self):
        with open(self.util.MASTERPATH + "\\BridgeDataQuery\Database\\temp.txt", "w") as saveFile:
            for i in range(self.util.number_of_items):
                saveFile.write(self.populator.entryList[self.populator.parameterNames[i]].get() + "\n")

        with open(self.util.MASTERPATH + "\\BridgeDataQuery\Database\\temp.txt", "r") as loadFile:
            for i, line in enumerate(loadFile):
                if str(self.populator.parameterNames[i]) == '(Reserved)':
                    self.populator.query[self.populator.parameterNames[i] + "_" + str(i)] = (line.strip())
                else:
                    self.populator.query[self.populator.parameterNames[i]] = (line.strip())

        self.util.list_generator.setSearchList(self.populator.query)
        Search.Search(self)

    def clear(self):
        for i in range(self.util.number_of_items):
            self.populator.entryList[self.populator.parameterNames[i + 0]].delete(0, END)

    def name_report(self):
        NameReport.NameReport(self)

    def report_settings(self):
        ReportSettings.ReportSettings(self)

    def markov_chain_menu(self):
        MarkovChainMenu.MarkovChainMenu(self)

    def set_filepath(self, filepath):
        self.filepath = filepath

    def run(self):
        self.files, self.filename = 'single', 'report'
        self.populator = PopulateSearch.PopulateSearch(self)  # self.frame.tkraise()

    def c_lo_run(self):
        self.files, self.filename = 'single', 'report'
        self.populator = PopulateSearchMenu.PopulateSearchMenu(self)

    def save(self):
        path = tkf.asksaveasfilename(filetypes=(QRY_EXT, ALL_EXT))
        try:
            if path[-4:] != ".qry":
                path = path + ".qry"
            with open(path, "w") as saveFile:
                for i in range(self.util.number_of_items):
                    saveFile.write(self.populator.entryList[self.populator.parameterNames[i]].get() + "\n")
        except:
            return

    def load(self):
        try:
            path = tkf.askopenfilename(filetypes=(QRY_EXT, ALL_EXT))
            with open(path, "r") as loadFile:
                for i in range(len(self.populator.entryList)):
                    self.populator.entryList[self.populator.parameterNames[i]].delete(0, END)
                for i, line in enumerate(loadFile):
                    if line.strip():
                        self.populator.entryList[self.populator.parameterNames[i]].insert(i, line.strip())
        except:
            return

    def search(self):
        ReportMenu(self, "search").populate()

    def clear(self):
        for i in range(len(self.populator.entryList)):
            self.populator.entryList[self.populator.parameterNames[i + 0]].delete(0, END)

    def report_settings(self):
        ReportMenu(self, "report_generator0 Settings").populate()

    def markov_chain_menu(self):
        MarkovChainMenu(self, "Markov Chain Monte Carlo").populate()

    def radial_search(self):
        GeographicSearchMenu(self, "Geographic search").populate()

    def search_resume(self, settings):
        entryList = self.populator.entryList
        with open(MASTER + ROOT + "\Database\\temp.txt", "w") as saveFile:
            for i in range(len(entryList)):
                saveFile.write(entryList[self.populator.parameterNames[i]].get() + "\n")
        Search(settings=settings).process_data(
            entries=entryList, settings=settings,
            dtype={item: str for item in entryList if item != FOLDER},
            filepath=self.filepath, fileName=Search.name_file(self.filepath),
            folderSuffix=Search.set_folders(
                [str(i) for i in range(1992, 2017)],
                entryList[FOLDER].get()
            ),
            files=Search.set_files(
                self.util.lists.state_code_state(),
                entryList[FILE].get()
            )
        )

    def set_filepath(self, filepath):
        self.filepath = filepath


class SimulationMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        top_left_splitter(self, open=open_folder, save=save_file, updateFunction=self.combos)
        self.topleft.setMinimumSize(WIDTH / 5, HEIGHT / 7)
        self.topright.setMinimumSize(WIDTH / 3, HEIGHT / 7)
        self.readLabel.setText(self.parent.databaseMenu.dataSource)

        self.uniquesDict = {}
        """TOP RIGHT"""
        modeGroup = QtWidgets.QButtonGroup(self.topRightLayout)
        _, self.seriesRadio = make_pair(
            self, pair='radio', text='Series:', layout=self.topRightLayout, row=1, column=0,
            description=SERIES_DESCRIPTION
        )

        _, self.parallelRadio = make_pair(
            self, pair='radio', text='Parallel:', layout=self.topRightLayout, row=1,
            column=2, description=PARALLEL_DESCRIPTION
        )

        modeGroup.addButton(self.parallelRadio)
        modeGroup.addButton(self.seriesRadio)
        self.seriesRadio.setChecked(True)
        self.parallelRadio.setChecked(False)
        self.mode = 'series'

        samplerGroup = QtWidgets.QButtonGroup(self.topRightLayout)

        _, self.mcRadio = make_pair(
            self, pair='radio', text='Monte Carlo:', layout=self.topRightLayout, row=2,
            column=0, description=''
        )
        _, self.lhsRadio = make_pair(
            self, pair='radio', text='Latin Hypercube:', layout=self.topRightLayout, row=2,
            column=2, description=LATIN_HYPERCUBES_DESCRIPTION
        )

        samplerGroup.addButton(self.lhsRadio)
        samplerGroup.addButton(self.mcRadio)
        self.mcRadio.setChecked(True)

        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout, row=6, column=0,
            description=RUN_MARKOV_CHAIN_DESCRIPTION
        )

        self.siteContainer = make_browser(layout=self.bottomLayout, file=MARKOV_CHAIN_GRAPH)
        self.indexLabel = make_label(
            self, text='Index:', layout=self.topRightLayout, row=3, column=0,
            description=INDEX_COMBO_DESCRIPTION
        )
        self.columnLabel = make_label(
            self, text='Column:', layout=self.topRightLayout, row=3, column=2,
            description=COLUMN_COMBO_DESCRIPTION
        )

        _, self.iterationsDial = make_pair(
            self, pair='dial', dialSettings=(1, 100000, 1, 1), text='Iterations:',
            layout=self.topRightLayout, row=4, column=0,
            description=ITERATIONS_DESCRIPTION
        )

        self.initialStateLabel = make_label(
            self, text='Initial State:', layout=self.topRightLayout, row=4, column=2,
            description=INITIAL_STATE_DESCRIPTION
        )

        _, self.conditionCombo = make_pair(
            self, pair='combo', comboItems=('', '>', '>=', '<', '<='), text='Condition:',
            layout=self.topRightLayout, row=5, column=0, description=''
        )

        try:
            self.combos()
        except:
            pass

    @staticmethod
    def get_full_data(path):
        fullDataList = dh.read_data_list(path)
        uniquesDict = {}
        uniquesList = []
        for dF in fullDataList:
            uniquesList.append({column: dh.get_uniques(pd.DataFrame(dF.loc[:, column])) for column in dF.columns})
        for u in uniquesList:
            for k in u:
                if k not in uniquesDict:
                    uniquesDict[k] = u[k]
                else:
                    for v in u[k]:
                        if v not in uniquesDict[k]:
                            uniquesDict[k] = np.append(uniquesDict[k], v)
        return fullDataList, uniquesDict

        self.indexCombo = make_combo(
            self, [''] + self.headers, command=self.update_columns, layout=self.topRightLayout,
            row=3, column=1, width=200, description=INDEX_COMBO_DESCRIPTION
        )

        self.columnCombo = make_combo(
            self, self.headers, command=self.update_states, layout=self.topRightLayout, row=3,
            column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )
        self.set_data(self.indexCombo.currentText())
        self.initialStateCombo = make_combo(
            self, dh.get_uniques(self.dataDream), layout=self.topRightLayout, row=4,
            column=3, width=50, description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def update_columns2(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()

        options = [h for h in self.headers if h != index]
        self.columnCombo = make_combo(
            self, options, command=self.update_states, layout=self.topRightLayout, row=3,
            column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
        )

        if index != column:
            self.columnCombo.setCurrentText(column)
        self.update_states()

    def update_columns(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()

        if index == column:
            options = [h for h in self.headers if h != index]
            self.columnCombo = make_combo(
                self, options, command=self.update_states, layout=self.topRightLayout, row=3,
                column=3, width=200, description=COLUMN_COMBO_DESCRIPTION
            )
            self.update_states()
        else:
            self.set_data(index)
            self.graph_raw()

    def update_states(self, setData=True):
        if setData:
            self.set_data(self.indexCombo.currentText())
        self.initialStateCombo = make_combo(
            self, dh.get_uniques(self.dataDream), layout=self.topRightLayout, row=4,
            column=3, width=50, description=INITIAL_STATE_DESCRIPTION
        )
        self.graph_raw()

    def set_data(self, index):
        i = index if index != '' else None
        self.dataDream = dh.merge_data_list(
            dh.read_data_list(self.readLabel.text(), index=i, column=self.columnCombo.currentText())
        )

    def run(self):
        initialState = self.initialStateCombo.currentText()
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        iterations = self.iterationsDial.value()
        condition = dh.get_operator(self.conditionCombo.currentText())
        if self.validate(dir):
            try:
                import time
                t0 = time.time()
                dataMatrix, data, xKeys, yKeys, xMKeys, yMKeys = dh.process_simulation_data(
                    dh.sort_data(self.dataDream), self.mode
                )
                if yKeys:
                    inverseKeys = {yKeys[k]: k for k in yKeys}
                    initialState = inverseKeys[initialState]
                data = pd.DataFrame(data, columns=(column,), index=data.index)
                timeSteps, dindex = MonteCarlo.mh.time_steps(dataMatrix, self.mode)
                stateVector = dh.sort_data(MarkovChain.mh.state_vector(initialState, data))
                transitionProbabilityMatrix = dh.sort_data(
                    MarkovChain.transition_probability_matrix(dataMatrix, self.mode, condition)
                )
                frequency = dh.sort_data(MarkovChain.mh.frequency(dataMatrix))
                markovChain = MarkovChain.markov_chain(stateVector, transitionProbabilityMatrix, timeSteps)
                monteCarlo = MonteCarlo.monte_carlo(stateVector, transitionProbabilityMatrix, iterations, timeSteps)
                monteCarloBounds = MonteCarlo.mh.min_max_mean(monteCarlo, mode=self.mode)
                monteCarloFrequency = dh.sort_data(MonteCarlo.monte_carlo_frequency(monteCarlo, frequency.index))
                dp = lib.data_api.file_api.file_functions.remove_all_duplicates(data)
                x = ((dindex, dp.index), (markovChain.T.index,))
                y = ((monteCarloBounds, dp), (markovChain.T,))
                make_plot(
                    MARKOV_CHAIN_GRAPH, X=x, Y=y, titles=('Monte Carlo', 'Markov Chain'),
                    xLabels=(index if self.mode == 'series' else 'Time Step', 'Iteration'),
                    yLabels=(column, 'Probability'), lineWidths=((3, 1), (3,)), legends=((True, True), (True,)),
                    types=(('line', 'scatter'), ('line',)), xKeys=(xKeys, None), yKeys=(yKeys, None)
                )
                x = ((frequency.index,), (monteCarloFrequency.index,))
                y = ((pd.DataFrame(frequency),), (pd.DataFrame(monteCarloFrequency),))
                make_plot(
                    MARKOV_CHAIN_FREQUENCY_GRAPH, X=x, Y=y, titles=('Raw Frequency', 'Monte Carlo Frequency'),
                    xLabels=(column, column), yLabels=('Frequency', 'Frequency'), lineWidths=((3,), (3,)),
                    legends=((True,), (True,)), types=(('line',), ('line',)), xKeys=(yMKeys, yKeys),
                    yKeys=(None, None)
                )
                frequencyCurves = MonteCarlo.mh.frequency_curves(dataMatrix)
                monteCarloFrequencyCurves = MonteCarlo.mh.frequency_curves(monteCarlo)
                print(frequencyCurves)
                print(markovChain)
                print(monteCarloFrequencyCurves)
                x = ((frequencyCurves.T.index,), (monteCarloFrequencyCurves.T.index,))
                y = ((frequencyCurves.T,), (monteCarloFrequencyCurves.T,))
                make_plot(
                    MARKOV_CHAIN_FREQUENCY_CURVES_GRAPH, X=x, Y=y, titles=('Raw Data', 'Monte Carlo'),
                    xLabels=(column, column), yLabels=('Frequency', 'Frequency'), lineWidths=((3,), (3,)),
                    legends=((True,), (True,)), types=(('line',), ('line',)), xKeys=(yMKeys, yKeys),
                    yKeys=(None, None)
                )
                self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)
                MarkovChain.create_transition_matrix_html(
                    MarkovChain.mh.denumerify_transition_matrix(
                        transitionProbabilityMatrix,
                        yMKeys
                    )
                )  # print(time.time() - t0)
            except Exception as e:
                print(e)

    def graph_raw(self):
        index = self.indexCombo.currentText()
        column = self.columnCombo.currentText()
        dir = self.readLabel.text()
        if self.validate(dir):
            _, data, xKeys, yKeys, _, _ = dh.process_simulation_data(self.dataDream, self.mode)
            data = pd.DataFrame(data, columns=(column,), index=data.index)
            dp = lib.data_api.file_api.file_functions.remove_all_duplicates(data)
            x = ((dp.index,),)
            y = ((dp,),)
            make_plot(
                MARKOV_CHAIN_GRAPH, X=x, Y=y, titles=('Raw Data',),
                xLabels=(index if self.mode == 'series' else 'Time Step',), yLabels=(column,), lineWidths=((1,),),
                legends=((True,),), types=(('scatter',),), xKeys=(xKeys,), yKeys=(yKeys,)
            )
            self.siteContainer = load_browser(self.siteContainer, MARKOV_CHAIN_GRAPH)

    def validate(self, dir):
        error = False
        self.get_mode()
        if self.mcRadio.isChecked():
            self.sampler = 'mc'
        elif self.lhsRadio.isChecked():
            self.sampler = 'lhs'
        if dir == '':
            QMessageBox.critical(self, "No Directory", "Specify a directory.", QMessageBox.Ok)
            error = True
        if self.mode == 'parallel':
            if dh.count_files(self.readLabel.text()) > 1:
                pass
            else:
                QMessageBox.critical(
                    self, 'Unsatisfiable Constraint',
                    'Parallel mode requires more than one data file.', QMessageBox.Ok
                )
        if error == False:
            return True
        else:
            return False


class SubMenu:
    def __init__(self, parent, container, title):
        self.test = test_search.Tests(self)
        self.parent = parent
        self.util = self.parent.util
        self.title = title
        self.top = self.util.top(container, title)
        self.container = container
        self.settings = []
        self.parent.util.set_active(self.top)
        self.top = Toplevel(self.parent.container, borderwidth=5)
        self.frame = self.parent.container
        self.top.title(self.title)

    def cancel(self):
        self.settings[:] = []
        try:
            for button in self.parent.util.checkButtons:
                button.deselect()
        except Exception as e:
            print(e)
        self.top.destroy()

    def toggle_check(self, i):
        self.settings[i] = False if self.settings[i] else True

    def select_check(self, i):
        self.util.checkButtons[i].select()

    def deselect_check(self, i):
        self.util.checkButtons[i].deselect()

    def toggle_radio(self, i, v):
        self.settings[i].set(v)

    def select_radio(self, v):
        self.util.radioButtons[v].select()

    def deselect_radio(self, v):
        self.util.radioButtons[v].deselect()


class SubMenu(QtWidgets.QWidget):
    def __init__(self, parent, title, icon, standard=True):
        self.parent = parent
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.resize(350, 400)
        self.hbox = QtWidgets.QHBoxLayout(self)
        self.topleft = make_frame(parent)
        self.topLeftLayout = make_grid(self.topleft)
        self.topright = make_frame(parent)
        self.topRightLayout = make_grid(self.topright)
        self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
        self.bottom = make_frame(parent)
        self.bottomLayout = make_grid(self.bottom)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))
        if standard:
            self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)
        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        self.bottom.setMinimumSize(WIDTH / 4, HEIGHT / 4)

        menubar = QtWidgets.QMenuBar()
        menubar.setStyleSheet(MENUBAR_STYLE)
        self.file_dropdown(menubar)

    def file_dropdown(self, menubar):
        fileMenu = menubar.addMenu('&File')

        openFileAction = QtWidgets.QAction(QtGui.QIcon(OPEN_FILE_ICON), '&Open File', self)
        openFileAction.setShortcut('Ctrl+O')
        openFileAction.setStatusTip(OPEN_FILE_DESCRIPTION)
        openFileAction.triggered.connect(lambda: open_files(self))
        fileMenu.addAction(openFileAction)

        saveFileAction = QtWidgets.QAction(QtGui.QIcon(SAVE_FILE_ICON), '&Save File', self)
        saveFileAction.setShortcut('Ctrl+S')
        saveFileAction.setStatusTip(SAVE_FILE_DESCRIPTION)
        saveFileAction.triggered.connect(lambda: save_file(self))

        fileMenu.addAction(saveFileAction)

    def __init__(self, parent, title, icon, opensave=True, standard=True, tabbed=False):
        self.parent = parent
        self.results = None
        self.resultsTitle = ''
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        # self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.hbox = QtWidgets.QHBoxLayout(self)

        if opensave:
            self.topleft = make_frame(parent)
            self.topLeftLayout = make_grid(self.topleft)
            self.topright = make_frame(parent)
            self.topRightLayout = make_grid(self.topright)
            self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
            self.bottom = make_frame(parent)
            self.bottomLayout = make_grid(self.bottom)
            self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))
            if standard:
                self.hbox.addWidget(
                    self.splitter2
                )  # self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 5)  # set_widget_size(self.topright, WIDTH / 6, HEIGHT / 5)  # self.bottom.setMinimumSize(WIDTH / 3, HEIGHT / 3)
        elif tabbed:
            self.tabs = QtWidgets.QTabWidget()
            self.tabs.setStyleSheet(TAB_STYLE)
            self.hbox.addWidget(self.tabs)
        self.setLayout(self.hbox)

        # menu_bar(self)

    def export_results(self):
        try:
            formats = [x.text() for x in self.exportFormats.selectedItems()]
            if len(formats) == 0:
                QMessageBox.critical(self, "No Selection", "Select a format.", QMessageBox.Ok)
                return
            if type(self.results) != pd.DataFrame and type(self.results) != list:
                QMessageBox.critical(self, "Nothing To Export", "Run an analysis before exporting.", QMessageBox.Ok)
                return
            if type(self.results) == list:
                for result in self.results:
                    dh.export_data(
                        dataFrame=result, savePath=os.path.join(self.saveLabel.text(), self.resultsTitle),
                        formats=formats, suffix=self.resultsSuffix
                    )
            else:
                dh.export_data(
                    dataFrame=self.results, savePath=os.path.join(self.saveLabel.text(), self.resultsTitle),
                    formats=formats, suffix=self.resultsSuffix
                )
        except Exception as e:
            print(e)

    def __init__(self, parent, title, icon, standard=True):
        self.parent = parent
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.resize(350, 400)
        self.hbox = QtWidgets.QHBoxLayout(self)
        self.topleft = make_frame(parent)
        self.topLeftLayout = make_grid(self.topleft)
        self.topright = make_frame(parent)
        self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
        self.bottom = make_frame(parent)
        self.bottomLayout = make_grid(self.bottom)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))
        if standard:
            self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)
        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        self.bottom.setMinimumSize(WIDTH / 4, HEIGHT / 4)

        menubar = QtWidgets.QMenuBar()
        menubar.setStyleSheet(MENUBAR_STYLE)
        self.file_dropdown(menubar)

    def __init__(self, parent, title, icon, standard=True):
        self.parent = parent
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.resize(350, 400)
        self.hbox = QtWidgets.QHBoxLayout(self)
        self.topleft = make_frame(parent)
        self.topLeftLayout = make_grid(self.topleft)
        self.topright = make_frame(parent)
        self.topRightLayout = make_grid(self.topright)
        self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
        self.bottom = make_frame(parent)
        self.bottomLayout = make_grid(self.bottom)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))
        if standard:
            self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)
        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        self.bottom.setMinimumSize(WIDTH / 4, HEIGHT / 4)
        menubar = QtWidgets.QMenuBar()
        menubar.setStyleSheet(MENUBAR_STYLE)
        self.file_dropdown(menubar)

    def __init__(self, parent, title, icon):
        super(SubMenu, self).__init__()
        self.parent = parent
        self.isPinned = False
        self.pressing = False
        self.setWindowFlags(QtCore.Qt.FramelessWindowHint)
        self.setStyleSheet(qss.format_qss(qss.window + qss.widget, self.parent.palette))
        self.title = title
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.hbox = QtWidgets.QGridLayout(self)
        self.hbox.addWidget(components.TSTitleBar(self, self.title), 0, 0)
        self.frame, self._layout = self.parent.menuBuilder.subdivision(self)
        self.frameS, self._layoutS = self.parent.menuBuilder.subdivision(self)
        self.hbox.addWidget(self.frame, 1, 0)
        self.hbox.addWidget(self.frameS, 2, 0)
        self.setLayout(self.hbox)
        self._layout.setContentsMargins(5, 0, 5, 0)
        self._layout.setSpacing(0)
        self._layoutS.setContentsMargins(5, 0, 5, 5)
        self._layoutS.setSpacing(0)
        self.hbox.setContentsMargins(0, 0, 0, 0)
        self.statusbar = self.parent.menuBuilder.make_statusbar(self, self._layoutS, 0, 1)
        self.statusbar.setMinimumHeight(self.parent.palette.minHeight)
        self.pinButton = self.parent.menuBuilder.make_button(
            self, layout=self._layoutS, command=self.pin, row=0,
            column=0, width=25, height=25, icon=icons.pin,
            tooltip=tooltips.pinButton
        )

    def pin(self):
        self.isPinned = not self.isPinned
        if self.isPinned:
            self.setWindowFlags(self.windowFlags() ^ QtCore.Qt.WindowStaysOnTopHint)
            self.pinButton.setStyleSheet(qss.format_qss(qss.buttonConnected, self.parent.palette))
            self.update_status('Window pinned.', 'success')
        else:
            self.setWindowFlags(self.windowFlags() & ~QtCore.Qt.WindowStaysOnTopHint)
            self.pinButton.setStyleSheet(qss.format_qss(qss.button, self.parent.palette))
            self.update_status('Window unpinned.', 'success')
        self.show()

    def update_status(self, msg, status):
        if status == 'success':
            stylesheet = qss.statusbarSuccess
        elif status == 'error':
            stylesheet = qss.statusbarError
        elif status == 'alert':
            stylesheet = qss.statusbarAlert
        self.statusbar.showMessage(msg)
        self.statusbar.adjustSize()
        self.statusbar.setStyleSheet(qss.format_qss(stylesheet, self.parent.palette))
        self.parent.update_status('{}: {}'.format(self.title.upper(), msg), status)

    def __init__(self, parent, title, icon, opensave=True, standard=True, tabbed=False):
        self.parent = parent
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        # self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.resize(WIDTH / 2, HEIGHT / 2)
        self.hbox = QtWidgets.QHBoxLayout(self)
        if opensave:
            self.topleft = make_frame(parent)
            self.topLeftLayout = make_grid(self.topleft)
            self.topright = make_frame(parent)
            self.topRightLayout = make_grid(self.topright)
            self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
            self.bottom = make_frame(parent)
            self.bottomLayout = make_grid(self.bottom)
            self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))
            if standard:
                self.hbox.addWidget(self.splitter2)
            self.setLayout(self.hbox)
            self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
            set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
            self.bottom.setMinimumSize(WIDTH / 4, HEIGHT / 4)
        elif tabbed:
            self.tabs = QtWidgets.QTabWidget()
            self.tabs.setStyleSheet(TAB_STYLE)
            self.hbox.addWidget(self.tabs)

            # menubar = QtWidgets.QMenuBar()  # menubar.setStyleSheet(MENUBAR_STYLE)  # self.file_dropdown(menubar)

    def file_dropdown(self, menubar):
        fileMenu = menubar.addMenu('&File')
        openFileAction = QtWidgets.QAction(QtGui.QIcon(OPEN_FILE_ICON), '&Open File', self)
        openFileAction.setShortcut('Ctrl+O')
        openFileAction.triggered.connect(lambda: open_files(self))
        fileMenu.addAction(openFileAction)
        saveFileAction = QtWidgets.QAction(QtGui.QIcon(SAVE_FILE_ICON), '&Save File', self)
        saveFileAction.setShortcut('Ctrl+S')
        saveFileAction.triggered.connect(lambda: save_file(self))
        fileMenu.addAction(saveFileAction)

    def __init__(self, parent, title, icon, opensave=True, standard=True, tabbed=False):
        self.parent = parent
        self.results = None
        self.resultsTitle = ''
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        # self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.hbox = QtWidgets.QHBoxLayout(self)

        if opensave:
            # self.topleft = make_frame(parent)
            # self.topLeftLayout = make_grid(self.topleft)
            self.topright = make_frame(parent)
            self.topRightLayout = make_grid(self.topright)
            # self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
            self.bottom = make_frame(parent)
            self.bottomLayout = make_grid(self.bottom)
            self.splitter2 = make_splitter(style='h', widgets=(self.topright, self.bottom))
            if standard:
                self.hbox.addWidget(self.splitter2)

        elif tabbed:
            self.tabs = QtWidgets.QTabWidget()
            self.tabs.setStyleSheet(TAB_STYLE)
            self.hbox.addWidget(self.tabs)
        self.setLayout(self.hbox)

        # menu_bar(self)

    def export_results(self):
        try:
            formats = [x.text() for x in self.exportFormats.selectedItems()]
            if len(formats) == 0:
                QMessageBox.critical(self, "No Selection", "Select a format.", QMessageBox.Ok)
                return
            if type(self.results) != pd.DataFrame and type(self.results) != list and type(self.results) != dict:
                QMessageBox.critical(self, "Nothing To Export", "Run an analysis before exporting.", QMessageBox.Ok)
                return
            if type(self.results) == list:
                for i, result in enumerate(self.results):
                    DataProcessor.export_data(
                        dataFrame=result,
                        savePath=os.path.join(self.saveLabel.text(), self.resultsTitle),
                        formats=formats, suffix=''
                    )
            elif type(self.results) == dict:
                for i, result in enumerate(self.results):
                    DataProcessor.export_data(
                        dataFrame=self.results[result],
                        savePath=os.path.join(self.saveLabel.text(), result + self.resultsTitle),
                        formats=formats, suffix=''
                    )
            else:
                DataProcessor.export_data(
                    dataFrame=self.results,
                    savePath=os.path.join(self.saveLabel.text(), self.resultsTitle),
                    formats=formats, suffix=''
                )
        except Exception as e:
            print(e)

    def __init__(self, parent, title, icon, opensave=True, standard=True, tabbed=False):
        self.parent = parent
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        # self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.hbox = make_grid()  # QtWidgets.QHBoxLayout(self)
        self.setLayout(self.hbox)

        `"""`if opensave:
            self.topleft = make_frame(parent)
            self.topLeftLayout = make_grid(self.topleft)
            self.topright = make_frame(parent)
            self.topRightLayout = make_grid(self.topright)
            self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
            self.bottom = make_frame(parent)
            self.bottomLayout = make_grid(self.bottom)
            self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))
            if standard:
                self.hbox.addWidget(self.splitter2)
            #self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 5)
            #set_widget_size(self.topright, WIDTH / 6, HEIGHT / 5)
            #self.bottom.setMinimumSize(WIDTH / 3, HEIGHT / 3)
        elif tabbed:
            self.tabs = QtWidgets.QTabWidget()
            self.tabs.setStyleSheet(TAB_STYLE)
            self.hbox.addWidget(self.tabs)"""  # menu_bar(self)

        try:
            if type(self.results) != pd.DataFrame:
                QMessageBox.critical(self, "Nothing To Export", "Run an analysis before exporting.", QMessageBox.Ok)
        except Exception as e:
            print(e)

        try:
            dh.export_data(
                self.results, os.path.join(self.saveLabel.text(), 'MK'), csv=True,
                suffix=' Regression6 results'
            )
        except Exception as e:
            print(e)

    def __init__(self, parent, title, icon, opensave=True, standard=True, tabbed=False):
        self.parent = parent
        self.results = None
        self.resultsTitle = ''
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        # self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.hbox = QtWidgets.QHBoxLayout(self)

        if opensave:
            # self.topleft = make_frame(parent)
            # self.topLeftLayout = make_grid(self.topleft)
            self.topright = make_frame(self.parent)
            self.topRightLayout = make_grid(self.topright)
            # self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
            self.bottom = make_frame(self.parent)
            self.bottomLayout = make_grid(self.bottom)
            self.splitter2 = make_splitter(style='h', widgets=(self.topright, self.bottom))
            if standard:
                self.hbox.addWidget(self.splitter2)

        elif tabbed:
            self.tabs = QtWidgets.QTabWidget()
            self.tabs.setStyleSheet(TAB_STYLE)
            self.hbox.addWidget(self.tabs)
        self.setLayout(self.hbox)

        # menu_bar(self)

    def __init__(self, parent, title, icon):
        super(SubMenu, self).__init__()
        self.parent = parent
        self.setStyleSheet(qss.format_qss(qss.window + qss.widget, self.parent.palette))
        self.title = title
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.hbox = QtWidgets.QGridLayout(self)
        self.isPinned = False
        self.frame, self._layout = self.parent.menuBuilder.subdivision(self)
        self.frameS, self._layoutS = self.parent.menuBuilder.subdivision(self)
        self.hbox.addWidget(self.frame, 0, 0)
        self.hbox.addWidget(self.frameS, 1, 0)
        self.setLayout(self.hbox)
        self.statusbar = self.parent.menuBuilder.make_statusbar(self, self._layoutS, 0, 1)
        self.pinButton = self.parent.menuBuilder.make_button(
            self, layout=self._layoutS, command=self.pin, row=0,
            column=0, width=25, height=25, icon=icons.pin,
            tooltip=tooltips.pinButton
        )

    def pin(self):
        self.isPinned = not self.isPinned
        if self.isPinned:
            self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
            self.pinButton.setStyleSheet(qss.format_qss(qss.buttonConnected, self.parent.palette))
            self.update_status('Window pinned.', qss.statusbarSuccess)
        else:
            self.setWindowFlags(self.windowFlags() & ~QtCore.Qt.WindowStaysOnTopHint)
            self.pinButton.setStyleSheet(qss.format_qss(qss.button, self.parent.palette))
            self.update_status('Window unpinned.', qss.statusbarSuccess)
        self.show()

    def update_status(self, msg, stylesheet):
        self.statusbar.showMessage(msg)
        self.statusbar.adjustSize()
        self.statusbar.setStyleSheet(qss.format_qss(stylesheet, self.parent.palette))
        self.parent.update_status('{}: {}'.format(self.title.upper(), msg), stylesheet)

    def __init__(self, parent, title, icon):
        super(SubMenu, self).__init__()
        self.parent = parent
        self.setStyleSheet(qss.WINDOW_STYLE + qss.WIDGET_STYLE)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.hbox = QtWidgets.QHBoxLayout(self)
        self.pinButton = menus.make_button(
            self, layout=self.hbox, command=self.pin, row=0, column=0, width=25,
            icon=icons.PIN_ICON, )
        self.isPinned = False
        self.frame, self._layout = menus.make_subdivision(self)
        self.hbox.addWidget(self.frame)
        self.setLayout(self.hbox)

    def pin(self):
        if self.isPinned:
            self.setWindowFlags(self.windowFlags() & ~QtCore.Qt.WindowStaysOnTopHint)
            self.pinButton.setStyleSheet(qss.BUTTON_STYLE)
            self.isPinned = False
        else:
            self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
            self.pinButton.setStyleSheet(qss.PINNED_BUTTON_STYLE)
            self.isPinned = True
        self.show()

    def __init__(self, parent, title, icon, standard=True):
        self.parent = parent
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.resize(350, 400)
        self.hbox = QtWidgets.QHBoxLayout(self)
        self.topleft = make_frame(parent)
        self.topLeftLayout = make_grid(self.topleft)
        self.topright = make_frame(parent)
        self.topRightLayout = make_grid(self.topright)
        self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
        self.bottom = make_frame(parent)
        self.bottomLayout = make_grid(self.bottom)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))
        if standard:
            self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)
        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        self.bottom.setMinimumSize(WIDTH / 4, HEIGHT / 4)

    def __init__(self, parent, title, icon, opensave=True, standard=True, tabbed=False):
        self.parent = parent
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        # self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        # self.resize(WIDTH / 1, HEIGHT / 1)
        self.hbox = QtWidgets.QHBoxLayout(self)
        if opensave:
            self.topleft = make_frame(parent)
            self.topLeftLayout = make_grid(self.topleft)
            self.topright = make_frame(parent)
            self.topRightLayout = make_grid(self.topright)
            self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
            self.bottom = make_frame(parent)
            self.bottomLayout = make_grid(self.bottom)
            self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))
            if standard:
                self.hbox.addWidget(self.splitter2)
            self.setLayout(
                self.hbox
            )  # self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 5)  # set_widget_size(self.topright, WIDTH / 6, HEIGHT / 5)  # self.bottom.setMinimumSize(WIDTH / 3, HEIGHT / 3)
        elif tabbed:
            self.tabs = QtWidgets.QTabWidget()
            self.tabs.setStyleSheet(TAB_STYLE)
            self.hbox.addWidget(self.tabs)

            # menubar = QtWidgets.QMenuBar()  # menubar.setStyleSheet(MENUBAR_STYLE)  # self.file_dropdown(menubar)

    def export_results(self):
        try:
            formats = [x.text() for x in self.exportFormats.selectedItems()]
            if len(formats) == 0:
                QMessageBox.critical(self, "No Selection", "Select a format.", QMessageBox.Ok)
            else:
                print(formats)
        except Exception as e:
            print(e)

    def __init__(self, parent, title, icon, standard=True):
        self.parent = parent
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.resize(350, 400)
        self.hbox = QtWidgets.QHBoxLayout(self)

        if standard == True:
            self.topleft = make_frame(parent)
            self.topLeftLayout = make_grid(self.topleft)

            self.topright = make_frame(parent)
            self.topRightLayout = make_grid(self.topright)

            self.bottom = make_frame(parent)
            self.bottomLayout = make_grid(self.bottom)

            self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
            self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))

            self.hbox.addWidget(self.splitter2)
            self.setLayout(self.hbox)
            self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
            menu.set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
            self.bottom.setMinimumSize(WIDTH / 4, HEIGHT / 4)

    def __init__(self, parent, title, icon, standard=True):
        self.parent = parent
        super(SubMenu, self).__init__()
        self.setStyleSheet(WINDOW_STYLE + WIDGET_STYLE)
        # self.setWindowFlags(QtCore.Qt.WindowStaysOnTopHint)
        self.setWindowTitle(title)
        self.icon = QtGui.QIcon(icon)
        self.setWindowIcon(self.icon)
        self.resize(WIDTH / 2, HEIGHT / 2)
        self.hbox = QtWidgets.QHBoxLayout(self)
        self.topleft = make_frame(parent)
        self.topLeftLayout = make_grid(self.topleft)
        self.topright = make_frame(parent)
        self.topRightLayout = make_grid(self.topright)
        self.splitter1 = make_splitter(style='h', widgets=(self.topleft, self.topright))
        self.bottom = make_frame(parent)
        self.bottomLayout = make_grid(self.bottom)
        self.splitter2 = make_splitter(style='v', widgets=(self.splitter1, self.bottom))
        if standard:
            self.hbox.addWidget(self.splitter2)
        self.setLayout(self.hbox)
        self.topleft.setMinimumSize(WIDTH / 6, HEIGHT / 8)
        set_widget_size(self.topright, WIDTH / 6, HEIGHT / 8)
        self.bottom.setMinimumSize(WIDTH / 4, HEIGHT / 4)

        menubar = QtWidgets.QMenuBar()
        menubar.setStyleSheet(MENUBAR_STYLE)
        self.file_dropdown(menubar)


class TasksMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        """TOP LEFT"""
        # FILES TO READ
        self.readLabel = QtWidgets.QLabel('')
        openFolderIcon = QtGui.QIcon(OPEN_FOLDER_ICON)
        self.readButton = QtWidgets.QPushButton(openFolderIcon, '', self)
        self.readButton.setStyleSheet(BUTTON_STYLE)
        self.readButton.setIconSize(QtCore.QSize(20, 20))
        menu.set_widget_size(self.readButton, 5, 20)
        self.readButton.clicked.connect(lambda: menu.open_files(self, multiple=True, label=self.readLabel))
        self.topLeftLayout.addWidget(self.readButton, 0, 0)
        self.topLeftLayout.addWidget(self.readLabel, 0, 1)

        # FILE TO SAVE
        self.saveLabel = QtWidgets.QLabel('')
        saveFileIcon = QtGui.QIcon(SAVE_FILE_ICON)
        self.saveButton = QtWidgets.QPushButton(saveFileIcon, '', self)
        self.saveButton.setStyleSheet(BUTTON_STYLE)
        self.saveButton.setIconSize(QtCore.QSize(20, 20))
        menu.set_widget_size(self.saveButton, 5, 20)
        self.saveButton.clicked.connect(lambda: menu.save_file(self, label=self.saveLabel))
        self.topLeftLayout.addWidget(self.saveButton, 1, 0)
        self.topLeftLayout.addWidget(self.saveLabel, 1, 1)

        """TOP RIGHT"""
        # RUN BUTTON
        self.runButton = make_button(self, lambda: menu.save_file(self), 'Run')
        self.topRightLayout.addWidget(self.runButton, 4, 0)


class WebScrapingMenu(SubMenu):
    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.urlLabel = make_label(
            self, text='URL:', layout=self.topLeftLayout, row=0, column=0, width=50,
            description=URL_DESCRIPTION
        )
        self.urlEntry = make_entry(
            self, layout=self.topLeftLayout, row=0, column=1, width=200,
            description=URL_DESCRIPTION
        )
        self.tokenLabel = make_label(
            self, text='Token:', layout=self.topLeftLayout, row=1, column=0, width=50,
            description=TOKEN_DESCRIPTION
        )
        self.tokenEntry = make_entry(
            self, layout=self.topLeftLayout, row=1, column=1, width=200,
            description=TOKEN_DESCRIPTION
        )
        """TOP RIGHT"""
        self.paragraphsLabel = make_label(
            self, text='Paragraphs:', layout=self.topRightLayout, row=1, column=0,
            description=PARAGRAPHS_DESCRIPTION
        )
        self.paragraphsCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=1,
            description=PARAGRAPHS_DESCRIPTION
        )
        self.tablesLabel = make_label(
            self, text='Tables:', layout=self.topRightLayout, row=1, column=2,
            description=TABLES_DESCRIPTION
        )
        self.tablesCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=3,
            description=TABLES_DESCRIPTION
        )
        self.imagesLabel = make_label(
            self, text='Images:', layout=self.topRightLayout, row=2, column=0,
            description=IMAGES_DESCRIPTION
        )
        self.imagesCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=2, column=1,
            description=IMAGES_DESCRIPTION
        )
        self.javascriptLabel = make_label(
            self, text='Javascript:', layout=self.topRightLayout, row=2, column=2,
            description=JAVASCRIPT_DESCRIPTION
        )
        self.javascriptCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=2, column=3,
            description=JAVASCRIPT_DESCRIPTION
        )
        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=4,
            column=0
        )
        self.siteContainer = make_browser(layout=self.bottomLayout, file=None)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.urlLabel = make_label(
            self, text='URL:', layout=self.topLeftLayout, row=0, column=0, width=50,
            description=URL_DESCRIPTION
        )
        self.urlEntry = make_entry(
            self, layout=self.topLeftLayout, row=0, column=1, width=200,
            description=URL_DESCRIPTION
        )
        self.tokenLabel = make_label(
            self, text='Token:', layout=self.topLeftLayout, row=1, column=0, width=50,
            description=TOKEN_DESCRIPTION
        )
        self.tokenEntry = make_entry(
            self, layout=self.topLeftLayout, row=1, column=1, width=200,
            description=TOKEN_DESCRIPTION
        )

        """TOP RIGHT"""
        self.paragraphsLabel = make_label(
            self, text='Paragraphs:', layout=self.topRightLayout, row=1, column=0,
            description=PARAGRAPHS_DESCRIPTION
        )
        self.paragraphsCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=1,
            description=PARAGRAPHS_DESCRIPTION
        )
        self.tablesLabel = make_label(
            self, text='Tables:', layout=self.topRightLayout, row=1, column=2,
            description=TABLES_DESCRIPTION
        )
        self.tablesCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=3,
            description=TABLES_DESCRIPTION
        )
        self.runButton = make_button(
            self, command=lambda: self.run(), text='Run', layout=self.topRightLayout, row=4,
            column=0
        )

        self.siteContainer = make_browser(layout=self.bottomLayout, file=None)
        self.bottomLayout.addWidget(self.siteContainer)

    def __init__(self, parent, title, icon):
        SubMenu.__init__(self, parent, title, icon)
        self.urlLabel = make_label(
            self, text='URL:', layout=self.topLeftLayout, row=0, column=0, width=50,
            description=URL_DESCRIPTION
        )
        self.urlEntry = make_entry(
            self, layout=self.topLeftLayout, row=0, column=1, width=200,
            description=URL_DESCRIPTION
        )
        self.tokenLabel = make_label(
            self, text='Token:', layout=self.topLeftLayout, row=1, column=0, width=50,
            description=TOKEN_DESCRIPTION
        )
        self.tokenEntry = make_entry(
            self, layout=self.topLeftLayout, row=1, column=1, width=200,
            description=TOKEN_DESCRIPTION
        )

        """TOP RIGHT"""
        self.paragraphsLabel = make_label(
            self, text='Paragraphs:', layout=self.topRightLayout, row=1, column=0,
            description=PARAGRAPHS_DESCRIPTION
        )
        self.paragraphsCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=1,
            description=PARAGRAPHS_DESCRIPTION
        )
        self.tablesLabel = make_label(
            self, text='Tables:', layout=self.topRightLayout, row=1, column=2,
            description=TABLES_DESCRIPTION
        )
        self.tablesCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=1, column=3,
            description=TABLES_DESCRIPTION
        )
        self.imagesLabel = make_label(
            self, text='Images:', layout=self.topRightLayout, row=2, column=0,
            description=IMAGES_DESCRIPTION
        )
        self.imagesCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=2, column=1,
            description=IMAGES_DESCRIPTION
        )
        self.javascriptLabel = make_label(
            self, text='Javascript:', layout=self.topRightLayout, row=2, column=2,
            description=JAVASCRIPT_DESCRIPTION
        )
        self.javascriptCheck = make_button(
            self, type='check', layout=self.topRightLayout, row=2, column=3,
            description=JAVASCRIPT_DESCRIPTION
        )

        self.runButton = make_button(self, command=self.run, text='Run', layout=self.topRightLayout, row=4, column=0)

        self.siteContainer = make_browser(layout=self.bottomLayout, file=None)

    def run(self):
        soup = lib.data_api.html_api.html_apicrawl.get_soup(self.urlEntry.text())
        paragraphs = lib.data_api.html_api.html_apicrawl.get_paragraphs(soup)
        lib.data_api.html_api.html_apicrawl.formatter(self.tokenEntry.text(), paragraphs)
        self.siteContainer = load_browser(self.siteContainer, file=self.urlEntry.text(), online=True)

    def __init__(self, parent, title, icon2):
        SubMenu.__init__(self, parent, title, icon2)
        self.urlLabel = make_label(
            self, text='URL:', layout=self.topLeftLayout,
            row=0, column=0, width=50,
            description=URL_DESCRIPTION
        )
        self.urlEntry = make_entry(
            self, layout=self.topLeftLayout,
            row=0, column=1, width=200,
            description=URL_DESCRIPTION
        )
        self.tokenLabel = make_label(
            self, text='Token:', layout=self.topLeftLayout,
            row=1, column=0, width=50,
            description=TOKEN_DESCRIPTION
        )
        self.tokenEntry = make_entry(
            self, layout=self.topLeftLayout,
            row=1, column=1, width=200,
            description=TOKEN_DESCRIPTION
        )
        """TOP RIGHT"""
        self.paragraphsLabel = make_label(
            self, text='Paragraphs:', layout=self.topRightLayout,
            row=1, column=0,
            description=PARAGRAPHS_DESCRIPTION
        )
        self.paragraphsCheck = make_button(
            self, type='check', layout=self.topRightLayout,
            row=1, column=1,
            description=PARAGRAPHS_DESCRIPTION
        )
        self.tablesLabel = make_label(
            self, text='Tables:', layout=self.topRightLayout,
            row=1, column=1,
            description=TABLES_DESCRIPTION
        )
        self.tablesCheck = make_button(
            self, type='check', layout=self.topRightLayout,
            row=1, column=2,
            description=TABLES_DESCRIPTION
        )
        self.imagesLabel = make_label(
            self, text='Images:', layout=self.topRightLayout,
            row=1, column=0,
            description=IMAGES_DESCRIPTION
        )
        self.imagesCheck = make_button(
            self, type='check', layout=self.topRightLayout,
            row=1, column=1,
            description=IMAGES_DESCRIPTION
        )
        self.javascriptLabel = make_label(
            self, text='Javascript:', layout=self.topRightLayout,
            row=1, column=1,
            description=JAVASCRIPT_DESCRIPTION
        )
        self.javascriptCheck = make_button(
            self, type='check', layout=self.topRightLayout,
            row=1, column=2,
            description=JAVASCRIPT_DESCRIPTION
        )
        self.runButton = make_button(
            self, command=self.run, text='Run', layout=self.topRightLayout,
            row=3, column=0
        )
        self.siteContainer = make_browser(layout=self.bottomLayout, file=None)

    def run(self):
        from Utilities14 import WebScrapingHandler
        soup = WebScrapingHandler.get_soup(self.urlEntry.text())
        paragraphs = WebScrapingHandler.get_paragraphs(soup)
        WebScrapingHandler.formatter(self.tokenEntry.text(), paragraphs)
        self.siteContainer = load_browser(self.siteContainer, file=self.urlEntry.text(), online=True)

"""

import os

# MAIN MENU
icon = 'icon'
MAIN_MENU = os.path.join(icon, 'MainMenuICON')
CLASSIFICATION_ICON = os.path.join(MAIN_MENU, 'classification_labeled.png')
CLUSTERING_ICON = os.path.join(MAIN_MENU, 'MainMenuClustering.png')
DATABASE_ICON = os.path.join(MAIN_MENU, 'database_labeled.png')
DIMENSIONALITY_ICON = os.path.join(MAIN_MENU, 'MainMenuDimensionality.png')
DOCUMENTATION_ICON = os.path.join(MAIN_MENU, 'documentation_labeled.png')
REGRESSION_ICON = os.path.join(MAIN_MENU, 'regression_labeled.png')
SEARCH_ICON = os.path.join(MAIN_MENU, 'search_labeled.png')
SIMULATION_ICON = os.path.join(MAIN_MENU, 'MainMenuSimulation.png')
STATISTICS_ICON = os.path.join(MAIN_MENU, 'statistics_labeled.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
CLASSIFICATION_ICON = os.path.join(icon, 'classification0.png')
DATABASE_ICON = os.path.join(icon, 'database.png')
DOCUMENTATION_ICON = os.path.join(icon, '1.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
MCMC_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
REGRESSION_ICON = os.path.join(icon, 'Regression6.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
SEARCH_ICON = os.path.join(icon, 'interface7.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DATABASE_ICON = os.path.join(icon, 'database.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
MCMC_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
SEARCH_ICON = os.path.join(icon, 'interface7.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
# MAIN MENU
MAIN_MENU = os.path.join(icon, 'MainMenuIcons')
CLASSIFICATION_ICON = os.path.join(MAIN_MENU, 'classification_labeled.png')
CLUSTERING_ICON = os.path.join(MAIN_MENU, 'MainMenuClustering.png')
DATABASE_ICON = os.path.join(MAIN_MENU, 'database_labeled.png')
DIMENSIONALITY_ICON = os.path.join(MAIN_MENU, 'MainMenuDimensionality.png')
DOCUMENTATION_ICON = os.path.join(MAIN_MENU, 'documentation_labeled.png')
REGRESSION_ICON = os.path.join(MAIN_MENU, 'regression_labeled.png')
SEARCH_ICON = os.path.join(MAIN_MENU, 'search_labeled.png')
SIMULATION_ICON = os.path.join(MAIN_MENU, 'MainMenuSimulation.png')
STATISTICS_ICON = os.path.join(MAIN_MENU, 'statistics_labeled.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DATABASE_ICON = os.path.join(icon, 'database.png')
DOCUMENTATION_ICON = os.path.join(icon, '1.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
MCMC_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
SEARCH_ICON = os.path.join(icon, 'interface7.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
CLASSIFICATION_ICON = os.path.join(icon, 'classification0.png')
DATABASE_ICON = os.path.join(icon, 'database.png')
DOCUMENTATION_ICON = os.path.join(icon, '1.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
MCMC_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
REGRESSION_ICON = os.path.join(icon, 'Regression6.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
SEARCH_ICON = os.path.join(icon, 'interface7.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
# MAIN MENU
MAIN_MENU = os.path.join(icon, 'MainMenuIcons')
CLASSIFICATION_ICON = os.path.join(MAIN_MENU, 'classification_labeled.png')
DATABASE_ICON = os.path.join(MAIN_MENU, 'database_labeled.png')
DOCUMENTATION_ICON = os.path.join(MAIN_MENU, 'documentation_labeled.png')
REGRESSION_ICON = os.path.join(MAIN_MENU, 'regression_labeled.png')
SEARCH_ICON = os.path.join(MAIN_MENU, 'search_labeled.png')
STATISTICS_ICON = os.path.join(MAIN_MENU, 'statistics_labeled.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
SIMULATION_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
CLASSIFICATION_ICON = os.path.join(icon, 'classification0.png')
DATABASE_ICON = os.path.join(icon, 'database.png')
DOCUMENTATION_ICON = os.path.join(icon, '1.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
MCMC_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
REGRESSION_ICON = os.path.join(icon, 'Regression6.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
SEARCH_ICON = os.path.join(icon, 'interface7.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DATABASE_ICON = os.path.join(icon, 'database.png')
DOCUMENTATION_ICON = os.path.join(icon, '1.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
MCMC_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
SEARCH_ICON = os.path.join(icon, 'interface7.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
# MAIN MENU
MAIN_MENU = os.path.join(icon, 'MainMenuIcons')
CLASSIFICATION_ICON = os.path.join(MAIN_MENU, 'classification_labeled.png')
DATABASE_ICON = os.path.join(MAIN_MENU, 'database_labeled.png')
DOCUMENTATION_ICON = os.path.join(MAIN_MENU, 'documentation_labeled.png')
REGRESSION_ICON = os.path.join(MAIN_MENU, 'regression_labeled.png')
SEARCH_ICON = os.path.join(MAIN_MENU, 'search_labeled.png')
STATISTICS_ICON = os.path.join(MAIN_MENU, 'statistics_labeled.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
SIMULATION_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
CLASSIFICATION_ICON = os.path.join(icon, 'classification0.png')
DATABASE_ICON = os.path.join(icon, 'database.png')
DOCUMENTATION_ICON = os.path.join(icon, '1.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
MCMC_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
REGRESSION_ICON = os.path.join(icon, 'Regression6.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
SEARCH_ICON = os.path.join(icon, 'interface7.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
MAIN_MENU = os.path.join(icon, 'MainMenuIcons')
CLASSIFICATION_ICON = os.path.join(MAIN_MENU, 'classification_labeled.png')
DATABASE_ICON = os.path.join(MAIN_MENU, 'database_labeled.png')
DOCUMENTATION_ICON = os.path.join(MAIN_MENU, 'documentation_labeled.png')
REGRESSION_ICON = os.path.join(MAIN_MENU, 'regression_labeled.png')
SEARCH_ICON = os.path.join(MAIN_MENU, 'search_labeled.png')
STATISTICS_ICON = os.path.join(MAIN_MENU, 'statistics_labeled.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
SIMULATION_ICON = os.path.join(icon, 'simulation.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
WEB_SCRAPING_ICON = os.path.join(icon, 'webScraping.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DATABASE_ICON = os.path.join(icon, 'database.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
SEARCH_ICON = os.path.join(icon, 'interface7.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
BACKGROUND_IMAGE = os.path.join(icon, 'background.png')
DATABASE_ICON = os.path.join(icon, 'database.png')
DOWN_ARROW_ICON = os.path.join(icon, 'downArrow.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
GEO_SEARCH_ICON = os.path.join(icon, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(icon, 'machineLearning.png')
OPEN_FILE_ICON = os.path.join(icon, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(icon, 'saveFolder.png')
SEARCH_ICON = os.path.join(icon, 'interface7.png')
WINDOW_ICON = os.path.join(icon, 'window.png')
btnSz = '96w'
# MAIN MENU
BACKGROUND_IMG = os.path.join(icon, 'background.png')
cSETRLogo = os.path.join(icon, 'csetr-logo.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
book = os.path.join(icon, '11-Content', '02-Books', '48w', 'book-close')
wifi = os.path.join(icon, '05-Internet-Networks-Servers', '02-Wifi', '512w', 'wifi')
help = os.path.join(icon, '01-interface7 Essential', '16-Help2', '512w', 'question-help-circle')
deviceExchange = os.path.join(
    icon, '20-Phones-Mobile-Devices', '15-Connect-Devices', '512w',
    'connect-device-exchange'
)
medicalCross = os.path.join(icon, '35-Health-Beauty', '08-Medical-Apps', '512w', 'medical-app-smartphone')
imu = os.path.join(icon, '01-interface7 Essential', '17-stats0', '512w', 'graph2-stats0')
pin = os.path.join(icon, '01-interface7 Essential', '31-Pin', btnSz, 'pin')
settings = os.path.join(icon, '01-interface7 Essential', '03-Menu', '48w', 'navigation-menu-vertical')
bookShelf = os.path.join(icon, '11-Content', '02-Books', '512w', 'book-library-shelf')
battery = os.path.join(icon, '20-Phones-Mobile-Devices', '17-Charging-Battery', '512w', 'charging-battery-full-1')
sensor = os.path.join(icon, '30-Tools-Construction', '08-Equipment', '512w', 'equipment-pressure-measure')
downArrow = os.path.join(icon, '05-Internet-Networks-Servers', '08-Upload-Download', btnSz, 'download-arrow-1')
refreshButton = os.path.join(icon, '01-interface7 Essential', '42-Multimedia-Controls', btnSz, 'button-refresh-arrows')
exportButton = os.path.join(icon, '19-Emails', '06-Drawers', btnSz, 'drawer-send')
cube = os.path.join(icon, '12-Design', '06-Shapes', '512w', 'shape-cube')
lockClosed = os.path.join(icon, '01-interface7 Essential', '11-Lock-Unlock', btnSz, 'lock-1')
lockOpen = os.path.join(icon, '01-interface7 Essential', '11-Lock-Unlock', btnSz, 'lock-unlock')
add = os.path.join(icon, '01-interface7 Essential', '43-Remove-Add', btnSz, 'add-circle-bold')
connected = os.path.join(icon, '01-interface7 Essential', '47-Connect', btnSz, 'flash-1')
disconnected = os.path.join(icon, '01-interface7 Essential', '47-Connect', btnSz, 'flash-off')
btnSz = '48w'
# MAIN MENU
BACKGROUND_IMG = os.path.join(icon, 'background.png')
cSETRLogo = os.path.join(icon, 'csetr-logo.png')
EXIT_ICON = os.path.join(icon, 'exit.png')
OPEN_FOLDER_ICON = os.path.join(icon, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(icon, 'saveFile.png')
wifi = os.path.join(icon, '05-Internet-Networks-Servers', '02-Wifi', '48w', 'wifi')
help = os.path.join(icon, '01-Interface Essential', '16-Help', '48w', 'question-help-circle')
deviceExchange = os.path.join(icon, '20-Phones-Mobile-Devices', '15-Connect-Devices', '48w', 'connect-device-exchange')
medicalCross = os.path.join(icon, '35-Health-Beauty', '08-Medical-Apps', '48w', 'medical-app-smartphone')
imu = os.path.join(icon, '01-Interface Essential', '17-stats', '48w', 'graph-stats')
pin = os.path.join(icon, '01-Interface Essential', '31-Pin', btnSz, 'pin')
settings = os.path.join(icon, '01-Interface Essential', '03-Menu', '48w', 'navigation-menu-vertical')
bookShelf = os.path.join(icon, '11-Content', '02-Books', '48w', 'book-library-shelf')
battery = os.path.join(icon, '20-Phones-Mobile-Devices', '17-Charging-Battery', '48w', 'charging-battery-full-1')
sensor = os.path.join(icon, '30-Tools-Construction', '08-Equipment', '48w', 'equipment-pressure-measure')
refreshButton = os.path.join(icon, '01-Interface Essential', '42-Multimedia-Controls', btnSz, 'button-refresh-arrows')
cube = os.path.join(icon, '12-Design', '06-Shapes', '48w', 'shape-cube')
lockClosed = os.path.join(icon, '01-Interface Essential', '11-Lock-Unlock', btnSz, 'lock-1')
lockOpen = os.path.join(icon, '01-Interface Essential', '11-Lock-Unlock', btnSz, 'lock-unlock')
add = os.path.join(icon, '01-Interface Essential', '43-Remove-Add', btnSz, 'add-circle-bold')
connected = os.path.join(icon, '01-Interface Essential', '47-Connect', btnSz, 'flash-1')
disconnected = os.path.join(icon, '01-Interface Essential', '47-Connect', btnSz, 'flash-off')
scenarioGenerator = os.path.join(icon, '01-Interface Essential', '13-Controls', btnSz, 'settings-slider-alternate')
# MAIN MENU
CLASSIFICATION_DESCRIPTION = 'Classification: Classify data.'
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
DOCUMENTATION_DESCRIPTION = '1: Browse detailed descriptions and tutorials of each module.'
EXIT_DESCRIPTION = 'Exit application.'
GEO_SEARCH_DESCRIPTION = 'Geographic search: Explore your database and produce geographical information system visualizations.'
MCMC_DESCRIPTION = 'Markov Chain Monte Carlo: Develop Monte Carlo simulations based on Transition Matrices and Markov Chains'
OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
REGRESSION_DESCRIPTION = 'Regression6: Perform Regression6 analysis on your data and visualize your results.'
SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SEARCH_DESCRIPTION = 'search Engine: Navigate your database and specify criteria for extracting data.'
WEB_SCRAPING_DESCRIPTION = 'Web Scraping: Gather and analyze information from the web.'

# CLASSIFICATION DESCRIPTION
CLASS_COMBO_DESCRIPTION = 'Data column to use as object_oriented.'
NAIVE_BAYES_DESCRIPTION = 'Naive Bayes:'
QDA_DESCRIPTION = 'Quadratic Discriminant Analysis:'

# REGRESSION MENU
AB_DESCRIPTION = 'Adaptive Boosting:\n' \
                 'An AdaBoost regressor is a \n' \
                 'meta-estimator that begins by fitting a regressor\n' \
                 'on the original dataset and then fits additional\n' \
                 'copies of the regressor on the same dataset but\n' \
                 'where the weights of instances are adjusted\n' \
                 'according to the error of the current prediction.\n' \
                 'As such, subsequent regressors focus more on\n' \
                 'difficult cases.'
AUTOMATIC_TUNING_DESCRIPTION = 'Tune each machine learning parameter\n' \
                               'automatically through a genetic\n' \
                               'grid interface7 cross validation algorithm.'
D_TREE_DESCRIPTION = 'Decision Tree:\n' \
                     'Creates a model that predicts the value of a target\n' \
                     'variable by learning simple decision rules inferred\n' \
                     'from the data features.'
E_NET_DESCRIPTION = 'Elastic Net:\n' \
                    'Linear Model trained with L1 and L2 prior as regularizer.'
K_NEIGHBORS_DESCRIPTION = 'K Nearest Neighbors:\n' \
                          'The target is predicted by local interpolation of\n' \
                          'the targets associated of the nearest neighbors in\n' \
                          'the training set.'
K_RIDGE_DESCRIPTION = 'K Ridge:\n' \
                      'Kernel ridge Regression6 (KRR) combines ridge Regression6\n' \
                      '(linear least squares with l2-norm regularization) with\n' \
                      'the kernel trick. It thus learns a linear function in\n' \
                      'the space induced by the respective kernel and the data.\n' \
                      'For non-linear kernels, this corresponds to a non-linear\n' \
                      'function in the original space.\n' \
                      'The form of the model learned by KRR is identical to support\n' \
                      'vector Regression6 (SVR). However, different loss functions\n' \
                      'are used: KRR uses squared error loss while support vector\n' \
                      'Regression6 uses epsilon-insensitive loss, both combined with\n' \
                      'l2 regularization. In contrast to SVR, fitting a KRR model\n' \
                      'can be done in closed-form and is typically faster for\n' \
                      'medium-sized datasets. On the search hand, the learned model\n' \
                      'is non-sparse and thus slower than SVR, which learns a sparse\n' \
                      'model for epsilon > 0, at prediction-time.'
MLP_DESCRIPTION = 'Multilayer Perceptron Neural Network:\n' \
                  'This model optimizes the squared-loss using LBFGS\n' \
                  'or stochastic gradient descent.'
R_FOREST_DESCRIPTION = 'Random Forest:\n' \
                       'A random forest is a meta estimator that fits a number\n' \
                       'of classifying decision trees on various sub-samples\n' \
                       'of the dataset and use averaging to improve the predictive\n' \
                       'accuracy and control over-fitting. The sub-sample size is\n' \
                       'always the same as the original input sample size but the\n' \
                       'samples are drawn with replacement if bootstrap2=True (default).'
RUN_CLASSIFICATION_DESCRIPTION = 'Run classification0 analysis.'
RUN_MACHINE_LEARNING_DESCRIPTION = 'Run analysis.'
RUN_REGRESSION_DESCRIPTION = 'Run Regression6 analysis.'
SVM_DESCRIPTION = 'Support Vector Machine:\n' \
                  'Epsilon-Support Vector Regression6.\n' \
                  'The free parameters in the model are C and epsilon.\n' \
                  'The implementation is based on libsvm.'
RBM_DESCRIPTION = ''
SGD_DESCRIPTION = ''

# DATABASE MENU
DATABASE_APPLY_BUTTON_DESCRIPTION = 'Use these settings throughout the entire software.'
ENCODING_DESCRIPTION = 'Encoding of files in database.'
INDEX_COLUMN_DESCRIPTION = 'Column containing index labels.'
LATITUDE_COLUMN_DESCRIPTION = 'Column containing latitude information.'
LONGITUDE_COLUMN_DESCRIPTION = 'Column containing longitude information.'

# SEARCH MENU
CLEAR_BUTTON_DESCRIPTION = 'Clear all interface7 criteria.'
EXCEL_EXPORT_DESCRIPTION = 'Export results in Excel .xlsx format.'
HTML_EXPORT_DESCRIPTION = 'Export results in HTML2 format.'
PDF_EXPORT_DESCRIPTION = 'Export results in PDF format.'
RUN_SEARCH_DESCRIPTION = 'search database.'
TXT_EXPORT_DESCRIPTION = 'Export results in text format compatible with .txt, .csv, .dat'

# MARKOV CHAIN MONTE CARLO MENU
CENTRAL_COMPOSITE_DESCRIPTION = 'Sample data using central composite method.'
COLUMN_COMBO_DESCRIPTION = 'Database column to use.'
INDEX_COMBO_DESCRIPTION = 'Database column to use as index.'
INITIAL_STATE_DESCRIPTION = 'Initial state for simulation.'
ITERATIONS_DESCRIPTION = 'Number of iterations to run simulation.'
LATIN_HYPERCUBES_DESCRIPTION = 'Sample data using latin hypercubes method.'
PARALLEL_DESCRIPTION = 'Read data across columns as in parallel.'
RUN_MARKOV_CHAIN_DESCRIPTION = 'Develop Transition Matrix and Markov Chains.'
RUN_MONTE_CARLO_DESCRIPTION = 'Run Monte Carlo simulation.'
SERIES_DESCRIPTION = 'Read data throughout columns as in series.'

# GEOGRAPHIC SEARCH MENU
LATITUDE_DESCRIPTION = 'Latitude component of the interface7 centroid coordinate.'
LONGITUDE_DESCRIPTION = 'Longitude component of the interface7 centroid coordinate.'
RADIUS_DESCRIPTION = 'Distance from interface7 centroid coordinate for which to interface7 in.'
RUN_GEOSEARCH_DESCRIPTION = 'Run interface7.'
UNITS_DESCRIPTION = 'Units to calculate distance in.'

# WEB SCRAPING MENU
IMAGES_DESCRIPTION = 'Scrapes all image tags'
JAVASCRIPT_DESCRIPTION = 'Scrapes all javascript on page '
LINKS_DESCRIPTION = 'Extract links.'
PARAGRAPHS_DESCRIPTION = 'Extract paragraphs.'
PHOTOS_DESCRIPTION = 'Extract photographs.'
URL_DESCRIPTION = 'Url.'
TABLES_DESCRIPTION = 'Extract data tables.'
TOKEN_DESCRIPTION = 'Token to interface7 for.'

# SVM PARAMETERS
C_DESCRIPTION = 'C:\n' \
                'float, optional (default=1.0).\n' \
                'Penalty parameter C of the error term.'
CACHE_SIZE_DESCRIPTION = 'Cache Size:\n' \
                         'float, optional.\n' \
                         'Specify the size of the kernel cache (in MB).'
COEF0_DESCRIPTION = 'Coefficient 0:\n' \
                    'float, optional (default=0.0).\n' \
                    'Independent term in kernel function.\n' \
                    'It is only significant in poly and sigmoid.'
DEGREE_DESCRIPTION = 'Polynomial Degree:\n' \
                     'int, optional (default=2).\n' \
                     'Degree of the polynomial kernel\n' \
                     'function (poly). Ignored by all\nsearch kernels.'
EPSILON_DESCRIPTION = 'Epsilon:\n' \
                      'float, optional (default=0.1).\n' \
                      'Epsilon in the epsilon-SVR model.\n' \
                      'It specifies the epsilon-tube within\n' \
                      'which no penalty is associated in the\n' \
                      'training loss function with points\n' \
                      'predicted within a distance epsilon\n' \
                      'from the actual value.'
GAMMA_DESCRIPTION = 'Gamma:\n' \
                    'float, optional (default=auto).\n' \
                    'Kernel coefficient for rbf, poly\n' \
                    'and sigmoid. If gamma is auto then\n' \
                    '1/n_features will be used instead.'
KERNEL_DESCRIPTION = 'Kernel:\n' \
                     'string, optional (default=rbf).\n' \
                     'Specifies the kernel type to be used\n' \
                     'in the algorithm. It must be one of\n' \
                     'linear, poly, rbf, sigmoid,\n' \
                     'precomputed or a callable. If none\n' \
                     'is given, rbf will be used. If a\n' \
                     'callable is given it is used to\n' \
                     'precompute the kernel matrix.'
MAX_ITER_DESCRIPTION = 'Maximum Iterations:\n' \
                       'int, optional (default=-1).\n' \
                       'Hard limit on iterations within\n' \
                       'solver, or -1 for no limit.'
SHRINKING_DESCRIPTION = 'Shrinking:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether to use the shrinking heuristic.'
TOL_DESCRIPTION = 'Tolerance:\n' \
                  'float, optional (default=1e-2)\n' \
                  'Tolerance for stopping criterion.'
VERBOSE_DESCRIPTION = 'Verbose:\n' \
                      'bool, default=False.\n' \
                      'Enable verbose output. Note that this \n' \
                      'setting takes advantage of a per-process\n' \
                      'runtime setting in libsvm that, if\n' \
                      'enabled, may not work properly in a\n' \
                      'multithreaded context.'

# KNN PARAMETERS
ALGORITHM_DESCRIPTION = 'Algorithm:\n' \
                        '{auto, ball_tree, kd_tree, brute}, optional.\n' \
                        'Algorithm used to compute the nearest neighbors:\n' \
                        'ball_tree will use BallTree.\n' \
                        'kd_tree will use KDTree.\n' \
                        'brute will use a brute-force interface7.\n' \
                        'auto will attempt to decide the most appropriate\n' \
                        'algorithm based on the values passed to fit method.\n' \
                        'Note: fitting on sparse input will override the\n' \
                        'setting of this parameter, using brute force.'
LEAF_SIZE_DESCRIPTION = 'Leaf Size:\n' \
                        'int, optional (default = 30).\n' \
                        'Leaf size passed to BallTree or KDTree.\n' \
                        'This can affect the speed of the\n' \
                        'construction and query, as well as\n' \
                        'the memory required to store the tree.\n' \
                        'The optimal value depends on the nature\n' \
                        'of the problem.'
METRIC_DESCRIPTION = 'Metric:\n' \
                     'string or callable, default minkowski.\n' \
                     'The distance metric to use for the tree.\n' \
                     'The default metric is minkowski, and with p=1\n' \
                     'is equivalent to the standard Euclidean metric.\n' \
                     'See the 1 of the DistanceMetric object_oriented\n' \
                     'for a list of available metrics.'
N_JOBS_DESCRIPTION = 'CPU Cores:\n' \
                     'int, optional (default = 1).\n' \
                     'The number of parallel jobs to run for\n' \
                     'neighbors interface7. If -1, then the number\n' \
                     'ofjobs is set to the number of CPU cores.\n' \
                     'Doesnt affect fit method.'
N_NEIGHBORS_DESCRIPTION = 'Number of Neighbors:\n' \
                          'int, optional (default = 5).\n' \
                          'Number of neighbors to use by\n' \
                          'default for kneighbors queries.'
P_DESCRIPTION = 'Minkowski Power:\n' \
                'integer, optional (default = 1).\n' \
                'Power parameter for the Minkowski metric.\n' \
                'When p = 1, this is equivalent to using\n' \
                'manhattan_distance (l1), and\n' \
                'euclidean_distance (l2) for p = 1.\n' \
                'For arbitrary p, minkowski_distance (l_p) is used.'
WEIGHTS_DESCRIPTION = 'Weights Function:\n' \
                      'str or callable, default=uniform.\n' \
                      'weight function used in\n' \
                      'prediction. Possible values:\n' \
                      'uniform: uniform weights. All\n' \
                      'points in each neighborhood are\n' \
                      'weighted equally.\n' \
                      'distance: weight points by the\n' \
                      'inverse of their distance. In this\n' \
                      'case, closer neighbors of a query\n' \
                      'point will have a greater influence\n' \
                      'than neighbors which are further away.'

# K RIDGE PARAMETERS
ALPHA_DESCRIPTION = 'Alpha:\n' \
                    '{float, array-like}, shape = [n_targets].\n' \
                    'Small positive values of alpha improve the\n' \
                    'conditioning of the problem and reduce the\n' \
                    'variance of the estimates. Alpha corresponds\n' \
                    'to (1*C)^-1 in search linear models such as\n' \
                    'LogisticRegression or LinearSVC. If an array\n' \
                    'is passed, penalties are assumed to be specific\n' \
                    'to the targets. Hence they must correspond in number.'

# DECISION TREE PARAMETERS
CRITERION_DESCRIPTION = 'Criterion:\n' \
                        'string, optional (default=mse).\n' \
                        'The function to measure the quality of a split.\n' \
                        'Supported criteria are mse for the mean\n' \
                        'squared error, which is equal to variance\n' \
                        'reduction as feature selection criterion\n' \
                        'and minimizes the L2 loss using the mean\n' \
                        'of each terminal node, friedman_mse, which\n' \
                        'uses mean squared error with Friedmans\n' \
                        'improvement score for potential splits, and\n' \
                        'mae for the mean absolute error, which\n' \
                        'minimizes the L1 loss using the median of\n' \
                        'each terminal node.'
MAX_DEPTH_DESCRIPTION = 'Maximum Depth:\n' \
                        'int or None, optional (default=None).\n' \
                        'The maximum depth of the tree. If None, then\n' \
                        'nodes are expanded until all leaves are pure\n' \
                        'or until all leaves contain less than\n' \
                        'min_samples_split samples.'
MAX_FEATURES_DESCRIPTION = 'Maximum Features:\n' \
                           'int, float, string or None, optional (default=None).\n' \
                           'The number of features to consider when looking for\n' \
                           'the best split:\n' \
                           'If int, then consider max_features features at each split.\n' \
                           'If float, then max_features is a percentage and\n' \
                           'int(max_features * n_features) features are considered\n' \
                           'at each split.\n' \
                           'If auto, then max_features=n_features.\n' \
                           'If sqrt, then max_features=sqrt(n_features).\n' \
                           'If log2, then max_features=log2(n_features).\n' \
                           'If None, then max_features=n_features.\n' \
                           'Note: the interface7 for a split does not stop until at\n' \
                           'least one valid partition of the node samples is\n' \
                           'found, even if it requires to effectively inspect more\n' \
                           'than max_features features.'
MAX_LEAF_NODES_DESCRIPTION = 'Maximum Leaf Nodes:\n' \
                             'int or None, optional (default=None).\n' \
                             'Grow a tree with max_leaf_nodes in\n' \
                             'best-first fashion.\n' \
                             'Best nodes are defined as relative\n' \
                             'reduction in impurity. If None then\n' \
                             'unlimited number of leaf nodes.'
MIN_IMPURITY_DECREASE_DESCRIPTION = 'Minimum Impurity Decrease:\n' \
                                    'float, optional (default=0.).\n' \
                                    'A node will be split if this split\n' \
                                    'induces a decrease of the impurity\n' \
                                    'greater than or equal to this value.\n' \
                                    'The weighted impurity decrease equation\n' \
                                    'is the following:\n' \
                                    'N_t/N*(i-N_t_R/N_t*r_i-N_t_L/N_t*l_i)' \
                                    'where l is left, r is right, i is the\n' \
                                    'impurity, N is the total number of\n' \
                                    'samples, N_t is the number of samples\n' \
                                    'at the current node, N_t_L is the number\n' \
                                    'of samples in the left child, and N_t_R\n' \
                                    'is the number of samples in the right child.' \
                                    'N, N_t, N_t_R and N_t_L all refer to the\n' \
                                    'weighted sum, if sample_weight is passed.'
MIN_SAMPLES_LEAF_DESCRIPTION = 'Minimum Samples at Leaf:\n' \
                               'int, float, optional (default=1).\n' \
                               'The minimum number of samples required\n' \
                               'to be at a leaf node:\n' \
                               'If int, then consider min_samples_leaf\n' \
                               'as the minimum number.\n' \
                               'If float, then min_samples_leaf is a\n' \
                               'percentage and ceil(min_samples_leaf * n_samples)\n' \
                               'are the minimum number of samples for each node.'
MIN_SAMPLES_SPLIT_DESCRIPTION = 'Minimum Samples Split:\n' \
                                'int, float, optional (default=1).\n' \
                                'The minimum number of samples\n' \
                                'required to split an internal node:\n' \
                                'If int, then consider min_samples_split\n' \
                                'as the minimum number.\n' \
                                'If float, then min_samples_split\n' \
                                'is a percentage and\n' \
                                'ceil(min_samples_split * n_samples)\n' \
                                'are the minimum number of samples\n' \
                                'for each split.'
MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION = 'Minimum Sum Weighted Fraction:\n' \
                                       'float, optional (default=0.)\n' \
                                       'The minimum weighted fraction of the\n' \
                                       'sum total of weights (of all the input samples)\n' \
                                       'required to be at a leaf node. Samples have\n' \
                                       'equal weight when sample_weight is not provided.'
PRESORT_DESCRIPTION = 'Presort Data:\n' \
                      'bool, optional (default=False).\n' \
                      'Whether to presort the data to speed\n' \
                      'up the finding of best splits in fitting.\n' \
                      'For the default settings of a decision tree\n' \
                      'on large datasets, setting this to true may\n' \
                      'slow down the training process. When using\n' \
                      'either a smaller dataset or a restricted\n' \
                      'depth, this may speed up the training.'
RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                           'int, RandomState instance or None, optional (default=None).\n' \
                           'If int, random_state is the seed used by the random number\n' \
                           'generator1; If RandomState instance, random_state is the\n' \
                           'random number generator1; If None, the random number\n' \
                           'generator1 is the RandomState instance used by np.random.'
SPLITTER_DESCRIPTION = 'Splitter:\n' \
                       'string, optional (default=best).\n' \
                       'The strategy used to choose the split\n' \
                       'at each node. Supported strategies are\n' \
                       'best to choose the best split and\n' \
                       'random to choose the best random split.'

# RANDOM FOREST
BOOTSTRAP_DESCRIPTION = 'Bootstrap:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether bootstrap2 samples are\n' \
                        'used when building trees.'
N_ESTIMATORS_DESCRIPTION = 'Number of Trees:\n' \
                           'integer, optional (default=10).\n' \
                           'The number of trees in the forest.'
OOB_SCORE_DESCRIPTION = 'Out-of-Bag Samples:\n' \
                        'bool, optional (default=False).\n' \
                        'Whether to use out-of-bag\n' \
                        'samples to estimate the R^1 on\n' \
                        'unseen data.'
WARM_START_DESCRIPTION = 'Warm Start:\n' \
                         'bool, optional (default=False).\n' \
                         'When set to True, reuse the\n' \
                         'solution of the previous call\n' \
                         'to fit and add more estimators\n' \
                         'to the ensemble, otherwise,just\n' \
                         'fit a whole new forest.'

# MULTILAYER PERCEPTRON
ACTIVATION_DESCRIPTION = 'Activation Function:\n' \
                         '{identity, logistic, tanh, relu}, default=relu.\n' \
                         'Activation function for the hidden layer.\n' \
                         'identity: no-op activation, useful to implement linear bottleneck, returns f(x) = x.\n' \
                         'logistic: the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n' \
                         'tanh: the hyperbolic tan function, returns f(x) = tanh(x).\n' \
                         'relu: the rectified linear unit function, returns f(x) = max(0, x).\n'
BATCH_SIZE_DESCRIPTION = 'Batch Size:\n' \
                         'int, optional, default=auto.\n' \
                         'Size of minibatches for stochastic optimizers.\n' \
                         'If the solver is lbfgs, the classifier will not\n' \
                         'use minibatch.\n' \
                         'When set to auto, batch_size=min(200, n_samples).'
BETA_1_DESCRIPTION = 'First Moment Exponential Decay:\n' \
                     'float, optional, default=0.5.\n' \
                     'Exponential decay rate for estimates of\n' \
                     'first moment vector in adam, should be in\n' \
                     '[0, 1). Only used when solver=adam.'
BETA_2_DESCRIPTION = 'Second Moment Exponential Decay:\n' \
                     'float, optional, default=0.999.\n' \
                     'Exponential decay rate for estimates of\n' \
                     'second moment vector in adam, should be in\n' \
                     '[0, 1). Only used when solver=adam.'
EARLY_STOPPING_DESCRIPTION = 'Early Stopping:\n' \
                             'bool, default=False.\n' \
                             'Whether to use early stopping to terminate\n' \
                             'training when validation score is not improving.\n' \
                             'If set to true, it will automatically set aside 10%\n' \
                             'of training data as validation and terminate\n' \
                             'training when validation score is not improving by\n' \
                             'at least tol for two consecutive epochs. Only\n' \
                             'effective when solver=sgd or adam.'
HIDDEN_LAYER_SIZES_DESCRIPTION = 'Hidden Layer Sizes:\n' \
                                 'tuple, length = n_layers - 1, default=(100,).\n' \
                                 'The ith element represents the number of neurons\n' \
                                 'in the ith hidden layer.'
LEARNING_RATE_DESCRIPTION = 'Learning Rate:\n' \
                            '{constant, invscaling, adaptive}, default=constant.\n' \
                            'Learning rate schedule for weight updates.\n' \
                            'constant is a constant learning rate given by learning_rate_init.\n' \
                            'invscaling gradually decreases the learning rate learning_rate_ at\n' \
                            'each time step t using an inverse scaling exponent of power_t.\n' \
                            'effective_learning_rate = learning_rate_init / pow(t, power_t)\n' \
                            'adaptive keeps the learning rate constant to learning_rate_init\n' \
                            'as long as training loss keeps decreasing. Each time two consecutive\n' \
                            'epochs fail to decrease training loss by at least tol, or fail to\n' \
                            'increase validation score by at least tol if early_stopping\n' \
                            'is on, the current learning rate is divided by 5.' \
                            'Only used when solver=sgd.'
LEARNING_RATE_INIT_DESCRIPTION = 'Initial Learning Rate:\n' \
                                 'double, optional, default=0.001.\n' \
                                 'The initial learning rate used. It controls\n' \
                                 'the step-size in updating the weights.\n' \
                                 'Only used when solver=sgd or adam.'
MLP_ALPHA_DESCRIPTION = 'Penalty Parameter (Alpha):\n' \
                        'float, optional, default=0.0001.\n' \
                        'L2 penalty (regularization term) parameter.'
MLP_EPSILON_DESCRIPTION = 'Numerical Stability (Epsilon):\n' \
                          'float, optional, default=1e-5.\n' \
                          'Value for numerical stability in adam.\n' \
                          'Only used when solver=adam.'
MLP_MAX_ITER_DESCRIPTION = 'Maximum Iterations:\n' \
                           'int, optional, default=200.\n' \
                           'Maximum number of iterations. The solver iterates\n' \
                           'until convergence (determined by tol) or this\n' \
                           'number of iterations. For stochastic solvers\n' \
                           '(sgd, adam), note that this determines the\n' \
                           'number of epochs (how many times each data point\n' \
                           'will be used), not the number of gradient steps.'
MLP_RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                               'int, RandomState instance or None, optional, default=None.\n' \
                               'If int, random_state is the seed used by the random\n' \
                               'number generator1; If RandomState instance, random_state\n' \
                               'is the random number generator1; If None, the random number\n' \
                               'generator1 is the RandomState instance used by np.random.'
MLP_TOL_DESCRIPTION = 'Tolerance:\n' \
                      'float, optional, default 1e-3.\n' \
                      'Tolerance for the optimization.\n' \
                      'When the loss or score is not improving\n' \
                      'by at least tol for two consecutive\n' \
                      'iterations, unless learning_rate is\n' \
                      'set to adaptive, convergence is\n' \
                      'considered to be reached and training stops.'
MLP_WARM_START_DESCRIPTION = 'Warm Start:\n' \
                             'bool, optional, default False.\n' \
                             'When set to True, reuse the solution\n' \
                             'of the previous call to fit as\n' \
                             'initialization, otherwise, just\n' \
                             'erase the previous solution.'
MOMENTUM_DESCRIPTION = 'Momentum:\n' \
                       'float, default 0.5.\n' \
                       'Momentum for gradient descent update.\n' \
                       'Should be between 0 and 1. Only used\n' \
                       'when solver=sgd.'
NESTEROVS_MOMENTUM_DESCRIPTION = 'Nesterov\'s Momentum:\n' \
                                 'boolean, default=True.\n' \
                                 'Whether to use Nesterovs momentum.\n' \
                                 'Only used when solver=sgd\n' \
                                 'and momentum > 0.'
POWER_T_DESCRIPTION = 'Power for Inverse Learning Rate:\n' \
                      'double, optional, default=0.5\n' \
                      'The exponent for inverse scaling learning rate.\n' \
                      'It is used in updating effective learning rate\n' \
                      'when the learning_rate is set to invscaling.\n' \
                      'Only used when solver=sgd.'
SHUFFLE_DESCRIPTION = 'Shuffle:\n' \
                      'bool, optional, default=True.\n' \
                      'Whether to shuffle samples in each iteration.\n' \
                      'Only used when solver=sgd or adam.'
SOLVER_DESCRIPTION = 'Weight Optimization Solver:\n' \
                     '{lbfgs, sgd, adam}, default=adam.\n' \
                     'The solver for weight optimization.\n' \
                     'lbfgs is an optimizer in the family\n' \
                     'of quasi-Newton methods.\n' \
                     'sgd refers to stochastic gradient descent.\n' \
                     'adam refers to a stochastic gradient-based\n' \
                     'optimizer proposed by Kingma, Diederik, and Jimmy Ba.\n' \
                     'Note: The default solver adam works pretty well\n' \
                     'on relatively large datasets\n' \
                     '(with thousands of training samples or more)\n' \
                     'in terms of both training time and validation score.\n' \
                     'For small datasets, however, lbfgs can converge\n' \
                     'faster and perform better.'
VALIDATION_FRACTION_DESCRIPTION = 'Validation Fraction:\n' \
                                  'float, optional, default=0.1.\n' \
                                  'The proportion of training data to set\n' \
                                  'aside as validation set for early stopping.\n' \
                                  'Must be between 0 and 1. Only used if\n' \
                                  'early_stopping is True.'

# MAIN MENU
CLASSIFICATION_DESCRIPTION = 'Classification: Classify data.'
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
DOCUMENTATION_DESCRIPTION = '1: Browse detailed descriptions and tutorials of each module.'
EXIT_DESCRIPTION = 'Exit application.'
GEO_SEARCH_DESCRIPTION = 'Geographic search: Explore your database and produce geographical information system visualizations.'
MCMC_DESCRIPTION = 'Markov Chain Monte Carlo: Develop Monte Carlo simulations based on Transition Matrices and Markov Chains'
OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
REGRESSION_DESCRIPTION = 'Regression6: Perform Regression6 analysis on your data and visualize your results.'
SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SEARCH_DESCRIPTION = 'search Engine: Navigate your database and specify criteria for extracting data.'
WEB_SCRAPING_DESCRIPTION = 'Web Scraping: Gather and analyze information from the web.'

# CLASSIFICATION DESCRIPTION
QDA_DESCRIPTION = 'Quadratic Discriminant Analysis:'

# REGRESSION MENU
AB_DESCRIPTION = 'Adaptive Boosting:\n' \
                 'An AdaBoost regressor is a \n' \
                 'meta-estimator that begins by fitting a regressor\n' \
                 'on the original dataset and then fits additional\n' \
                 'copies of the regressor on the same dataset but\n' \
                 'where the weights of instances are adjusted\n' \
                 'according to the error of the current prediction.\n' \
                 'As such, subsequent regressors focus more on\n' \
                 'difficult cases.'
AUTOMATIC_TUNING_DESCRIPTION = 'Tune each machine learning parameter\n' \
                               'automatically through a genetic\n' \
                               'grid interface7 cross validation algorithm.'
D_TREE_DESCRIPTION = 'Decision Tree:\n' \
                     'Creates a model that predicts the value of a target\n' \
                     'variable by learning simple decision rules inferred\n' \
                     'from the data features.'
E_NET_DESCRIPTION = 'Elastic Net:\n' \
                    'Linear Model trained with L1 and L2 prior as regularizer.'
K_NEIGHBORS_DESCRIPTION = 'K Nearest Neighbors:\n' \
                          'The target is predicted by local interpolation of\n' \
                          'the targets associated of the nearest neighbors in\n' \
                          'the training set.'
K_RIDGE_DESCRIPTION = 'K Ridge:\n' \
                      'Kernel ridge Regression6 (KRR) combines ridge Regression6\n' \
                      '(linear least squares with l2-norm regularization) with\n' \
                      'the kernel trick. It thus learns a linear function in\n' \
                      'the space induced by the respective kernel and the data.\n' \
                      'For non-linear kernels, this corresponds to a non-linear\n' \
                      'function in the original space.\n' \
                      'The form of the model learned by KRR is identical to support\n' \
                      'vector Regression6 (SVR). However, different loss functions\n' \
                      'are used: KRR uses squared error loss while support vector\n' \
                      'Regression6 uses epsilon-insensitive loss, both combined with\n' \
                      'l2 regularization. In contrast to SVR, fitting a KRR model\n' \
                      'can be done in closed-form and is typically faster for\n' \
                      'medium-sized datasets. On the search hand, the learned model\n' \
                      'is non-sparse and thus slower than SVR, which learns a sparse\n' \
                      'model for epsilon > 0, at prediction-time.'
MLP_DESCRIPTION = 'Multilayer Perceptron Neural Network:\n' \
                  'This model optimizes the squared-loss using LBFGS\n' \
                  'or stochastic gradient descent.'
R_FOREST_DESCRIPTION = 'Random Forest:\n' \
                       'A random forest is a meta estimator that fits a number\n' \
                       'of classifying decision trees on various sub-samples\n' \
                       'of the dataset and use averaging to improve the predictive\n' \
                       'accuracy and control over-fitting. The sub-sample size is\n' \
                       'always the same as the original input sample size but the\n' \
                       'samples are drawn with replacement if bootstrap2=True (default).'
RUN_CLASSIFICATION_DESCRIPTION = 'Run classification0 analysis.'
RUN_MACHINE_LEARNING_DESCRIPTION = 'Run analysis.'
RUN_REGRESSION_DESCRIPTION = 'Run Regression6 analysis.'
SVM_DESCRIPTION = 'Support Vector Machine:\n' \
                  'Epsilon-Support Vector Regression6.\n' \
                  'The free parameters in the model are C and epsilon.\n' \
                  'The implementation is based on libsvm.'
RBM_DESCRIPTION = ''
SGD_DESCRIPTION = ''

# DATABASE MENU
DATABASE_APPLY_BUTTON_DESCRIPTION = 'Use these settings throughout the entire software.'
ENCODING_DESCRIPTION = 'Encoding of files in database.'
INDEX_COLUMN_DESCRIPTION = 'Column containing index labels.'
LATITUDE_COLUMN_DESCRIPTION = 'Column containing latitude information.'
LONGITUDE_COLUMN_DESCRIPTION = 'Column containing longitude information.'

# SEARCH MENU
CLEAR_BUTTON_DESCRIPTION = 'Clear all interface7 criteria.'
EXCEL_EXPORT_DESCRIPTION = 'Export results in Excel .xlsx format.'
HTML_EXPORT_DESCRIPTION = 'Export results in HTML2 format.'
PDF_EXPORT_DESCRIPTION = 'Export results in PDF format.'
RUN_SEARCH_DESCRIPTION = 'search database.'
TXT_EXPORT_DESCRIPTION = 'Export results in text format compatible with .txt, .csv, .dat'

# MARKOV CHAIN MONTE CARLO MENU
CENTRAL_COMPOSITE_DESCRIPTION = 'Sample data using central composite method.'
COLUMN_COMBO_DESCRIPTION = 'Database column to use.'
INDEX_COMBO_DESCRIPTION = 'Database column to use as index.'
INITIAL_STATE_DESCRIPTION = 'Initial state for simulation.'
ITERATIONS_DESCRIPTION = 'Number of iterations to run simulation.'
LATIN_HYPERCUBES_DESCRIPTION = 'Sample data using latin hypercubes method.'
PARALLEL_DESCRIPTION = 'Read data across columns as in parallel.'
RUN_MARKOV_CHAIN_DESCRIPTION = 'Develop Transition Matrix and Markov Chains.'
RUN_MONTE_CARLO_DESCRIPTION = 'Run Monte Carlo simulation.'
SERIES_DESCRIPTION = 'Read data throughout columns as in series.'

# GEOGRAPHIC SEARCH MENU
LATITUDE_DESCRIPTION = 'Latitude component of the interface7 centroid coordinate.'
LONGITUDE_DESCRIPTION = 'Longitude component of the interface7 centroid coordinate.'
RADIUS_DESCRIPTION = 'Distance from interface7 centroid coordinate for which to interface7 in.'
RUN_GEOSEARCH_DESCRIPTION = 'Run interface7.'
UNITS_DESCRIPTION = 'Units to calculate distance in.'

# WEB SCRAPING MENU
IMAGES_DESCRIPTION = 'Scrapes all image tags'
JAVASCRIPT_DESCRIPTION = 'Scrapes all javascript on page '
LINKS_DESCRIPTION = 'Extract links.'
PARAGRAPHS_DESCRIPTION = 'Extract paragraphs.'
PHOTOS_DESCRIPTION = 'Extract photographs.'
URL_DESCRIPTION = 'Url.'
TABLES_DESCRIPTION = 'Extract data tables.'
TOKEN_DESCRIPTION = 'Token to interface7 for.'

# SVM PARAMETERS
C_DESCRIPTION = 'C:\n' \
                'float, optional (default=1.0).\n' \
                'Penalty parameter C of the error term.'
CACHE_SIZE_DESCRIPTION = 'Cache Size:\n' \
                         'float, optional.\n' \
                         'Specify the size of the kernel cache (in MB).'
COEF0_DESCRIPTION = 'Coefficient 0:\n' \
                    'float, optional (default=0.0).\n' \
                    'Independent term in kernel function.\n' \
                    'It is only significant in poly and sigmoid.'
DEGREE_DESCRIPTION = 'Polynomial Degree:\n' \
                     'int, optional (default=2).\n' \
                     'Degree of the polynomial kernel\n' \
                     'function (poly). Ignored by all\nsearch kernels.'
EPSILON_DESCRIPTION = 'Epsilon:\n' \
                      'float, optional (default=0.1).\n' \
                      'Epsilon in the epsilon-SVR model.\n' \
                      'It specifies the epsilon-tube within\n' \
                      'which no penalty is associated in the\n' \
                      'training loss function with points\n' \
                      'predicted within a distance epsilon\n' \
                      'from the actual value.'
GAMMA_DESCRIPTION = 'Gamma:\n' \
                    'float, optional (default=auto).\n' \
                    'Kernel coefficient for rbf, poly\n' \
                    'and sigmoid. If gamma is auto then\n' \
                    '1/n_features will be used instead.'
KERNEL_DESCRIPTION = 'Kernel:\n' \
                     'string, optional (default=rbf).\n' \
                     'Specifies the kernel type to be used\n' \
                     'in the algorithm. It must be one of\n' \
                     'linear, poly, rbf, sigmoid,\n' \
                     'precomputed or a callable. If none\n' \
                     'is given, rbf will be used. If a\n' \
                     'callable is given it is used to\n' \
                     'precompute the kernel matrix.'
MAX_ITER_DESCRIPTION = 'Maximum Iterations:\n' \
                       'int, optional (default=-1).\n' \
                       'Hard limit on iterations within\n' \
                       'solver, or -1 for no limit.'
SHRINKING_DESCRIPTION = 'Shrinking:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether to use the shrinking heuristic.'
TOL_DESCRIPTION = 'Tolerance:\n' \
                  'float, optional (default=1e-2)\n' \
                  'Tolerance for stopping criterion.'
VERBOSE_DESCRIPTION = 'Verbose:\n' \
                      'bool, default=False.\n' \
                      'Enable verbose output. Note that this \n' \
                      'setting takes advantage of a per-process\n' \
                      'runtime setting in libsvm that, if\n' \
                      'enabled, may not work properly in a\n' \
                      'multithreaded context.'

# KNN PARAMETERS
ALGORITHM_DESCRIPTION = 'Algorithm:\n' \
                        '{auto, ball_tree, kd_tree, brute}, optional.\n' \
                        'Algorithm used to compute the nearest neighbors:\n' \
                        'ball_tree will use BallTree.\n' \
                        'kd_tree will use KDTree.\n' \
                        'brute will use a brute-force interface7.\n' \
                        'auto will attempt to decide the most appropriate\n' \
                        'algorithm based on the values passed to fit method.\n' \
                        'Note: fitting on sparse input will override the\n' \
                        'setting of this parameter, using brute force.'
LEAF_SIZE_DESCRIPTION = 'Leaf Size:\n' \
                        'int, optional (default = 30).\n' \
                        'Leaf size passed to BallTree or KDTree.\n' \
                        'This can affect the speed of the\n' \
                        'construction and query, as well as\n' \
                        'the memory required to store the tree.\n' \
                        'The optimal value depends on the nature\n' \
                        'of the problem.'
METRIC_DESCRIPTION = 'Metric:\n' \
                     'string or callable, default minkowski.\n' \
                     'The distance metric to use for the tree.\n' \
                     'The default metric is minkowski, and with p=1\n' \
                     'is equivalent to the standard Euclidean metric.\n' \
                     'See the 1 of the DistanceMetric object_oriented\n' \
                     'for a list of available metrics.'
N_JOBS_DESCRIPTION = 'CPU Cores:\n' \
                     'int, optional (default = 1).\n' \
                     'The number of parallel jobs to run for\n' \
                     'neighbors interface7. If -1, then the number\n' \
                     'ofjobs is set to the number of CPU cores.\n' \
                     'Doesnt affect fit method.'
N_NEIGHBORS_DESCRIPTION = 'Number of Neighbors:\n' \
                          'int, optional (default = 5).\n' \
                          'Number of neighbors to use by\n' \
                          'default for kneighbors queries.'
P_DESCRIPTION = 'Minkowski Power:\n' \
                'integer, optional (default = 1).\n' \
                'Power parameter for the Minkowski metric.\n' \
                'When p = 1, this is equivalent to using\n' \
                'manhattan_distance (l1), and\n' \
                'euclidean_distance (l2) for p = 1.\n' \
                'For arbitrary p, minkowski_distance (l_p) is used.'
WEIGHTS_DESCRIPTION = 'Weights Function:\n' \
                      'str or callable, default=uniform.\n' \
                      'weight function used in\n' \
                      'prediction. Possible values:\n' \
                      'uniform: uniform weights. All\n' \
                      'points in each neighborhood are\n' \
                      'weighted equally.\n' \
                      'distance: weight points by the\n' \
                      'inverse of their distance. In this\n' \
                      'case, closer neighbors of a query\n' \
                      'point will have a greater influence\n' \
                      'than neighbors which are further away.'

# K RIDGE PARAMETERS
ALPHA_DESCRIPTION = 'Alpha:\n' \
                    '{float, array-like}, shape = [n_targets].\n' \
                    'Small positive values of alpha improve the\n' \
                    'conditioning of the problem and reduce the\n' \
                    'variance of the estimates. Alpha corresponds\n' \
                    'to (1*C)^-1 in search linear models such as\n' \
                    'LogisticRegression or LinearSVC. If an array\n' \
                    'is passed, penalties are assumed to be specific\n' \
                    'to the targets. Hence they must correspond in number.'

# DECISION TREE PARAMETERS
CRITERION_DESCRIPTION = 'Criterion:\n' \
                        'string, optional (default=mse).\n' \
                        'The function to measure the quality of a split.\n' \
                        'Supported criteria are mse for the mean\n' \
                        'squared error, which is equal to variance\n' \
                        'reduction as feature selection criterion\n' \
                        'and minimizes the L2 loss using the mean\n' \
                        'of each terminal node, friedman_mse, which\n' \
                        'uses mean squared error with Friedmans\n' \
                        'improvement score for potential splits, and\n' \
                        'mae for the mean absolute error, which\n' \
                        'minimizes the L1 loss using the median of\n' \
                        'each terminal node.'
MAX_DEPTH_DESCRIPTION = 'Maximum Depth:\n' \
                        'int or None, optional (default=None).\n' \
                        'The maximum depth of the tree. If None, then\n' \
                        'nodes are expanded until all leaves are pure\n' \
                        'or until all leaves contain less than\n' \
                        'min_samples_split samples.'
MAX_FEATURES_DESCRIPTION = 'Maximum Features:\n' \
                           'int, float, string or None, optional (default=None).\n' \
                           'The number of features to consider when looking for\n' \
                           'the best split:\n' \
                           'If int, then consider max_features features at each split.\n' \
                           'If float, then max_features is a percentage and\n' \
                           'int(max_features * n_features) features are considered\n' \
                           'at each split.\n' \
                           'If auto, then max_features=n_features.\n' \
                           'If sqrt, then max_features=sqrt(n_features).\n' \
                           'If log2, then max_features=log2(n_features).\n' \
                           'If None, then max_features=n_features.\n' \
                           'Note: the interface7 for a split does not stop until at\n' \
                           'least one valid partition of the node samples is\n' \
                           'found, even if it requires to effectively inspect more\n' \
                           'than max_features features.'
MAX_LEAF_NODES_DESCRIPTION = 'Maximum Leaf Nodes:\n' \
                             'int or None, optional (default=None).\n' \
                             'Grow a tree with max_leaf_nodes in\n' \
                             'best-first fashion.\n' \
                             'Best nodes are defined as relative\n' \
                             'reduction in impurity. If None then\n' \
                             'unlimited number of leaf nodes.'
MIN_IMPURITY_DECREASE_DESCRIPTION = 'Minimum Impurity Decrease:\n' \
                                    'float, optional (default=0.).\n' \
                                    'A node will be split if this split\n' \
                                    'induces a decrease of the impurity\n' \
                                    'greater than or equal to this value.\n' \
                                    'The weighted impurity decrease equation\n' \
                                    'is the following:\n' \
                                    'N_t/N*(i-N_t_R/N_t*r_i-N_t_L/N_t*l_i)' \
                                    'where l is left, r is right, i is the\n' \
                                    'impurity, N is the total number of\n' \
                                    'samples, N_t is the number of samples\n' \
                                    'at the current node, N_t_L is the number\n' \
                                    'of samples in the left child, and N_t_R\n' \
                                    'is the number of samples in the right child.' \
                                    'N, N_t, N_t_R and N_t_L all refer to the\n' \
                                    'weighted sum, if sample_weight is passed.'
MIN_SAMPLES_LEAF_DESCRIPTION = 'Minimum Samples at Leaf:\n' \
                               'int, float, optional (default=1).\n' \
                               'The minimum number of samples required\n' \
                               'to be at a leaf node:\n' \
                               'If int, then consider min_samples_leaf\n' \
                               'as the minimum number.\n' \
                               'If float, then min_samples_leaf is a\n' \
                               'percentage and ceil(min_samples_leaf * n_samples)\n' \
                               'are the minimum number of samples for each node.'
MIN_SAMPLES_SPLIT_DESCRIPTION = 'Minimum Samples Split:\n' \
                                'int, float, optional (default=1).\n' \
                                'The minimum number of samples\n' \
                                'required to split an internal node:\n' \
                                'If int, then consider min_samples_split\n' \
                                'as the minimum number.\n' \
                                'If float, then min_samples_split\n' \
                                'is a percentage and\n' \
                                'ceil(min_samples_split * n_samples)\n' \
                                'are the minimum number of samples\n' \
                                'for each split.'
MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION = 'Minimum Sum Weighted Fraction:\n' \
                                       'float, optional (default=0.)\n' \
                                       'The minimum weighted fraction of the\n' \
                                       'sum total of weights (of all the input samples)\n' \
                                       'required to be at a leaf node. Samples have\n' \
                                       'equal weight when sample_weight is not provided.'
PRESORT_DESCRIPTION = 'Presort Data:\n' \
                      'bool, optional (default=False).\n' \
                      'Whether to presort the data to speed\n' \
                      'up the finding of best splits in fitting.\n' \
                      'For the default settings of a decision tree\n' \
                      'on large datasets, setting this to true may\n' \
                      'slow down the training process. When using\n' \
                      'either a smaller dataset or a restricted\n' \
                      'depth, this may speed up the training.'
RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                           'int, RandomState instance or None, optional (default=None).\n' \
                           'If int, random_state is the seed used by the random number\n' \
                           'generator1; If RandomState instance, random_state is the\n' \
                           'random number generator1; If None, the random number\n' \
                           'generator1 is the RandomState instance used by np.random.'
SPLITTER_DESCRIPTION = 'Splitter:\n' \
                       'string, optional (default=best).\n' \
                       'The strategy used to choose the split\n' \
                       'at each node. Supported strategies are\n' \
                       'best to choose the best split and\n' \
                       'random to choose the best random split.'

# RANDOM FOREST
BOOTSTRAP_DESCRIPTION = 'Bootstrap:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether bootstrap2 samples are\n' \
                        'used when building trees.'
N_ESTIMATORS_DESCRIPTION = 'Number of Trees:\n' \
                           'integer, optional (default=10).\n' \
                           'The number of trees in the forest.'
OOB_SCORE_DESCRIPTION = 'Out-of-Bag Samples:\n' \
                        'bool, optional (default=False).\n' \
                        'Whether to use out-of-bag\n' \
                        'samples to estimate the R^1 on\n' \
                        'unseen data.'
WARM_START_DESCRIPTION = 'Warm Start:\n' \
                         'bool, optional (default=False).\n' \
                         'When set to True, reuse the\n' \
                         'solution of the previous call\n' \
                         'to fit and add more estimators\n' \
                         'to the ensemble, otherwise,just\n' \
                         'fit a whole new forest.'

# MULTILAYER PERCEPTRON
ACTIVATION_DESCRIPTION = 'Activation Function:\n' \
                         '{identity, logistic, tanh, relu}, default=relu.\n' \
                         'Activation function for the hidden layer.\n' \
                         'identity: no-op activation, useful to implement linear bottleneck, returns f(x) = x.\n' \
                         'logistic: the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n' \
                         'tanh: the hyperbolic tan function, returns f(x) = tanh(x).\n' \
                         'relu: the rectified linear unit function, returns f(x) = max(0, x).\n'
BATCH_SIZE_DESCRIPTION = 'Batch Size:\n' \
                         'int, optional, default=auto.\n' \
                         'Size of minibatches for stochastic optimizers.\n' \
                         'If the solver is lbfgs, the classifier will not\n' \
                         'use minibatch.\n' \
                         'When set to auto, batch_size=min(200, n_samples).'
BETA_1_DESCRIPTION = 'First Moment Exponential Decay:\n' \
                     'float, optional, default=0.5.\n' \
                     'Exponential decay rate for estimates of\n' \
                     'first moment vector in adam, should be in\n' \
                     '[0, 1). Only used when solver=adam.'
BETA_2_DESCRIPTION = 'Second Moment Exponential Decay:\n' \
                     'float, optional, default=0.999.\n' \
                     'Exponential decay rate for estimates of\n' \
                     'second moment vector in adam, should be in\n' \
                     '[0, 1). Only used when solver=adam.'
EARLY_STOPPING_DESCRIPTION = 'Early Stopping:\n' \
                             'bool, default=False.\n' \
                             'Whether to use early stopping to terminate\n' \
                             'training when validation score is not improving.\n' \
                             'If set to true, it will automatically set aside 10%\n' \
                             'of training data as validation and terminate\n' \
                             'training when validation score is not improving by\n' \
                             'at least tol for two consecutive epochs. Only\n' \
                             'effective when solver=sgd or adam.'
HIDDEN_LAYER_SIZES_DESCRIPTION = 'Hidden Layer Sizes:\n' \
                                 'tuple, length = n_layers - 1, default=(100,).\n' \
                                 'The ith element represents the number of neurons\n' \
                                 'in the ith hidden layer.'
LEARNING_RATE_DESCRIPTION = 'Learning Rate:\n' \
                            '{constant, invscaling, adaptive}, default=constant.\n' \
                            'Learning rate schedule for weight updates.\n' \
                            'constant is a constant learning rate given by learning_rate_init.\n' \
                            'invscaling gradually decreases the learning rate learning_rate_ at\n' \
                            'each time step t using an inverse scaling exponent of power_t.\n' \
                            'effective_learning_rate = learning_rate_init / pow(t, power_t)\n' \
                            'adaptive keeps the learning rate constant to learning_rate_init\n' \
                            'as long as training loss keeps decreasing. Each time two consecutive\n' \
                            'epochs fail to decrease training loss by at least tol, or fail to\n' \
                            'increase validation score by at least tol if early_stopping\n' \
                            'is on, the current learning rate is divided by 5.' \
                            'Only used when solver=sgd.'
LEARNING_RATE_INIT_DESCRIPTION = 'Initial Learning Rate:\n' \
                                 'double, optional, default=0.001.\n' \
                                 'The initial learning rate used. It controls\n' \
                                 'the step-size in updating the weights.\n' \
                                 'Only used when solver=sgd or adam.'
MLP_ALPHA_DESCRIPTION = 'Penalty Parameter (Alpha):\n' \
                        'float, optional, default=0.0001.\n' \
                        'L2 penalty (regularization term) parameter.'
MLP_EPSILON_DESCRIPTION = 'Numerical Stability (Epsilon):\n' \
                          'float, optional, default=1e-5.\n' \
                          'Value for numerical stability in adam.\n' \
                          'Only used when solver=adam.'
MLP_MAX_ITER_DESCRIPTION = 'Maximum Iterations:\n' \
                           'int, optional, default=200.\n' \
                           'Maximum number of iterations. The solver iterates\n' \
                           'until convergence (determined by tol) or this\n' \
                           'number of iterations. For stochastic solvers\n' \
                           '(sgd, adam), note that this determines the\n' \
                           'number of epochs (how many times each data point\n' \
                           'will be used), not the number of gradient steps.'
MLP_RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                               'int, RandomState instance or None, optional, default=None.\n' \
                               'If int, random_state is the seed used by the random\n' \
                               'number generator1; If RandomState instance, random_state\n' \
                               'is the random number generator1; If None, the random number\n' \
                               'generator1 is the RandomState instance used by np.random.'
MLP_TOL_DESCRIPTION = 'Tolerance:\n' \
                      'float, optional, default 1e-3.\n' \
                      'Tolerance for the optimization.\n' \
                      'When the loss or score is not improving\n' \
                      'by at least tol for two consecutive\n' \
                      'iterations, unless learning_rate is\n' \
                      'set to adaptive, convergence is\n' \
                      'considered to be reached and training stops.'
MLP_WARM_START_DESCRIPTION = 'Warm Start:\n' \
                             'bool, optional, default False.\n' \
                             'When set to True, reuse the solution\n' \
                             'of the previous call to fit as\n' \
                             'initialization, otherwise, just\n' \
                             'erase the previous solution.'
MOMENTUM_DESCRIPTION = 'Momentum:\n' \
                       'float, default 0.5.\n' \
                       'Momentum for gradient descent update.\n' \
                       'Should be between 0 and 1. Only used\n' \
                       'when solver=sgd.'
NESTEROVS_MOMENTUM_DESCRIPTION = 'Nesterov\'s Momentum:\n' \
                                 'boolean, default=True.\n' \
                                 'Whether to use Nesterovs momentum.\n' \
                                 'Only used when solver=sgd\n' \
                                 'and momentum > 0.'
POWER_T_DESCRIPTION = 'Power for Inverse Learning Rate:\n' \
                      'double, optional, default=0.5\n' \
                      'The exponent for inverse scaling learning rate.\n' \
                      'It is used in updating effective learning rate\n' \
                      'when the learning_rate is set to invscaling.\n' \
                      'Only used when solver=sgd.'
SHUFFLE_DESCRIPTION = 'Shuffle:\n' \
                      'bool, optional, default=True.\n' \
                      'Whether to shuffle samples in each iteration.\n' \
                      'Only used when solver=sgd or adam.'
SOLVER_DESCRIPTION = 'Weight Optimization Solver:\n' \
                     '{lbfgs, sgd, adam}, default=adam.\n' \
                     'The solver for weight optimization.\n' \
                     'lbfgs is an optimizer in the family\n' \
                     'of quasi-Newton methods.\n' \
                     'sgd refers to stochastic gradient descent.\n' \
                     'adam refers to a stochastic gradient-based\n' \
                     'optimizer proposed by Kingma, Diederik, and Jimmy Ba.\n' \
                     'Note: The default solver adam works pretty well\n' \
                     'on relatively large datasets\n' \
                     '(with thousands of training samples or more)\n' \
                     'in terms of both training time and validation score.\n' \
                     'For small datasets, however, lbfgs can converge\n' \
                     'faster and perform better.'
VALIDATION_FRACTION_DESCRIPTION = 'Validation Fraction:\n' \
                                  'float, optional, default=0.1.\n' \
                                  'The proportion of training data to set\n' \
                                  'aside as validation set for early stopping.\n' \
                                  'Must be between 0 and 1. Only used if\n' \
                                  'early_stopping is True.'
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
EXIT_DESCRIPTION = 'Exit application.'
GEO_SEARCH_DESCRIPTION = 'Geographic search: Explore your database and produce geographical information system visualizations.'
MACHINE_LEARNING_DESCRIPTION = 'Machine Learning: Perform statistical analysis on your data and visualize your results.'
OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SEARCH_DESCRIPTION = 'search Engine: Navigate your database and specify criteria for extracting data.'
# MAIN MENU
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
EXIT_DESCRIPTION = 'Exit application.'
GEO_SEARCH_DESCRIPTION = 'Geographic other0: Explore your database and produce geographical information system visualizations.'
MACHINE_LEARNING_DESCRIPTION = 'Machine Learning: Perform statistical analysis on your data and visualize your results.'
MCMC_DESCRIPTION = 'Markov Chain Monte Carlo: Develop Monte Carlo simulations based on Transition Matrices and Markov Chains'
OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SEARCH_DESCRIPTION = 'other0 Engine: Navigate your database and specify criteria for extracting data.'
WEB_SCRAPING_DESCRIPTION = 'Web Scraping: Gather and analyze information from the web.'

# MACHINE LEARNING MENU
RUN_CLASSIFICATION_DESCRIPTION = 'Run classification0 analysis.'
RUN_REGRESSION_DESCRIPTION = 'Run Regression6 analysis.'
SVM_DESCRIPTION = 'Support Vector Machine:\n' \
                  'Epsilon-Support Vector Regression0.\n' \
                  'The free parameters in the model are C and epsilon.\n' \
                  'The implementation is based on libsvm.'
K_NEIGHBORS_DESCRIPTION = 'K Nearest Neighbors:\n' \
                          'The target is predicted by local interpolation of\n' \
                          'the targets associated of the nearest neighbors in\n' \
                          'the training set.'
NN_DESCRIPTION = 'Multilayer Perceptron Neural Network:\n' \
                 'This model optimizes the squared-loss using LBFGS\n' \
                 'or stochastic gradient descent.'
K_RIDGE_DESCRIPTION = 'K Ridge:\n' \
                      'Kernel ridge Regression6 (KRR) combines ridge Regression6\n' \
                      '(linear least squares with l2-norm regularization) with\n' \
                      'the kernel trick. It thus learns a linear function in\n' \
                      'the space induced by the respective kernel and the data.\n' \
                      'For non-linear kernels, this corresponds to a non-linear\n' \
                      'function in the original space.\n' \
                      'The form of the model learned by KRR is identical to support\n' \
                      'vector Regression6 (SVR). However, different loss functions\n' \
                      'are used: KRR uses squared error loss while support vector\n' \
                      'Regression6 uses epsilon-insensitive loss, both combined with\n' \
                      'l2 regularization. In contrast to SVR, fitting a KRR model\n' \
                      'can be done in closed-form and is typically faster for\n' \
                      'medium-sized datasets. On the search hand, the learned model\n' \
                      'is non-sparse and thus slower than SVR, which learns a sparse\n' \
                      'model for epsilon > 0, at prediction-time.'
R_FOREST_DESCRIPTION = 'Random Forest:\n' \
                       'A random forest is a meta estimator that fits a number\n' \
                       'of classifying decision trees on various sub-samples\n' \
                       'of the dataset and use averaging to improve the predictive\n' \
                       'accuracy and control over-fitting. The sub-sample size is\n' \
                       'always the same as the original input sample size but the\n' \
                       'samples are drawn with replacement if bootstrap2=True (default).'
D_TREE_DESCRIPTION = 'Decision Tree:\n' \
                     'Creates a model that predicts the value of a target\n' \
                     'variable by learning simple decision rules inferred\n' \
                     'from the data features.'
E_NET_DESCRIPTION = 'Elastic Net:\n' \
                    'Linear Model trained with L1 and L2 prior as regularizer.'
AB_DESCRIPTION = 'Adaptive Boosting:\n' \
                 'An AdaBoost regressor is a \n' \
                 'meta-estimator that begins by fitting a regressor\n' \
                 ' on the original dataset and then fits additional\n' \
                 ' copies of the regressor on the same dataset but\n' \
                 ' where the weights of instances are adjusted\n' \
                 ' according to the error of the current prediction.\n' \
                 ' As such, subsequent regressors focus more on\n' \
                 ' difficult cases.'
RUN_MACHINE_LEARNING_DESCRIPTION = 'Run analysis.'
AUTOMATIC_TUNING_DESCRIPTION = 'Tune each machine learning parameter\n' \
                               'automatically through a genetic\n' \
                               'grid search cross validation algorithm.'

# DATABASE MENU
ENCODING_DESCRIPTION = 'Encoding of files in database.'
INDEX_COLUMN_DESCRIPTION = 'Column containing index labels.'
LATITUDE_COLUMN_DESCRIPTION = 'Column containing latitude information.'
LONGITUDE_COLUMN_DESCRIPTION = 'Column containing longitude information.'
DATABASE_APPLY_BUTTON_DESCRIPTION = 'Use these settings throughout the entire software.'

# SEARCH MENU
TXT_EXPORT_DESCRIPTION = 'Export results in text format compatible with .txt, .csv, .dat'
EXCEL_EXPORT_DESCRIPTION = 'Export results in Excel .xlsx format.'
PDF_EXPORT_DESCRIPTION = 'Export results in PDF format.'
HTML_EXPORT_DESCRIPTION = 'Export results in HTML2 format.'
CLEAR_BUTTON_DESCRIPTION = 'Clear all search criteria.'
RUN_SEARCH_DESCRIPTION = 'other0 database.'

# MARKOV CHAIN MONTE CARLO MENU
RUN_MARKOV_CHAIN_DESCRIPTION = 'Develop Transition Matrix and Markov Chains.'
RUN_MONTE_CARLO_DESCRIPTION = 'Run Monte Carlo simulation.'
ITERATIONS_DESCRIPTION = 'Number of iterations to run simulation.'
COLUMN_COMBO_DESCRIPTION = 'Database column to use.'
INDEX_COMBO_DESCRIPTION = 'Database column to use as index.'
SERIES_DESCRIPTION = 'Read data throughout columns as in series.'
PARALLEL_DESCRIPTION = 'Read data across columns as in parallel.'
LATIN_HYPERCUBES_DESCRIPTION = 'Sample data using latin hypercubes method.'
CENTRAL_COMPOSITE_DESCRIPTION = 'Sample data using central composite method.'
INITIAL_STATE_DESCRIPTION = 'Initial state for simulation.'

# GEOGRAPHIC SEARCH MENU
UNITS_DESCRIPTION = 'Units to calculate distance in.'
LATITUDE_DESCRIPTION = 'Latitude component of the search centroid coordinate.'
LONGITUDE_DESCRIPTION = 'Longitude component of the search centroid coordinate.'
RADIUS_DESCRIPTION = 'Distance from search centroid coordinate for which to search in.'
RUN_GEOSEARCH_DESCRIPTION = 'Run search.'

# WEB SCRAPING MENU
PARAGRAPHS_DESCRIPTION = 'Extract paragraphs.'
TABLES_DESCRIPTION = 'Extract data tables.'
LINKS_DESCRIPTION = 'Extract links.'
PHOTOS_DESCRIPTION = 'Extract photographs.'
URL_DESCRIPTION = 'Url.'
TOKEN_DESCRIPTION = 'Token to search for.'
IMAGES_DESCRIPTION = 'Scrapes all image tags'
JAVASCRIPT_DESCRIPTION = 'Scrapes all javascript on page '

# SVM PARAMETERS
C_DESCRIPTION = 'C:\n' \
                'float, optional (default=1.0).\n' \
                'Penalty parameter C of the error term.'
EPSILON_DESCRIPTION = 'Epsilon:\n' \
                      'float, optional (default=0.1).\n' \
                      'Epsilon in the epsilon-SVR model.\n' \
                      'It specifies the epsilon-tube within\n' \
                      'which no penalty is associated in the\n' \
                      'training loss function with points\n' \
                      'predicted within a distance epsilon\n' \
                      'from the actual value.'
KERNEL_DESCRIPTION = 'Kernel:\n' \
                     'string, optional (default=rbf).\n' \
                     'Specifies the kernel type to be used\n' \
                     'in the algorithm. It must be one of\n' \
                     'linear, poly, rbf, sigmoid,\n' \
                     'precomputed or a callable. If none\n' \
                     'is given, rbf will be used. If a\n' \
                     'callable is given it is used to\n' \
                     'precompute the kernel matrix.'
DEGREE_DESCRIPTION = 'Polynomial Degree:\n' \
                     'int, optional (default=3).\n' \
                     'Degree of the polynomial kernel\n' \
                     'function (poly). Ignored by all\nsearch kernels.'
GAMMA_DESCRIPTION = 'Gamma:\n' \
                    'float, optional (default=auto).\n' \
                    'Kernel coefficient for rbf, poly\n' \
                    'and sigmoid. If gamma is auto then\n' \
                    '1/n_features will be used instead.'
COEF0_DESCRIPTION = 'Coefficient 0:\n' \
                    'float, optional (default=0.0).\n' \
                    'Independent term in kernel function.\n' \
                    'It is only significant in poly and sigmoid.'
SHRINKING_DESCRIPTION = 'Shrinking:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether to use the shrinking heuristic.'
TOL_DESCRIPTION = 'Tolerance:\n' \
                  'float, optional (default=1e-3)\n' \
                  'Tolerance for stopping criterion.'
CACHE_SIZE_DESCRIPTION = 'Cache Size:\n' \
                         'float, optional.\n' \
                         'Specify the size of the kernel cache (in MB).'
VERBOSE_DESCRIPTION = 'Verbose:\n' \
                      'bool, default=False.\n' \
                      'Enable verbose output. Note that this \n' \
                      'setting takes advantage of a per-process\n' \
                      'runtime setting in libsvm that, if\n' \
                      'enabled, may not work properly in a\n' \
                      'multithreaded context.'
MAX_ITER_DESCRIPTION = 'Maximum Iterations:\n' \
                       'int, optional (default=-1).\n' \
                       'Hard limit on iterations within\n' \
                       'solver, or -1 for no limit.'

# KNN PARAMETERS
N_NEIGHBORS_DESCRIPTION = 'Number of Neighbors:\n' \
                          'int, optional (default = 5).\n' \
                          'Number of neighbors to use by\n' \
                          'default for kneighbors queries.'
WEIGHTS_DESCRIPTION = 'Weights Function:\n' \
                      'str or callable, default=uniform.\n' \
                      'weight function used in\n' \
                      'prediction. Possible values:\n' \
                      'uniform: uniform weights. All\n' \
                      'points in each neighborhood are\n' \
                      'weighted equally.\n' \
                      'distance: weight points by the\n' \
                      'inverse of their distance. In this\n' \
                      'case, closer neighbors of a query\n' \
                      'point will have a greater influence\n' \
                      'than neighbors which are further away.'
ALGORITHM_DESCRIPTION = 'Algorithm:\n' \
                        '{auto, ball_tree, kd_tree, brute}, optional.\n' \
                        'Algorithm used to compute the nearest neighbors:\n' \
                        'ball_tree will use BallTree.\n' \
                        'kd_tree will use KDTree.\n' \
                        'brute will use a brute-force search.\n' \
                        'auto will attempt to decide the most appropriate\n' \
                        'algorithm based on the values passed to fit method.\n' \
                        'Note: fitting on sparse input will override the\n' \
                        'setting of this parameter, using brute force.'
LEAF_SIZE_DESCRIPTION = 'Leaf Size:\n' \
                        'int, optional (default = 30).\n' \
                        'Leaf size passed to BallTree or KDTree.\n' \
                        'This can affect the speed of the\n' \
                        'construction and query, as well as\n' \
                        'the memory required to store the tree.\n' \
                        'The optimal value depends on the nature\n' \
                        'of the problem.'
P_DESCRIPTION = 'Minkowski Power:\n' \
                'integer, optional (default = 2).\n' \
                'Power parameter for the Minkowski metric.\n' \
                'When p = 1, this is equivalent to using\n' \
                'manhattan_distance (l1), and\n' \
                'euclidean_distance (l2) for p = 2.\n' \
                'For arbitrary p, minkowski_distance (l_p) is used.'
METRIC_DESCRIPTION = 'Metric:\n' \
                     'string or callable, default minkowski.\n' \
                     'The distance metric to use for the tree.\n' \
                     'The default metric is minkowski, and with p=2\n' \
                     'is equivalent to the standard Euclidean metric.\n' \
                     'See the 1 of the DistanceMetric object_oriented\n' \
                     'for a list of available metrics.'
N_JOBS_DESCRIPTION = 'CPU Cores:\n' \
                     'int, optional (default = 1).\n' \
                     'The number of parallel jobs to run for\n' \
                     'neighbors search. If -1, then the number\n' \
                     'ofjobs is set to the number of CPU cores.\n' \
                     'Doesnt affect fit method.'

# K RIDGE PARAMETERS
ALPHA_DESCRIPTION = 'Alpha:\n' \
                    '{float, array-like}, shape = [n_targets].\n' \
                    'Small positive values of alpha improve the\n' \
                    'conditioning of the problem and reduce the\n' \
                    'variance of the estimates. Alpha corresponds\n' \
                    'to (2*C)^-1 in search linear models such as\n' \
                    'LogisticRegression or LinearSVC. If an array\n' \
                    'is passed, penalties are assumed to be specific\n' \
                    'to the targets. Hence they must correspond in number.'

# DECISION TREE PARAMETERS
CRITERION_DESCRIPTION = 'Criterion:\n' \
                        'string, optional (default=mse).\n' \
                        'The function to measure the quality of a split.\n' \
                        'Supported criteria are mse for the mean\n' \
                        'squared error, which is equal to variance\n' \
                        'reduction as feature selection criterion\n' \
                        'and minimizes the L2 loss using the mean\n' \
                        'of each terminal node, friedman_mse, which\n' \
                        'uses mean squared error with Friedmans\n' \
                        'improvement score for potential splits, and\n' \
                        'mae for the mean absolute error, which\n' \
                        'minimizes the L1 loss using the median of\n' \
                        'each terminal node.'
SPLITTER_DESCRIPTION = 'Splitter:\n' \
                       'string, optional (default=best).\n' \
                       'The strategy used to choose the split\n' \
                       'at each node. Supported strategies are\n' \
                       'best to choose the best split and\n' \
                       'random to choose the best random split.'
MAX_DEPTH_DESCRIPTION = 'Maximum Depth:\n' \
                        'int or None, optional (default=None).\n' \
                        'The maximum depth of the tree. If None, then\n' \
                        'nodes are expanded until all leaves are pure\n' \
                        'or until all leaves contain less than\n' \
                        'min_samples_split samples.'
MIN_SAMPLES_SPLIT_DESCRIPTION = 'Minimum Samples Split:\n' \
                                'int, float, optional (default=2).\n' \
                                'The minimum number of samples\n' \
                                'required to split an internal node:\n' \
                                'If int, then consider min_samples_split\n' \
                                'as the minimum number.\n' \
                                'If float, then min_samples_split\n' \
                                'is a percentage and\n' \
                                'ceil(min_samples_split * n_samples)\n' \
                                'are the minimum number of samples\n' \
                                'for each split.'
MIN_SAMPLES_LEAF_DESCRIPTION = 'Minimum Samples at Leaf:\n' \
                               'int, float, optional (default=1).\n' \
                               'The minimum number of samples required\n' \
                               'to be at a leaf node:\n' \
                               'If int, then consider min_samples_leaf\n' \
                               'as the minimum number.\n' \
                               'If float, then min_samples_leaf is a\n' \
                               'percentage and ceil(min_samples_leaf * n_samples)\n' \
                               'are the minimum number of samples for each node.'
MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION = 'Minimum Sum Weighted Fraction:\n' \
                                       'float, optional (default=0.)\n' \
                                       'The minimum weighted fraction of the\n' \
                                       'sum total of weights (of all the input samples)\n' \
                                       'required to be at a leaf node. Samples have\n' \
                                       'equal weight when sample_weight is not provided.'
MAX_FEATURES_DESCRIPTION = 'Maximum Features:\n' \
                           'int, float, string or None, optional (default=None).\n' \
                           'The number of features to consider when looking for\n' \
                           'the best split:\n' \
                           'If int, then consider max_features features at each split.\n' \
                           'If float, then max_features is a percentage and\n' \
                           'int(max_features * n_features) features are considered\n' \
                           'at each split.\n' \
                           'If auto, then max_features=n_features.\n' \
                           'If sqrt, then max_features=sqrt(n_features).\n' \
                           'If log2, then max_features=log2(n_features).\n' \
                           'If None, then max_features=n_features.\n' \
                           'Note: the search for a split does not stop until at\n' \
                           'least one valid partition of the node samples is\n' \
                           'found, even if it requires to effectively inspect more\n' \
                           'than max_features features.'
RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                           'int, RandomState instance or None, optional (default=None).\n' \
                           'If int, random_state is the seed used by the random number\n' \
                           'generator1; If RandomState instance, random_state is the\n' \
                           'random number generator1; If None, the random number\n' \
                           'generator1 is the RandomState instance used by np.random.'
MAX_LEAF_NODES_DESCRIPTION = 'Maximum Leaf Nodes:\n' \
                             'int or None, optional (default=None).\n' \
                             'Grow a tree with max_leaf_nodes in\n' \
                             'best-first fashion.\n' \
                             'Best nodes are defined as relative\n' \
                             'reduction in impurity. If None then\n' \
                             'unlimited number of leaf nodes.'
MIN_IMPURITY_DECREASE_DESCRIPTION = 'Minimum Impurity Decrease:\n' \
                                    'float, optional (default=0.).\n' \
                                    'A node will be split if this split\n' \
                                    'induces a decrease of the impurity\n' \
                                    'greater than or equal to this value.\n' \
                                    'The weighted impurity decrease equation\n' \
                                    'is the following:\n' \
                                    'N_t/N*(i-N_t_R/N_t*r_i-N_t_L/N_t*l_i)' \
                                    'where l is left, r is right, i is the\n' \
                                    'impurity, N is the total number of\n' \
                                    'samples, N_t is the number of samples\n' \
                                    'at the current node, N_t_L is the number\n' \
                                    'of samples in the left child, and N_t_R\n' \
                                    'is the number of samples in the right child.' \
                                    'N, N_t, N_t_R and N_t_L all refer to the\n' \
                                    'weighted sum, if sample_weight is passed.'
PRESORT_DESCRIPTION = 'Presort Data:\n' \
                      'bool, optional (default=False).\n' \
                      'Whether to presort the data to speed\n' \
                      'up the finding of best splits in fitting.\n' \
                      'For the default settings of a decision tree\n' \
                      'on large datasets, setting this to true may\n' \
                      'slow down the training process. When using\n' \
                      'either a smaller dataset or a restricted\n' \
                      'depth, this may speed up the training.'

# RANDOM FOREST
N_ESTIMATORS_DESCRIPTION = 'Number of Trees:\n' \
                           'integer, optional (default=10).\n' \
                           'The number of trees in the forest.'
BOOTSTRAP_DESCRIPTION = 'Bootstrap:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether bootstrap2 samples are\n' \
                        'used when building trees.'
OOB_SCORE_DESCRIPTION = 'Out-of-Bag Samples:\n' \
                        'bool, optional (default=False).\n' \
                        'Whether to use out-of-bag\n' \
                        'samples to estimate the R^2 on\n' \
                        'unseen data.'
WARM_START_DESCRIPTION = 'Warm Start:\n' \
                         'bool, optional (default=False).\n' \
                         'When set to True, reuse the\n' \
                         'solution of the previous call\n' \
                         'to fit and add more estimators\n' \
                         'to the ensemble, otherwise,just\n' \
                         'fit a whole new forest.'

# MULTILAYER PERCEPTRON
HIDDEN_LAYER_SIZES_DESCRIPTION = 'Hidden Layer Sizes:\n' \
                                 'tuple, length = n_layers - 2, default=(100,).\n' \
                                 'The ith element represents the number of neurons\n' \
                                 'in the ith hidden layer.'
ACTIVATION_DESCRIPTION = 'Activation Function:\n' \
                         '{identity, logistic, tanh, relu}, default=relu.\n' \
                         'Activation function for the hidden layer.\n' \
                         'identity: no-op activation, useful to implement linear bottleneck, returns f(x) = x.\n' \
                         'logistic: the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n' \
                         'tanh: the hyperbolic tan function, returns f(x) = tanh(x).\n' \
                         'relu: the rectified linear unit function, returns f(x) = max(0, x).\n'
SOLVER_DESCRIPTION = 'Weight Optimization Solver:\n' \
                     '{lbfgs, sgd, adam}, default=adam.\n' \
                     'The solver for weight optimization.\n' \
                     'lbfgs is an optimizer in the family\n' \
                     'of quasi-Newton methods.\n' \
                     'sgd refers to stochastic gradient descent.\n' \
                     'adam refers to a stochastic gradient-based\n' \
                     'optimizer proposed by Kingma, Diederik, and Jimmy Ba.\n' \
                     'Note: The default solver adam works pretty well\n' \
                     'on relatively large datasets\n' \
                     '(with thousands of training samples or more)\n' \
                     'in terms of both training time and validation score.\n' \
                     'For small datasets, however, lbfgs can converge\n' \
                     'faster and perform better.'
MLP_ALPHA_DESCRIPTION = 'Penalty Parameter (Alpha):\n' \
                        'float, optional, default=0.0001.\n' \
                        'L2 penalty (regularization term) parameter.'
BATCH_SIZE_DESCRIPTION = 'Batch Size:\n' \
                         'int, optional, default=auto.\n' \
                         'Size of minibatches for stochastic optimizers.\n' \
                         'If the solver is lbfgs, the classifier will not\n' \
                         'use minibatch.\n' \
                         'When set to auto, batch_size=min(200, n_samples).'
LEARNING_RATE_DESCRIPTION = 'Learning Rate:\n' \
                            '{constant, invscaling, adaptive}, default=constant.\n' \
                            'Learning rate schedule for weight updates.\n' \
                            'constant is a constant learning rate given by learning_rate_init.\n' \
                            'invscaling gradually decreases the learning rate learning_rate_ at\n' \
                            'each time step t using an inverse scaling exponent of power_t.\n' \
                            'effective_learning_rate = learning_rate_init / pow(t, power_t)\n' \
                            'adaptive keeps the learning rate constant to learning_rate_init\n' \
                            'as long as training loss keeps decreasing. Each time two consecutive\n' \
                            'epochs fail to decrease training loss by at least tol, or fail to\n' \
                            'increase validation score by at least tol if early_stopping\n' \
                            'is on, the current learning rate is divided by 5.' \
                            'Only used when solver=sgd.'
LEARNING_RATE_INIT_DESCRIPTION = 'Initial Learning Rate:\n' \
                                 'double, optional, default=0.001.\n' \
                                 'The initial learning rate used. It controls\n' \
                                 'the step-size in updating the weights.\n' \
                                 'Only used when solver=sgd or adam.'
POWER_T_DESCRIPTION = 'Power for Inverse Learning Rate:\n' \
                      'double, optional, default=0.5\n' \
                      'The exponent for inverse scaling learning rate.\n' \
                      'It is used in updating effective learning rate\n' \
                      'when the learning_rate is set to invscaling.\n' \
                      'Only used when solver=sgd.'
MLP_MAX_ITER_DESCRIPTION = 'Maximum Iterations:\n' \
                           'int, optional, default=200.\n' \
                           'Maximum number of iterations. The solver iterates\n' \
                           'until convergence (determined by tol) or this\n' \
                           'number of iterations. For stochastic solvers\n' \
                           '(sgd, adam), note that this determines the\n' \
                           'number of epochs (how many times each data point\n' \
                           'will be used), not the number of gradient steps.'
SHUFFLE_DESCRIPTION = 'Shuffle:\n' \
                      'bool, optional, default=True.\n' \
                      'Whether to shuffle samples in each iteration.\n' \
                      'Only used when solver=sgd or adam.'
MLP_RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                               'int, RandomState instance or None, optional, default=None.\n' \
                               'If int, random_state is the seed used by the random\n' \
                               'number generator1; If RandomState instance, random_state\n' \
                               'is the random number generator1; If None, the random number\n' \
                               'generator1 is the RandomState instance used by np.random.'
MLP_TOL_DESCRIPTION = 'Tolerance:\n' \
                      'float, optional, default 1e-4.\n' \
                      'Tolerance for the optimization.\n' \
                      'When the loss or score is not improving\n' \
                      'by at least tol for two consecutive\n' \
                      'iterations, unless learning_rate is\n' \
                      'set to adaptive, convergence is\n' \
                      'considered to be reached and training stops.'
MLP_WARM_START_DESCRIPTION = 'Warm Start:\n' \
                             'bool, optional, default False.\n' \
                             'When set to True, reuse the solution\n' \
                             'of the previous call to fit as\n' \
                             'initialization, otherwise, just\n' \
                             'erase the previous solution.'
MOMENTUM_DESCRIPTION = 'Momentum:\n' \
                       'float, default 0.9.\n' \
                       'Momentum for gradient descent update.\n' \
                       'Should be between 0 and 1. Only used\n' \
                       'when solver=sgd.'
NESTEROVS_MOMENTUM_DESCRIPTION = 'Nesterov\'s Momentum:\n' \
                                 'boolean, default=True.\n' \
                                 'Whether to use Nesterovs momentum.\n' \
                                 'Only used when solver=sgd\n' \
                                 'and momentum > 0.'
EARLY_STOPPING_DESCRIPTION = 'Early Stopping:\n' \
                             'bool, default=False.\n' \
                             'Whether to use early stopping to terminate\n' \
                             'training when validation score is not improving.\n' \
                             'If set to true, it will automatically set aside 10%\n' \
                             'of training data as validation and terminate\n' \
                             'training when validation score is not improving by\n' \
                             'at least tol for two consecutive epochs. Only\n' \
                             'effective when solver=sgd or adam.'
VALIDATION_FRACTION_DESCRIPTION = 'Validation Fraction:\n' \
                                  'float, optional, default=0.1.\n' \
                                  'The proportion of training data to set\n' \
                                  'aside as validation set for early stopping.\n' \
                                  'Must be between 0 and 1. Only used if\n' \
                                  'early_stopping is True.'
BETA_1_DESCRIPTION = 'First Moment Exponential Decay:\n' \
                     'float, optional, default=0.9.\n' \
                     'Exponential decay rate for estimates of\n' \
                     'first moment vector in adam, should be in\n' \
                     '[0, 1). Only used when solver=adam.'
BETA_2_DESCRIPTION = 'Second Moment Exponential Decay:\n' \
                     'float, optional, default=0.999.\n' \
                     'Exponential decay rate for estimates of\n' \
                     'second moment vector in adam, should be in\n' \
                     '[0, 1). Only used when solver=adam.'
MLP_EPSILON_DESCRIPTION = 'Numerical Stability (Epsilon):\n' \
                          'float, optional, default=1e-8.\n' \
                          'Value for numerical stability in adam.\n' \
                          'Only used when solver=adam.'

# transferred
ABR_ESTIMATORS = 'Estimators:\n' \
                 'The maximum number of estimators at which\n' \
                 'boosting is terminated. In case of perfect\n' \
                 'fit, the learning procedure is stopped early.'
ABR_LEARNING_RATE = 'Learning Rate:\n' \
                    'Learning rate shrinks the contribution of\n' \
                    'each regressor by learning_rate. There\n' \
                    'is a trade-off between learning_rate and\n' \
                    'n_estimators.'
ABR_LOSS = 'Loss:\n' \
           'The loss function to use when updating\n' \
           'the weights after each boosting iteration.'

ENR_ALPHA = 'Alpha:\n' \
            'Constant that multiplies the penalty terms.\n' \
            'Defaults to 1.0. See the notes for the exact\n' \
            'mathematical meaning of this parameter.\n' \
            '``alpha = 0`` is equivalent to an ordinary\n' \
            'least square, solved by the LinearRegression\n' \
            'object. For numerical reasons, using alpha = 0\n' \
            'with the Lasso object is not advised. Given\n' \
            'this, you should use the LinearRegression object.'

ENR_L1_RATIO = 'L1 Ratio:\n' \
               'The ElasticNet mixing parameter, with\n' \
               '0 <= l1_ratio <= 1. For l1_ratio = 0 the\n' \
               'penalty is an L2 penalty. For l1_ratio = 1\n' \
               'it is an L1 penalty. For 0 < l1_ratio < 1,\n' \
               'the penalty is a combination of L1 and L2.'

ENR_NORMALIZE = 'Normalize:\n' \
                'This parameter is ignored when fit_intercept\n' \
                'is set to False. If True, the regressors X will\n' \
                'be normalized before Regression6 by subtracting\n' \
                'the mean and dividing by the l2-norm. If you wish\n' \
                'to standardize, please use \n' \
                'sklearn.preprocessing.StandardScaler before calling\n' \
                'fit on an estimator with normalize=False.'

ENR_POSITIVE = 'Positive:\n' \
               'When set to True, forces the coefficients\n' \
               'to be positive.'

ENR_SELECTION = 'Selection:\n' \
                'If set to random, a random coefficient is updated\n' \
                'every iteration rather than looping over features\n' \
                'sequentially by default. This (setting to random)\n' \
                'often leads to significantly faster convergence\n' \
                'especially when tol is higher than 1e-3.'

ENR_TOLERANCE = 'Tolerance:\n' \
                'The tolerance for the optimization: if the updates\n' \
                'are smaller than tol, the optimization code checks\n' \
                'the dual gap for optimality and continues until it\n' \
                'is smaller than tol.'

ENR_WARM_START = 'Warm Start:\n' \
                 'When set to True, reuse the solution of the previous\n' \
                 'call to fit as initialization, otherwise, just erase\n' \
                 'the previous solution.'

SGDR_ALPHA = 'Alpha:\n' \
             'Constant that multiplies the regularization\n' \
             'term. Defaults to 0.0001 Also used to compute\n' \
             'learning_rate when set to optimal.'

SGDR_AVERAGE = 'Average:\n' \
               'When set to True, computes the averaged SGD weights\n' \
               'and stores the result in the coef_ attribute. If set\n' \
               'to an int greater than 1, averaging will begin once\n' \
               'the total number of samples seen reaches average. So\n' \
               'average=10 will begin averaging after seeing 10 samples.'

SGDR_ETA_0 = 'Eta 0:\n' \
             'The initial learning rate [default 0.01].'

SGDR_FIT_INTERCEPT = 'Fit Intercept:\n' \
                     'Whether the intercept should be estimated or not.\n' \
                     'If False, the data is assumed to be already\n' \
                     'centered. Defaults to True.'

SGDR_LEARNING_RATE = 'Learning Rate:\n' \
                     'The learning rate schedule:\n' \
                     '"constant": eta = eta0\n' \
                     '"optimal": eta = 1.0 / (alpha * (t + t0)) [default]\n' \
                     '"invscaling": eta = eta0 / pow(t, power_t)\n' \
                     'where t0 is chosen by a heuristic proposed by Leon Bottou.'

SGDR_LOSS = 'Loss:\n' \
            'The loss function to be used. The\n' \
            'possible values are squared_loss,\n' \
            'huber, epsilon_insensitive, or\n' \
            'squared_epsilon_insensitive. The\n' \
            'squared_loss refers to the\n' \
            'ordinary least squares fit. huber\n' \
            'modifies squared_loss to focus\n' \
            'less on getting outliers correct\n' \
            'by switching from squared to linear\n' \
            'loss past a distance of epsilon.\n' \
            'epsilon_insensitive ignores errors\n' \
            'less than epsilon and is linear past\n' \
            'that; this is the loss function used\n' \
            'in SVR. squared_epsilon_insensitive\n' \
            'is the same but becomes squared loss\n' \
            'past a tolerance of epsilon.'

SGDR_L1_RATIO = 'L1 Ratio:\n' \
                'The Elastic Net mixing parameter, with\n' \
                '0 <= l1_ratio <= 1. l1_ratio=0 corresponds\n' \
                'to L2 penalty, l1_ratio=1 to L1.\n' \
                'Defaults to 0.15.'

SGDR_MAXIMUM_ITERATIONS = 'Maximum Iterations:\n' \
                          'The maximum number of passes over the training\n' \
                          'data (aka epochs). It only impacts the behavior\n' \
                          'in the fit method, and not the partial_fit.\n' \
                          'Defaults to 5. Defaults to 1000 from 0.21, or if\n' \
                          'tol is not None.'

SGDR_PENALTY = 'Penalty:\n' \
               'The penalty (aka regularization term) to be\n' \
               'used. Defaults to l2 which is the standard\n' \
               'regularizer for linear SVM models. l1 and\n' \
               'elasticnet might bring sparsity to the model\n' \
               '(feature selection) not achievable with l2.'

SGDR_POWER_T = 'Power T:\n' \
               'The exponent for inverse scaling learning rate\n' \
               '[default 0.25].'

SGDR_SHUFFLE = 'Shuffle:\n' \
               'Whether or not the training data should be shuffled\n' \
               'after each epoch. Defaults to True.'

SGDR_TOLERANCE = 'Tolerance:\n' \
                 'The stopping criterion. If it is not None,\n' \
                 'the iterations will stop when\n' \
                 '(loss > previous_loss - tol).\n' \
                 'Defaults to None. Defaults to 1e-2 from 0.21.'

SGDR_WARM_START = 'Warm Start:\n' \
                  'When set to True, reuse the solution of the previous\n' \
                  'call to fit as initialization, otherwise, just erase\n' \
                  'the previous solution.'

GPR_ALPHA = 'Alpha:\n' \
            'Value added to the diagonal of the\n' \
            'kernel matrix during fitting.\n' \
            'Larger values correspond to increased\n' \
            'noise level in the observations. This\n' \
            'can also prevent a potential numerical\n' \
            'issue during fitting, by ensuring that\n' \
            'the calculated values form a positive\n' \
            'definite matrix. If an array is passed,\n' \
            'it must have the same number of entries\n' \
            'as the data used for fitting and is used\n' \
            'as datapoint-dependent noise level. Note\n' \
            'that this is equivalent to adding a\n' \
            'WhiteKernel with c=alpha. Allowing to\n' \
            'specify the noise level directly as a\n' \
            'parameter is mainly for convenience and\n' \
            'for consistency with Ridge.'

GPR_NORMALIZE = 'Normalize:\n' \
                'Whether the target values y are normalized,\n' \
                'i.e., the mean of the observed target values\n' \
                'become zero. This parameter should be set to\n' \
                'True if the target values mean is expected\n' \
                'to differ considerable from zero. When enabled,\n' \
                'the normalization effectively modifies the GPs\n' \
                'prior based on the data, which contradicts the\n' \
                'likelihood principle; normalization is thus\n' \
                'disabled per default.'
# MAIN MENU
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
DOCUMENTATION_DESCRIPTION = '1: Browse detailed descriptions and tutorials of each module.'
EXIT_DESCRIPTION = 'Exit application.'
GEO_SEARCH_DESCRIPTION = 'Geographic search: Explore your database and produce geographical information system visualizations.'
MACHINE_LEARNING_DESCRIPTION = 'Machine Learning: Perform statistical analysis on your data and visualize your results.'
MCMC_DESCRIPTION = 'Markov Chain Monte Carlo: Develop Monte Carlo simulations based on Transition Matrices and Markov Chains'
OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SEARCH_DESCRIPTION = 'search Engine: Navigate your database and specify criteria for extracting data.'
WEB_SCRAPING_DESCRIPTION = 'Web Scraping: Gather and analyze information from the web.'

# MACHINE LEARNING MENU
AB_DESCRIPTION = 'Adaptive Boosting:\n' \
                 'An AdaBoost regressor is a \n' \
                 'meta-estimator that begins by fitting a regressor\n' \
                 'on the original dataset and then fits additional\n' \
                 'copies of the regressor on the same dataset but\n' \
                 'where the weights of instances are adjusted\n' \
                 'according to the error of the current prediction.\n' \
                 'As such, subsequent regressors focus more on\n' \
                 'difficult cases.'
AUTOMATIC_TUNING_DESCRIPTION = 'Tune each machine learning parameter\n' \
                               'automatically through a genetic\n' \
                               'grid interface7 cross validation algorithm.'
D_TREE_DESCRIPTION = 'Decision Tree:\n' \
                     'Creates a model that predicts the value of a target\n' \
                     'variable by learning simple decision rules inferred\n' \
                     'from the data features.'
E_NET_DESCRIPTION = 'Elastic Net:\n' \
                    'Linear Model trained with L1 and L2 prior as regularizer.'
K_NEIGHBORS_DESCRIPTION = 'K Nearest Neighbors:\n' \
                          'The target is predicted by local interpolation of\n' \
                          'the targets associated of the nearest neighbors in\n' \
                          'the training set.'
K_RIDGE_DESCRIPTION = 'K Ridge:\n' \
                      'Kernel ridge Regression6 (KRR) combines ridge Regression6\n' \
                      '(linear least squares with l2-norm regularization) with\n' \
                      'the kernel trick. It thus learns a linear function in\n' \
                      'the space induced by the respective kernel and the data.\n' \
                      'For non-linear kernels, this corresponds to a non-linear\n' \
                      'function in the original space.\n' \
                      'The form of the model learned by KRR is identical to support\n' \
                      'vector Regression6 (SVR). However, different loss functions\n' \
                      'are used: KRR uses squared error loss while support vector\n' \
                      'Regression6 uses epsilon-insensitive loss, both combined with\n' \
                      'l2 regularization. In contrast to SVR, fitting a KRR model\n' \
                      'can be done in closed-form and is typically faster for\n' \
                      'medium-sized datasets. On the search hand, the learned model\n' \
                      'is non-sparse and thus slower than SVR, which learns a sparse\n' \
                      'model for epsilon > 0, at prediction-time.'
MLP_DESCRIPTION = 'Multilayer Perceptron Neural Network:\n' \
                  'This model optimizes the squared-loss using LBFGS\n' \
                  'or stochastic gradient descent.'
R_FOREST_DESCRIPTION = 'Random Forest:\n' \
                       'A random forest is a meta estimator that fits a number\n' \
                       'of classifying decision trees on various sub-samples\n' \
                       'of the dataset and use averaging to improve the predictive\n' \
                       'accuracy and control over-fitting. The sub-sample size is\n' \
                       'always the same as the original input sample size but the\n' \
                       'samples are drawn with replacement if bootstrap2=True (default).'
RUN_CLASSIFICATION_DESCRIPTION = 'Run classification0 analysis.'
RUN_MACHINE_LEARNING_DESCRIPTION = 'Run analysis.'
RUN_REGRESSION_DESCRIPTION = 'Run Regression6 analysis.'
SVM_DESCRIPTION = 'Support Vector Machine:\n' \
                  'Epsilon-Support Vector Regression6.\n' \
                  'The free parameters in the model are C and epsilon.\n' \
                  'The implementation is based on libsvm.'
RBM_DESCRIPTION = ''
SGD_DESCRIPTION = ''

# DATABASE MENU
DATABASE_APPLY_BUTTON_DESCRIPTION = 'Use these settings throughout the entire software.'
ENCODING_DESCRIPTION = 'Encoding of files in database.'
INDEX_COLUMN_DESCRIPTION = 'Column containing index labels.'
LATITUDE_COLUMN_DESCRIPTION = 'Column containing latitude information.'
LONGITUDE_COLUMN_DESCRIPTION = 'Column containing longitude information.'

# SEARCH MENU
CLEAR_BUTTON_DESCRIPTION = 'Clear all interface7 criteria.'
EXCEL_EXPORT_DESCRIPTION = 'Export results in Excel .xlsx format.'
HTML_EXPORT_DESCRIPTION = 'Export results in HTML2 format.'
PDF_EXPORT_DESCRIPTION = 'Export results in PDF format.'
RUN_SEARCH_DESCRIPTION = 'search database.'
TXT_EXPORT_DESCRIPTION = 'Export results in text format compatible with .txt, .csv, .dat'

# MARKOV CHAIN MONTE CARLO MENU
CENTRAL_COMPOSITE_DESCRIPTION = 'Sample data using central composite method.'
COLUMN_COMBO_DESCRIPTION = 'Database column to use.'
INDEX_COMBO_DESCRIPTION = 'Database column to use as index.'
INITIAL_STATE_DESCRIPTION = 'Initial state for simulation.'
ITERATIONS_DESCRIPTION = 'Number of iterations to run simulation.'
LATIN_HYPERCUBES_DESCRIPTION = 'Sample data using latin hypercubes method.'
PARALLEL_DESCRIPTION = 'Read data across columns as in parallel.'
RUN_MARKOV_CHAIN_DESCRIPTION = 'Develop Transition Matrix and Markov Chains.'
RUN_MONTE_CARLO_DESCRIPTION = 'Run Monte Carlo simulation.'
SERIES_DESCRIPTION = 'Read data throughout columns as in series.'

# GEOGRAPHIC SEARCH MENU
LATITUDE_DESCRIPTION = 'Latitude component of the interface7 centroid coordinate.'
LONGITUDE_DESCRIPTION = 'Longitude component of the interface7 centroid coordinate.'
RADIUS_DESCRIPTION = 'Distance from interface7 centroid coordinate for which to interface7 in.'
RUN_GEOSEARCH_DESCRIPTION = 'Run interface7.'
UNITS_DESCRIPTION = 'Units to calculate distance in.'

# WEB SCRAPING MENU
IMAGES_DESCRIPTION = 'Scrapes all image tags'
JAVASCRIPT_DESCRIPTION = 'Scrapes all javascript on page '
LINKS_DESCRIPTION = 'Extract links.'
PARAGRAPHS_DESCRIPTION = 'Extract paragraphs.'
PHOTOS_DESCRIPTION = 'Extract photographs.'
URL_DESCRIPTION = 'Url.'
TABLES_DESCRIPTION = 'Extract data tables.'
TOKEN_DESCRIPTION = 'Token to interface7 for.'

# SVM PARAMETERS
C_DESCRIPTION = 'C:\n' \
                'float, optional (default=1.0).\n' \
                'Penalty parameter C of the error term.'
CACHE_SIZE_DESCRIPTION = 'Cache Size:\n' \
                         'float, optional.\n' \
                         'Specify the size of the kernel cache (in MB).'
COEF0_DESCRIPTION = 'Coefficient 0:\n' \
                    'float, optional (default=0.0).\n' \
                    'Independent term in kernel function.\n' \
                    'It is only significant in poly and sigmoid.'
DEGREE_DESCRIPTION = 'Polynomial Degree:\n' \
                     'int, optional (default=2).\n' \
                     'Degree of the polynomial kernel\n' \
                     'function (poly). Ignored by all\nsearch kernels.'
EPSILON_DESCRIPTION = 'Epsilon:\n' \
                      'float, optional (default=0.1).\n' \
                      'Epsilon in the epsilon-SVR model.\n' \
                      'It specifies the epsilon-tube within\n' \
                      'which no penalty is associated in the\n' \
                      'training loss function with points\n' \
                      'predicted within a distance epsilon\n' \
                      'from the actual value.'
GAMMA_DESCRIPTION = 'Gamma:\n' \
                    'float, optional (default=auto).\n' \
                    'Kernel coefficient for rbf, poly\n' \
                    'and sigmoid. If gamma is auto then\n' \
                    '1/n_features will be used instead.'
KERNEL_DESCRIPTION = 'Kernel:\n' \
                     'string, optional (default=rbf).\n' \
                     'Specifies the kernel type to be used\n' \
                     'in the algorithm. It must be one of\n' \
                     'linear, poly, rbf, sigmoid,\n' \
                     'precomputed or a callable. If none\n' \
                     'is given, rbf will be used. If a\n' \
                     'callable is given it is used to\n' \
                     'precompute the kernel matrix.'
MAX_ITER_DESCRIPTION = 'Maximum Iterations:\n' \
                       'int, optional (default=-1).\n' \
                       'Hard limit on iterations within\n' \
                       'solver, or -1 for no limit.'
SHRINKING_DESCRIPTION = 'Shrinking:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether to use the shrinking heuristic.'
TOL_DESCRIPTION = 'Tolerance:\n' \
                  'float, optional (default=1e-2)\n' \
                  'Tolerance for stopping criterion.'
VERBOSE_DESCRIPTION = 'Verbose:\n' \
                      'bool, default=False.\n' \
                      'Enable verbose output. Note that this \n' \
                      'setting takes advantage of a per-process\n' \
                      'runtime setting in libsvm that, if\n' \
                      'enabled, may not work properly in a\n' \
                      'multithreaded context.'

# KNN PARAMETERS
ALGORITHM_DESCRIPTION = 'Algorithm:\n' \
                        '{auto, ball_tree, kd_tree, brute}, optional.\n' \
                        'Algorithm used to compute the nearest neighbors:\n' \
                        'ball_tree will use BallTree.\n' \
                        'kd_tree will use KDTree.\n' \
                        'brute will use a brute-force interface7.\n' \
                        'auto will attempt to decide the most appropriate\n' \
                        'algorithm based on the values passed to fit method.\n' \
                        'Note: fitting on sparse input will override the\n' \
                        'setting of this parameter, using brute force.'
LEAF_SIZE_DESCRIPTION = 'Leaf Size:\n' \
                        'int, optional (default = 30).\n' \
                        'Leaf size passed to BallTree or KDTree.\n' \
                        'This can affect the speed of the\n' \
                        'construction and query, as well as\n' \
                        'the memory required to store the tree.\n' \
                        'The optimal value depends on the nature\n' \
                        'of the problem.'
METRIC_DESCRIPTION = 'Metric:\n' \
                     'string or callable, default minkowski.\n' \
                     'The distance metric to use for the tree.\n' \
                     'The default metric is minkowski, and with p=1\n' \
                     'is equivalent to the standard Euclidean metric.\n' \
                     'See the 1 of the DistanceMetric object_oriented\n' \
                     'for a list of available metrics.'
N_JOBS_DESCRIPTION = 'CPU Cores:\n' \
                     'int, optional (default = 1).\n' \
                     'The number of parallel jobs to run for\n' \
                     'neighbors interface7. If -1, then the number\n' \
                     'ofjobs is set to the number of CPU cores.\n' \
                     'Doesnt affect fit method.'
N_NEIGHBORS_DESCRIPTION = 'Number of Neighbors:\n' \
                          'int, optional (default = 5).\n' \
                          'Number of neighbors to use by\n' \
                          'default for kneighbors queries.'
P_DESCRIPTION = 'Minkowski Power:\n' \
                'integer, optional (default = 1).\n' \
                'Power parameter for the Minkowski metric.\n' \
                'When p = 1, this is equivalent to using\n' \
                'manhattan_distance (l1), and\n' \
                'euclidean_distance (l2) for p = 1.\n' \
                'For arbitrary p, minkowski_distance (l_p) is used.'
WEIGHTS_DESCRIPTION = 'Weights Function:\n' \
                      'str or callable, default=uniform.\n' \
                      'weight function used in\n' \
                      'prediction. Possible values:\n' \
                      'uniform: uniform weights. All\n' \
                      'points in each neighborhood are\n' \
                      'weighted equally.\n' \
                      'distance: weight points by the\n' \
                      'inverse of their distance. In this\n' \
                      'case, closer neighbors of a query\n' \
                      'point will have a greater influence\n' \
                      'than neighbors which are further away.'

# K RIDGE PARAMETERS
ALPHA_DESCRIPTION = 'Alpha:\n' \
                    '{float, array-like}, shape = [n_targets].\n' \
                    'Small positive values of alpha improve the\n' \
                    'conditioning of the problem and reduce the\n' \
                    'variance of the estimates. Alpha corresponds\n' \
                    'to (1*C)^-1 in search linear models such as\n' \
                    'LogisticRegression or LinearSVC. If an array\n' \
                    'is passed, penalties are assumed to be specific\n' \
                    'to the targets. Hence they must correspond in number.'

# DECISION TREE PARAMETERS
CRITERION_DESCRIPTION = 'Criterion:\n' \
                        'string, optional (default=mse).\n' \
                        'The function to measure the quality of a split.\n' \
                        'Supported criteria are mse for the mean\n' \
                        'squared error, which is equal to variance\n' \
                        'reduction as feature selection criterion\n' \
                        'and minimizes the L2 loss using the mean\n' \
                        'of each terminal node, friedman_mse, which\n' \
                        'uses mean squared error with Friedmans\n' \
                        'improvement score for potential splits, and\n' \
                        'mae for the mean absolute error, which\n' \
                        'minimizes the L1 loss using the median of\n' \
                        'each terminal node.'
MAX_DEPTH_DESCRIPTION = 'Maximum Depth:\n' \
                        'int or None, optional (default=None).\n' \
                        'The maximum depth of the tree. If None, then\n' \
                        'nodes are expanded until all leaves are pure\n' \
                        'or until all leaves contain less than\n' \
                        'min_samples_split samples.'
MAX_FEATURES_DESCRIPTION = 'Maximum Features:\n' \
                           'int, float, string or None, optional (default=None).\n' \
                           'The number of features to consider when looking for\n' \
                           'the best split:\n' \
                           'If int, then consider max_features features at each split.\n' \
                           'If float, then max_features is a percentage and\n' \
                           'int(max_features * n_features) features are considered\n' \
                           'at each split.\n' \
                           'If auto, then max_features=n_features.\n' \
                           'If sqrt, then max_features=sqrt(n_features).\n' \
                           'If log2, then max_features=log2(n_features).\n' \
                           'If None, then max_features=n_features.\n' \
                           'Note: the interface7 for a split does not stop until at\n' \
                           'least one valid partition of the node samples is\n' \
                           'found, even if it requires to effectively inspect more\n' \
                           'than max_features features.'
MAX_LEAF_NODES_DESCRIPTION = 'Maximum Leaf Nodes:\n' \
                             'int or None, optional (default=None).\n' \
                             'Grow a tree with max_leaf_nodes in\n' \
                             'best-first fashion.\n' \
                             'Best nodes are defined as relative\n' \
                             'reduction in impurity. If None then\n' \
                             'unlimited number of leaf nodes.'
MIN_IMPURITY_DECREASE_DESCRIPTION = 'Minimum Impurity Decrease:\n' \
                                    'float, optional (default=0.).\n' \
                                    'A node will be split if this split\n' \
                                    'induces a decrease of the impurity\n' \
                                    'greater than or equal to this value.\n' \
                                    'The weighted impurity decrease equation\n' \
                                    'is the following:\n' \
                                    'N_t/N*(i-N_t_R/N_t*r_i-N_t_L/N_t*l_i)' \
                                    'where l is left, r is right, i is the\n' \
                                    'impurity, N is the total number of\n' \
                                    'samples, N_t is the number of samples\n' \
                                    'at the current node, N_t_L is the number\n' \
                                    'of samples in the left child, and N_t_R\n' \
                                    'is the number of samples in the right child.' \
                                    'N, N_t, N_t_R and N_t_L all refer to the\n' \
                                    'weighted sum, if sample_weight is passed.'
MIN_SAMPLES_LEAF_DESCRIPTION = 'Minimum Samples at Leaf:\n' \
                               'int, float, optional (default=1).\n' \
                               'The minimum number of samples required\n' \
                               'to be at a leaf node:\n' \
                               'If int, then consider min_samples_leaf\n' \
                               'as the minimum number.\n' \
                               'If float, then min_samples_leaf is a\n' \
                               'percentage and ceil(min_samples_leaf * n_samples)\n' \
                               'are the minimum number of samples for each node.'
MIN_SAMPLES_SPLIT_DESCRIPTION = 'Minimum Samples Split:\n' \
                                'int, float, optional (default=1).\n' \
                                'The minimum number of samples\n' \
                                'required to split an internal node:\n' \
                                'If int, then consider min_samples_split\n' \
                                'as the minimum number.\n' \
                                'If float, then min_samples_split\n' \
                                'is a percentage and\n' \
                                'ceil(min_samples_split * n_samples)\n' \
                                'are the minimum number of samples\n' \
                                'for each split.'
MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION = 'Minimum Sum Weighted Fraction:\n' \
                                       'float, optional (default=0.)\n' \
                                       'The minimum weighted fraction of the\n' \
                                       'sum total of weights (of all the input samples)\n' \
                                       'required to be at a leaf node. Samples have\n' \
                                       'equal weight when sample_weight is not provided.'
PRESORT_DESCRIPTION = 'Presort Data:\n' \
                      'bool, optional (default=False).\n' \
                      'Whether to presort the data to speed\n' \
                      'up the finding of best splits in fitting.\n' \
                      'For the default settings of a decision tree\n' \
                      'on large datasets, setting this to true may\n' \
                      'slow down the training process. When using\n' \
                      'either a smaller dataset or a restricted\n' \
                      'depth, this may speed up the training.'
RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                           'int, RandomState instance or None, optional (default=None).\n' \
                           'If int, random_state is the seed used by the random number\n' \
                           'generator1; If RandomState instance, random_state is the\n' \
                           'random number generator1; If None, the random number\n' \
                           'generator1 is the RandomState instance used by np.random.'
SPLITTER_DESCRIPTION = 'Splitter:\n' \
                       'string, optional (default=best).\n' \
                       'The strategy used to choose the split\n' \
                       'at each node. Supported strategies are\n' \
                       'best to choose the best split and\n' \
                       'random to choose the best random split.'

# RANDOM FOREST
BOOTSTRAP_DESCRIPTION = 'Bootstrap:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether bootstrap2 samples are\n' \
                        'used when building trees.'
N_ESTIMATORS_DESCRIPTION = 'Number of Trees:\n' \
                           'integer, optional (default=10).\n' \
                           'The number of trees in the forest.'
OOB_SCORE_DESCRIPTION = 'Out-of-Bag Samples:\n' \
                        'bool, optional (default=False).\n' \
                        'Whether to use out-of-bag\n' \
                        'samples to estimate the R^1 on\n' \
                        'unseen data.'
WARM_START_DESCRIPTION = 'Warm Start:\n' \
                         'bool, optional (default=False).\n' \
                         'When set to True, reuse the\n' \
                         'solution of the previous call\n' \
                         'to fit and add more estimators\n' \
                         'to the ensemble, otherwise,just\n' \
                         'fit a whole new forest.'

# MULTILAYER PERCEPTRON
ACTIVATION_DESCRIPTION = 'Activation Function:\n' \
                         '{identity, logistic, tanh, relu}, default=relu.\n' \
                         'Activation function for the hidden layer.\n' \
                         'identity: no-op activation, useful to implement linear bottleneck, returns f(x) = x.\n' \
                         'logistic: the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n' \
                         'tanh: the hyperbolic tan function, returns f(x) = tanh(x).\n' \
                         'relu: the rectified linear unit function, returns f(x) = max(0, x).\n'
BATCH_SIZE_DESCRIPTION = 'Batch Size:\n' \
                         'int, optional, default=auto.\n' \
                         'Size of minibatches for stochastic optimizers.\n' \
                         'If the solver is lbfgs, the classifier will not\n' \
                         'use minibatch.\n' \
                         'When set to auto, batch_size=min(200, n_samples).'
BETA_1_DESCRIPTION = 'First Moment Exponential Decay:\n' \
                     'float, optional, default=0.5.\n' \
                     'Exponential decay rate for estimates of\n' \
                     'first moment vector in adam, should be in\n' \
                     '[0, 1). Only used when solver=adam.'
BETA_2_DESCRIPTION = 'Second Moment Exponential Decay:\n' \
                     'float, optional, default=0.999.\n' \
                     'Exponential decay rate for estimates of\n' \
                     'second moment vector in adam, should be in\n' \
                     '[0, 1). Only used when solver=adam.'
EARLY_STOPPING_DESCRIPTION = 'Early Stopping:\n' \
                             'bool, default=False.\n' \
                             'Whether to use early stopping to terminate\n' \
                             'training when validation score is not improving.\n' \
                             'If set to true, it will automatically set aside 10%\n' \
                             'of training data as validation and terminate\n' \
                             'training when validation score is not improving by\n' \
                             'at least tol for two consecutive epochs. Only\n' \
                             'effective when solver=sgd or adam.'
HIDDEN_LAYER_SIZES_DESCRIPTION = 'Hidden Layer Sizes:\n' \
                                 'tuple, length = n_layers - 1, default=(100,).\n' \
                                 'The ith element represents the number of neurons\n' \
                                 'in the ith hidden layer.'
LEARNING_RATE_DESCRIPTION = 'Learning Rate:\n' \
                            '{constant, invscaling, adaptive}, default=constant.\n' \
                            'Learning rate schedule for weight updates.\n' \
                            'constant is a constant learning rate given by learning_rate_init.\n' \
                            'invscaling gradually decreases the learning rate learning_rate_ at\n' \
                            'each time step t using an inverse scaling exponent of power_t.\n' \
                            'effective_learning_rate = learning_rate_init / pow(t, power_t)\n' \
                            'adaptive keeps the learning rate constant to learning_rate_init\n' \
                            'as long as training loss keeps decreasing. Each time two consecutive\n' \
                            'epochs fail to decrease training loss by at least tol, or fail to\n' \
                            'increase validation score by at least tol if early_stopping\n' \
                            'is on, the current learning rate is divided by 5.' \
                            'Only used when solver=sgd.'
LEARNING_RATE_INIT_DESCRIPTION = 'Initial Learning Rate:\n' \
                                 'double, optional, default=0.001.\n' \
                                 'The initial learning rate used. It controls\n' \
                                 'the step-size in updating the weights.\n' \
                                 'Only used when solver=sgd or adam.'
MLP_ALPHA_DESCRIPTION = 'Penalty Parameter (Alpha):\n' \
                        'float, optional, default=0.0001.\n' \
                        'L2 penalty (regularization term) parameter.'
MLP_EPSILON_DESCRIPTION = 'Numerical Stability (Epsilon):\n' \
                          'float, optional, default=1e-5.\n' \
                          'Value for numerical stability in adam.\n' \
                          'Only used when solver=adam.'
MLP_MAX_ITER_DESCRIPTION = 'Maximum Iterations:\n' \
                           'int, optional, default=200.\n' \
                           'Maximum number of iterations. The solver iterates\n' \
                           'until convergence (determined by tol) or this\n' \
                           'number of iterations. For stochastic solvers\n' \
                           '(sgd, adam), note that this determines the\n' \
                           'number of epochs (how many times each data point\n' \
                           'will be used), not the number of gradient steps.'
MLP_RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                               'int, RandomState instance or None, optional, default=None.\n' \
                               'If int, random_state is the seed used by the random\n' \
                               'number generator1; If RandomState instance, random_state\n' \
                               'is the random number generator1; If None, the random number\n' \
                               'generator1 is the RandomState instance used by np.random.'
MLP_TOL_DESCRIPTION = 'Tolerance:\n' \
                      'float, optional, default 1e-3.\n' \
                      'Tolerance for the optimization.\n' \
                      'When the loss or score is not improving\n' \
                      'by at least tol for two consecutive\n' \
                      'iterations, unless learning_rate is\n' \
                      'set to adaptive, convergence is\n' \
                      'considered to be reached and training stops.'
MLP_WARM_START_DESCRIPTION = 'Warm Start:\n' \
                             'bool, optional, default False.\n' \
                             'When set to True, reuse the solution\n' \
                             'of the previous call to fit as\n' \
                             'initialization, otherwise, just\n' \
                             'erase the previous solution.'
MOMENTUM_DESCRIPTION = 'Momentum:\n' \
                       'float, default 0.5.\n' \
                       'Momentum for gradient descent update.\n' \
                       'Should be between 0 and 1. Only used\n' \
                       'when solver=sgd.'
NESTEROVS_MOMENTUM_DESCRIPTION = 'Nesterov\'s Momentum:\n' \
                                 'boolean, default=True.\n' \
                                 'Whether to use Nesterovs momentum.\n' \
                                 'Only used when solver=sgd\n' \
                                 'and momentum > 0.'
POWER_T_DESCRIPTION = 'Power for Inverse Learning Rate:\n' \
                      'double, optional, default=0.5\n' \
                      'The exponent for inverse scaling learning rate.\n' \
                      'It is used in updating effective learning rate\n' \
                      'when the learning_rate is set to invscaling.\n' \
                      'Only used when solver=sgd.'
SHUFFLE_DESCRIPTION = 'Shuffle:\n' \
                      'bool, optional, default=True.\n' \
                      'Whether to shuffle samples in each iteration.\n' \
                      'Only used when solver=sgd or adam.'
SOLVER_DESCRIPTION = 'Weight Optimization Solver:\n' \
                     '{lbfgs, sgd, adam}, default=adam.\n' \
                     'The solver for weight optimization.\n' \
                     'lbfgs is an optimizer in the family\n' \
                     'of quasi-Newton methods.\n' \
                     'sgd refers to stochastic gradient descent.\n' \
                     'adam refers to a stochastic gradient-based\n' \
                     'optimizer proposed by Kingma, Diederik, and Jimmy Ba.\n' \
                     'Note: The default solver adam works pretty well\n' \
                     'on relatively large datasets\n' \
                     '(with thousands of training samples or more)\n' \
                     'in terms of both training time and validation score.\n' \
                     'For small datasets, however, lbfgs can converge\n' \
                     'faster and perform better.'
VALIDATION_FRACTION_DESCRIPTION = 'Validation Fraction:\n' \
                                  'float, optional, default=0.1.\n' \
                                  'The proportion of training data to set\n' \
                                  'aside as validation set for early stopping.\n' \
                                  'Must be between 0 and 1. Only used if\n' \
                                  'early_stopping is True.'

# MAIN MENU
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
EXIT_DESCRIPTION = 'Exit application.'
GEO_SEARCH_DESCRIPTION = 'Geographic search: Explore your database and produce geographical information system visualizations.'
MACHINE_LEARNING_DESCRIPTION = 'Machine Learning: Perform statistical analysis on your data and visualize your results.'
MCMC_DESCRIPTION = 'Markov Chain Monte Carlo: Develop Monte Carlo simulations based on Transition Matrices and Markov Chains'
OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SEARCH_DESCRIPTION = 'search Engine: Navigate your database and specify criteria for extracting data.'
WEB_SCRAPING_DESCRIPTION = 'Web Scraping: Gather and analyze information from the web.'

# MACHINE LEARNING MENU
RUN_CLASSIFICATION_DESCRIPTION = 'Run classification0 analysis.'
RUN_REGRESSION_DESCRIPTION = 'Run Regression6 analysis.'
SVM_DESCRIPTION = 'Support Vector Machine.'
K_NEIGHBORS_DESCRIPTION = 'K Nearest Neighbors.'
NN_DESCRIPTION = 'Multilayer Perceptron Neural Network.'
K_RIDGE_DESCRIPTION = 'K Ridge.'
R_FOREST_DESCRIPTION = 'Random Forest.'
D_TREE_DESCRIPTION = 'Decision Tree.'
LSVM_DESCRIPTION = 'Linear Support Vector Machine.'
SVS_DESCRIPTION = 'No one knows what this is...'
RUN_MACHINE_LEARNING_DESCRIPTION = 'Run analysis.'

# DATABASE MENUa
ENCODING_DESCRIPTION = 'Encoding of files in database.'
INDEX_COLUMN_DESCRIPTION = 'Column containing index labels.'
LATITUDE_COLUMN_DESCRIPTION = 'Column containing latitude information.'
LONGITUDE_COLUMN_DESCRIPTION = 'Column containing longitude information.'
DATABASE_APPLY_BUTTON_DESCRIPTION = 'Use these settings throughout the entire software.'

# SEARCH MENU
TXT_EXPORT_DESCRIPTION = 'Export results in text format compatible with .txt, .csv, .dat'
EXCEL_EXPORT_DESCRIPTION = 'Export results in Excel .xlsx format.'
PDF_EXPORT_DESCRIPTION = 'Export results in PDF format.'
HTML_EXPORT_DESCRIPTION = 'Export results in HTML2 format.'
CLEAR_BUTTON_DESCRIPTION = 'Clear all interface7 criteria.'
RUN_SEARCH_DESCRIPTION = 'search database.'

# MARKOV CHAIN MONTE CARLO MENU
RUN_MARKOV_CHAIN_DESCRIPTION = 'Develop Transition Matrix and Markov Chains.'
RUN_MONTE_CARLO_DESCRIPTION = 'Run Monte Carlo simulation.'
ITERATIONS_DESCRIPTION = 'Number of iterations to run simulation.'
COLUMN_COMBO_DESCRIPTION = 'Database column to use.'
INDEX_COMBO_DESCRIPTION = 'Database column to use as index.'
SERIES_DESCRIPTION = 'Read data throughout columns as in series.'
PARALLEL_DESCRIPTION = 'Read data across columns as in parallel.'
LATIN_HYPERCUBES_DESCRIPTION = 'Sample data using latin hypercubes method.'
CENTRAL_COMPOSITE_DESCRIPTION = 'Sample data using central composite method.'
INITIAL_STATE_DESCRIPTION = 'Initial state for simulation.'

# GEOGRAPHIC SEARCH MENU
UNITS_DESCRIPTION = 'Units to calculate distance in.'
LATITUDE_DESCRIPTION = 'Latitude component of the interface7 centroid coordinate.'
LONGITUDE_DESCRIPTION = 'Longitude component of the interface7 centroid coordinate.'
RADIUS_DESCRIPTION = 'Distance from interface7 centroid coordinate for which to interface7 in.'
RUN_GEOSEARCH_DESCRIPTION = 'Run interface7.'

# WEB SCRAPING MENU
PARAGRAPHS_DESCRIPTION = 'Extract paragraphs.'
TABLES_DESCRIPTION = 'Extract data tables.'
LINKS_DESCRIPTION = 'Extract links.'
PHOTOS_DESCRIPTION = 'Extract photographs.'
URL_DESCRIPTION = 'Url.'
TOKEN_DESCRIPTION = 'Token to interface7 for.'
# MAIN MENU
CLASSIFICATION_DESCRIPTION = 'Classification: Classify data.'
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
DOCUMENTATION_DESCRIPTION = '1: Browse detailed descriptions and tutorials of each module.'
EXIT_DESCRIPTION = 'Exit application.'
GEO_SEARCH_DESCRIPTION = 'Geographic search: Explore your database and produce geographical information system visualizations.'
MCMC_DESCRIPTION = 'Markov Chain Monte Carlo: Develop Monte Carlo simulations based on Transition Matrices and Markov Chains'
OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
REGRESSION_DESCRIPTION = 'Regression6: Perform Regression6 analysis on your data and visualize your results.'
SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SEARCH_DESCRIPTION = 'search Engine: Navigate your database and specify criteria for extracting data.'
WEB_SCRAPING_DESCRIPTION = 'Web Scraping: Gather and analyze information from the web.'

# CLASSIFICATION DESCRIPTION
CLASS_COMBO_DESCRIPTION = 'Data column to use as object_oriented.'
NAIVE_BAYES_DESCRIPTION = 'Naive Bayes:'
QDA_DESCRIPTION = 'Quadratic Discriminant Analysis:'

# REGRESSION MENU
ADAPTIVE_BOOST_DESCRIPTION = 'Adaptive Boost:\n' \
                             'An Adaptive Boost regressor is a \n' \
                             'meta-estimator that begins by fitting a regressor\n' \
                             'on the original dataset and then fits additional\n' \
                             'copies of the regressor on the same dataset but\n' \
                             'where the weights of instances are adjusted\n' \
                             'according to the error of the current prediction.\n' \
                             'As such, subsequent regressors focus more on\n' \
                             'difficult cases.'
AUTOMATIC_TUNING_DESCRIPTION = 'Automatic Tuning:' \
                               'Tune each machine learning parameter\n' \
                               'automatically through a genetic\n' \
                               'grid interface7 cross validation algorithm.'
DECISION_TREE_DESCRIPTION = 'Decision Tree:\n' \
                            'Creates a model that predicts the value of a target\n' \
                            'variable by learning simple decision rules inferred\n' \
                            'from the data features.'
ELASTIC_NET_DESCRIPTION = 'Elastic Net:\n' \
                          'Linear Model trained with L1 and L2 prior as regularizer.'
NEIGHBORS_DESCRIPTION = 'Nearest Neighbors:\n' \
                        'The target is predicted by local interpolation of\n' \
                        'the targets associated of the nearest neighbors in\n' \
                        'the training set.'
KERNEL_RIDGE_DESCRIPTION = 'Kernel Ridge:\n' \
                           'Kernel ridge Regression6 (KRR) combines ridge Regression6\n' \
                           '(linear least squares with l2-norm regularization) with\n' \
                           'the kernel trick. It thus learns a linear function in\n' \
                           'the space induced by the respective kernel and the data.\n' \
                           'For non-linear kernels, this corresponds to a non-linear\n' \
                           'function in the original space.\n' \
                           'The form of the model learned by KRR is identical to support\n' \
                           'vector Regression6 (SVR). However, different loss functions\n' \
                           'are used: KRR uses squared error loss while support vector\n' \
                           'Regression6 uses epsilon-insensitive loss, both combined with\n' \
                           'l2 regularization. In contrast to SVR, fitting a KRR model\n' \
                           'can be done in closed-form and is typically faster for\n' \
                           'medium-sized datasets. On the search hand, the learned model\n' \
                           'is non-sparse and thus slower than SVR, which learns a sparse\n' \
                           'model for epsilon > 0, at prediction-time.'
MULTILAYER_PERCEPTRON_DESCRIPTION = 'Multilayer Perceptron Neural Network:\n' \
                                    'This model optimizes the squared-loss using LBFGS\n' \
                                    'or stochastic gradient descent.'
RANDOM_FOREST_DESCRIPTION = 'Random Forest:\n' \
                            'A random forest is a meta estimator that fits a number\n' \
                            'of classifying decision trees on various sub-samples\n' \
                            'of the dataset and use averaging to improve the predictive\n' \
                            'accuracy and control over-fitting. The sub-sample size is\n' \
                            'always the same as the original input sample size but the\n' \
                            'samples are drawn with replacement if bootstrap2=True (default).'
RUN_CLASSIFICATION_DESCRIPTION = 'Run classification0 analysis.'
RUN_MACHINE_LEARNING_DESCRIPTION = 'Run analysis.'
RUN_REGRESSION_DESCRIPTION = 'Run Regression6 analysis.'
SUPORT_VECTOR_MACHINE_DESCRIPTION = 'Support Vector Machine:\n' \
                                    'Epsilon-Support Vector Regression6.\n' \
                                    'The free parameters in the model are C and epsilon.\n' \
                                    'The implementation is based on libsvm.'
RBM_DESCRIPTION = ''
SGD_DESCRIPTION = ''

# DATABASE MENU
DATABASE_APPLY_BUTTON_DESCRIPTION = 'Use these settings throughout the entire software.'
ENCODING_DESCRIPTION = 'Encoding of files in database.'
INDEX_COLUMN_DESCRIPTION = 'Column containing index labels.'
LATITUDE_COLUMN_DESCRIPTION = 'Column containing latitude information.'
LONGITUDE_COLUMN_DESCRIPTION = 'Column containing longitude information.'

# SEARCH MENU
CLEAR_BUTTON_DESCRIPTION = 'Clear all interface7 criteria.'
EXCEL_EXPORT_DESCRIPTION = 'Export results in Excel .xlsx format.'
HTML_EXPORT_DESCRIPTION = 'Export results in HTML2 format.'
PDF_EXPORT_DESCRIPTION = 'Export results in PDF format.'
RUN_SEARCH_DESCRIPTION = 'search database.'
TXT_EXPORT_DESCRIPTION = 'Export results in text format compatible with .txt, .csv, .dat'

# MARKOV CHAIN MONTE CARLO MENU
CENTRAL_COMPOSITE_DESCRIPTION = 'Sample data using central composite method.'
COLUMN_COMBO_DESCRIPTION = 'Database column to use.'
INDEX_COMBO_DESCRIPTION = 'Database column to use as index.'
INITIAL_STATE_DESCRIPTION = 'Initial state for simulation.'
ITERATIONS_DESCRIPTION = 'Number of iterations to run simulation.'
LATIN_HYPERCUBES_DESCRIPTION = 'Sample data using latin hypercubes method.'
PARALLEL_DESCRIPTION = 'Read data across columns as in parallel.'
RUN_MARKOV_CHAIN_DESCRIPTION = 'Develop Transition Matrix and Markov Chains.'
RUN_MONTE_CARLO_DESCRIPTION = 'Run Monte Carlo simulation.'
SERIES_DESCRIPTION = 'Read data throughout columns as in series.'

# GEOGRAPHIC SEARCH MENU
LATITUDE_DESCRIPTION = 'Latitude component of the interface7 centroid coordinate.'
LONGITUDE_DESCRIPTION = 'Longitude component of the interface7 centroid coordinate.'
RADIUS_DESCRIPTION = 'Distance from interface7 centroid coordinate for which to interface7 in.'
RUN_GEOSEARCH_DESCRIPTION = 'Run interface7.'
UNITS_DESCRIPTION = 'Units to calculate distance in.'

# WEB SCRAPING MENU
IMAGES_DESCRIPTION = 'Scrapes all image tags'
JAVASCRIPT_DESCRIPTION = 'Scrapes all javascript on page '
LINKS_DESCRIPTION = 'Extract links.'
PARAGRAPHS_DESCRIPTION = 'Extract paragraphs.'
PHOTOS_DESCRIPTION = 'Extract photographs.'
URL_DESCRIPTION = 'Url.'
TABLES_DESCRIPTION = 'Extract data tables.'
TOKEN_DESCRIPTION = 'Token to interface7 for.'

# SVM PARAMETERS
C_DESCRIPTION = 'C:\n' \
                'float, optional (default=1.0).\n' \
                'Penalty parameter C of the error term.'
CACHE_SIZE_DESCRIPTION = 'Cache Size:\n' \
                         'float, optional.\n' \
                         'Specify the size of the kernel cache (in MB).'
COEFFICIENT_0_DESCRIPTION = 'Coefficient 0:\n' \
                            'float, optional (default=0.0).\n' \
                            'Independent term in kernel function.\n' \
                            'It is only significant in poly and sigmoid.'
POLYNOMIAL_DEGREE_DESCRIPTION = 'Polynomial Degree:\n' \
                                'int, optional (default=2).\n' \
                                'Degree of the polynomial kernel\n' \
                                'function (poly). Ignored by all\nsearch kernels.'
EPSILON_DESCRIPTION = 'Epsilon:\n' \
                      'float, optional (default=0.1).\n' \
                      'Epsilon in the epsilon-SVR model.\n' \
                      'It specifies the epsilon-tube within\n' \
                      'which no penalty is associated in the\n' \
                      'training loss function with points\n' \
                      'predicted within a distance epsilon\n' \
                      'from the actual value.'
GAMMA_DESCRIPTION = 'Gamma:\n' \
                    'float, optional (default=auto).\n' \
                    'Kernel coefficient for rbf, poly\n' \
                    'and sigmoid. If gamma is auto then\n' \
                    '1/n_features will be used instead.'
KERNEL_DESCRIPTION = 'Kernel:\n' \
                     'string, optional (default=rbf).\n' \
                     'Specifies the kernel type to be used\n' \
                     'in the algorithm. It must be one of\n' \
                     'linear, poly, rbf, sigmoid,\n' \
                     'precomputed or a callable. If none\n' \
                     'is given, rbf will be used. If a\n' \
                     'callable is given it is used to\n' \
                     'precompute the kernel matrix.'
MAXIMUM_ITERATIONS_DESCRIPTION = 'Maximum Iterations:\n' \
                                 'int, optional (default=-1).\n' \
                                 'Hard limit on iterations within\n' \
                                 'solver, or -1 for no limit.'
SHRINKING_DESCRIPTION = 'Shrinking:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether to use the shrinking heuristic.'
TOLERANCE_DESCRIPTION = 'Tolerance:\n' \
                        'float, optional (default=1e-2)\n' \
                        'Tolerance for stopping criterion.'
VERBOSE_DESCRIPTION = 'Verbose:\n' \
                      'bool, default=False.\n' \
                      'Enable verbose output. Note that this \n' \
                      'setting takes advantage of a per-process\n' \
                      'runtime setting in libsvm that, if\n' \
                      'enabled, may not work properly in a\n' \
                      'multithreaded context.'

# KNN PARAMETERS
ALGORITHM_DESCRIPTION = 'Algorithm:\n' \
                        '{auto, ball_tree, kd_tree, brute}, optional.\n' \
                        'Algorithm used to compute the nearest neighbors:\n' \
                        'ball_tree will use BallTree.\n' \
                        'kd_tree will use KDTree.\n' \
                        'brute will use a brute-force interface7.\n' \
                        'auto will attempt to decide the most appropriate\n' \
                        'algorithm based on the values passed to fit method.\n' \
                        'Note: fitting on sparse input will override the\n' \
                        'setting of this parameter, using brute force.'
LEAF_SIZE_DESCRIPTION = 'Leaf Size:\n' \
                        'int, optional (default = 30).\n' \
                        'Leaf size passed to BallTree or KDTree.\n' \
                        'This can affect the speed of the\n' \
                        'construction and query, as well as\n' \
                        'the memory required to store the tree.\n' \
                        'The optimal value depends on the nature\n' \
                        'of the problem.'
METRIC_DESCRIPTION = 'Metric:\n' \
                     'string or callable, default minkowski.\n' \
                     'The distance metric to use for the tree.\n' \
                     'The default metric is minkowski, and with p=1\n' \
                     'is equivalent to the standard Euclidean metric.\n' \
                     'See the 1 of the DistanceMetric object_oriented\n' \
                     'for a list of available metrics.'
NUMBER_OF_JOBS_DESCRIPTION = 'Number of Jobs Cores:\n' \
                             'int, optional (default = 1).\n' \
                             'The number of parallel jobs to run for\n' \
                             'neighbors interface7. If -1, then the number\n' \
                             'ofjobs is set to the number of CPU cores.\n' \
                             'Doesnt affect fit method.'
NUMBER_OF_NEIGHBORS_DESCRIPTION = 'Number of Neighbors:\n' \
                                  'int, optional (default = 5).\n' \
                                  'Number of neighbors to use by\n' \
                                  'default for kneighbors queries.'
MINKOWSKI_POWER_DESCRIPTION = 'Minkowski Power:\n' \
                              'integer, optional (default = 1).\n' \
                              'Power parameter for the Minkowski metric.\n' \
                              'When p = 1, this is equivalent to using\n' \
                              'manhattan_distance (l1), and\n' \
                              'euclidean_distance (l2) for p = 1.\n' \
                              'For arbitrary p, minkowski_distance (l_p) is used.'
WEIGHTS_FUNCTION_DESCRIPTION = 'Weights Function:\n' \
                               'str or callable, default=uniform.\n' \
                               'weight function used in\n' \
                               'prediction. Possible values:\n' \
                               'uniform: uniform weights. All\n' \
                               'points in each neighborhood are\n' \
                               'weighted equally.\n' \
                               'distance: weight points by the\n' \
                               'inverse of their distance. In this\n' \
                               'case, closer neighbors of a query\n' \
                               'point will have a greater influence\n' \
                               'than neighbors which are further away.'

# K RIDGE PARAMETERS
ALPHA_DESCRIPTION = 'Alpha:\n' \
                    '{float, array-like}, shape = [n_targets].\n' \
                    'Small positive values of alpha improve the\n' \
                    'conditioning of the problem and reduce the\n' \
                    'variance of the estimates. Alpha corresponds\n' \
                    'to (1*C)^-1 in search linear models such as\n' \
                    'LogisticRegression or LinearSVC. If an array\n' \
                    'is passed, penalties are assumed to be specific\n' \
                    'to the targets. Hence they must correspond in number.'

# DECISION TREE PARAMETERS
CRITERION_DESCRIPTION = 'Criterion:\n' \
                        'string, optional (default=mse).\n' \
                        'The function to measure the quality of a split.\n' \
                        'Supported criteria are mse for the mean\n' \
                        'squared error, which is equal to variance\n' \
                        'reduction as feature selection criterion\n' \
                        'and minimizes the L2 loss using the mean\n' \
                        'of each terminal node, friedman_mse, which\n' \
                        'uses mean squared error with Friedmans\n' \
                        'improvement score for potential splits, and\n' \
                        'mae for the mean absolute error, which\n' \
                        'minimizes the L1 loss using the median of\n' \
                        'each terminal node.'
MAXIMUM_DEPTH_DESCRIPTION = 'Maximum Depth:\n' \
                            'int or None, optional (default=None).\n' \
                            'The maximum depth of the tree. If None, then\n' \
                            'nodes are expanded until all leaves are pure\n' \
                            'or until all leaves contain less than\n' \
                            'min_samples_split samples.'
MAXIMUM_FEATURES_DESCRIPTION = 'Maximum Features:\n' \
                               'int, float, string or None, optional (default=None).\n' \
                               'The number of features to consider when looking for\n' \
                               'the best split:\n' \
                               'If int, then consider max_features features at each split.\n' \
                               'If float, then max_features is a percentage and\n' \
                               'int(max_features * n_features) features are considered\n' \
                               'at each split.\n' \
                               'If auto, then max_features=n_features.\n' \
                               'If sqrt, then max_features=sqrt(n_features).\n' \
                               'If log2, then max_features=log2(n_features).\n' \
                               'If None, then max_features=n_features.\n' \
                               'Note: the interface7 for a split does not stop until at\n' \
                               'least one valid partition of the node samples is\n' \
                               'found, even if it requires to effectively inspect more\n' \
                               'than max_features features.'
MAXIMUM_LEAF_NODES_DESCRIPTION = 'Maximum Leaf Nodes:\n' \
                                 'int or None, optional (default=None).\n' \
                                 'Grow a tree with max_leaf_nodes in\n' \
                                 'best-first fashion.\n' \
                                 'Best nodes are defined as relative\n' \
                                 'reduction in impurity. If None then\n' \
                                 'unlimited number of leaf nodes.'
MINIMUM_IMPURITY_DECREASE_DESCRIPTION = 'Minimum Impurity Decrease:\n' \
                                        'float, optional (default=0.).\n' \
                                        'A node will be split if this split\n' \
                                        'induces a decrease of the impurity\n' \
                                        'greater than or equal to this value.\n' \
                                        'The weighted impurity decrease equation\n' \
                                        'is the following:\n' \
                                        'N_t/N*(i-N_t_R/N_t*r_i-N_t_L/N_t*l_i)' \
                                        'where l is left, r is right, i is the\n' \
                                        'impurity, N is the total number of\n' \
                                        'samples, N_t is the number of samples\n' \
                                        'at the current node, N_t_L is the number\n' \
                                        'of samples in the left child, and N_t_R\n' \
                                        'is the number of samples in the right child.' \
                                        'N, N_t, N_t_R and N_t_L all refer to the\n' \
                                        'weighted sum, if sample_weight is passed.'
MINIMUM_SAMPLES_LEAF_DESCRIPTION = 'Minimum Samples at Leaf:\n' \
                                   'int, float, optional (default=1).\n' \
                                   'The minimum number of samples required\n' \
                                   'to be at a leaf node:\n' \
                                   'If int, then consider min_samples_leaf\n' \
                                   'as the minimum number.\n' \
                                   'If float, then min_samples_leaf is a\n' \
                                   'percentage and ceil(min_samples_leaf * n_samples)\n' \
                                   'are the minimum number of samples for each node.'
MINIMUM_SAMPLES_SPLIT_DESCRIPTION = 'Minimum Samples Split:\n' \
                                    'int, float, optional (default=1).\n' \
                                    'The minimum number of samples\n' \
                                    'required to split an internal node:\n' \
                                    'If int, then consider min_samples_split\n' \
                                    'as the minimum number.\n' \
                                    'If float, then min_samples_split\n' \
                                    'is a percentage and\n' \
                                    'ceil(min_samples_split * n_samples)\n' \
                                    'are the minimum number of samples\n' \
                                    'for each split.'
MINIMUM_WEIGHT_FRACTION_LEAF_DESCRIPTION = 'Minimum Sum Weighted Fraction:\n' \
                                           'float, optional (default=0.)\n' \
                                           'The minimum weighted fraction of the\n' \
                                           'sum total of weights (of all the input samples)\n' \
                                           'required to be at a leaf node. Samples have\n' \
                                           'equal weight when sample_weight is not provided.'
PRESORT_DESCRIPTION = 'Presort Data:\n' \
                      'bool, optional (default=False).\n' \
                      'Whether to presort the data to speed\n' \
                      'up the finding of best splits in fitting.\n' \
                      'For the default settings of a decision tree\n' \
                      'on large datasets, setting this to true may\n' \
                      'slow down the training process. When using\n' \
                      'either a smaller dataset or a restricted\n' \
                      'depth, this may speed up the training.'
RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                           'int, RandomState instance or None, optional (default=None).\n' \
                           'If int, random_state is the seed used by the random number\n' \
                           'generator1; If RandomState instance, random_state is the\n' \
                           'random number generator1; If None, the random number\n' \
                           'generator1 is the RandomState instance used by np.random.'
SPLITTER_DESCRIPTION = 'Splitter:\n' \
                       'string, optional (default=best).\n' \
                       'The strategy used to choose the split\n' \
                       'at each node. Supported strategies are\n' \
                       'best to choose the best split and\n' \
                       'random to choose the best random split.'

# RANDOM FOREST
BOOTSTRAP_DESCRIPTION = 'Bootstrap:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether bootstrap2 samples are\n' \
                        'used when building trees.'
NUMBER_OF_ESTIMATORS_DESCRIPTION = 'Number of Trees:\n' \
                                   'integer, optional (default=10).\n' \
                                   'The number of trees in the forest.'
OUT_OF_BAG_SCORE_DESCRIPTION = 'Out-of-Bag Samples:\n' \
                               'bool, optional (default=False).\n' \
                               'Whether to use out-of-bag\n' \
                               'samples to estimate the R^1 on\n' \
                               'unseen data.'
WARM_START_DESCRIPTION = 'Warm Start:\n' \
                         'bool, optional (default=False).\n' \
                         'When set to True, reuse the\n' \
                         'solution of the previous call\n' \
                         'to fit and add more estimators\n' \
                         'to the ensemble, otherwise,just\n' \
                         'fit a whole new forest.'

# MULTILAYER PERCEPTRON
ACTIVATION_FUNCTION_DESCRIPTION = 'Activation Function:\n' \
                                  '{identity, logistic, tanh, relu}, default=relu.\n' \
                                  'Activation function for the hidden layer.\n' \
                                  'identity: no-op activation, useful to implement linear bottleneck, returns f(x) = x.\n' \
                                  'logistic: the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n' \
                                  'tanh: the hyperbolic tan function, returns f(x) = tanh(x).\n' \
                                  'relu: the rectified linear unit function, returns f(x) = max(0, x).\n'
BATCH_SIZE_DESCRIPTION = 'Batch Size:\n' \
                         'int, optional, default=auto.\n' \
                         'Size of minibatches for stochastic optimizers.\n' \
                         'If the solver is lbfgs, the classifier will not\n' \
                         'use minibatch.\n' \
                         'When set to auto, batch_size=min(200, n_samples).'
FIRST_MOMENT_EXPONENTIAL_DECAY_DESCRIPTION = 'First Moment Exponential Decay:\n' \
                                             'float, optional, default=0.5.\n' \
                                             'Exponential decay rate for estimates of\n' \
                                             'first moment vector in adam, should be in\n' \
                                             '[0, 1). Only used when solver=adam.'
SECOND_MOMENT_EXPONENTIAL_DECAY_DESCRIPTION = 'Second Moment Exponential Decay:\n' \
                                              'float, optional, default=0.999.\n' \
                                              'Exponential decay rate for estimates of\n' \
                                              'second moment vector in adam, should be in\n' \
                                              '[0, 1). Only used when solver=adam.'
EARLY_STOPPING_DESCRIPTION = 'Early Stopping:\n' \
                             'bool, default=False.\n' \
                             'Whether to use early stopping to terminate\n' \
                             'training when validation score is not improving.\n' \
                             'If set to true, it will automatically set aside 10%\n' \
                             'of training data as validation and terminate\n' \
                             'training when validation score is not improving by\n' \
                             'at least tol for two consecutive epochs. Only\n' \
                             'effective when solver=sgd or adam.'
HIDDEN_LAYER_SIZES_DESCRIPTION = 'Hidden Layer Sizes:\n' \
                                 'tuple, length = n_layers - 1, default=(100,).\n' \
                                 'The ith element represents the number of neurons\n' \
                                 'in the ith hidden layer.'
LEARNING_RATE_DESCRIPTION = 'Learning Rate:\n' \
                            '{constant, invscaling, adaptive}, default=constant.\n' \
                            'Learning rate schedule for weight updates.\n' \
                            'constant is a constant learning rate given by learning_rate_init.\n' \
                            'invscaling gradually decreases the learning rate learning_rate_ at\n' \
                            'each time step t using an inverse scaling exponent of power_t.\n' \
                            'effective_learning_rate = learning_rate_init / pow(t, power_t)\n' \
                            'adaptive keeps the learning rate constant to learning_rate_init\n' \
                            'as long as training loss keeps decreasing. Each time two consecutive\n' \
                            'epochs fail to decrease training loss by at least tol, or fail to\n' \
                            'increase validation score by at least tol if early_stopping\n' \
                            'is on, the current learning rate is divided by 5.' \
                            'Only used when solver=sgd.'
LEARNING_RATE_INIT_DESCRIPTION = 'Initial Learning Rate:\n' \
                                 'double, optional, default=0.001.\n' \
                                 'The initial learning rate used. It controls\n' \
                                 'the step-size in updating the weights.\n' \
                                 'Only used when solver=sgd or adam.'
MULTILAYER_PERCEPTRON_ALPHA_DESCRIPTION = 'Penalty Parameter (Alpha):\n' \
                                          'float, optional, default=0.0001.\n' \
                                          'L2 penalty (regularization term) parameter.'
MULTILAYER_PERCEPTRON_EPSILON_DESCRIPTION = 'Numerical Stability (Epsilon):\n' \
                                            'float, optional, default=1e-5.\n' \
                                            'Value for numerical stability in adam.\n' \
                                            'Only used when solver=adam.'
MULTILAYER_PERCEPTRON_MAXIMUM_ITERATIONS_DESCRIPTION = 'Maximum Iterations:\n' \
                                                       'int, optional, default=200.\n' \
                                                       'Maximum number of iterations. The solver iterates\n' \
                                                       'until convergence (determined by tol) or this\n' \
                                                       'number of iterations. For stochastic solvers\n' \
                                                       '(sgd, adam), note that this determines the\n' \
                                                       'number of epochs (how many times each data point\n' \
                                                       'will be used), not the number of gradient steps.'
MULTILAYER_PERCEPTRON_RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                                                 'int, RandomState instance or None, optional, default=None.\n' \
                                                 'If int, random_state is the seed used by the random\n' \
                                                 'number generator1; If RandomState instance, random_state\n' \
                                                 'is the random number generator1; If None, the random number\n' \
                                                 'generator1 is the RandomState instance used by np.random.'
MULTILAYER_PERCEPTRO_TOLERANCE_DESCRIPTION = 'Tolerance:\n' \
                                             'float, optional, default 1e-3.\n' \
                                             'Tolerance for the optimization.\n' \
                                             'When the loss or score is not improving\n' \
                                             'by at least tol for two consecutive\n' \
                                             'iterations, unless learning_rate is\n' \
                                             'set to adaptive, convergence is\n' \
                                             'considered to be reached and training stops.'
MULTILAYER_PERCEPTRO_WARM_START_DESCRIPTION = 'Warm Start:\n' \
                                              'bool, optional, default False.\n' \
                                              'When set to True, reuse the solution\n' \
                                              'of the previous call to fit as\n' \
                                              'initialization, otherwise, just\n' \
                                              'erase the previous solution.'
MOMENTUM_DESCRIPTION = 'Momentum:\n' \
                       'float, default 0.5.\n' \
                       'Momentum for gradient descent update.\n' \
                       'Should be between 0 and 1. Only used\n' \
                       'when solver=sgd.'
NESTEROVS_MOMENTUM_DESCRIPTION = 'Nesterov\'s Momentum:\n' \
                                 'boolean, default=True.\n' \
                                 'Whether to use Nesterovs momentum.\n' \
                                 'Only used when solver=sgd\n' \
                                 'and momentum > 0.'
POWER_T_DESCRIPTION = 'Power for Inverse Learning Rate:\n' \
                      'double, optional, default=0.5\n' \
                      'The exponent for inverse scaling learning rate.\n' \
                      'It is used in updating effective learning rate\n' \
                      'when the learning_rate is set to invscaling.\n' \
                      'Only used when solver=sgd.'
SHUFFLE_DESCRIPTION = 'Shuffle:\n' \
                      'bool, optional, default=True.\n' \
                      'Whether to shuffle samples in each iteration.\n' \
                      'Only used when solver=sgd or adam.'
SOLVER_DESCRIPTION = 'Weight Optimization Solver:\n' \
                     '{lbfgs, sgd, adam}, default=adam.\n' \
                     'The solver for weight optimization.\n' \
                     'lbfgs is an optimizer in the family\n' \
                     'of quasi-Newton methods.\n' \
                     'sgd refers to stochastic gradient descent.\n' \
                     'adam refers to a stochastic gradient-based\n' \
                     'optimizer proposed by Kingma, Diederik, and Jimmy Ba.\n' \
                     'Note: The default solver adam works pretty well\n' \
                     'on relatively large datasets\n' \
                     '(with thousands of training samples or more)\n' \
                     'in terms of both training time and validation score.\n' \
                     'For small datasets, however, lbfgs can converge\n' \
                     'faster and perform better.'
VALIDATION_FRACTION_DESCRIPTION = 'Validation Fraction:\n' \
                                  'float, optional, default=0.1.\n' \
                                  'The proportion of training data to set\n' \
                                  'aside as validation set for early stopping.\n' \
                                  'Must be between 0 and 1. Only used if\n' \
                                  'early_stopping is True.'
# MAIN MENU
CLASSIFICATION_DESCRIPTION = 'Classification: Classify data.'
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
DOCUMENTATION_DESCRIPTION = '1: Browse detailed descriptions and tutorials of each module.'
EXIT_DESCRIPTION = 'Exit application.'
GEO_SEARCH_DESCRIPTION = 'Geographic search: Explore your database and produce geographical information system visualizations.'
MCMC_DESCRIPTION = 'Markov Chain Monte Carlo: Develop Monte Carlo simulations based on Transition Matrices and Markov Chains'
OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
REGRESSION_DESCRIPTION = 'Regression6: Perform Regression6 analysis on your data and visualize your results.'
SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SEARCH_DESCRIPTION = 'search Engine: Navigate your database and specify criteria for extracting data.'
WEB_SCRAPING_DESCRIPTION = 'Web Scraping: Gather and analyze information from the web.'

# CLASSIFICATION DESCRIPTION
CLASS_COMBO_DESCRIPTION = 'Data column to use as object_oriented.'
NAIVE_BAYES_DESCRIPTION = 'Naive Bayes:'
QDA_DESCRIPTION = 'Quadratic Discriminant Analysis:'

# REGRESSION MENU
ADAPTIVE_BOOST_DESCRIPTION = 'Adaptive Boost:\n' \
                             'An Adaptive Boost regressor is a \n' \
                             'meta-estimator that begins by fitting a regressor\n' \
                             'on the original dataset and then fits additional\n' \
                             'copies of the regressor on the same dataset but\n' \
                             'where the weights of instances are adjusted\n' \
                             'according to the error of the current prediction.\n' \
                             'As such, subsequent regressors focus more on\n' \
                             'difficult cases.'
AUTOMATIC_TUNING_DESCRIPTION = 'Automatic Tuning:' \
                               'Tune each machine learning parameter\n' \
                               'automatically through a genetic\n' \
                               'grid interface7 cross validation algorithm.'
DECISION_TREE_DESCRIPTION = 'Decision Tree:\n' \
                            'Creates a model that predicts the value of a target\n' \
                            'variable by learning simple decision rules inferred\n' \
                            'from the data features.'
ELASTIC_NET_DESCRIPTION = 'Elastic Net:\n' \
                          'Linear Model trained with L1 and L2 prior as regularizer.'
NEIGHBORS_DESCRIPTION = 'Nearest Neighbors:\n' \
                        'The target is predicted by local interpolation of\n' \
                        'the targets associated of the nearest neighbors in\n' \
                        'the training set.'
KERNEL_RIDGE_DESCRIPTION = 'Kernel Ridge:\n' \
                           'Kernel ridge Regression6 (KRR) combines ridge Regression6\n' \
                           '(linear least squares with l2-norm regularization) with\n' \
                           'the kernel trick. It thus learns a linear function in\n' \
                           'the space induced by the respective kernel and the data.\n' \
                           'For non-linear kernels, this corresponds to a non-linear\n' \
                           'function in the original space.\n' \
                           'The form of the model learned by KRR is identical to support\n' \
                           'vector Regression6 (SVR). However, different loss functions\n' \
                           'are used: KRR uses squared error loss while support vector\n' \
                           'Regression6 uses epsilon-insensitive loss, both combined with\n' \
                           'l2 regularization. In contrast to SVR, fitting a KRR model\n' \
                           'can be done in closed-form and is typically faster for\n' \
                           'medium-sized datasets. On the search hand, the learned model\n' \
                           'is non-sparse and thus slower than SVR, which learns a sparse\n' \
                           'model for epsilon > 0, at prediction-time.'
MULTILAYER_PERCEPTRON_DESCRIPTION = 'Multilayer Perceptron Neural Network:\n' \
                                    'This model optimizes the squared-loss using LBFGS\n' \
                                    'or stochastic gradient descent.'
RANDOM_FOREST_DESCRIPTION = 'Random Forest:\n' \
                            'A random forest is a meta estimator that fits a number\n' \
                            'of classifying decision trees on various sub-samples\n' \
                            'of the dataset and use averaging to improve the predictive\n' \
                            'accuracy and control over-fitting. The sub-sample size is\n' \
                            'always the same as the original input sample size but the\n' \
                            'samples are drawn with replacement if bootstrap2=True (default).'
RUN_CLASSIFICATION_DESCRIPTION = 'Run classification0 analysis.'
RUN_MACHINE_LEARNING_DESCRIPTION = 'Run analysis.'
RUN_REGRESSION_DESCRIPTION = 'Run Regression6 analysis.'
SUPORT_VECTOR_MACHINE_DESCRIPTION = 'Support Vector Machine:\n' \
                                    'Epsilon-Support Vector Regression6.\n' \
                                    'The free parameters in the model are C and epsilon.\n' \
                                    'The implementation is based on libsvm.'
RBM_DESCRIPTION = ''
SGD_DESCRIPTION = ''

# DATABASE MENU
DATABASE_APPLY_BUTTON_DESCRIPTION = 'Use these settings throughout the entire software.'
ENCODING_DESCRIPTION = 'Encoding of files in database.'
INDEX_COLUMN_DESCRIPTION = 'Column containing index labels.'
LATITUDE_COLUMN_DESCRIPTION = 'Column containing latitude information.'
LONGITUDE_COLUMN_DESCRIPTION = 'Column containing longitude information.'

# SEARCH MENU
CLEAR_BUTTON_DESCRIPTION = 'Clear all interface7 criteria.'
EXCEL_EXPORT_DESCRIPTION = 'Export results in Excel .xlsx format.'
HTML_EXPORT_DESCRIPTION = 'Export results in HTML2 format.'
PDF_EXPORT_DESCRIPTION = 'Export results in PDF format.'
RUN_SEARCH_DESCRIPTION = 'search database.'
TXT_EXPORT_DESCRIPTION = 'Export results in text format compatible with .txt, .csv, .dat'

# MARKOV CHAIN MONTE CARLO MENU
CENTRAL_COMPOSITE_DESCRIPTION = 'Sample data using central composite method.'
COLUMN_COMBO_DESCRIPTION = 'Database column to use.'
INDEX_COMBO_DESCRIPTION = 'Database column to use as index.'
INITIAL_STATE_DESCRIPTION = 'Initial state for simulation.'
ITERATIONS_DESCRIPTION = 'Number of iterations to run simulation.'
LATIN_HYPERCUBES_DESCRIPTION = 'Sample data using latin hypercubes method.'
PARALLEL_DESCRIPTION = 'Read data across columns as in parallel.'
RUN_MARKOV_CHAIN_DESCRIPTION = 'Develop Transition Matrix and Markov Chains.'
RUN_MONTE_CARLO_DESCRIPTION = 'Run Monte Carlo simulation.'
SERIES_DESCRIPTION = 'Read data throughout columns as in series.'

# GEOGRAPHIC SEARCH MENU
LATITUDE_DESCRIPTION = 'Latitude component of the interface7 centroid coordinate.'
LONGITUDE_DESCRIPTION = 'Longitude component of the interface7 centroid coordinate.'
RADIUS_DESCRIPTION = 'Distance from interface7 centroid coordinate for which to interface7 in.'
RUN_GEOSEARCH_DESCRIPTION = 'Run interface7.'
UNITS_DESCRIPTION = 'Units to calculate distance in.'

# WEB SCRAPING MENU
IMAGES_DESCRIPTION = 'Scrapes all image tags'
JAVASCRIPT_DESCRIPTION = 'Scrapes all javascript on page '
LINKS_DESCRIPTION = 'Extract links.'
PARAGRAPHS_DESCRIPTION = 'Extract paragraphs.'
PHOTOS_DESCRIPTION = 'Extract photographs.'
URL_DESCRIPTION = 'Url.'
TABLES_DESCRIPTION = 'Extract data tables.'
TOKEN_DESCRIPTION = 'Token to interface7 for.'

# SVM PARAMETERS
C_DESCRIPTION = 'C:\n' \
                'float, optional (default=1.0).\n' \
                'Penalty parameter C of the error term.'
CACHE_SIZE_DESCRIPTION = 'Cache Size:\n' \
                         'float, optional.\n' \
                         'Specify the size of the kernel cache (in MB).'
COEFFICIENT_0_DESCRIPTION = 'Coefficient 0:\n' \
                            'float, optional (default=0.0).\n' \
                            'Independent term in kernel function.\n' \
                            'It is only significant in poly and sigmoid.'
POLYNOMIAL_DEGREE_DESCRIPTION = 'Polynomial Degree:\n' \
                                'int, optional (default=2).\n' \
                                'Degree of the polynomial kernel\n' \
                                'function (poly). Ignored by all\nsearch kernels.'
EPSILON_DESCRIPTION = 'Epsilon:\n' \
                      'float, optional (default=0.1).\n' \
                      'Epsilon in the epsilon-SVR model.\n' \
                      'It specifies the epsilon-tube within\n' \
                      'which no penalty is associated in the\n' \
                      'training loss function with points\n' \
                      'predicted within a distance epsilon\n' \
                      'from the actual value.'
GAMMA_DESCRIPTION = 'Gamma:\n' \
                    'float, optional (default=auto).\n' \
                    'Kernel coefficient for rbf, poly\n' \
                    'and sigmoid. If gamma is auto then\n' \
                    '1/n_features will be used instead.'
KERNEL_DESCRIPTION = 'Kernel:\n' \
                     'string, optional (default=rbf).\n' \
                     'Specifies the kernel type to be used\n' \
                     'in the algorithm. It must be one of\n' \
                     'linear, poly, rbf, sigmoid,\n' \
                     'precomputed or a callable. If none\n' \
                     'is given, rbf will be used. If a\n' \
                     'callable is given it is used to\n' \
                     'precompute the kernel matrix.'
MAXIMUM_ITERATIONS_DESCRIPTION = 'Maximum Iterations:\n' \
                                 'int, optional (default=-1).\n' \
                                 'Hard limit on iterations within\n' \
                                 'solver, or -1 for no limit.'
SHRINKING_DESCRIPTION = 'Shrinking:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether to use the shrinking heuristic.'
TOLERANCE_DESCRIPTION = 'Tolerance:\n' \
                        'float, optional (default=1e-2)\n' \
                        'Tolerance for stopping criterion.'
VERBOSE_DESCRIPTION = 'Verbose:\n' \
                      'bool, default=False.\n' \
                      'Enable verbose output. Note that this \n' \
                      'setting takes advantage of a per-process\n' \
                      'runtime setting in libsvm that, if\n' \
                      'enabled, may not work properly in a\n' \
                      'multithreaded context.'

# KNN PARAMETERS
ALGORITHM_DESCRIPTION = 'Algorithm:\n' \
                        '{auto, ball_tree, kd_tree, brute}, optional.\n' \
                        'Algorithm used to compute the nearest neighbors:\n' \
                        'ball_tree will use BallTree.\n' \
                        'kd_tree will use KDTree.\n' \
                        'brute will use a brute-force interface7.\n' \
                        'auto will attempt to decide the most appropriate\n' \
                        'algorithm based on the values passed to fit method.\n' \
                        'Note: fitting on sparse input will override the\n' \
                        'setting of this parameter, using brute force.'
LEAF_SIZE_DESCRIPTION = 'Leaf Size:\n' \
                        'int, optional (default = 30).\n' \
                        'Leaf size passed to BallTree or KDTree.\n' \
                        'This can affect the speed of the\n' \
                        'construction and query, as well as\n' \
                        'the memory required to store the tree.\n' \
                        'The optimal value depends on the nature\n' \
                        'of the problem.'
METRIC_DESCRIPTION = 'Metric:\n' \
                     'string or callable, default minkowski.\n' \
                     'The distance metric to use for the tree.\n' \
                     'The default metric is minkowski, and with p=1\n' \
                     'is equivalent to the standard Euclidean metric.\n' \
                     'See the 1 of the DistanceMetric object_oriented\n' \
                     'for a list of available metrics.'
NUMBER_OF_JOBS_DESCRIPTION = 'Number of Jobs Cores:\n' \
                             'int, optional (default = 1).\n' \
                             'The number of parallel jobs to run for\n' \
                             'neighbors interface7. If -1, then the number\n' \
                             'ofjobs is set to the number of CPU cores.\n' \
                             'Doesnt affect fit method.'
NUMBER_OF_NEIGHBORS_DESCRIPTION = 'Number of Neighbors:\n' \
                                  'int, optional (default = 5).\n' \
                                  'Number of neighbors to use by\n' \
                                  'default for kneighbors queries.'
MINKOWSKI_POWER_DESCRIPTION = 'Minkowski Power:\n' \
                              'integer, optional (default = 1).\n' \
                              'Power parameter for the Minkowski metric.\n' \
                              'When p = 1, this is equivalent to using\n' \
                              'manhattan_distance (l1), and\n' \
                              'euclidean_distance (l2) for p = 1.\n' \
                              'For arbitrary p, minkowski_distance (l_p) is used.'
WEIGHTS_FUNCTION_DESCRIPTION = 'Weights Function:\n' \
                               'str or callable, default=uniform.\n' \
                               'weight function used in\n' \
                               'prediction. Possible values:\n' \
                               'uniform: uniform weights. All\n' \
                               'points in each neighborhood are\n' \
                               'weighted equally.\n' \
                               'distance: weight points by the\n' \
                               'inverse of their distance. In this\n' \
                               'case, closer neighbors of a query\n' \
                               'point will have a greater influence\n' \
                               'than neighbors which are further away.'

# K RIDGE PARAMETERS
ALPHA_DESCRIPTION = 'Alpha:\n' \
                    '{float, array-like}, shape = [n_targets].\n' \
                    'Small positive values of alpha improve the\n' \
                    'conditioning of the problem and reduce the\n' \
                    'variance of the estimates. Alpha corresponds\n' \
                    'to (1*C)^-1 in search linear models such as\n' \
                    'LogisticRegression or LinearSVC. If an array\n' \
                    'is passed, penalties are assumed to be specific\n' \
                    'to the targets. Hence they must correspond in number.'

# DECISION TREE PARAMETERS
CRITERION_DESCRIPTION = 'Criterion:\n' \
                        'string, optional (default=mse).\n' \
                        'The function to measure the quality of a split.\n' \
                        'Supported criteria are mse for the mean\n' \
                        'squared error, which is equal to variance\n' \
                        'reduction as feature selection criterion\n' \
                        'and minimizes the L2 loss using the mean\n' \
                        'of each terminal node, friedman_mse, which\n' \
                        'uses mean squared error with Friedmans\n' \
                        'improvement score for potential splits, and\n' \
                        'mae for the mean absolute error, which\n' \
                        'minimizes the L1 loss using the median of\n' \
                        'each terminal node.'
MAXIMUM_DEPTH_DESCRIPTION = 'Maximum Depth:\n' \
                            'int or None, optional (default=None).\n' \
                            'The maximum depth of the tree. If None, then\n' \
                            'nodes are expanded until all leaves are pure\n' \
                            'or until all leaves contain less than\n' \
                            'min_samples_split samples.'
MAXIMUM_FEATURES_DESCRIPTION = 'Maximum Features:\n' \
                               'int, float, string or None, optional (default=None).\n' \
                               'The number of features to consider when looking for\n' \
                               'the best split:\n' \
                               'If int, then consider max_features features at each split.\n' \
                               'If float, then max_features is a percentage and\n' \
                               'int(max_features * n_features) features are considered\n' \
                               'at each split.\n' \
                               'If auto, then max_features=n_features.\n' \
                               'If sqrt, then max_features=sqrt(n_features).\n' \
                               'If log2, then max_features=log2(n_features).\n' \
                               'If None, then max_features=n_features.\n' \
                               'Note: the interface7 for a split does not stop until at\n' \
                               'least one valid partition of the node samples is\n' \
                               'found, even if it requires to effectively inspect more\n' \
                               'than max_features features.'
MAXIMUM_LEAF_NODES_DESCRIPTION = 'Maximum Leaf Nodes:\n' \
                                 'int or None, optional (default=None).\n' \
                                 'Grow a tree with max_leaf_nodes in\n' \
                                 'best-first fashion.\n' \
                                 'Best nodes are defined as relative\n' \
                                 'reduction in impurity. If None then\n' \
                                 'unlimited number of leaf nodes.'
MINIMUM_IMPURITY_DECREASE_DESCRIPTION = 'Minimum Impurity Decrease:\n' \
                                        'float, optional (default=0.).\n' \
                                        'A node will be split if this split\n' \
                                        'induces a decrease of the impurity\n' \
                                        'greater than or equal to this value.\n' \
                                        'The weighted impurity decrease equation\n' \
                                        'is the following:\n' \
                                        'N_t/N*(i-N_t_R/N_t*r_i-N_t_L/N_t*l_i)' \
                                        'where l is left, r is right, i is the\n' \
                                        'impurity, N is the total number of\n' \
                                        'samples, N_t is the number of samples\n' \
                                        'at the current node, N_t_L is the number\n' \
                                        'of samples in the left child, and N_t_R\n' \
                                        'is the number of samples in the right child.' \
                                        'N, N_t, N_t_R and N_t_L all refer to the\n' \
                                        'weighted sum, if sample_weight is passed.'
MINIMUM_SAMPLES_LEAF_DESCRIPTION = 'Minimum Samples at Leaf:\n' \
                                   'int, float, optional (default=1).\n' \
                                   'The minimum number of samples required\n' \
                                   'to be at a leaf node:\n' \
                                   'If int, then consider min_samples_leaf\n' \
                                   'as the minimum number.\n' \
                                   'If float, then min_samples_leaf is a\n' \
                                   'percentage and ceil(min_samples_leaf * n_samples)\n' \
                                   'are the minimum number of samples for each node.'
MINIMUM_SAMPLES_SPLIT_DESCRIPTION = 'Minimum Samples Split:\n' \
                                    'int, float, optional (default=1).\n' \
                                    'The minimum number of samples\n' \
                                    'required to split an internal node:\n' \
                                    'If int, then consider min_samples_split\n' \
                                    'as the minimum number.\n' \
                                    'If float, then min_samples_split\n' \
                                    'is a percentage and\n' \
                                    'ceil(min_samples_split * n_samples)\n' \
                                    'are the minimum number of samples\n' \
                                    'for each split.'
MINIMUM_WEIGHT_FRACTION_LEAF_DESCRIPTION = 'Minimum Sum Weighted Fraction:\n' \
                                           'float, optional (default=0.)\n' \
                                           'The minimum weighted fraction of the\n' \
                                           'sum total of weights (of all the input samples)\n' \
                                           'required to be at a leaf node. Samples have\n' \
                                           'equal weight when sample_weight is not provided.'
PRESORT_DESCRIPTION = 'Presort Data:\n' \
                      'bool, optional (default=False).\n' \
                      'Whether to presort the data to speed\n' \
                      'up the finding of best splits in fitting.\n' \
                      'For the default settings of a decision tree\n' \
                      'on large datasets, setting this to true may\n' \
                      'slow down the training process. When using\n' \
                      'either a smaller dataset or a restricted\n' \
                      'depth, this may speed up the training.'
RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                           'int, RandomState instance or None, optional (default=None).\n' \
                           'If int, random_state is the seed used by the random number\n' \
                           'generator1; If RandomState instance, random_state is the\n' \
                           'random number generator1; If None, the random number\n' \
                           'generator1 is the RandomState instance used by np.random.'
SPLITTER_DESCRIPTION = 'Splitter:\n' \
                       'string, optional (default=best).\n' \
                       'The strategy used to choose the split\n' \
                       'at each node. Supported strategies are\n' \
                       'best to choose the best split and\n' \
                       'random to choose the best random split.'

# RANDOM FOREST
BOOTSTRAP_DESCRIPTION = 'Bootstrap:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether bootstrap2 samples are\n' \
                        'used when building trees.'
NUMBER_OF_ESTIMATORS_DESCRIPTION = 'Number of Trees:\n' \
                                   'integer, optional (default=10).\n' \
                                   'The number of trees in the forest.'
OUT_OF_BAG_SCORE_DESCRIPTION = 'Out-of-Bag Samples:\n' \
                               'bool, optional (default=False).\n' \
                               'Whether to use out-of-bag\n' \
                               'samples to estimate the R^1 on\n' \
                               'unseen data.'
WARM_START_DESCRIPTION = 'Warm Start:\n' \
                         'bool, optional (default=False).\n' \
                         'When set to True, reuse the\n' \
                         'solution of the previous call\n' \
                         'to fit and add more estimators\n' \
                         'to the ensemble, otherwise,just\n' \
                         'fit a whole new forest.'
# MULTILAYER PERCEPTRON
ACTIVATION_FUNCTION_DESCRIPTION = 'Activation Function:\n' \
                                  '{identity, logistic, tanh, relu}, default=relu.\n' \
                                  'Activation function for the hidden layer.\n' \
                                  'identity: no-op activation, useful to implement linear bottleneck, returns f(x) = x.\n' \
                                  'logistic: the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n' \
                                  'tanh: the hyperbolic tan function, returns f(x) = tanh(x).\n' \
                                  'relu: the rectified linear unit function, returns f(x) = max(0, x).\n'
BATCH_SIZE_DESCRIPTION = 'Batch Size:\n' \
                         'int, optional, default=auto.\n' \
                         'Size of minibatches for stochastic optimizers.\n' \
                         'If the solver is lbfgs, the classifier will not\n' \
                         'use minibatch.\n' \
                         'When set to auto, batch_size=min(200, n_samples).'
FIRST_MOMENT_EXPONENTIAL_DECAY_DESCRIPTION = 'First Moment Exponential Decay:\n' \
                                             'float, optional, default=0.5.\n' \
                                             'Exponential decay rate for estimates of\n' \
                                             'first moment vector in adam, should be in\n' \
                                             '[0, 1). Only used when solver=adam.'
SECOND_MOMENT_EXPONENTIAL_DECAY_DESCRIPTION = 'Second Moment Exponential Decay:\n' \
                                              'float, optional, default=0.999.\n' \
                                              'Exponential decay rate for estimates of\n' \
                                              'second moment vector in adam, should be in\n' \
                                              '[0, 1). Only used when solver=adam.'
EARLY_STOPPING_DESCRIPTION = 'Early Stopping:\n' \
                             'bool, default=False.\n' \
                             'Whether to use early stopping to terminate\n' \
                             'training when validation score is not improving.\n' \
                             'If set to true, it will automatically set aside 10%\n' \
                             'of training data as validation and terminate\n' \
                             'training when validation score is not improving by\n' \
                             'at least tol for two consecutive epochs. Only\n' \
                             'effective when solver=sgd or adam.'
HIDDEN_LAYER_SIZES_DESCRIPTION = 'Hidden Layer Sizes:\n' \
                                 'tuple, length = n_layers - 1, default=(100,).\n' \
                                 'The ith element represents the number of neurons\n' \
                                 'in the ith hidden layer.'
LEARNING_RATE_DESCRIPTION = 'Learning Rate:\n' \
                            '{constant, invscaling, adaptive}, default=constant.\n' \
                            'Learning rate schedule for weight updates.\n' \
                            'constant is a constant learning rate given by learning_rate_init.\n' \
                            'invscaling gradually decreases the learning rate learning_rate_ at\n' \
                            'each time step t using an inverse scaling exponent of power_t.\n' \
                            'effective_learning_rate = learning_rate_init / pow(t, power_t)\n' \
                            'adaptive keeps the learning rate constant to learning_rate_init\n' \
                            'as long as training loss keeps decreasing. Each time two consecutive\n' \
                            'epochs fail to decrease training loss by at least tol, or fail to\n' \
                            'increase validation score by at least tol if early_stopping\n' \
                            'is on, the current learning rate is divided by 5.' \
                            'Only used when solver=sgd.'
LEARNING_RATE_INIT_DESCRIPTION = 'Initial Learning Rate:\n' \
                                 'double, optional, default=0.001.\n' \
                                 'The initial learning rate used. It controls\n' \
                                 'the step-size in updating the weights.\n' \
                                 'Only used when solver=sgd or adam.'
MULTILAYER_PERCEPTRON_ALPHA_DESCRIPTION = 'Penalty Parameter (Alpha):\n' \
                                          'float, optional, default=0.0001.\n' \
                                          'L2 penalty (regularization term) parameter.'
MULTILAYER_PERCEPTRON_EPSILON_DESCRIPTION = 'Numerical Stability (Epsilon):\n' \
                                            'float, optional, default=1e-5.\n' \
                                            'Value for numerical stability in adam.\n' \
                                            'Only used when solver=adam.'
MULTILAYER_PERCEPTRON_MAXIMUM_ITERATIONS_DESCRIPTION = 'Maximum Iterations:\n' \
                                                       'int, optional, default=200.\n' \
                                                       'Maximum number of iterations. The solver iterates\n' \
                                                       'until convergence (determined by tol) or this\n' \
                                                       'number of iterations. For stochastic solvers\n' \
                                                       '(sgd, adam), note that this determines the\n' \
                                                       'number of epochs (how many times each data point\n' \
                                                       'will be used), not the number of gradient steps.'
MULTILAYER_PERCEPTRON_RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                                                 'int, RandomState instance or None, optional, default=None.\n' \
                                                 'If int, random_state is the seed used by the random\n' \
                                                 'number generator1; If RandomState instance, random_state\n' \
                                                 'is the random number generator1; If None, the random number\n' \
                                                 'generator1 is the RandomState instance used by np.random.'
MULTILAYER_PERCEPTRO_TOLERANCE_DESCRIPTION = 'Tolerance:\n' \
                                             'float, optional, default 1e-3.\n' \
                                             'Tolerance for the optimization.\n' \
                                             'When the loss or score is not improving\n' \
                                             'by at least tol for two consecutive\n' \
                                             'iterations, unless learning_rate is\n' \
                                             'set to adaptive, convergence is\n' \
                                             'considered to be reached and training stops.'
MULTILAYER_PERCEPTRO_WARM_START_DESCRIPTION = 'Warm Start:\n' \
                                              'bool, optional, default False.\n' \
                                              'When set to True, reuse the solution\n' \
                                              'of the previous call to fit as\n' \
                                              'initialization, otherwise, just\n' \
                                              'erase the previous solution.'
MOMENTUM_DESCRIPTION = 'Momentum:\n' \
                       'float, default 0.5.\n' \
                       'Momentum for gradient descent update.\n' \
                       'Should be between 0 and 1. Only used\n' \
                       'when solver=sgd.'
NESTEROVS_MOMENTUM_DESCRIPTION = 'Nesterov\'s Momentum:\n' \
                                 'boolean, default=True.\n' \
                                 'Whether to use Nesterovs momentum.\n' \
                                 'Only used when solver=sgd\n' \
                                 'and momentum > 0.'
POWER_T_DESCRIPTION = 'Power for Inverse Learning Rate:\n' \
                      'double, optional, default=0.5\n' \
                      'The exponent for inverse scaling learning rate.\n' \
                      'It is used in updating effective learning rate\n' \
                      'when the learning_rate is set to invscaling.\n' \
                      'Only used when solver=sgd.'
SHUFFLE_DESCRIPTION = 'Shuffle:\n' \
                      'bool, optional, default=True.\n' \
                      'Whether to shuffle samples in each iteration.\n' \
                      'Only used when solver=sgd or adam.'
SOLVER_DESCRIPTION = 'Weight Optimization Solver:\n' \
                     '{lbfgs, sgd, adam}, default=adam.\n' \
                     'The solver for weight optimization.\n' \
                     'lbfgs is an optimizer in the family\n' \
                     'of quasi-Newton methods.\n' \
                     'sgd refers to stochastic gradient descent.\n' \
                     'adam refers to a stochastic gradient-based\n' \
                     'optimizer proposed by Kingma, Diederik, and Jimmy Ba.\n' \
                     'Note: The default solver adam works pretty well\n' \
                     'on relatively large datasets\n' \
                     '(with thousands of training samples or more)\n' \
                     'in terms of both training time and validation score.\n' \
                     'For small datasets, however, lbfgs can converge\n' \
                     'faster and perform better.'
VALIDATION_FRACTION_DESCRIPTION = 'Validation Fraction:\n' \
                                  'float, optional, default=0.1.\n' \
                                  'The proportion of training data to set\n' \
                                  'aside as validation set for early stopping.\n' \
                                  'Must be between 0 and 1. Only used if\n' \
                                  'early_stopping is True.'
# MAIN MENU
CLASSIFICATION_MENU_DESCRIPTION = ''
CLUSTERING_MENU_DESCRIPTION = ''
DATABASE_MENU_DESCRIPTION = ''
DIMENSIONALITY_MENU_DESCRIPTION = ''
DOCUMENTATION_MENU_DESCRIPTION = ''
REGRESSION_MENU_DESCRIPTION = ''
SEARCH_MENU_DESCRIPTION = ''
SIMULATION_MENU_DESCRIPTION = ''
# GENERAL
OPEN_FILE_DESCRIPTION = ''
OPEN_FOLDER_DESCRIPTION = ''
SAVE_FILE_DESCRIPTION = ''
SAVE_FOLDER_DESCRIPTION = ''
INDEPENDENT_VARIABLE_DESCRIPTION = ''
DEPENDENT_VARIABLE_DESCRIPTION = ''
# DATABASE MENU
DATABASE_ENCODING_DESCRIPTION = ''
DATABASE_INDEX_DESCRIPTION = ''
DATABASE_LONGITUDE_DESCRIPTION = ''
DATABASE_LATITUDE_DESCRIPTION = ''
# EXPORTING
EXPORT_EXCEL_DESCRIPTION = ''
EXPORT_CSV_DESCRIPTION = ''
# MACHINE LEARNING
AUTOMATIC_TUNING_DESCRIPTION = ''
# REGRESSION MENU
REGRESSION_RUN_DESCRIPTION = ''
# SEARCH MENU
SEARCH_RUN_DESCRIPTION = ''
# SIMULATION MENU
MARKOV_CHAIN_INITIAL_STATE_DESCRIPTION = ''
LATIN_HYPERCUBE_ITERATIONS_DESCRIPTION = ''
MONTE_CARLO_ITERATIONS_DESCRIPTION = ''
# MAIN MENU
CLASSIFICATION_MENU_DESCRIPTION = ''
DATABASE_MENU_DESCRIPTION = ''
DOCUMENTATION_MENU_DESCRIPTION = ''
REGRESSION_MENU_DESCRIPTION = ''
SEARCH_MENU_DESCRIPTION = ''
SIMULATION_MENU_DESCRIPTION = ''
# GENERAL
OPEN_FILE_DESCRIPTION = ''
OPEN_FOLDER_DESCRIPTION = ''
SAVE_FILE_DESCRIPTION = ''
SAVE_FOLDER_DESCRIPTION = ''
# DATABASE MENU
DATABASE_ENCODING_DESCRIPTION = ''
DATABASE_INDEX_DESCRIPTION = ''
DATABASE_LONGITUDE_DESCRIPTION = ''
DATABASE_LATITUDE_DESCRIPTION = ''
# EXPORTING
EXPORT_EXCEL_DESCRIPTION = ''
EXPORT_CSV_DESCRIPTION = ''
# MACHINE LEARNING
AUTOMATIC_TUNING_DESCRIPTION = ''
# REGRESSION MENU
INDEPENDENT_VARIABLE_DESCRIPTION = ''
DEPENDENT_VARIABLE_DESCRIPTION = ''
REGRESSION_RUN_DESCRIPTION = ''
# SEARCH MENU
SEARCH_RUN_DESCRIPTION = ''
# SIMULATION MENU
INDEPENDENT_VARIABLE_DESCRIPTION = ''
DEPENDENT_VARIABLE_DESCRIPTION = ''
MARKOV_CHAIN_INITIAL_STATE_DESCRIPTION = ''
LATIN_HYPERCUBE_ITERATIONS_DESCRIPTION = ''
MONTE_CARLO_ITERATIONS_DESCRIPTION = ''

from Utilities.Dependencies import *
from Utilities.Variables import *

# SYSTEM
SMALL_FONT = ("Verdana", 8)
MEDIUM_FONT = ("Verdana", 10)
LARGE_FONT = ("Verdana", 12)
user32 = ctypes.windll.user32
WIDTH = user32.GetSystemMetrics(0)
HEIGHT = user32.GetSystemMetrics(1)
HAND = 'hand2'
PTR = 'left_ptr'

# PATHS
ROOT = os.getcwd()
DATABASE = ROOT + '\Database\Years\\'
VALUES = ROOT + r'\Interface\InterfaceUtilities\Labels\parameterValues.txt'
STATES = ROOT + r'\Database\Information\allStates.txt'
STATE_CODES = ROOT + r'\Database\Information\allStateCodes.txt'
ITEM_NAMES = ROOT + r'\Interface\InterfaceUtilities\Labels\ItemNames.txt'
temp_RSP = ROOT + '\\Utilities14\Preferences\Temporary_Report_Preferences.txt'
RSP = ROOT + '\\Utilities14\Preferences\Report_Preferences.txt'
TEMP_SAVE = ROOT + "\Database\\temp.txt"
BASE_MAP = ROOT + r'\Graphs\Maps\baseMap.html'
BASE_GRAPH = ROOT + r'\Graphs\Tooltip.html'


def collect_headers(dir):
    """
    Create a file containing all unique
    column names in the entire database
    """
    headers = [FOLDER]
    for folder in os.listdir(dir):
        path = os.path.join(dir, folder)
        for filepath in os.listdir(path):
            try:
                with open(os.path.join(path, filepath), newline='') as file:
                    header = next(csv.reader(file))
                for column in header:
                    if column not in headers:
                        headers.append(column)
            except:
                pass

    with open(ITEM_NAMES, "w") as file:
        for header in headers:
            file.write(header + '\n')

    return headers


HEADERS = collect_headers(DATABASE)
# ENUMERATE OF FEATURES IN DATABASE
FEATURES = {}
with open(ITEM_NAMES, "r") as f:
    for i, line in enumerate(f):
        FEATURES[i] = line.strip()

# List of items that can transition through states
tmp = []
with open(VALUES, "r") as parameterValuesFile:
    with open(ITEM_NAMES, "r") as parameterNamesFile:
        for name, value in zip(csv.reader(parameterNamesFile), (csv.reader(parameterValuesFile))):
            if name[0] != FOLDER and name[0] != FILE and "None" not in value:
                tmp.append(name[0])
LEARNABLE = [FEATURES[i] for i in FEATURES if (FEATURES[i]) in tmp]

# EXTENSIONS
CSV_EXT = '.csv'
KML_EXT = '.kml'
PDF_EXT = '.pdf'
QRY_EXT = '.qry'
TXT_EXT = '.txt'
XLSX_EXT = '.xlsx'

# EXTENSION TUPLES
ALL_FILES = 'All files (*.*)'
CSV_FILES = 'csv files (*.csv);;'
KML_FILES = 'kml files (*.kml);;'
PDF_FILES = 'pdf files (*.pdf);;'
QRY_FILES = 'Query files (*.qry);;'
TXT_FILES = 'text files (*.txt);;'
XLSX_FILES = 'xlsx files (*.xlsx);;'

# NUMERICAL
CURRENT_YEAR = datetime.datetime.now().year - 1
EARTH_RADIUS = {'km': 6373, 'm': 6373000, 'mi': 3960, 'ft': 3950 * 5280}
INDICATORS = ('--', '-')
NA_VALUES = ['N']
OPERATORS = {'>=': operator.ge, '<=': operator.le, '>': operator.gt, '<': operator.lt}
UNITS = ('km', 'm', 'mi', 'ft')

# DESCRIPTIONS
ICONS = ROOT + r'\Interface\InterfaceUtilities\Icons'

WINDOW_ICON = ICONS + r'\window.png'

OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
OPEN_FOLDER_ICON = ICONS + r'\openFolder.png'

SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SAVE_FOLDER_ICON = ICONS + r'\saveFolder.png'

OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FILE_ICON = ICONS + r'\openFile.png'

SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FILE_ICON = ICONS + r'\saveFile.png'

EXIT_DESCRIPTION = 'Exit application.'
EXIT_ICON = ICONS + r'\exit.png'

# Data encapsulates interface7, geosearch, machine learning, and sentiment analysis
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
DATABASE_ICON = ICONS + r'\database.png'

SEARCH_DESCRIPTION = 'search Engine: Navigate your database and specify criteria for extracting data.'
SEARCH_ICON = ICONS + r'\search.png'

GEO_SEARCH_DESCRIPTION = 'Geographic search: Explore your database and produce geographical information system visualizations.'
GEO_SEARCH_ICON = ICONS + r'\geoSearch.png'

MACHINE_LEARNING_DESCRIPTION = 'Machine Learning: Perform statistical analysis on your data and visualize your results.'
MACHINE_LEARNING_ICON = ICONS + r'\machineLearning.png'

BACKGROUND_IMAGE = ICONS + r'\background.png'
DOWN_ARROW_ICON = ICONS + r'downArrow.png'

BACKGROUND_COLOR_DARK = r'rgb(25,25,25)'
BACKGROUND_COLOR_LIGHT = r'rgb(49,49,49)'
BORDER_COLOR = r'rgb(70,70,70)'
FONT_COLOR = r'rgb(255,255,255)'
BUTTON_COLOR = r'rgb(55,55,55)'
BORDER_RADIUS = r'3px'
BORDER_WIDTH = r'3px'
BORDER_STYLE = r'double'
LIGHT_GRADIENT = r'qlineargradient(x1: 0.3, y1: 1, x2: -0.2, y2: -0.5, stop: 0.05 rgb(32,33,30), stop: 0.5 rgb(56,58,55), stop: 0.5 rgb(61,63,60), stop: 1.0 rgb(46,50,48));'
DARK_GRADIENT = r'qlineargradient(x1: 0.3, y1: 1, x2: -0.2, y2: -0.5, stop: 0.05 rgb(22,23,20), stop: 0.5 rgb(90,90,90), stop: 0.5 rgb(114,115,113), stop: 1.0 rgb(46,50,48));'
WIDGET_STYLE = """
            QWidget
            {
                color: """ + FONT_COLOR + """;
                background-color: """ + BACKGROUND_COLOR_DARK + """;
                selection-background-color:""" + BACKGROUND_COLOR_LIGHT + """;
                selection-color: """ + FONT_COLOR + """;
                background-clip: border;
                border-image: none;
                outline: 0;
            }
            """
ENTRY_STYLE = """
            QWidget
            {
                background-color: """ + BACKGROUND_COLOR_DARK + """;
                border: 2px """ + BORDER_STYLE + """ """ + BORDER_COLOR + """;
            }
            """
WINDOW_STYLE = """
            QMainWindow {
                background: """ + BACKGROUND_COLOR_DARK + """;
                color: """ + FONT_COLOR + """;
                background-image: url(./interface7/InterfaceUtilities0/icon2/background.png);

            }
            QMainWindow::separator {
                background: """ + BACKGROUND_COLOR_LIGHT + """;
                color: """ + BACKGROUND_COLOR_LIGHT + """;
                width: 10px; /* when vertical */
                height: 10px; /* when horizontal */
            }

            QMainWindow::separator:hover {
                background: """ + BACKGROUND_COLOR_LIGHT + """;
                color: black;
            }

            """
BUTTON_STYLE = """
            QPushButton {
                background: """ + LIGHT_GRADIENT + """;
                color: """ + FONT_COLOR + """;
                border: """ + BORDER_WIDTH + """ """ + BORDER_STYLE + """ """ + BORDER_COLOR + """;
                border-radius: """ + BORDER_RADIUS + """;
                min-width: 80px;
            }

            QPushButton:hover {
                background: """ + DARK_GRADIENT + """;
                border: """ + BORDER_WIDTH + """ """ + BORDER_STYLE + """ """ + BORDER_COLOR + """;
            }

            QPushButton:pressed {
                background: """ + DARK_GRADIENT + """;
            }

            QPushButton:flat {
                background: """ + LIGHT_GRADIENT + """;
                border: """ + BORDER_COLOR + """;; /* no border for a flat push button */
            }

            QPushButton:default {
                background: """ + LIGHT_GRADIENT + """;
                border: """ + BORDER_WIDTH + """ """ + BORDER_STYLE + """ """ + BORDER_COLOR + """;
            }


            """

CHECK_STYLE = """
            QCheckBox {
                spacing: 5px;
            }

            QCheckBox::indicator {
                width: 13px;
                height: 13px;
            }

            QCheckBox::indicator:unchecked {
            }

            QCheckBox::indicator:unchecked:hover {
            }

            QCheckBox::indicator:unchecked:pressed {
            }

            QCheckBox::indicator:checked {
            }

            QCheckBox::indicator:checked:hover {
            }

            QCheckBox::indicator:checked:pressed {
            }

            QCheckBox::indicator:indeterminate:hover {
            }

            QCheckBox::indicator:indeterminate:pressed {
            }
            """

COMBO_STYLE = """
            QComboBox {
                background: """ + LIGHT_GRADIENT + """;
                color: rgb(255,255,255);
                border: 3px """ + BORDER_STYLE + """ """ + BORDER_COLOR + """;
                padding: 1px 1px 1px 3px;
                min-width: 6px;
            }

            QComboBox:!editable::hover {
                background: """ + DARK_GRADIENT + """;
            }

            QComboBox:editable {
                background: """ + DARK_GRADIENT + """;
            }

            /* QComboBox gets the "on" state when the popup is open */
            QComboBox:!editable:on, QComboBox::drop-down:editable:on {
                background: """ + DARK_GRADIENT + """;
            }

            QComboBox:on { /* shift the text when the popup opens */
                padding-top: 3px;
                padding-left: 4px;
            }

            QComboBox::drop-down {
                subcontrol-origin: padding;
                subcontrol-position: top right;
                width: 10px;
                border-left-width: 1px;
                border-left-color: darkgray;
                border-left-style: """ + BORDER_STYLE + """;
                border-top-right-radius: """ + BORDER_RADIUS + """;
                border-bottom-right-radius: """ + BORDER_RADIUS + """;
            }

            QComboBox::down-arrow {

            }

            QComboBox::down-arrow:on { /* shift the arrow when popup is open */
                top: 1px;
                left: 1px;
            }
            """

FRAME_STYLE = """
            QFrame {
                background: """ + BACKGROUND_COLOR_DARK + """;
                background-image: url(./interface7/InterfaceUtilities0/icon2/background.png);
            }
            """
LABEL_STYLE = """
            QLabel {
                background: """ + BACKGROUND_COLOR_DARK + """;
                color: """ + FONT_COLOR + """;
                border: 1px """ + BORDER_STYLE + """ """ + BORDER_COLOR + """;
                border-radius: """ + BORDER_RADIUS + """;
                padding: 2px;
            }
            """

MENUBAR_STYLE = """
            QMenuBar {
                background: """ + BACKGROUND_COLOR_LIGHT + """;
                color: """ + FONT_COLOR + """;
                border: 1px solid rgb(0,0,0);
            }

            QMenuBar::item {
                background: """ + BACKGROUND_COLOR_LIGHT + """;
                color: """ + FONT_COLOR + """;
            }

            QMenuBar::item::selected {
                background: """ + BACKGROUND_COLOR_DARK + """;
            }

            QMenu {
                background: """ + BACKGROUND_COLOR_LIGHT + """;
                color: """ + FONT_COLOR + """;
                border: 1px solid #000;
            }

            QMenu::item::selected {
                background-color: """ + BACKGROUND_COLOR_DARK + """;
            }
            """

SCROLL_STYLE = """
            QScrollBar:vertical {
                 background: """ + BACKGROUND_COLOR_DARK + """;
                 width: 15px;
                 margin: 22px 0 22px 0;
             }
             QScrollBar::handle:vertical {
                 background: """ + DARK_GRADIENT + """;
                 min-height: 20px;
             }
             QScrollBar::handle:vertical:pressed {
                 background: """ + DARK_GRADIENT + """;
                 min-height: 20px;
             }
             QScrollBar::add-line:vertical {
                 background: """ + LIGHT_GRADIENT + """;
                 height: 20px;
                 subcontrol-position: bottom;
                 subcontrol-origin: margin;
             }

             QScrollBar::sub-line:vertical {
                 background: """ + DARK_GRADIENT + """;
                 height: 20px;
                 subcontrol-position: top;
                 subcontrol-origin: margin;
             }
             QScrollBar::up-arrow:vertical, QScrollBar::down-arrow:vertical {
                 border: 2px solid """ + DARK_GRADIENT + """;
                 width: 3px;
                 height: 3px;
                 background: black;
             }
            QScrollBar::up-arrow:vertical:pressed, QScrollBar::down-arrow:vertical:pressed {
                 border: 2px solid """ + LIGHT_GRADIENT + """;
                 width: 3px;
                 height: 3px;
                 background: black;
             }

             QScrollBar::add-page:vertical, QScrollBar::sub-page:vertical {
                 background: none;
             }
             """
SPLITTER_STYLE = """
            QSplitter {
                background: """ + BACKGROUND_COLOR_DARK + """;
            }
            QSplitter::handle {
                background: """ + BACKGROUND_COLOR_LIGHT + """;
                color: """ + FONT_COLOR + """;
            }

            QSplitter::handle:hover {
                background: white;
            }


            QSplitter::handle:horizontal {
                width: 8px;
            }

            QSplitter::handle:vertical {
                height: 8px;
            }

            QSplitter::handle:pressed {
                background-color: """ + DARK_GRADIENT + """;
            }
            """

STATUSBAR_STYLE = """
            QStatusBar {
                background: """ + BACKGROUND_COLOR_LIGHT + """;
                color: """ + FONT_COLOR + """;
                border: 1px solid rgb(100,100,100);
            }

            QStatusBar::item {
                border: """ + BORDER_WIDTH + """ """ + BORDER_STYLE + """ """ + BORDER_COLOR + """;
                border-radius: """ + BORDER_RADIUS + """;

            }"""

TOOLBAR_STYLE = """
            QToolBar, QToolButton, QToolTip {
                background: rgb(56,60,55);
                background: """ + LIGHT_GRADIENT + """;

                color: """ + FONT_COLOR + """;
                spacing: 3px; /* spacing between items in the tool bar */
                border: 1px """ + BORDER_STYLE + """ """ + BORDER_COLOR + """;

            }
            QToolBar {
                background-image: url(./interface7/InterfaceUtilities0/icon2/background.png);
            }


            QToolButton:hover {
                background: """ + DARK_GRADIENT + """;
                border: 0px;
            }

            QToolBar::handle {
                background: """ + BACKGROUND_COLOR_LIGHT + """;
                border: 1px solid rgb(100,100,100);
            }
            """

import ctypes
import datetime
import operator

# SYSTEM
SMALL_FONT = ("Verdana", 8)
MEDIUM_FONT = ("Verdana", 10)
LARGE_FONT = ("Verdana", 12)
user32 = ctypes.windll.user32
WIDTH = user32.GetSystemMetrics(0)
HEIGHT = user32.GetSystemMetrics(1)
HAND = 'hand2'
PTR = 'left_ptr'
# NUMERICAL
CURRENT_YEAR = datetime.datetime.now().year - 1
EARTH_RADIUS = {'km': 6373, 'm': 6373000, 'mi': 3960, 'ft': 3950 * 5280}
INTERVALS = {'from to': '--', 'between': '-'}
NA_VALUES = None  # ['N']
OPERATORS = {'>=': operator.ge, '<=': operator.le, '>': operator.gt, '<': operator.lt, '==': operator.eq}
INVERTED_OPERATORS = {operator.ge: '>=', operator.le: '<=', operator.gt: '>', operator.lt: '<', operator.eq: '=='}
OPERATORS_WORDS = {
    'greaterthanorequalto': '>=', 'lessthanorequalto': '<=', 'greaterthan': '>', 'lessthan': '<',
    'equal':                '=='
}

UNITS = ('km', 'm', 'mi', 'ft')

CLASSIFIERS_NAMES = ('Adaptive Boost',
                     'Decision Tree',
                     'Gaussian Process',
                     'Multilayer Perceptron',
                     'Naive Bayes',
                     'Nearest Neighbors',
                     'Quadratic Discriminant',
                     'Random Forest',
                     'Stochastic Gradient Descent',
                     'Support Vector Machine')
CLUSTERERS_NAMES = ('Affinity Propagation',
                    'Agglomerative Clustering',
                    'Birch Clustering',
                    'DBSCAN',
                    'Gaussian Mixtures',
                    'K-Means',
                    'Mean Shift',
                    'Spectral Clustering',
                    'Ward Hierarchical Clustering',)
DIMENSIONALITY_REDUCERS_NAMES = ('Feature Agglomeration',
                                 'Principal Component Analysis',
                                 'Random Projection')
REGRESSORS_NAMES = ('Adaptive Boost',
                    'Decision Tree',
                    'Elastic Net',
                    'Gaussian Process',
                    'Nearest Neighbors',
                    'Kernel Ridge',
                    'Multilayer Perceptron',
                    'Random Forest',
                    'Stochastic Gradient Descent',
                    'Support Vector Machine')
SAMPLER_NAMES = ('Latin Hypercube',
                 'Monte Carlo')
SCALER_NAMES = ('None',
                'MinMax',
                'MaxAbs',
                # 'Normalizer',
                'QuantileTransformer',
                'Robust',
                'Standard')
# SYSTEM
ST5NBPDWN = ctypes.windll.user32
RMGXU7RE = ST5NBPDWN.GetSystemMetrics(0)
CUYBEM43 = ST5NBPDWN.GetSystemMetrics(1)
BRM37XHNB = (
    'Accelerometer',
    'Cardiogram',
)

from Utilities.Dependencies import *

# SYSTEM
SMALL_FONT = ("Verdana", 8)
MEDIUM_FONT = ("Verdana", 10)
LARGE_FONT = ("Verdana", 12)
user32 = ctypes.windll.user32
WIDTH = user32.GetSystemMetrics(0)
HEIGHT = user32.GetSystemMetrics(1)
HAND = 'hand2'
PTR = 'left_ptr'
# NUMERICAL
CURRENT_YEAR = datetime.datetime.now().year - 1
EARTH_RADIUS = {'km': 6373, 'm': 6373000, 'mi': 3960, 'ft': 3950 * 5280}
INTERVALS = {'from to': '--', 'between': '-'}
NA_VALUES = None  # ['N']
OPERATORS = {'>=': operator.ge, '<=': operator.le, '>': operator.gt, '<': operator.lt, '==': operator.eq}
INVERTED_OPERATORS = {operator.ge: '>=', operator.le: '<=', operator.gt: '>', operator.lt: '<', operator.eq: '=='}
OPERATORS_WORDS = {
    'greaterthanorequalto': '>=', 'lessthanorequalto': '<=', 'greaterthan': '>', 'lessthan': '<',
    'equal':                '=='
}

UNITS = ('km', 'm', 'mi', 'ft')

CLASSIFIERS_NAMES = ('Adaptive Boost',
                     'Decision Tree',
                     'Gaussian Process',
                     'Multilayer Perceptron',
                     'Naive Bayes',
                     'Nearest Neighbors',
                     'Quadratic Discriminant',
                     'Random Forest',
                     'Stochastic Gradient Descent',
                     'Support Vector Machine')
CLUSTERERS_NAMES = ('Affinity Propagation',
                    'Agglomerative Clustering',
                    'Birch Clustering',
                    'DBSCAN',
                    'Gaussian Mixtures',
                    'K-Means',
                    'Mean Shift',
                    'Spectral Clustering',
                    'Ward Hierarchical Clustering',)
DIMENSIONALITY_REDUCERS_NAMES = ('Feature Agglomeration',
                                 'Principal Component Analysis',
                                 'Random Projection')
REGRESSORS_NAMES = ('Adaptive Boost',
                    'Decision Tree',
                    'Elastic Net',
                    'Gaussian Process',
                    'Nearest Neighbors',
                    'Kernel Ridge',
                    'Multilayer Perceptron',
                    'Random Forest',
                    'Stochastic Gradient Descent',
                    'Support Vector Machine')
SAMPLER_NAMES = ('Latin Hypercube',
                 'Monte Carlo')
SCALER_NAMES = ('None',
                'MinMax',
                'MaxAbs',
                # 'Normalizer',
                'QuantileTransformer',
                'Robust',
                'Standard')
import ctypes
import datetime
import operator

# SYSTEM
SMALL_FONT = ("Verdana", 8)
MEDIUM_FONT = ("Verdana", 10)
LARGE_FONT = ("Verdana", 12)
user32 = ctypes.windll.user32
WIDTH = user32.GetSystemMetrics(0)
HEIGHT = user32.GetSystemMetrics(1)
HAND = 'hand2'
PTR = 'left_ptr'
# NUMERICAL
CURRENT_YEAR = datetime.datetime.now().year
INTERVALS = {'from to': '--', 'between': '-'}
NA_VALUES = ['N']
OPERATORS = {'>=': operator.ge, '<=': operator.le, '>': operator.gt, '<': operator.lt, '==': operator.eq}
INVERTED_OPERATORS = {operator.ge: '>=', operator.le: '<=', operator.gt: '>', operator.lt: '<', operator.eq: '=='}
OPERATORS_WORDS = {
    'greaterthanorequalto': '>=', 'lessthanorequalto': '<=', 'greaterthan': '>', 'lessthan': '<',
    'equal':                '=='
}

# DATABASE
ENCODING = None
ID = None
LATITUDE = None
LONGITUDE = None
NA_VALUES = None  # ['N']
SEPARATOR = ','
HEADERS = ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']

import tkinter.ttk as ttk
from tkinter import *


class MainPathSettings:
    def __init__(self, parent, MASTERPATH):
        top = self.top = Toplevel(parent)
        self.top.title("Main5 Path")
        self.top.grab_set()
        self.main_path = MASTERPATH

        Label(top, text="Main5 Path:").grid(row=1, column=1, sticky=W)

        self.e = Entry(top, width=15)
        self.e.grid(row=1, column=2, columnspan=2, sticky=W)

        # SEPARATOR
        separator = ttk.Separator(top, orient=HORIZONTAL)
        separator.grid(row=2, column=1, columnspan=4, sticky=W + E)

        apply_button = Button(top, text="Apply", command=self.apply, cursor='hand2')
        apply_button.grid(row=3, column=2, sticky=E)

        cancel_button = Button(top, text="Cancel", command=self.cancel, cursor='hand2')
        cancel_button.grid(row=3, column=3, sticky=E)

    def update_main_path_preferences(self):
        with open(
            self.MASTERPATH + "\BridgeDataQuery\\Utilities14\Main_Path_Preferences.txt",
            "w"
        ) as report_preferences:
            report_preferences.write(self.main_path)

    def apply(self):
        self.update_main_path_preferences()
        self.top.destroy()

    def cancel(self):
        self.top.destroy()


class MasterPath:
    def __init__(self):
        self.MASTERPATH = str("C:\\Users\\frano\PycharmProjects")

    def getMasterPath(self):
        return self.MASTERPATH


class MasterPath:
    def __init__(self):
        self.MASTERPATH = str("C:\\Users\\clozo_000\PycharmProjects")

    def getMasterPath(self):
        return self.MASTERPATH


from Utilities.Paths import *

# MAIN MENU
MAIN_MENU = os.path.join(ICONS, 'MainMenuIcons')
CLASSIFICATION_ICON = os.path.join(MAIN_MENU, 'classification_labeled.png')
CLUSTERING_ICON = os.path.join(MAIN_MENU, 'MainMenuClustering.png')
DATABASE_ICON = os.path.join(MAIN_MENU, 'database_labeled.png')
DIMENSIONALITY_ICON = os.path.join(MAIN_MENU, 'MainMenuDimensionality.png')
DOCUMENTATION_ICON = os.path.join(MAIN_MENU, 'documentation_labeled.png')
REGRESSION_ICON = os.path.join(MAIN_MENU, 'regression_labeled.png')
SEARCH_ICON = os.path.join(MAIN_MENU, 'search_labeled.png')
SIMULATION_ICON = os.path.join(MAIN_MENU, 'MainMenuSimulation.png')
STATISTICS_ICON = os.path.join(MAIN_MENU, 'statistics_labeled.png')

BACKGROUND_IMAGE = os.path.join(ICONS, 'background.png')
DOWN_ARROW_ICON = os.path.join(ICONS, 'downArrow.png')
EXIT_ICON = os.path.join(ICONS, 'exit.png')
GEO_SEARCH_ICON = os.path.join(ICONS, 'geoSearch.png')
MACHINE_LEARNING_ICON = os.path.join(ICONS, 'machineLearning.png')
OPEN_FILE_ICON = os.path.join(ICONS, 'openFile.png')
OPEN_FOLDER_ICON = os.path.join(ICONS, 'openFolder.png')
SAVE_FILE_ICON = os.path.join(ICONS, 'saveFile.png')
SAVE_FOLDER_ICON = os.path.join(ICONS, 'saveFolder.png')
WEB_SCRAPING_ICON = os.path.join(ICONS, 'webScraping.png')
WINDOW_ICON = os.path.join(ICONS, 'window.png')

# MAIN MENU
CLASSIFICATION_DESCRIPTION = 'Classification: Classify data.'
DATABASE_DESCRIPTION = 'Database: Set your database and its variables.'
DOCUMENTATION_DESCRIPTION = '1: Browse detailed descriptions and tutorials of each module.'
EXIT_DESCRIPTION = 'Exit application.'
GEO_SEARCH_DESCRIPTION = 'Geographic search: Explore your database and produce geographical information system visualizations.'
MCMC_DESCRIPTION = 'Markov Chain Monte Carlo: Develop Monte Carlo simulations based on Transition Matrices and Markov Chains'
OPEN_FILE_DESCRIPTION = 'Open file.'
OPEN_FOLDER_DESCRIPTION = 'Open a folder from which to extract files.'
REGRESSION_DESCRIPTION = 'Regression6: Perform Regression6 analysis on your data and visualize your results.'
SAVE_FILE_DESCRIPTION = 'Save file.'
SAVE_FOLDER_DESCRIPTION = 'Open a folder to save files in.'
SEARCH_DESCRIPTION = 'search Engine: Navigate your database and specify criteria for extracting data.'
WEB_SCRAPING_DESCRIPTION = 'Web Scraping: Gather and analyze information from the web.'
# CLASSIFICATION DESCRIPTION
CLASS_COMBO_DESCRIPTION = 'Data column to use as object_oriented.'
NAIVE_BAYES_DESCRIPTION = 'Naive Bayes:'
QDA_DESCRIPTION = 'Quadratic Discriminant Analysis:'
# REGRESSION MENU
ADAPTIVE_BOOST_DESCRIPTION = 'Adaptive Boost:\n' \
                             'An Adaptive Boost regressor is a \n' \
                             'meta-estimator that begins by fitting a regressor\n' \
                             'on the original dataset and then fits additional\n' \
                             'copies of the regressor on the same dataset but\n' \
                             'where the weights of instances are adjusted\n' \
                             'according to the error of the current prediction.\n' \
                             'As such, subsequent regressors focus more on\n' \
                             'difficult cases.'
AUTOMATIC_TUNING_DESCRIPTION = 'Automatic Tuning:' \
                               'Tune each machine learning parameter\n' \
                               'automatically through a genetic\n' \
                               'grid interface7 cross validation algorithm.'
DECISION_TREE_DESCRIPTION = 'Decision Tree:\n' \
                            'Creates a model that predicts the value of a target\n' \
                            'variable by learning simple decision rules inferred\n' \
                            'from the data features.'
ELASTIC_NET_DESCRIPTION = 'Elastic Net:\n' \
                          'Linear Model trained with L1 and L2 prior as regularizer.'
NEIGHBORS_DESCRIPTION = 'Nearest Neighbors:\n' \
                        'The target is predicted by local interpolation of\n' \
                        'the targets associated of the nearest neighbors in\n' \
                        'the training set.'
KERNEL_RIDGE_DESCRIPTION = 'Kernel Ridge:\n' \
                           'Kernel ridge Regression6 (KRR) combines ridge Regression6\n' \
                           '(linear least squares with l2-norm regularization) with\n' \
                           'the kernel trick. It thus learns a linear function in\n' \
                           'the space induced by the respective kernel and the data.\n' \
                           'For non-linear kernels, this corresponds to a non-linear\n' \
                           'function in the original space.\n' \
                           'The form of the model learned by KRR is identical to support\n' \
                           'vector Regression6 (SVR). However, different loss functions\n' \
                           'are used: KRR uses squared error loss while support vector\n' \
                           'Regression6 uses epsilon-insensitive loss, both combined with\n' \
                           'l2 regularization. In contrast to SVR, fitting a KRR model\n' \
                           'can be done in closed-form and is typically faster for\n' \
                           'medium-sized datasets. On the search hand, the learned model\n' \
                           'is non-sparse and thus slower than SVR, which learns a sparse\n' \
                           'model for epsilon > 0, at prediction-time.'
MULTILAYER_PERCEPTRON_DESCRIPTION = 'Multilayer Perceptron Neural Network:\n' \
                                    'This model optimizes the squared-loss using LBFGS\n' \
                                    'or stochastic gradient descent.'
RANDOM_FOREST_DESCRIPTION = 'Random Forest:\n' \
                            'A random forest is a meta estimator that fits a number\n' \
                            'of classifying decision trees on various sub-samples\n' \
                            'of the dataset and use averaging to improve the predictive\n' \
                            'accuracy and control over-fitting. The sub-sample size is\n' \
                            'always the same as the original input sample size but the\n' \
                            'samples are drawn with replacement if bootstrap2=True (default).'
RUN_CLASSIFICATION_DESCRIPTION = 'Run classification0 analysis.'
RUN_MACHINE_LEARNING_DESCRIPTION = 'Run analysis.'
RUN_REGRESSION_DESCRIPTION = 'Run Regression6 analysis.'
SUPORT_VECTOR_MACHINE_DESCRIPTION = 'Support Vector Machine:\n' \
                                    'Epsilon-Support Vector Regression6.\n' \
                                    'The free parameters in the model are C and epsilon.\n' \
                                    'The implementation is based on libsvm.'
RBM_DESCRIPTION = ''
SGD_DESCRIPTION = ''
# DATABASE MENU
DATABASE_APPLY_BUTTON_DESCRIPTION = 'Use these settings throughout the entire software.'
ENCODING_DESCRIPTION = 'Encoding of files in database.'
INDEX_COLUMN_DESCRIPTION = 'Column containing index labels.'
LATITUDE_COLUMN_DESCRIPTION = 'Column containing latitude information.'
LONGITUDE_COLUMN_DESCRIPTION = 'Column containing longitude information.'
# SEARCH MENU
CLEAR_BUTTON_DESCRIPTION = 'Clear all interface7 criteria.'
EXCEL_EXPORT_DESCRIPTION = 'Export results in Excel .xlsx format.'
HTML_EXPORT_DESCRIPTION = 'Export results in HTML2 format.'
PDF_EXPORT_DESCRIPTION = 'Export results in PDF format.'
RUN_SEARCH_DESCRIPTION = 'search database.'
TXT_EXPORT_DESCRIPTION = 'Export results in text format compatible with .txt, .csv, .dat'
# MARKOV CHAIN MONTE CARLO MENU
CENTRAL_COMPOSITE_DESCRIPTION = 'Sample data using central composite method.'
COLUMN_COMBO_DESCRIPTION = 'Database column to use.'
INDEX_COMBO_DESCRIPTION = 'Database column to use as index.'
INITIAL_STATE_DESCRIPTION = 'Initial state for simulation.'
ITERATIONS_DESCRIPTION = 'Number of iterations to run simulation.'
LATIN_HYPERCUBES_DESCRIPTION = 'Sample data using latin hypercubes method.'
PARALLEL_DESCRIPTION = 'Read data across columns as in parallel.'
RUN_MARKOV_CHAIN_DESCRIPTION = 'Develop Transition Matrix and Markov Chains.'
RUN_MONTE_CARLO_DESCRIPTION = 'Run Monte Carlo simulation.'
SERIES_DESCRIPTION = 'Read data throughout columns as in series.'
# GEOGRAPHIC SEARCH MENU
LATITUDE_DESCRIPTION = 'Latitude component of the interface7 centroid coordinate.'
LONGITUDE_DESCRIPTION = 'Longitude component of the interface7 centroid coordinate.'
RADIUS_DESCRIPTION = 'Distance from interface7 centroid coordinate for which to interface7 in.'
RUN_GEOSEARCH_DESCRIPTION = 'Run interface7.'
UNITS_DESCRIPTION = 'Units to calculate distance in.'
# WEB SCRAPING MENU
IMAGES_DESCRIPTION = 'Scrapes all image tags'
JAVASCRIPT_DESCRIPTION = 'Scrapes all javascript on page '
LINKS_DESCRIPTION = 'Extract links.'
PARAGRAPHS_DESCRIPTION = 'Extract paragraphs.'
PHOTOS_DESCRIPTION = 'Extract photographs.'
URL_DESCRIPTION = 'Url.'
TABLES_DESCRIPTION = 'Extract data tables.'
TOKEN_DESCRIPTION = 'Token to interface7 for.'
# SVM PARAMETERS
C_DESCRIPTION = 'C:\n' \
                'float, optional (default=1.0).\n' \
                'Penalty parameter C of the error term.'
CACHE_SIZE_DESCRIPTION = 'Cache Size:\n' \
                         'float, optional.\n' \
                         'Specify the size of the kernel cache (in MB).'
COEFFICIENT_0_DESCRIPTION = 'Coefficient 0:\n' \
                            'float, optional (default=0.0).\n' \
                            'Independent term in kernel function.\n' \
                            'It is only significant in poly and sigmoid.'
POLYNOMIAL_DEGREE_DESCRIPTION = 'Polynomial Degree:\n' \
                                'int, optional (default=2).\n' \
                                'Degree of the polynomial kernel\n' \
                                'function (poly). Ignored by all\nsearch kernels.'
EPSILON_DESCRIPTION = 'Epsilon:\n' \
                      'float, optional (default=0.1).\n' \
                      'Epsilon in the epsilon-SVR model.\n' \
                      'It specifies the epsilon-tube within\n' \
                      'which no penalty is associated in the\n' \
                      'training loss function with points\n' \
                      'predicted within a distance epsilon\n' \
                      'from the actual value.'
GAMMA_DESCRIPTION = 'Gamma:\n' \
                    'float, optional (default=auto).\n' \
                    'Kernel coefficient for rbf, poly\n' \
                    'and sigmoid. If gamma is auto then\n' \
                    '1/n_features will be used instead.'
KERNEL_DESCRIPTION = 'Kernel:\n' \
                     'string, optional (default=rbf).\n' \
                     'Specifies the kernel type to be used\n' \
                     'in the algorithm. It must be one of\n' \
                     'linear, poly, rbf, sigmoid,\n' \
                     'precomputed or a callable. If none\n' \
                     'is given, rbf will be used. If a\n' \
                     'callable is given it is used to\n' \
                     'precompute the kernel matrix.'
MAXIMUM_ITERATIONS_DESCRIPTION = 'Maximum Iterations:\n' \
                                 'int, optional (default=-1).\n' \
                                 'Hard limit on iterations within\n' \
                                 'solver, or -1 for no limit.'
SHRINKING_DESCRIPTION = 'Shrinking:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether to use the shrinking heuristic.'
TOLERANCE_DESCRIPTION = 'Tolerance:\n' \
                        'float, optional (default=1e-2)\n' \
                        'Tolerance for stopping criterion.'
VERBOSE_DESCRIPTION = 'Verbose:\n' \
                      'bool, default=False.\n' \
                      'Enable verbose output. Note that this \n' \
                      'setting takes advantage of a per-process\n' \
                      'runtime setting in libsvm that, if\n' \
                      'enabled, may not work properly in a\n' \
                      'multithreaded context.'
# KNN PARAMETERS
ALGORITHM_DESCRIPTION = 'Algorithm:\n' \
                        '{auto, ball_tree, kd_tree, brute}, optional.\n' \
                        'Algorithm used to compute the nearest neighbors:\n' \
                        'ball_tree will use BallTree.\n' \
                        'kd_tree will use KDTree.\n' \
                        'brute will use a brute-force interface7.\n' \
                        'auto will attempt to decide the most appropriate\n' \
                        'algorithm based on the values passed to fit method.\n' \
                        'Note: fitting on sparse input will override the\n' \
                        'setting of this parameter, using brute force.'
LEAF_SIZE_DESCRIPTION = 'Leaf Size:\n' \
                        'int, optional (default = 30).\n' \
                        'Leaf size passed to BallTree or KDTree.\n' \
                        'This can affect the speed of the\n' \
                        'construction and query, as well as\n' \
                        'the memory required to store the tree.\n' \
                        'The optimal value depends on the nature\n' \
                        'of the problem.'
METRIC_DESCRIPTION = 'Metric:\n' \
                     'string or callable, default minkowski.\n' \
                     'The distance metric to use for the tree.\n' \
                     'The default metric is minkowski, and with p=1\n' \
                     'is equivalent to the standard Euclidean metric.\n' \
                     'See the 1 of the DistanceMetric object_oriented\n' \
                     'for a list of available metrics.'
NUMBER_OF_JOBS_DESCRIPTION = 'Number of Jobs Cores:\n' \
                             'int, optional (default = 1).\n' \
                             'The number of parallel jobs to run for\n' \
                             'neighbors interface7. If -1, then the number\n' \
                             'ofjobs is set to the number of CPU cores.\n' \
                             'Doesnt affect fit method.'
NUMBER_OF_NEIGHBORS_DESCRIPTION = 'Number of Neighbors:\n' \
                                  'int, optional (default = 5).\n' \
                                  'Number of neighbors to use by\n' \
                                  'default for kneighbors queries.'
MINKOWSKI_POWER_DESCRIPTION = 'Minkowski Power:\n' \
                              'integer, optional (default = 1).\n' \
                              'Power parameter for the Minkowski metric.\n' \
                              'When p = 1, this is equivalent to using\n' \
                              'manhattan_distance (l1), and\n' \
                              'euclidean_distance (l2) for p = 1.\n' \
                              'For arbitrary p, minkowski_distance (l_p) is used.'
WEIGHTS_FUNCTION_DESCRIPTION = 'Weights Function:\n' \
                               'str or callable, default=uniform.\n' \
                               'weight function used in\n' \
                               'prediction. Possible values:\n' \
                               'uniform: uniform weights. All\n' \
                               'points in each neighborhood are\n' \
                               'weighted equally.\n' \
                               'distance: weight points by the\n' \
                               'inverse of their distance. In this\n' \
                               'case, closer neighbors of a query\n' \
                               'point will have a greater influence\n' \
                               'than neighbors which are further away.'
# K RIDGE PARAMETERS
ALPHA_DESCRIPTION = 'Alpha:\n' \
                    '{float, array-like}, shape = [n_targets].\n' \
                    'Small positive values of alpha improve the\n' \
                    'conditioning of the problem and reduce the\n' \
                    'variance of the estimates. Alpha corresponds\n' \
                    'to (1*C)^-1 in search linear models such as\n' \
                    'LogisticRegression or LinearSVC. If an array\n' \
                    'is passed, penalties are assumed to be specific\n' \
                    'to the targets. Hence they must correspond in number.'
# DECISION TREE PARAMETERS
CRITERION_DESCRIPTION = 'Criterion:\n' \
                        'string, optional (default=mse).\n' \
                        'The function to measure the quality of a split.\n' \
                        'Supported criteria are mse for the mean\n' \
                        'squared error, which is equal to variance\n' \
                        'reduction as feature selection criterion\n' \
                        'and minimizes the L2 loss using the mean\n' \
                        'of each terminal node, friedman_mse, which\n' \
                        'uses mean squared error with Friedmans\n' \
                        'improvement score for potential splits, and\n' \
                        'mae for the mean absolute error, which\n' \
                        'minimizes the L1 loss using the median of\n' \
                        'each terminal node.'
MAXIMUM_DEPTH_DESCRIPTION = 'Maximum Depth:\n' \
                            'int or None, optional (default=None).\n' \
                            'The maximum depth of the tree. If None, then\n' \
                            'nodes are expanded until all leaves are pure\n' \
                            'or until all leaves contain less than\n' \
                            'min_samples_split samples.'
MAXIMUM_FEATURES_DESCRIPTION = 'Maximum Features:\n' \
                               'int, float, string or None, optional (default=None).\n' \
                               'The number of features to consider when looking for\n' \
                               'the best split:\n' \
                               'If int, then consider max_features features at each split.\n' \
                               'If float, then max_features is a percentage and\n' \
                               'int(max_features * n_features) features are considered\n' \
                               'at each split.\n' \
                               'If auto, then max_features=n_features.\n' \
                               'If sqrt, then max_features=sqrt(n_features).\n' \
                               'If log2, then max_features=log2(n_features).\n' \
                               'If None, then max_features=n_features.\n' \
                               'Note: the interface7 for a split does not stop until at\n' \
                               'least one valid partition of the node samples is\n' \
                               'found, even if it requires to effectively inspect more\n' \
                               'than max_features features.'
MAXIMUM_LEAF_NODES_DESCRIPTION = 'Maximum Leaf Nodes:\n' \
                                 'int or None, optional (default=None).\n' \
                                 'Grow a tree with max_leaf_nodes in\n' \
                                 'best-first fashion.\n' \
                                 'Best nodes are defined as relative\n' \
                                 'reduction in impurity. If None then\n' \
                                 'unlimited number of leaf nodes.'
MINIMUM_IMPURITY_DECREASE_DESCRIPTION = 'Minimum Impurity Decrease:\n' \
                                        'float, optional (default=0.).\n' \
                                        'A node will be split if this split\n' \
                                        'induces a decrease of the impurity\n' \
                                        'greater than or equal to this value.\n' \
                                        'The weighted impurity decrease equation\n' \
                                        'is the following:\n' \
                                        'N_t/N*(i-N_t_R/N_t*r_i-N_t_L/N_t*l_i)' \
                                        'where l is left, r is right, i is the\n' \
                                        'impurity, N is the total number of\n' \
                                        'samples, N_t is the number of samples\n' \
                                        'at the current node, N_t_L is the number\n' \
                                        'of samples in the left child, and N_t_R\n' \
                                        'is the number of samples in the right child.' \
                                        'N, N_t, N_t_R and N_t_L all refer to the\n' \
                                        'weighted sum, if sample_weight is passed.'
MINIMUM_SAMPLES_LEAF_DESCRIPTION = 'Minimum Samples at Leaf:\n' \
                                   'int, float, optional (default=1).\n' \
                                   'The minimum number of samples required\n' \
                                   'to be at a leaf node:\n' \
                                   'If int, then consider min_samples_leaf\n' \
                                   'as the minimum number.\n' \
                                   'If float, then min_samples_leaf is a\n' \
                                   'percentage and ceil(min_samples_leaf * n_samples)\n' \
                                   'are the minimum number of samples for each node.'
MINIMUM_SAMPLES_SPLIT_DESCRIPTION = 'Minimum Samples Split:\n' \
                                    'int, float, optional (default=1).\n' \
                                    'The minimum number of samples\n' \
                                    'required to split an internal node:\n' \
                                    'If int, then consider min_samples_split\n' \
                                    'as the minimum number.\n' \
                                    'If float, then min_samples_split\n' \
                                    'is a percentage and\n' \
                                    'ceil(min_samples_split * n_samples)\n' \
                                    'are the minimum number of samples\n' \
                                    'for each split.'
MINIMUM_WEIGHT_FRACTION_LEAF_DESCRIPTION = 'Minimum Sum Weighted Fraction:\n' \
                                           'float, optional (default=0.)\n' \
                                           'The minimum weighted fraction of the\n' \
                                           'sum total of weights (of all the input samples)\n' \
                                           'required to be at a leaf node. Samples have\n' \
                                           'equal weight when sample_weight is not provided.'
PRESORT_DESCRIPTION = 'Presort Data:\n' \
                      'bool, optional (default=False).\n' \
                      'Whether to presort the data to speed\n' \
                      'up the finding of best splits in fitting.\n' \
                      'For the default settings of a decision tree\n' \
                      'on large datasets, setting this to true may\n' \
                      'slow down the training process. When using\n' \
                      'either a smaller dataset or a restricted\n' \
                      'depth, this may speed up the training.'
RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                           'int, RandomState instance or None, optional (default=None).\n' \
                           'If int, random_state is the seed used by the random number\n' \
                           'generator1; If RandomState instance, random_state is the\n' \
                           'random number generator1; If None, the random number\n' \
                           'generator1 is the RandomState instance used by np.random.'
SPLITTER_DESCRIPTION = 'Splitter:\n' \
                       'string, optional (default=best).\n' \
                       'The strategy used to choose the split\n' \
                       'at each node. Supported strategies are\n' \
                       'best to choose the best split and\n' \
                       'random to choose the best random split.'
# RANDOM FOREST
BOOTSTRAP_DESCRIPTION = 'Bootstrap:\n' \
                        'boolean, optional (default=True).\n' \
                        'Whether bootstrap2 samples are\n' \
                        'used when building trees.'
NUMBER_OF_ESTIMATORS_DESCRIPTION = 'Number of Trees:\n' \
                                   'integer, optional (default=10).\n' \
                                   'The number of trees in the forest.'
OUT_OF_BAG_SCORE_DESCRIPTION = 'Out-of-Bag Samples:\n' \
                               'bool, optional (default=False).\n' \
                               'Whether to use out-of-bag\n' \
                               'samples to estimate the R^1 on\n' \
                               'unseen data.'
WARM_START_DESCRIPTION = 'Warm Start:\n' \
                         'bool, optional (default=False).\n' \
                         'When set to True, reuse the\n' \
                         'solution of the previous call\n' \
                         'to fit and add more estimators\n' \
                         'to the ensemble, otherwise,just\n' \
                         'fit a whole new forest.'
# MULTILAYER PERCEPTRON
ACTIVATION_FUNCTION_DESCRIPTION = 'Activation Function:\n' \
                                  '{identity, logistic, tanh, relu}, default=relu.\n' \
                                  'Activation function for the hidden layer.\n' \
                                  'identity: no-op activation, useful to implement linear bottleneck, returns f(x) = x.\n' \
                                  'logistic: the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n' \
                                  'tanh: the hyperbolic tan function, returns f(x) = tanh(x).\n' \
                                  'relu: the rectified linear unit function, returns f(x) = max(0, x).\n'
BATCH_SIZE_DESCRIPTION = 'Batch Size:\n' \
                         'int, optional, default=auto.\n' \
                         'Size of minibatches for stochastic optimizers.\n' \
                         'If the solver is lbfgs, the classifier will not\n' \
                         'use minibatch.\n' \
                         'When set to auto, batch_size=min(200, n_samples).'
FIRST_MOMENT_EXPONENTIAL_DECAY_DESCRIPTION = 'First Moment Exponential Decay:\n' \
                                             'float, optional, default=0.5.\n' \
                                             'Exponential decay rate for estimates of\n' \
                                             'first moment vector in adam, should be in\n' \
                                             '[0, 1). Only used when solver=adam.'
SECOND_MOMENT_EXPONENTIAL_DECAY_DESCRIPTION = 'Second Moment Exponential Decay:\n' \
                                              'float, optional, default=0.999.\n' \
                                              'Exponential decay rate for estimates of\n' \
                                              'second moment vector in adam, should be in\n' \
                                              '[0, 1). Only used when solver=adam.'
EARLY_STOPPING_DESCRIPTION = 'Early Stopping:\n' \
                             'bool, default=False.\n' \
                             'Whether to use early stopping to terminate\n' \
                             'training when validation score is not improving.\n' \
                             'If set to true, it will automatically set aside 10%\n' \
                             'of training data as validation and terminate\n' \
                             'training when validation score is not improving by\n' \
                             'at least tol for two consecutive epochs. Only\n' \
                             'effective when solver=sgd or adam.'
HIDDEN_LAYER_SIZES_DESCRIPTION = 'Hidden Layer Sizes:\n' \
                                 'tuple, length = n_layers - 1, default=(100,).\n' \
                                 'The ith element represents the number of neurons\n' \
                                 'in the ith hidden layer.'
LEARNING_RATE_DESCRIPTION = 'Learning Rate:\n' \
                            '{constant, invscaling, adaptive}, default=constant.\n' \
                            'Learning rate schedule for weight updates.\n' \
                            'constant is a constant learning rate given by learning_rate_init.\n' \
                            'invscaling gradually decreases the learning rate learning_rate_ at\n' \
                            'each time step t using an inverse scaling exponent of power_t.\n' \
                            'effective_learning_rate = learning_rate_init / pow(t, power_t)\n' \
                            'adaptive keeps the learning rate constant to learning_rate_init\n' \
                            'as long as training loss keeps decreasing. Each time two consecutive\n' \
                            'epochs fail to decrease training loss by at least tol, or fail to\n' \
                            'increase validation score by at least tol if early_stopping\n' \
                            'is on, the current learning rate is divided by 5.' \
                            'Only used when solver=sgd.'
LEARNING_RATE_INIT_DESCRIPTION = 'Initial Learning Rate:\n' \
                                 'double, optional, default=0.001.\n' \
                                 'The initial learning rate used. It controls\n' \
                                 'the step-size in updating the weights.\n' \
                                 'Only used when solver=sgd or adam.'
MULTILAYER_PERCEPTRON_ALPHA_DESCRIPTION = 'Penalty Parameter (Alpha):\n' \
                                          'float, optional, default=0.0001.\n' \
                                          'L2 penalty (regularization term) parameter.'
MULTILAYER_PERCEPTRON_EPSILON_DESCRIPTION = 'Numerical Stability (Epsilon):\n' \
                                            'float, optional, default=1e-5.\n' \
                                            'Value for numerical stability in adam.\n' \
                                            'Only used when solver=adam.'
MULTILAYER_PERCEPTRON_MAXIMUM_ITERATIONS_DESCRIPTION = 'Maximum Iterations:\n' \
                                                       'int, optional, default=200.\n' \
                                                       'Maximum number of iterations. The solver iterates\n' \
                                                       'until convergence (determined by tol) or this\n' \
                                                       'number of iterations. For stochastic solvers\n' \
                                                       '(sgd, adam), note that this determines the\n' \
                                                       'number of epochs (how many times each data point\n' \
                                                       'will be used), not the number of gradient steps.'
MULTILAYER_PERCEPTRON_RANDOM_STATE_DESCRIPTION = 'Random State:\n' \
                                                 'int, RandomState instance or None, optional, default=None.\n' \
                                                 'If int, random_state is the seed used by the random\n' \
                                                 'number generator1; If RandomState instance, random_state\n' \
                                                 'is the random number generator1; If None, the random number\n' \
                                                 'generator1 is the RandomState instance used by np.random.'
MULTILAYER_PERCEPTRO_TOLERANCE_DESCRIPTION = 'Tolerance:\n' \
                                             'float, optional, default 1e-3.\n' \
                                             'Tolerance for the optimization.\n' \
                                             'When the loss or score is not improving\n' \
                                             'by at least tol for two consecutive\n' \
                                             'iterations, unless learning_rate is\n' \
                                             'set to adaptive, convergence is\n' \
                                             'considered to be reached and training stops.'
MULTILAYER_PERCEPTRO_WARM_START_DESCRIPTION = 'Warm Start:\n' \
                                              'bool, optional, default False.\n' \
                                              'When set to True, reuse the solution\n' \
                                              'of the previous call to fit as\n' \
                                              'initialization, otherwise, just\n' \
                                              'erase the previous solution.'
MOMENTUM_DESCRIPTION = 'Momentum:\n' \
                       'float, default 0.5.\n' \
                       'Momentum for gradient descent update.\n' \
                       'Should be between 0 and 1. Only used\n' \
                       'when solver=sgd.'
NESTEROVS_MOMENTUM_DESCRIPTION = 'Nesterov\'s Momentum:\n' \
                                 'boolean, default=True.\n' \
                                 'Whether to use Nesterovs momentum.\n' \
                                 'Only used when solver=sgd\n' \
                                 'and momentum > 0.'
POWER_T_DESCRIPTION = 'Power for Inverse Learning Rate:\n' \
                      'double, optional, default=0.5\n' \
                      'The exponent for inverse scaling learning rate.\n' \
                      'It is used in updating effective learning rate\n' \
                      'when the learning_rate is set to invscaling.\n' \
                      'Only used when solver=sgd.'
SHUFFLE_DESCRIPTION = 'Shuffle:\n' \
                      'bool, optional, default=True.\n' \
                      'Whether to shuffle samples in each iteration.\n' \
                      'Only used when solver=sgd or adam.'
SOLVER_DESCRIPTION = 'Weight Optimization Solver:\n' \
                     '{lbfgs, sgd, adam}, default=adam.\n' \
                     'The solver for weight optimization.\n' \
                     'lbfgs is an optimizer in the family\n' \
                     'of quasi-Newton methods.\n' \
                     'sgd refers to stochastic gradient descent.\n' \
                     'adam refers to a stochastic gradient-based\n' \
                     'optimizer proposed by Kingma, Diederik, and Jimmy Ba.\n' \
                     'Note: The default solver adam works pretty well\n' \
                     'on relatively large datasets\n' \
                     '(with thousands of training samples or more)\n' \
                     'in terms of both training time and validation score.\n' \
                     'For small datasets, however, lbfgs can converge\n' \
                     'faster and perform better.'
VALIDATION_FRACTION_DESCRIPTION = 'Validation Fraction:\n' \
                                  'float, optional, default=0.1.\n' \
                                  'The proportion of training data to set\n' \
                                  'aside as validation set for early stopping.\n' \
                                  'Must be between 0 and 1. Only used if\n' \
                                  'early_stopping is True.'
# TOOLTIP
# MAIN MENU
CLASSIFICATION_MENU_DESCRIPTION = ''
CLUSTERING_MENU_DESCRIPTION = ''
DATABASE_MENU_DESCRIPTION = ''
DIMENSIONALITY_MENU_DESCRIPTION = ''
DOCUMENTATION_MENU_DESCRIPTION = ''
REGRESSION_MENU_DESCRIPTION = ''
SEARCH_MENU_DESCRIPTION = ''
SIMULATION_MENU_DESCRIPTION = ''
# GENERAL
OPEN_FILE_DESCRIPTION = ''
OPEN_FOLDER_DESCRIPTION = ''
SAVE_FILE_DESCRIPTION = ''
SAVE_FOLDER_DESCRIPTION = ''
# DATABASE MENU
DATABASE_ENCODING_DESCRIPTION = ''
DATABASE_INDEX_DESCRIPTION = ''
DATABASE_LONGITUDE_DESCRIPTION = ''
DATABASE_LATITUDE_DESCRIPTION = ''
# EXPORTING
EXPORT_EXCEL_DESCRIPTION = ''
EXPORT_CSV_DESCRIPTION = ''
# MACHINE LEARNING
AUTOMATIC_TUNING_DESCRIPTION = ''
# REGRESSION MENU
INDEPENDENT_VARIABLE_DESCRIPTION = ''
DEPENDENT_VARIABLE_DESCRIPTION = ''
REGRESSION_RUN_DESCRIPTION = ''
# SEARCH MENU
SEARCH_RUN_DESCRIPTION = ''
# SIMULATION MENU
INDEPENDENT_VARIABLE_DESCRIPTION = ''
DEPENDENT_VARIABLE_DESCRIPTION = ''
MARKOV_CHAIN_INITIAL_STATE_DESCRIPTION = ''
LATIN_HYPERCUBE_ITERATIONS_DESCRIPTION = ''
MONTE_CARLO_ITERATIONS_DESCRIPTION = ''
# ADAPTIVE BOOST
ESTIMATORS_DESCRIPTION = ''
LEARNING_RATE_DESCRIPTION = ''
LOSS_DESCRIPTION = ''
# DECISION TREE
CRITERION_DESCRIPTION = ''
MAX_DEPTH_DESCRIPTION = ''
MAX_FEATURES_DESCRIPTION = ''
MAX_LEAF_NODES_DESCRIPTION = ''
MIN_SAMPLES_LEAF_DESCRIPTION = ''
MIN_SAMPLES_SPLIT_DESCRIPTION = ''
MIN_WEIGHT_FRACTION_LEAF_DESCRIPTION = ''
SPLITTER_DESCRIPTION = ''
# ELASTIC NET
a = ''
# GAUSSIAN PROCESS
b = ''
# KERNEL RIDGE
c = ''
# MULTILAYER PERCEPTRON
d = ''
# NEAREST NEIGHBORS
e = ''
# RANDOM FOREST
f = ''
# STOCHASTIC GRADIENT DESCENT
g = ''
# SUPPORT VECTOR MACHINE
h = ''
'''
